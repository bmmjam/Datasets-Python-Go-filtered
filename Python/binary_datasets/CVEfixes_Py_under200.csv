vulnerable_code,cwe_id,num_lines,is_vul
"##############################################################################
#
# Copyright (c) 2002 Zope Corporation and Contributors. All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE
#
##############################################################################
""""""Zope-specific Python Expression Handler

Handler for Python expressions that uses the RestrictedPython package.

$Id$
""""""
from AccessControl import safe_builtins
from AccessControl.ZopeGuards import guarded_getattr, get_safe_globals
from RestrictedPython import compile_restricted_eval
from zope.tales.tales import CompilerError
from zope.tales.pythonexpr import PythonExpr

class PythonExpr(PythonExpr):
    _globals = get_safe_globals()
    _globals['_getattr_'] = guarded_getattr
    _globals['__debug__' ] = __debug__

    def __init__(self, name, expr, engine):
        self.text = self.expr = text = expr.strip().replace('\n', ' ')

        # Unicode expression are not handled properly by RestrictedPython
        # We convert the expression to UTF-8 (ajung)
        if isinstance(text, unicode):
            text = text.encode('utf-8')
        code, err, warn, use = compile_restricted_eval(text, 
                                                       self.__class__.__name__)
        if err:
            raise engine.getCompilerError()('Python expression error:\n%s' %
                                            '\n'.join(err))            
        self._varnames = use.keys()
        self._code = code

    def __call__(self, econtext):
        __traceback_info__ = self.text
        vars = self._bind_used_names(econtext, {})
        vars.update(self._globals)
        return eval(self._code, vars, {})

class _SecureModuleImporter:
    __allow_access_to_unprotected_subobjects__ = True

    def __getitem__(self, module):
        mod = safe_builtins['__import__'](module)
        path = module.split('.')
        for name in path[1:]:
            mod = getattr(mod, name)
        return mod

from DocumentTemplate.DT_Util import TemplateDict, InstanceDict
from AccessControl.DTML import RestrictedDTML
class Rtd(RestrictedDTML, TemplateDict):
    this = None

def call_with_ns(f, ns, arg=1):
    td = Rtd()
    # prefer 'context' to 'here';  fall back to 'None'
    this = ns.get('context', ns.get('here'))
    td.this = this
    request = ns.get('request', {})
    td._push(request)
    td._push(InstanceDict(td.this, td))
    td._push(ns)
    try:
        if arg==2:
            return f(None, td)
        else:
            return f(td)
    finally:
        td._pop(3)
",CWE-79,82.0,1
""""""" Unit tests for Products.PageTemplates.ZRPythonExpr

$Id
""""""
import unittest

class MiscTests(unittest.TestCase):

    def test_call_with_ns_prefer_context_to_here(self):
        from Products.PageTemplates.ZRPythonExpr import call_with_ns
        context = ['context']
        here = ['here']
        request = {'request': 1}
        names = {'context' : context, 'here': here, 'request' : request}
        result = call_with_ns(lambda td: td.this, names)
        self.failUnless(result is context, result)

    def test_call_with_ns_no_context_or_here(self):
        from Products.PageTemplates.ZRPythonExpr import call_with_ns
        request = {'request': 1}
        names = {'request' : request}
        result = call_with_ns(lambda td: td.this, names)
        self.failUnless(result is None, result)

    def test_call_with_ns_no_request(self):
        from Products.PageTemplates.ZRPythonExpr import call_with_ns
        context = ['context']
        here = ['here']
        names = {'context' : context, 'here': here}

        def _find_request(td):
            ns = td._pop()              # peel off 'ns'
            instance_dict = td._pop()   # peel off InstanceDict
            request = td._pop()
            td._push(request)
            td._push(instance_dict)
            td._push(ns)
            return request

        result = call_with_ns(_find_request, names)
        self.assertEqual(result, {})
 
def test_suite():
    return unittest.makeSuite(MiscTests)

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

",CWE-79,49.0,1
"from ..expression import getEngine
from . import testHTMLTests


class ChameleonAqPageTemplate(testHTMLTests.AqPageTemplate):
    def pt_getEngine(self):
        return getEngine()


class ChameleonTalesExpressionTests(testHTMLTests.HTMLTests):
    def setUp(self):
        super().setUp()
        # override with templates using chameleon TALES expressions
        self.folder.laf = ChameleonAqPageTemplate()
        self.folder.t = ChameleonAqPageTemplate()

    # override ``PREFIX`` to be able to account for
    #   small differences between ``zope.tales`` and ``chameleon.tales``
    #   expressions (e.g. the ``zope.tales`` ``not`` expression
    #   returns ``int``, that of ``chameleon.tales`` ``bool``
    PREFIX = ""CH_""
",CWE-22,22.0,1
"##############################################################################
#
# Copyright (c) 2007 Zope Foundation and Contributors.
# All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################

import os

from setuptools import find_packages
from setuptools import setup


HERE = os.path.abspath(os.path.dirname(__file__))


def _read_file(filename):
    with open(os.path.join(HERE, filename)) as f:
        return f.read()


README = _read_file('README.rst')
CHANGES = _read_file('CHANGES.rst')

version = '5.3.0.dev0'


setup(
    name='Zope',
    version=version,
    url='https://zope.readthedocs.io/en/latest/',
    project_urls={
        'Documentation': 'https://zope.readthedocs.io',
        'Issue Tracker': 'https://github.com/zopefoundation/Zope/issues',
        'Sources': 'https://github.com/zopefoundation/Zope',
    },
    license='ZPL 2.1',
    description='Zope application server / web framework',
    author='Zope Foundation and Contributors',
    author_email='zope-dev@zope.org',
    long_description=""\n\n"".join([README, CHANGES]),
    classifiers=[
        'Development Status :: 6 - Mature',
        ""Environment :: Web Environment"",
        ""Framework :: Zope :: 5"",
        ""Intended Audience :: Developers"",
        ""License :: OSI Approved :: Zope Public License"",
        ""Operating System :: OS Independent"",
        ""Programming Language :: Python :: 3"",
        ""Programming Language :: Python :: 3 :: Only"",
        ""Programming Language :: Python :: 3.6"",
        ""Programming Language :: Python :: 3.7"",
        ""Programming Language :: Python :: 3.8"",
        ""Programming Language :: Python :: 3.9"",
        ""Programming Language :: Python :: Implementation :: CPython"",
        ""Topic :: Internet :: WWW/HTTP :: Dynamic Content"",
        ""Topic :: Internet :: WWW/HTTP :: WSGI :: Application"",
        ""Topic :: Software Development :: Libraries :: Application Frameworks"",
    ],
    packages=find_packages('src'),
    namespace_packages=['Products', 'Shared', 'Shared.DC', 'zmi'],
    package_dir={'': 'src'},
    python_requires='>= 3.6',
    install_requires=[
        'AccessControl >= 4.2',
        'Acquisition',
        'BTrees',
        'Chameleon >= 3.7.0',
        'DateTime',
        'DocumentTemplate >= 4.0',
        'ExtensionClass',
        'MultiMapping',
        'PasteDeploy',
        'Persistence',
        'RestrictedPython',
        'ZConfig >= 2.9.2',
        'ZODB',
        'setuptools >= 36.2',
        'transaction >= 2.4',
        'waitress',
        'zExceptions >= 3.4',
        'z3c.pt',
        'zope.browser',
        'zope.browsermenu',
        'zope.browserpage >= 4.4.0.dev0',
        'zope.browserresource >= 3.11',
        'zope.component',
        'zope.configuration',
        'zope.container',
        'zope.contentprovider',
        'zope.contenttype',
        'zope.datetime',
        'zope.deferredimport',
        'zope.event',
        'zope.exceptions',
        'zope.globalrequest',
        'zope.i18n [zcml]',
        'zope.i18nmessageid',
        'zope.interface >= 3.8',
        'zope.lifecycleevent',
        'zope.location',
        'zope.pagetemplate >= 4.0.2',
        'zope.processlifetime',
        'zope.proxy',
        'zope.ptresource',
        'zope.publisher',
        'zope.schema',
        'zope.security',
        'zope.sequencesort',
        'zope.site',
        'zope.size',
        'zope.tal',
        'zope.tales >= 5.0.2',
        'zope.testbrowser',
        'zope.testing',
        'zope.traversing',
        'zope.viewlet',
    ],
    include_package_data=True,
    zip_safe=False,
    extras_require={
        'docs': [
            'Sphinx',
            'sphinx_rtd_theme',
            'tempstorage',
        ],
        'wsgi': [
            'Paste',
        ],
    },
    entry_points={
        'paste.app_factory': [
            'main=Zope2.Startup.run:make_wsgi_app',
        ],
        'paste.filter_app_factory': [
            'httpexceptions=ZPublisher.httpexceptions:main',
        ],
        'console_scripts': [
            'addzopeuser=Zope2.utilities.adduser:main',
            'runwsgi=Zope2.Startup.serve:main',
            'mkwsgiinstance=Zope2.utilities.mkwsgiinstance:main',
            'zconsole=Zope2.utilities.zconsole:main',
        ],
        'zodbupdate.decode': [
            'decodes = OFS:zodbupdate_decode_dict',
        ],
        'zodbupdate': [
            'renames = OFS:zodbupdate_rename_dict',
        ],
    },
)
",CWE-1321,159.0,1
"#!/usr/bin/env python
#############################################################################
#  
#	Run Pyro servers as daemon processes on Unix/Linux.
#	This won't work on other operating systems such as Windows.
#	Author: Jeff Bauer  (jbauer@rubic.com)
#	This software is released under the MIT software license.
#	Based on an earlier daemonize module by Jeffery Kunce
#	Updated by Luis Camaano to double-fork-detach.
#
#   DEPRECATED. Don't use this in new code.
#
#	This is part of ""Pyro"" - Python Remote Objects
#	which is (c) Irmen de Jong - irmen@razorvine.net
#
#############################################################################

import sys, os, time
from signal import SIGINT

class DaemonizerException:
    def __init__(self, msg):
        self.msg = msg
    def __str__(self):
        return self.msg

class Daemonizer:
    """"""
    Daemonizer is a class wrapper to run a Pyro server program
    in the background as daemon process.  The only requirement 
    is for the derived class to implement a main_loop() method.
    See Test class below for an example.

    The following command line operations are provided to support
    typical /etc/init.d startup/shutdown on Unix systems:

        start | stop | restart

    In addition, a daemonized program can be called with arguments:

        status  - check if process is still running

        debug   - run the program in non-daemon mode for testing

    Note: Since Daemonizer uses fork(), it will not work on non-Unix
    systems.
    """"""
    def __init__(self, pidfile=None):
        if not pidfile:
            self.pidfile = ""/tmp/%s.pid"" % self.__class__.__name__.lower()
        else:
            self.pidfile = pidfile

    def become_daemon(self, root_dir='/'):
        if os.fork() != 0:  # launch child and ...
            os._exit(0)  # kill off parent
        os.setsid()
        os.chdir(root_dir)
        os.umask(0)
        if os.fork() != 0: # fork again so we are not a session leader
            os._exit(0)
        sys.stdin.close()
        sys.__stdin__ = sys.stdin
        sys.stdout.close()
        sys.stdout = sys.__stdout__ = _NullDevice()
        sys.stderr.close()
        sys.stderr = sys.__stderr__ = _NullDevice()
        for fd in range(1024):
            try:
                os.close(fd)
            except OSError:
                pass

    def daemon_start(self, start_as_daemon=1):
        if start_as_daemon:
            self.become_daemon()
        if self.is_process_running():
            msg = ""Unable to start server. Process is already running.""
            raise DaemonizerException(msg)
        f = open(self.pidfile, 'w')
        f.write(""%s"" % os.getpid())
        f.close()
        self.main_loop()

    def daemon_stop(self):
        pid = self.get_pid()
        try:
            os.kill(pid, SIGINT)  # SIGTERM is too harsh...
            time.sleep(1)
            try:
                os.unlink(self.pidfile)
            except OSError:
                pass
        except IOError:
            pass

    def get_pid(self):
        try:
            f = open(self.pidfile)
            pid = int(f.readline().strip())
            f.close()
        except IOError:
            pid = None
        return pid

    def is_process_running(self):
        pid = self.get_pid()
        if pid:
            try:
                os.kill(pid, 0)
                return 1
            except OSError:
                pass
        return 0

    def main_loop(self):
        """"""NOTE: This method must be implemented in the derived class.""""""
        msg = ""main_loop method not implemented in derived class: %s"" % \
              self.__class__.__name__
        raise DaemonizerException(msg)

    def process_command_line(self, argv, verbose=1):
        usage = ""usage:  %s  start | stop | restart | status | debug "" \
                ""(run as non-daemon)"" % os.path.basename(argv[0])
        if len(argv) < 2:
            print usage
            raise SystemExit
        else:
            operation = argv[1]
        pid = self.get_pid()
        if operation == 'status':
            if self.is_process_running():
                print ""Server process %s is running."" % pid
            else:
                print ""Server is not running.""
        elif operation == 'start':
            if self.is_process_running():
                print ""Server process %s is already running."" % pid
                raise SystemExit
            else:
                if verbose:
                    print ""Starting server process.""
                self.daemon_start()
        elif operation == 'stop':
            if self.is_process_running():
                self.daemon_stop()
                if verbose:
                    print ""Server process %s stopped."" % pid
            else:
                print ""Server process %s is not running."" % pid
                raise SystemExit
        elif operation == 'restart':
            self.daemon_stop()
            if verbose:
                print ""Restarting server process.""
            self.daemon_start()
        elif operation == 'debug':
            self.daemon_start(0)
        else:
            print ""Unknown operation:"", operation
            raise SystemExit


class _NullDevice:
    """"""A substitute for stdout/stderr that writes to nowhere.""""""
    def write(self, s):
        pass


class Test(Daemonizer):
    def __init__(self):
        Daemonizer.__init__(self)

    def main_loop(self):
        while 1:
            time.sleep(1)


if __name__ == ""__main__"":
    test = Test()
    test.process_command_line(sys.argv)
",CWE-59,182.0,1
"import getopt
from subprocess import Popen, PIPE
import sys

import Bcfg2.Server.Admin


class Viz(Bcfg2.Server.Admin.MetadataCore):
    __shorthelp__ = ""Produce graphviz diagrams of metadata structures""
    __longhelp__ = (__shorthelp__ + ""\n\nbcfg2-admin viz [--includehosts] ""
                                    ""[--includebundles] [--includekey] ""
                                    ""[--only-client clientname] ""
                                    ""[-o output.<ext>]\n"")
    __usage__ = (""bcfg2-admin viz [options]\n\n""
                 ""     %-32s%s\n""
                 ""     %-32s%s\n""
                 ""     %-32s%s\n""
                 ""     %-32s%s\n""
                 ""     %-32s%s\n"" %
                (""-H, --includehosts"",
                 ""include hosts in the viz output"",
                 ""-b, --includebundles"",
                 ""include bundles in the viz output"",
                 ""-k, --includekey"",
                 ""show a key for different digraph shapes"",
                 ""-c, --only-client <clientname>"",
                 ""show only the groups, bundles for the named client"",
                 ""-o, --outfile <file>"",
                 ""write viz output to an output file""))

    colors = ['steelblue1', 'chartreuse', 'gold', 'magenta',
              'indianred1', 'limegreen', 'orange1', 'lightblue2',
              'green1', 'blue1', 'yellow1', 'darkturquoise', 'gray66']

    plugin_blacklist = ['DBStats', 'Snapshots', 'Cfg', 'Pkgmgr', 'Packages',
                        'Rules', 'Account', 'Decisions', 'Deps', 'Git', 'Svn',
                        'Fossil', 'Bzr', 'Bundler', 'TGenshi', 'SGenshi',
                        'Base']

    def __init__(self, cfile):

        Bcfg2.Server.Admin.MetadataCore.__init__(self, cfile,
                                                 self.__usage__,
                                                 pblacklist=self.plugin_blacklist)

    def __call__(self, args):
        Bcfg2.Server.Admin.MetadataCore.__call__(self, args)
        # First get options to the 'viz' subcommand
        try:
            opts, args = getopt.getopt(args, 'Hbkc:o:',
                                       ['includehosts', 'includebundles',
                                        'includekey', 'only-client=', 'outfile='])
        except getopt.GetoptError:
            msg = sys.exc_info()[1]
            print(msg)
            print(self.__longhelp__)
            raise SystemExit(1)

        hset = False
        bset = False
        kset = False
        only_client = None
        outputfile = False
        for opt, arg in opts:
            if opt in (""-H"", ""--includehosts""):
                hset = True
            elif opt in (""-b"", ""--includebundles""):
                bset = True
            elif opt in (""-k"", ""--includekey""):
                kset = True
            elif opt in (""-c"", ""--only-client""):
                only_client = arg
            elif opt in (""-o"", ""--outfile""):
                outputfile = arg

        data = self.Visualize(self.get_repo_path(), hset, bset,
                              kset, only_client, outputfile)
        print(data)
        raise SystemExit(0)

    def Visualize(self, repopath, hosts=False,
                  bundles=False, key=False, only_client=None, output=False):
        """"""Build visualization of groups file.""""""
        if output:
            format = output.split('.')[-1]
        else:
            format = 'png'

        cmd = ""dot -T%s"" % (format)
        if output:
            cmd += "" -o %s"" % output
        dotpipe = Popen(cmd, shell=True, stdin=PIPE,
                        stdout=PIPE, close_fds=True)
        try:
            dotpipe.stdin.write(""digraph groups {\n"")
        except:
            print(""write to dot process failed. Is graphviz installed?"")
            raise SystemExit(1)
        dotpipe.stdin.write('\trankdir=""LR"";\n')
        dotpipe.stdin.write(self.metadata.viz(hosts, bundles,
                                              key, only_client, self.colors))
        if key:
            dotpipe.stdin.write(""\tsubgraph cluster_key {\n"")
            dotpipe.stdin.write('''\tstyle=""filled"";\n''')
            dotpipe.stdin.write('''\tcolor=""lightblue"";\n''')
            dotpipe.stdin.write('''\tBundle [ shape=""septagon"" ];\n''')
            dotpipe.stdin.write('''\tGroup [shape=""ellipse""];\n''')
            dotpipe.stdin.write('''\tProfile [style=""bold"", shape=""ellipse""];\n''')
            dotpipe.stdin.write('''\tHblock [label=""Host1|Host2|Host3"", shape=""record""];\n''')
            dotpipe.stdin.write('''\tlabel=""Key"";\n''')
            dotpipe.stdin.write(""\t}\n"")
        dotpipe.stdin.write(""}\n"")
        dotpipe.stdin.close()
        return dotpipe.stdout.read()
",CWE-20,115.0,1
"import os
from mercurial import ui, hg
from subprocess import Popen, PIPE
import Bcfg2.Server.Plugin

# for debugging output only
import logging
logger = logging.getLogger('Bcfg2.Plugins.Mercurial')

class Hg(Bcfg2.Server.Plugin.Plugin,
             Bcfg2.Server.Plugin.Version):
    """"""Mercurial is a version plugin for dealing with Bcfg2 repository.""""""
    name = 'Mercurial'
    __version__ = '$Id$'
    __author__ = 'bcfg-dev@mcs.anl.gov'
    experimental = True

    def __init__(self, core, datastore):
        Bcfg2.Server.Plugin.Plugin.__init__(self, core, datastore)
        Bcfg2.Server.Plugin.Version.__init__(self)
        self.core = core
        self.datastore = datastore

        # path to hg directory for Bcfg2 repo
        hg_dir = ""%s/.hg"" % datastore

        # Read changeset from bcfg2 repo
        if os.path.isdir(hg_dir):
            self.get_revision()
        else:
            logger.error(""%s is not present."" % hg_dir)
            raise Bcfg2.Server.Plugin.PluginInitError

        logger.debug(""Initialized hg plugin with hg directory = %s"" % hg_dir)

    def get_revision(self):
        """"""Read hg revision information for the Bcfg2 repository.""""""
        try:
            repo_path = ""%s/"" % self.datastore
            repo = hg.repository(ui.ui(), repo_path)
            tip = repo.changelog.tip()
            revision = repo.changelog.rev(tip)
        except:
            logger.error(""Failed to read hg repository; disabling mercurial support"")
            raise Bcfg2.Server.Plugin.PluginInitError
        return revision

",CWE-20,48.0,1
"import os
from subprocess import Popen, PIPE
import Bcfg2.Server.Plugin

# for debugging output only
import logging
logger = logging.getLogger('Bcfg2.Plugins.Svn')


class Svn(Bcfg2.Server.Plugin.Plugin,
          Bcfg2.Server.Plugin.Version):
    """"""Svn is a version plugin for dealing with Bcfg2 repos.""""""
    name = 'Svn'
    __version__ = '$Id$'
    __author__ = 'bcfg-dev@mcs.anl.gov'

    def __init__(self, core, datastore):
        Bcfg2.Server.Plugin.Plugin.__init__(self, core, datastore)
        self.core = core
        self.datastore = datastore

        # path to svn directory for bcfg2 repo
        svn_dir = ""%s/.svn"" % datastore

        # Read revision from bcfg2 repo
        if os.path.isdir(svn_dir):
            self.get_revision()
        else:
            logger.error(""%s is not a directory"" % svn_dir)
            raise Bcfg2.Server.Plugin.PluginInitError

        logger.debug(""Initialized svn plugin with svn directory = %s"" % svn_dir)

    def get_revision(self):
        """"""Read svn revision information for the Bcfg2 repository.""""""
        try:
            data = Popen((""env LC_ALL=C svn info %s"" %
                         (self.datastore)), shell=True,
                         stdout=PIPE).communicate()[0].split('\n')
            return [line.split(': ')[1] for line in data \
                    if line[:9] == 'Revision:'][-1]
        except IndexError:
            logger.error(""Failed to read svn info; disabling svn support"")
            logger.error('''Ran command ""svn info %s""''' % (self.datastore))
            logger.error(""Got output: %s"" % data)
            raise Bcfg2.Server.Plugin.PluginInitError
",CWE-20,47.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2011 Isaku Yamahata
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from nova import context
import nova.db.api
from nova import exception
from nova import test
from nova.image import s3


ami_manifest_xml = """"""<?xml version=""1.0"" ?>
<manifest>
        <version>2011-06-17</version>
        <bundler>
                <name>test-s3</name>
                <version>0</version>
                <release>0</release>
        </bundler>
        <machine_configuration>
                <architecture>x86_64</architecture>
                <block_device_mapping>
                        <mapping>
                                <virtual>ami</virtual>
                                <device>sda1</device>
                        </mapping>
                        <mapping>
                                <virtual>root</virtual>
                                <device>/dev/sda1</device>
                        </mapping>
                        <mapping>
                                <virtual>ephemeral0</virtual>
                                <device>sda2</device>
                        </mapping>
                        <mapping>
                                <virtual>swap</virtual>
                                <device>sda3</device>
                        </mapping>
                </block_device_mapping>
                <kernel_id>aki-00000001</kernel_id>
                <ramdisk_id>ari-00000001</ramdisk_id>
        </machine_configuration>
</manifest>
""""""


class TestS3ImageService(test.TestCase):
    def setUp(self):
        super(TestS3ImageService, self).setUp()
        self.flags(image_service='nova.image.fake.FakeImageService')
        self.image_service = s3.S3ImageService()
        self.context = context.RequestContext(None, None)

        # set up one fixture to test shows, should have id '1'
        nova.db.api.s3_image_create(self.context,
                                    '155d900f-4e14-4e4c-a73d-069cbf4541e6')

    def _assertEqualList(self, list0, list1, keys):
        self.assertEqual(len(list0), len(list1))
        key = keys[0]
        for x in list0:
            self.assertEqual(len(x), len(keys))
            self.assertTrue(key in x)
            for y in list1:
                self.assertTrue(key in y)
                if x[key] == y[key]:
                    for k in keys:
                        self.assertEqual(x[k], y[k])

    def test_show_cannot_use_uuid(self):
        self.assertRaises(exception.ImageNotFound,
                          self.image_service.show, self.context,
                          '155d900f-4e14-4e4c-a73d-069cbf4541e6')

    def test_show_translates_correctly(self):
        self.image_service.show(self.context, '1')

    def test_detail(self):
        self.image_service.detail(self.context)

    def test_s3_create(self):
        metadata = {'properties': {
            'root_device_name': '/dev/sda1',
            'block_device_mapping': [
                {'device_name': '/dev/sda1',
                 'snapshot_id': 'snap-12345678',
                 'delete_on_termination': True},
                {'device_name': '/dev/sda2',
                 'virutal_name': 'ephemeral0'},
                {'device_name': '/dev/sdb0',
                 'no_device': True}]}}
        _manifest, image, image_uuid = self.image_service._s3_parse_manifest(
            self.context, metadata, ami_manifest_xml)

        ret_image = self.image_service.show(self.context, image['id'])
        self.assertTrue('properties' in ret_image)
        properties = ret_image['properties']

        self.assertTrue('mappings' in properties)
        mappings = properties['mappings']
        expected_mappings = [
            {""device"": ""sda1"", ""virtual"": ""ami""},
            {""device"": ""/dev/sda1"", ""virtual"": ""root""},
            {""device"": ""sda2"", ""virtual"": ""ephemeral0""},
            {""device"": ""sda3"", ""virtual"": ""swap""}]
        self._assertEqualList(mappings, expected_mappings,
            ['device', 'virtual'])

        self.assertTrue('block_device_mapping', properties)
        block_device_mapping = properties['block_device_mapping']
        expected_bdm = [
            {'device_name': '/dev/sda1',
             'snapshot_id': 'snap-12345678',
             'delete_on_termination': True},
            {'device_name': '/dev/sda2',
             'virutal_name': 'ephemeral0'},
            {'device_name': '/dev/sdb0',
             'no_device': True}]
        self.assertEqual(block_device_mapping, expected_bdm)
",CWE-22,133.0,1
"# Copyright 2012 OpenStack LLC.
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import webob
from lxml import etree

from nova.api.openstack import wsgi
from nova.api.openstack.compute.contrib import quota_classes
from nova import test
from nova.tests.api.openstack import fakes


def quota_set(class_name):
    return {'quota_class_set': {'id': class_name, 'metadata_items': 128,
            'volumes': 10, 'gigabytes': 1000, 'ram': 51200,
            'floating_ips': 10, 'instances': 10, 'injected_files': 5,
            'cores': 20, 'injected_file_content_bytes': 10240}}


class QuotaClassSetsTest(test.TestCase):

    def setUp(self):
        super(QuotaClassSetsTest, self).setUp()
        self.controller = quota_classes.QuotaClassSetsController()

    def test_format_quota_set(self):
        raw_quota_set = {
            'instances': 10,
            'cores': 20,
            'ram': 51200,
            'volumes': 10,
            'floating_ips': 10,
            'metadata_items': 128,
            'gigabytes': 1000,
            'injected_files': 5,
            'injected_file_content_bytes': 10240}

        quota_set = self.controller._format_quota_set('test_class',
                                                      raw_quota_set)
        qs = quota_set['quota_class_set']

        self.assertEqual(qs['id'], 'test_class')
        self.assertEqual(qs['instances'], 10)
        self.assertEqual(qs['cores'], 20)
        self.assertEqual(qs['ram'], 51200)
        self.assertEqual(qs['volumes'], 10)
        self.assertEqual(qs['gigabytes'], 1000)
        self.assertEqual(qs['floating_ips'], 10)
        self.assertEqual(qs['metadata_items'], 128)
        self.assertEqual(qs['injected_files'], 5)
        self.assertEqual(qs['injected_file_content_bytes'], 10240)

    def test_quotas_show_as_admin(self):
        req = fakes.HTTPRequest.blank(
            '/v2/fake4/os-quota-class-sets/test_class',
            use_admin_context=True)
        res_dict = self.controller.show(req, 'test_class')

        self.assertEqual(res_dict, quota_set('test_class'))

    def test_quotas_show_as_unauthorized_user(self):
        req = fakes.HTTPRequest.blank(
            '/v2/fake4/os-quota-class-sets/test_class')
        self.assertRaises(webob.exc.HTTPForbidden, self.controller.show,
                          req, 'test_class')

    def test_quotas_update_as_admin(self):
        body = {'quota_class_set': {'instances': 50, 'cores': 50,
                                    'ram': 51200, 'volumes': 10,
                                    'gigabytes': 1000, 'floating_ips': 10,
                                    'metadata_items': 128, 'injected_files': 5,
                                    'injected_file_content_bytes': 10240}}

        req = fakes.HTTPRequest.blank(
            '/v2/fake4/os-quota-class-sets/test_class',
            use_admin_context=True)
        res_dict = self.controller.update(req, 'test_class', body)

        self.assertEqual(res_dict, body)

    def test_quotas_update_as_user(self):
        body = {'quota_class_set': {'instances': 50, 'cores': 50,
                                    'ram': 51200, 'volumes': 10,
                                    'gigabytes': 1000, 'floating_ips': 10,
                                    'metadata_items': 128, 'injected_files': 5,
                                    'injected_file_content_bytes': 10240}}

        req = fakes.HTTPRequest.blank(
            '/v2/fake4/os-quota-class-sets/test_class')
        self.assertRaises(webob.exc.HTTPForbidden, self.controller.update,
                          req, 'test_class', body)


class QuotaTemplateXMLSerializerTest(test.TestCase):
    def setUp(self):
        super(QuotaTemplateXMLSerializerTest, self).setUp()
        self.serializer = quota_classes.QuotaClassTemplate()
        self.deserializer = wsgi.XMLDeserializer()

    def test_serializer(self):
        exemplar = dict(quota_class_set=dict(
                id='test_class',
                metadata_items=10,
                injected_file_content_bytes=20,
                volumes=30,
                gigabytes=40,
                ram=50,
                floating_ips=60,
                instances=70,
                injected_files=80,
                cores=90))
        text = self.serializer.serialize(exemplar)

        print text
        tree = etree.fromstring(text)

        self.assertEqual('quota_class_set', tree.tag)
        self.assertEqual('test_class', tree.get('id'))
        self.assertEqual(len(exemplar['quota_class_set']) - 1, len(tree))
        for child in tree:
            self.assertTrue(child.tag in exemplar['quota_class_set'])
            self.assertEqual(int(child.text),
                             exemplar['quota_class_set'][child.tag])

    def test_deserializer(self):
        exemplar = dict(quota_class_set=dict(
                metadata_items='10',
                injected_file_content_bytes='20',
                volumes='30',
                gigabytes='40',
                ram='50',
                floating_ips='60',
                instances='70',
                injected_files='80',
                cores='90'))
        intext = (""<?xml version='1.0' encoding='UTF-8'?>\n""
                  '<quota_class_set>'
                  '<metadata_items>10</metadata_items>'
                  '<injected_file_content_bytes>20'
                  '</injected_file_content_bytes>'
                  '<volumes>30</volumes>'
                  '<gigabytes>40</gigabytes>'
                  '<ram>50</ram>'
                  '<floating_ips>60</floating_ips>'
                  '<instances>70</instances>'
                  '<injected_files>80</injected_files>'
                  '<cores>90</cores>'
                  '</quota_class_set>')

        result = self.deserializer.deserialize(intext)['body']
        self.assertEqual(result, exemplar)
",CWE-264,164.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2011 Isaku Yamahata
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from nova import flags
from nova import test
from nova.virt import driver

FLAGS = flags.FLAGS


class TestVirtDriver(test.TestCase):
    def test_block_device(self):
        swap = {'device_name': '/dev/sdb',
                'swap_size': 1}
        ephemerals = [{'num': 0,
                       'virtual_name': 'ephemeral0',
                       'device_name': '/dev/sdc1',
                       'size': 1}]
        block_device_mapping = [{'mount_device': '/dev/sde',
                                 'device_path': 'fake_device'}]
        block_device_info = {
                'root_device_name': '/dev/sda',
                'swap': swap,
                'ephemerals': ephemerals,
                'block_device_mapping': block_device_mapping}

        empty_block_device_info = {}

        self.assertEqual(
            driver.block_device_info_get_root(block_device_info), '/dev/sda')
        self.assertEqual(
            driver.block_device_info_get_root(empty_block_device_info), None)
        self.assertEqual(
            driver.block_device_info_get_root(None), None)

        self.assertEqual(
            driver.block_device_info_get_swap(block_device_info), swap)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['device_name'], None)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['swap_size'], 0)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['device_name'],
            None)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['swap_size'],
            0)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['device_name'], None)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['swap_size'], 0)

        self.assertEqual(
            driver.block_device_info_get_ephemerals(block_device_info),
            ephemerals)
        self.assertEqual(
            driver.block_device_info_get_ephemerals(empty_block_device_info),
            [])
        self.assertEqual(
            driver.block_device_info_get_ephemerals(None),
            [])

    def test_swap_is_usable(self):
        self.assertFalse(driver.swap_is_usable(None))
        self.assertFalse(driver.swap_is_usable({'device_name': None}))
        self.assertFalse(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 0}))
        self.assertTrue(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 1}))
",CWE-22,84.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2011 Isaku Yamahata
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from nova import flags
from nova import test
from nova.virt import driver

FLAGS = flags.FLAGS


class TestVirtDriver(test.TestCase):
    def test_block_device(self):
        swap = {'device_name': '/dev/sdb',
                'swap_size': 1}
        ephemerals = [{'num': 0,
                       'virtual_name': 'ephemeral0',
                       'device_name': '/dev/sdc1',
                       'size': 1}]
        block_device_mapping = [{'mount_device': '/dev/sde',
                                 'device_path': 'fake_device'}]
        block_device_info = {
                'root_device_name': '/dev/sda',
                'swap': swap,
                'ephemerals': ephemerals,
                'block_device_mapping': block_device_mapping}

        empty_block_device_info = {}

        self.assertEqual(
            driver.block_device_info_get_root(block_device_info), '/dev/sda')
        self.assertEqual(
            driver.block_device_info_get_root(empty_block_device_info), None)
        self.assertEqual(
            driver.block_device_info_get_root(None), None)

        self.assertEqual(
            driver.block_device_info_get_swap(block_device_info), swap)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['device_name'], None)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['swap_size'], 0)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['device_name'],
            None)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['swap_size'],
            0)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['device_name'], None)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['swap_size'], 0)

        self.assertEqual(
            driver.block_device_info_get_ephemerals(block_device_info),
            ephemerals)
        self.assertEqual(
            driver.block_device_info_get_ephemerals(empty_block_device_info),
            [])
        self.assertEqual(
            driver.block_device_info_get_ephemerals(None),
            [])

    def test_swap_is_usable(self):
        self.assertFalse(driver.swap_is_usable(None))
        self.assertFalse(driver.swap_is_usable({'device_name': None}))
        self.assertFalse(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 0}))
        self.assertTrue(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 1}))
",CWE-264,84.0,1
"# Copyright 2012, Piston Cloud Computing, Inc.
# Copyright 2012, OpenStack LLC.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import netaddr

from nova.compute import api as compute
from nova.scheduler import filters


class AffinityFilter(filters.BaseHostFilter):
    def __init__(self):
        self.compute_api = compute.API()

    def _affinity_host(self, context, instance_id):
        return self.compute_api.get(context, instance_id)['host']


class DifferentHostFilter(AffinityFilter):
    '''Schedule the instance on a different host from a set of instances.'''

    def host_passes(self, host_state, filter_properties):
        context = filter_properties['context']
        scheduler_hints = filter_properties.get('scheduler_hints') or {}
        me = host_state.host

        affinity_uuids = scheduler_hints.get('different_host', [])
        if isinstance(affinity_uuids, basestring):
            affinity_uuids = [affinity_uuids]
        if affinity_uuids:
            return not any([i for i in affinity_uuids
                              if self._affinity_host(context, i) == me])
        # With no different_host key
        return True


class SameHostFilter(AffinityFilter):
    '''Schedule the instance on the same host as another instance in a set of
    of instances.
    '''

    def host_passes(self, host_state, filter_properties):
        context = filter_properties['context']
        scheduler_hints = filter_properties.get('scheduler_hints') or {}
        me = host_state.host

        affinity_uuids = scheduler_hints.get('same_host', [])
        if isinstance(affinity_uuids, basestring):
            affinity_uuids = [affinity_uuids]
        if affinity_uuids:
            return any([i for i
                          in affinity_uuids
                          if self._affinity_host(context, i) == me])
        # With no same_host key
        return True


class SimpleCIDRAffinityFilter(AffinityFilter):
    def host_passes(self, host_state, filter_properties):
        scheduler_hints = filter_properties.get('scheduler_hints') or {}

        affinity_cidr = scheduler_hints.get('cidr', '/24')
        affinity_host_addr = scheduler_hints.get('build_near_host_ip')
        host_ip = host_state.capabilities.get('host_ip')
        if affinity_host_addr:
            affinity_net = netaddr.IPNetwork(str.join('', (affinity_host_addr,
                                                           affinity_cidr)))

            return netaddr.IPAddress(host_ip) in affinity_net

        # We don't have an affinity host address.
        return True
",CWE-20,86.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2011 Isaku Yamahata
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import os

from nova import exception
from nova import flags
from nova import test
from nova import utils
from nova.virt.disk import api as disk_api
from nova.virt import driver

FLAGS = flags.FLAGS


class TestVirtDriver(test.TestCase):
    def test_block_device(self):
        swap = {'device_name': '/dev/sdb',
                'swap_size': 1}
        ephemerals = [{'num': 0,
                       'virtual_name': 'ephemeral0',
                       'device_name': '/dev/sdc1',
                       'size': 1}]
        block_device_mapping = [{'mount_device': '/dev/sde',
                                 'device_path': 'fake_device'}]
        block_device_info = {
                'root_device_name': '/dev/sda',
                'swap': swap,
                'ephemerals': ephemerals,
                'block_device_mapping': block_device_mapping}

        empty_block_device_info = {}

        self.assertEqual(
            driver.block_device_info_get_root(block_device_info), '/dev/sda')
        self.assertEqual(
            driver.block_device_info_get_root(empty_block_device_info), None)
        self.assertEqual(
            driver.block_device_info_get_root(None), None)

        self.assertEqual(
            driver.block_device_info_get_swap(block_device_info), swap)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['device_name'], None)
        self.assertEqual(driver.block_device_info_get_swap(
            empty_block_device_info)['swap_size'], 0)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['device_name'],
            None)
        self.assertEqual(
            driver.block_device_info_get_swap({'swap': None})['swap_size'],
            0)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['device_name'], None)
        self.assertEqual(
            driver.block_device_info_get_swap(None)['swap_size'], 0)

        self.assertEqual(
            driver.block_device_info_get_ephemerals(block_device_info),
            ephemerals)
        self.assertEqual(
            driver.block_device_info_get_ephemerals(empty_block_device_info),
            [])
        self.assertEqual(
            driver.block_device_info_get_ephemerals(None),
            [])

    def test_swap_is_usable(self):
        self.assertFalse(driver.swap_is_usable(None))
        self.assertFalse(driver.swap_is_usable({'device_name': None}))
        self.assertFalse(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 0}))
        self.assertTrue(driver.swap_is_usable({'device_name': '/dev/sdb',
                                                'swap_size': 1}))


class TestVirtDisk(test.TestCase):
    def setUp(self):
        super(TestVirtDisk, self).setUp()
        self.executes = []

        def fake_execute(*cmd, **kwargs):
            self.executes.append(cmd)
            return None, None

        self.stubs.Set(utils, 'execute', fake_execute)

    def test_check_safe_path(self):
        ret = disk_api._join_and_check_path_within_fs('/foo', 'etc',
                                                      'something.conf')
        self.assertEquals(ret, '/foo/etc/something.conf')

    def test_check_unsafe_path(self):
        self.assertRaises(exception.Invalid,
                          disk_api._join_and_check_path_within_fs,
                          '/foo', 'etc/../../../something.conf')

    def test_inject_files_with_bad_path(self):
        self.assertRaises(exception.Invalid,
                          disk_api._inject_file_into_fs,
                          '/tmp', '/etc/../../../../etc/passwd',
                          'hax')

    def test_lxc_destroy_container(self):

        def proc_mounts(self, mount_point):
            mount_points = {
                '/mnt/loop/nopart': '/dev/loop0',
                '/mnt/loop/part': '/dev/mapper/loop0p1',
                '/mnt/nbd/nopart': '/dev/nbd15',
                '/mnt/nbd/part': '/dev/mapper/nbd15p1',
                '/mnt/guestfs': 'guestmount',
            }
            return mount_points[mount_point]

        self.stubs.Set(os.path, 'exists', lambda _: True)
        self.stubs.Set(disk_api._DiskImage, '_device_for_path', proc_mounts)
        expected_commands = []

        disk_api.destroy_container('/mnt/loop/nopart')
        expected_commands += [
                              ('umount', '/dev/loop0'),
                              ('losetup', '--detach', '/dev/loop0'),
                             ]

        disk_api.destroy_container('/mnt/loop/part')
        expected_commands += [
                              ('umount', '/dev/mapper/loop0p1'),
                              ('kpartx', '-d', '/dev/loop0'),
                              ('losetup', '--detach', '/dev/loop0'),
                             ]

        disk_api.destroy_container('/mnt/nbd/nopart')
        expected_commands += [
                              ('umount', '/dev/nbd15'),
                              ('qemu-nbd', '-d', '/dev/nbd15'),
                             ]

        disk_api.destroy_container('/mnt/nbd/part')
        expected_commands += [
                              ('umount', '/dev/mapper/nbd15p1'),
                              ('kpartx', '-d', '/dev/nbd15'),
                              ('qemu-nbd', '-d', '/dev/nbd15'),
                             ]

        disk_api.destroy_container('/mnt/guestfs')
        expected_commands += [
                              ('fusermount', '-u', '/mnt/guestfs'),
                             ]
        # It's not worth trying to match the last timeout command
        self.executes.pop()

        self.assertEqual(self.executes, expected_commands)
",CWE-264,168.0,1
,CWE-119,,1
"#!/usr/bin/env python

from distutils.core import setup
from distutils.extension import Extension
from distutils.command import build_ext

import os

USE_SYSTEM_LIB = False

if not os.path.exists(""fribidi-src""):
    USE_SYSTEM_LIB = True

if os.environ.get(""USE_SYSTEM_LIB"", ""False"").lower() in (""yes"", ""1"", ""true""):
    USE_SYSTEM_LIB = True


class my_build_ext(build_ext.build_ext):
    def build_extension(self, ext):
        configure = os.path.abspath(""fribidi-src/configure"")
        bdir = os.path.join(self.build_temp, ""fribidi"")
        if not os.path.isdir(bdir):
            os.makedirs(bdir)
        cwd = os.getcwd()
        os.chdir(bdir)
        try:
            if not os.path.exists(""./config.status""):
                os.system(""sh %s --with-glib=no"" % configure)
        finally:
            os.chdir(cwd)

        self.include_dirs[:0] = [bdir, ""%s/lib"" % bdir]
        self.compiler.set_include_dirs(self.include_dirs)

        return build_ext.build_ext.build_extension(self, ext)


def _getpkgconfigvalue(value, package=""fribidi""):
    """""" get a value from pkg-config for package (default: fribidi)
    param value: long-option to pkg-config
    """"""
    f = os.popen(""pkg-config --%s %s"" % (value, package))
    x = f.readline().strip()
    f.close()

    l = []
    for y in x.split("" ""):
        l.append(y[2:])
    return l

if USE_SYSTEM_LIB:
    lib_sources = []
    include_dirs = _getpkgconfigvalue(""cflags-only-I"") or [""/usr/include/fribidi""]
    libraries = _getpkgconfigvalue(""libs-only-l"") or [""fribidi""]
    define_macros = []
    my_build_ext = build_ext.build_ext
else:
        lib_sources = """"""
fribidi-src/lib/fribidi.c
fribidi-src/lib/fribidi-arabic.c
fribidi-src/lib/fribidi-bidi.c
fribidi-src/lib/fribidi-bidi-types.c
fribidi-src/lib/fribidi-deprecated.c
fribidi-src/lib/fribidi-joining.c
fribidi-src/lib/fribidi-joining-types.c
fribidi-src/lib/fribidi-mem.c
fribidi-src/lib/fribidi-mirroring.c
fribidi-src/lib/fribidi-run.c
fribidi-src/lib/fribidi-shape.c
fribidi-src/charset/fribidi-char-sets-cp1256.c
fribidi-src/charset/fribidi-char-sets-iso8859-8.c
fribidi-src/charset/fribidi-char-sets-cap-rtl.c
fribidi-src/charset/fribidi-char-sets-utf8.c
fribidi-src/charset/fribidi-char-sets.c
fribidi-src/charset/fribidi-char-sets-cp1255.c
fribidi-src/charset/fribidi-char-sets-iso8859-6.c
"""""".split()
        libraries = []
        include_dirs = [""fribidi-src"", ""fribidi-src/lib"", ""fribidi-src/charset""]
        define_macros = [(""HAVE_CONFIG_H"", 1)]


def read_long_description():
    fn = os.path.join(os.path.dirname(os.path.abspath(__file__)), ""README.rst"")
    return open(fn).read()


setup(name=""pyfribidi"",
      version=""0.10.1"",
      description=""Python libfribidi interface"",
      author=""Yaacov Zamir, Nir Soffer"",
      author_email=""kzamir@walla.co.il"",
      url=""http://hspell-gui.sourceforge.net/pyfribidi.html"",
      license=""GPL"",
      cmdclass={'build_ext': my_build_ext},
      long_description=read_long_description(),
      py_modules=[""pyfribidi2""],
      ext_modules=[Extension(
            name='pyfribidi',
            sources=['pyfribidi.c'] + lib_sources,
            define_macros=define_macros,
            libraries=libraries,
            include_dirs=include_dirs)])
",CWE-119,104.0,1
"import os
import Bcfg2.Server.Plugin


def async_run(prog, args):
    pid = os.fork()
    if pid:
        os.waitpid(pid, 0)
    else:
        dpid = os.fork()
        if not dpid:
            os.system("" "".join([prog] + args))
        os._exit(0)


class Trigger(Bcfg2.Server.Plugin.Plugin,
              Bcfg2.Server.Plugin.Statistics):
    """"""Trigger is a plugin that calls external scripts (on the server).""""""
    name = 'Trigger'
    __version__ = '$Id'
    __author__ = 'bcfg-dev@mcs.anl.gov'

    def __init__(self, core, datastore):
        Bcfg2.Server.Plugin.Plugin.__init__(self, core, datastore)
        Bcfg2.Server.Plugin.Statistics.__init__(self)
        try:
            os.stat(self.data)
        except:
            self.logger.error(""Trigger: spool directory %s does not exist; ""
                              ""unloading"" % self.data)
            raise Bcfg2.Server.Plugin.PluginInitError

    def process_statistics(self, metadata, _):
        args = [metadata.hostname, '-p', metadata.profile, '-g',
                ':'.join([g for g in metadata.groups])]
        for notifier in os.listdir(self.data):
            if ((notifier[-1] == '~') or
                (notifier[:2] == '.#') or
                (notifier[-4:] == '.swp') or
                (notifier in ['SCCS', '.svn', '4913'])):
                continue
            npath = self.data + '/' + notifier
            self.logger.debug(""Running %s %s"" % (npath, "" "".join(args)))
            async_run(npath, args)
",CWE-78,45.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2012 OpenStack LLC
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import copy
import datetime

from keystone.common import kvs
from keystone import exception
from keystone import token


class Token(kvs.Base, token.Driver):
    # Public interface
    def get_token(self, token_id):
        token = self.db.get('token-%s' % token_id)
        if (token and (token['expires'] is None
                       or token['expires'] > datetime.datetime.utcnow())):
            return token
        else:
            raise exception.TokenNotFound(token_id=token_id)

    def create_token(self, token_id, data):
        data_copy = copy.deepcopy(data)
        if 'expires' not in data:
            data_copy['expires'] = self._get_default_expire_time()
        self.db.set('token-%s' % token_id, data_copy)
        return copy.deepcopy(data_copy)

    def delete_token(self, token_id):
        try:
            return self.db.delete('token-%s' % token_id)
        except KeyError:
            raise exception.TokenNotFound(token_id=token_id)
",CWE-264,47.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2012 OpenStack LLC
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import copy
import datetime

from keystone.common import sql
from keystone import exception
from keystone import token


class TokenModel(sql.ModelBase, sql.DictBase):
    __tablename__ = 'token'
    id = sql.Column(sql.String(64), primary_key=True)
    expires = sql.Column(sql.DateTime(), default=None)
    extra = sql.Column(sql.JsonBlob())

    @classmethod
    def from_dict(cls, token_dict):
        # shove any non-indexed properties into extra
        extra = copy.deepcopy(token_dict)
        data = {}
        for k in ('id', 'expires'):
            data[k] = extra.pop(k, None)
        data['extra'] = extra
        return cls(**data)

    def to_dict(self):
        out = copy.deepcopy(self.extra)
        out['id'] = self.id
        out['expires'] = self.expires
        return out


class Token(sql.Base, token.Driver):
    # Public interface
    def get_token(self, token_id):
        session = self.get_session()
        token_ref = session.query(TokenModel).filter_by(id=token_id).first()
        now = datetime.datetime.utcnow()
        if token_ref and (not token_ref.expires or now < token_ref.expires):
            return token_ref.to_dict()
        else:
            raise exception.TokenNotFound(token_id=token_id)

    def create_token(self, token_id, data):
        data_copy = copy.deepcopy(data)
        if 'expires' not in data_copy:
            data_copy['expires'] = self._get_default_expire_time()

        token_ref = TokenModel.from_dict(data_copy)
        token_ref.id = token_id

        session = self.get_session()
        with session.begin():
            session.add(token_ref)
            session.flush()
        return token_ref.to_dict()

    def delete_token(self, token_id):
        session = self.get_session()
        token_ref = session.query(TokenModel)\
                                .filter_by(id=token_id)\
                                .first()
        if not token_ref:
            raise exception.TokenNotFound(token_id=token_id)

        with session.begin():
            session.delete(token_ref)
            session.flush()
",CWE-264,84.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2012 OpenStack LLC
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

""""""Main entry point into the Token service.""""""

import datetime

from keystone import config
from keystone import exception
from keystone.common import manager


CONF = config.CONF
config.register_int('expiration', group='token', default=86400)


class Manager(manager.Manager):
    """"""Default pivot point for the Token backend.

    See :mod:`keystone.common.manager.Manager` for more details on how this
    dynamically calls the backend.

    """"""

    def __init__(self):
        super(Manager, self).__init__(CONF.token.driver)


class Driver(object):
    """"""Interface description for a Token driver.""""""

    def get_token(self, token_id):
        """"""Get a token by id.

        :param token_id: identity of the token
        :type token_id: string
        :returns: token_ref
        :raises: keystone.exception.TokenNotFound

        """"""
        raise exception.NotImplemented()

    def create_token(self, token_id, data):
        """"""Create a token by id and data.

        :param token_id: identity of the token
        :type token_id: string
        :param data: dictionary with additional reference information

        ::

            {
                expires=''
                id=token_id,
                user=user_ref,
                tenant=tenant_ref,
                metadata=metadata_ref
            }

        :type data: dict
        :returns: token_ref or None.

        """"""
        raise exception.NotImplemented()

    def delete_token(self, token_id):
        """"""Deletes a token by id.

        :param token_id: identity of the token
        :type token_id: string
        :returns: None.
        :raises: keystone.exception.TokenNotFound

        """"""
        raise exception.NotImplemented()

    def _get_default_expire_time(self):
        """"""Determine when a token should expire based on the config.

        :returns: a naive utc datetime.datetime object

        """"""
        expire_delta = datetime.timedelta(seconds=CONF.token.expiration)
        return datetime.datetime.utcnow() + expire_delta
",CWE-264,98.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2012 OpenStack LLC
# Copyright 2012 Canonical Ltd.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

""""""Main entry point into the Catalog service.""""""

import uuid

from keystone import config
from keystone import exception
from keystone import identity
from keystone import policy
from keystone import token
from keystone.common import manager
from keystone.common import wsgi


CONF = config.CONF


class Manager(manager.Manager):
    """"""Default pivot point for the Catalog backend.

    See :mod:`keystone.common.manager.Manager` for more details on how this
    dynamically calls the backend.

    """"""

    def __init__(self):
        super(Manager, self).__init__(CONF.catalog.driver)


class Driver(object):
    """"""Interface description for an Catalog driver.""""""
    def list_services(self):
        """"""List all service ids in catalog.

        Returns: list of service_ids or an empty list.

        """"""
        raise exception.NotImplemented()

    def get_service(self, service_id):
        """"""Get service by id.

        Returns: service_ref dict or None.

        """"""
        raise exception.NotImplemented()

    def delete_service(self, service_id):
        raise exception.NotImplemented()

    def create_service(self, service_id, service_ref):
        raise exception.NotImplemented()

    def create_endpoint(self, endpoint_id, endpoint_ref):
        raise exception.NotImplemented()

    def delete_endpoint(self, endpoint_id):
        raise exception.NotImplemented()

    def get_endpoint(self, endpoint_id):
        """"""Get endpoint by id.

        Returns: endpoint_ref dict or None.

        """"""
        raise exception.NotImplemented()

    def list_endpoints(self):
        """"""List all endpoint ids in catalog.

        Returns: list of endpoint_ids or an empty list.

        """"""
        raise exception.NotImplemented()

    def get_catalog(self, user_id, tenant_id, metadata=None):
        """"""Retreive and format the current service catalog.

        Returns: A nested dict representing the service catalog or an
                 empty dict.

        Example:

            { 'RegionOne':
                {'compute': {
                    'adminURL': u'http://host:8774/v1.1/tenantid',
                    'internalURL': u'http://host:8774/v1.1/tenant_id',
                    'name': 'Compute Service',
                    'publicURL': u'http://host:8774/v1.1/tenantid'},
                 'ec2': {
                    'adminURL': 'http://host:8773/services/Admin',
                    'internalURL': 'http://host:8773/services/Cloud',
                    'name': 'EC2 Service',
                    'publicURL': 'http://host:8773/services/Cloud'}}

        """"""
        raise exception.NotImplemented()


class ServiceController(wsgi.Application):
    def __init__(self):
        self.catalog_api = Manager()
        super(ServiceController, self).__init__()

    # CRUD extensions
    # NOTE(termie): this OS-KSADM stuff is not very consistent
    def get_services(self, context):
        service_list = self.catalog_api.list_services(context)
        service_refs = [self.catalog_api.get_service(context, x)
                        for x in service_list]
        return {'OS-KSADM:services': service_refs}

    def get_service(self, context, service_id):
        service_ref = self.catalog_api.get_service(context, service_id)
        if not service_ref:
            raise exception.ServiceNotFound(service_id=service_id)
        return {'OS-KSADM:service': service_ref}

    def delete_service(self, context, service_id):
        service_ref = self.catalog_api.get_service(context, service_id)
        if not service_ref:
            raise exception.ServiceNotFound(service_id=service_id)
        self.catalog_api.delete_service(context, service_id)

    def create_service(self, context, OS_KSADM_service):
        service_id = uuid.uuid4().hex
        service_ref = OS_KSADM_service.copy()
        service_ref['id'] = service_id
        new_service_ref = self.catalog_api.create_service(
                context, service_id, service_ref)
        return {'OS-KSADM:service': new_service_ref}


class EndpointController(wsgi.Application):
    def __init__(self):
        self.catalog_api = Manager()
        self.identity_api = identity.Manager()
        self.policy_api = policy.Manager()
        self.token_api = token.Manager()
        super(EndpointController, self).__init__()

    def get_endpoints(self, context):
        self.assert_admin(context)
        endpoint_list = self.catalog_api.list_endpoints(context)
        endpoint_refs = [self.catalog_api.get_endpoint(context, e)
                         for e in endpoint_list]
        return {'endpoints': endpoint_refs}

    def create_endpoint(self, context, endpoint):
        self.assert_admin(context)
        endpoint_id = uuid.uuid4().hex
        endpoint_ref = endpoint.copy()
        endpoint_ref['id'] = endpoint_id

        service_id = endpoint_ref['service_id']
        if not self.catalog_api.get_service(context, service_id):
            raise exception.ServiceNotFound(service_id=service_id)

        new_endpoint_ref = self.catalog_api.create_endpoint(
                                context, endpoint_id, endpoint_ref)
        return {'endpoint': new_endpoint_ref}

    def delete_endpoint(self, context, endpoint_id):
        self.assert_admin(context)
        self.catalog_api.delete_endpoint(context, endpoint_id)
",CWE-287,182.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2012 OpenStack LLC
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

from keystone.common import serializer
from keystone.common import wsgi
from keystone import config
from keystone import exception
from keystone.openstack.common import jsonutils


CONF = config.CONF


# Header used to transmit the auth token
AUTH_TOKEN_HEADER = 'X-Auth-Token'


# Environment variable used to pass the request context
CONTEXT_ENV = wsgi.CONTEXT_ENV


# Environment variable used to pass the request params
PARAMS_ENV = wsgi.PARAMS_ENV


class TokenAuthMiddleware(wsgi.Middleware):
    def process_request(self, request):
        token = request.headers.get(AUTH_TOKEN_HEADER)
        context = request.environ.get(CONTEXT_ENV, {})
        context['token_id'] = token
        request.environ[CONTEXT_ENV] = context


class AdminTokenAuthMiddleware(wsgi.Middleware):
    """"""A trivial filter that checks for a pre-defined admin token.

    Sets 'is_admin' to true in the context, expected to be checked by
    methods that are admin-only.

    """"""

    def process_request(self, request):
        token = request.headers.get(AUTH_TOKEN_HEADER)
        context = request.environ.get(CONTEXT_ENV, {})
        context['is_admin'] = (token == CONF.admin_token)
        request.environ[CONTEXT_ENV] = context


class PostParamsMiddleware(wsgi.Middleware):
    """"""Middleware to allow method arguments to be passed as POST parameters.

    Filters out the parameters `self`, `context` and anything beginning with
    an underscore.

    """"""

    def process_request(self, request):
        params_parsed = request.params
        params = {}
        for k, v in params_parsed.iteritems():
            if k in ('self', 'context'):
                continue
            if k.startswith('_'):
                continue
            params[k] = v

        request.environ[PARAMS_ENV] = params


class JsonBodyMiddleware(wsgi.Middleware):
    """"""Middleware to allow method arguments to be passed as serialized JSON.

    Accepting arguments as JSON is useful for accepting data that may be more
    complex than simple primitives.

    In this case we accept it as urlencoded data under the key 'json' as in
    json=<urlencoded_json> but this could be extended to accept raw JSON
    in the POST body.

    Filters out the parameters `self`, `context` and anything beginning with
    an underscore.

    """"""
    def process_request(self, request):
        # Abort early if we don't have any work to do
        params_json = request.body
        if not params_json:
            return

        # Reject unrecognized content types. Empty string indicates
        # the client did not explicitly set the header
        if not request.content_type in ('application/json', ''):
            e = exception.ValidationError(attribute='application/json',
                                          target='Content-Type header')
            return wsgi.render_exception(e)

        params_parsed = {}
        try:
            params_parsed = jsonutils.loads(params_json)
        except ValueError:
            e = exception.ValidationError(attribute='valid JSON',
                                          target='request body')
            return wsgi.render_exception(e)
        finally:
            if not params_parsed:
                params_parsed = {}

        params = {}
        for k, v in params_parsed.iteritems():
            if k in ('self', 'context'):
                continue
            if k.startswith('_'):
                continue
            params[k] = v

        request.environ[PARAMS_ENV] = params


class XmlBodyMiddleware(wsgi.Middleware):
    """"""De/serializes XML to/from JSON.""""""

    def process_request(self, request):
        """"""Transform the request from XML to JSON.""""""
        incoming_xml = 'application/xml' in str(request.content_type)
        if incoming_xml and request.body:
            request.content_type = 'application/json'
            request.body = jsonutils.dumps(serializer.from_xml(request.body))

    def process_response(self, request, response):
        """"""Transform the response from JSON to XML.""""""
        outgoing_xml = 'application/xml' in str(request.accept)
        if outgoing_xml and response.body:
            response.content_type = 'application/xml'
            try:
                body_obj = jsonutils.loads(response.body)
                response.body = serializer.to_xml(body_obj)
            except Exception:
                raise exception.Error(message=response.body)
        return response


class NormalizingFilter(wsgi.Middleware):
    """"""Middleware filter to handle URL normalization.""""""

    def process_request(self, request):
        """"""Normalizes URLs.""""""
        # Removes a trailing slash from the given path, if any.
        if (len(request.environ['PATH_INFO']) > 1 and
                request.environ['PATH_INFO'][-1] == '/'):
            request.environ['PATH_INFO'] = request.environ['PATH_INFO'][:-1]
        # Rewrites path to root if no path is given.
        elif not request.environ['PATH_INFO']:
            request.environ['PATH_INFO'] = '/'
",CWE-119,167.0,1
,CWE-119,,1
"""""""Encryption module that uses pycryptopp or pycrypto""""""
try:
    # Pycryptopp is preferred over Crypto because Crypto has had
    # various periods of not being maintained, and pycryptopp uses
    # the Crypto++ library which is generally considered the 'gold standard'
    # of crypto implementations
    from pycryptopp.cipher import aes

    def aesEncrypt(data, key):
        cipher = aes.AES(key)
        return cipher.process(data)

    # magic.
    aesDecrypt = aesEncrypt

except ImportError:
    from Crypto.Cipher import AES

    def aesEncrypt(data, key):
        cipher = AES.new(key)

        data = data + ("" "" * (16 - (len(data) % 16)))
        return cipher.encrypt(data)

    def aesDecrypt(data, key):
        cipher = AES.new(key)

        return cipher.decrypt(data).rstrip()

def getKeyLength():
    return 32
",CWE-310,32.0,1
"# Copyright (c) 2010-2012 OpenStack, LLC.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from ConfigParser import ConfigParser, NoSectionError, NoOptionError

from swift.common.memcached import MemcacheRing


class MemcacheMiddleware(object):
    """"""
    Caching middleware that manages caching in swift.
    """"""

    def __init__(self, app, conf):
        self.app = app
        self.memcache_servers = conf.get('memcache_servers')
        if not self.memcache_servers:
            path = os.path.join(conf.get('swift_dir', '/etc/swift'),
                                'memcache.conf')
            memcache_conf = ConfigParser()
            if memcache_conf.read(path):
                try:
                    self.memcache_servers = \
                        memcache_conf.get('memcache', 'memcache_servers')
                except (NoSectionError, NoOptionError):
                    pass
        if not self.memcache_servers:
            self.memcache_servers = '127.0.0.1:11211'
        self.memcache = MemcacheRing(
            [s.strip() for s in self.memcache_servers.split(',') if s.strip()])

    def __call__(self, env, start_response):
        env['swift.cache'] = self.memcache
        return self.app(env, start_response)


def filter_factory(global_conf, **local_conf):
    conf = global_conf.copy()
    conf.update(local_conf)

    def cache_filter(app):
        return MemcacheMiddleware(app, conf)

    return cache_filter
",CWE-502,58.0,1
"# Copyright (c) 2010-2012 OpenStack, LLC.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from ConfigParser import NoSectionError, NoOptionError

from webob import Request

from swift.common.middleware import memcache
from swift.common.memcached import MemcacheRing

class FakeApp(object):
    def __call__(self, env, start_response):
        return env


class ExcConfigParser(object):

    def read(self, path):
        raise Exception('read called with %r' % path)


class EmptyConfigParser(object):

    def read(self, path):
        return False


class SetConfigParser(object):

    def read(self, path):
        return True

    def get(self, section, option):
        if section == 'memcache':
            if option == 'memcache_servers':
                return '1.2.3.4:5'
            else:
                raise NoOptionError(option)
        else:
            raise NoSectionError(option)


def start_response(*args):
    pass

class TestCacheMiddleware(unittest.TestCase):

    def setUp(self):
        self.app = memcache.MemcacheMiddleware(FakeApp(), {})

    def test_cache_middleware(self):
        req = Request.blank('/something', environ={'REQUEST_METHOD': 'GET'})
        resp = self.app(req.environ, start_response)
        self.assertTrue('swift.cache' in resp)
        self.assertTrue(isinstance(resp['swift.cache'], MemcacheRing))

    def test_conf_default_read(self):
        orig_parser = memcache.ConfigParser
        memcache.ConfigParser = ExcConfigParser
        exc = None
        try:
            app = memcache.MemcacheMiddleware(FakeApp(), {})
        except Exception, err:
            exc = err
        finally:
            memcache.ConfigParser = orig_parser
        self.assertEquals(str(exc),
            ""read called with '/etc/swift/memcache.conf'"")

    def test_conf_set_no_read(self):
        orig_parser = memcache.ConfigParser
        memcache.ConfigParser = ExcConfigParser
        exc = None
        try:
            app = memcache.MemcacheMiddleware(
                    FakeApp(), {'memcache_servers': '1.2.3.4:5'})
        except Exception, err:
            exc = err
        finally:
            memcache.ConfigParser = orig_parser
        self.assertEquals(exc, None)

    def test_conf_default(self):
        orig_parser = memcache.ConfigParser
        memcache.ConfigParser = EmptyConfigParser
        try:
            app = memcache.MemcacheMiddleware(FakeApp(), {})
        finally:
            memcache.ConfigParser = orig_parser
        self.assertEquals(app.memcache_servers, '127.0.0.1:11211')

    def test_conf_from_extra_conf(self):
        orig_parser = memcache.ConfigParser
        memcache.ConfigParser = SetConfigParser
        try:
            app = memcache.MemcacheMiddleware(FakeApp(), {})
        finally:
            memcache.ConfigParser = orig_parser
        self.assertEquals(app.memcache_servers, '1.2.3.4:5')

    def test_conf_from_inline_conf(self):
        orig_parser = memcache.ConfigParser
        memcache.ConfigParser = SetConfigParser
        try:
            app = memcache.MemcacheMiddleware(
                    FakeApp(), {'memcache_servers': '6.7.8.9:10'})
        finally:
            memcache.ConfigParser = orig_parser
        self.assertEquals(app.memcache_servers, '6.7.8.9:10')


if __name__ == '__main__':
    unittest.main()
",CWE-502,127.0,1
"from django.conf.urls import patterns, url
from django.contrib.auth import context_processors
from django.contrib.auth.urls import urlpatterns
from django.contrib.auth.views import password_reset
from django.contrib.auth.decorators import login_required
from django.contrib.messages.api import info
from django.http import HttpResponse
from django.shortcuts import render_to_response
from django.template import Template, RequestContext
from django.views.decorators.cache import never_cache

@never_cache
def remote_user_auth_view(request):
    ""Dummy view for remote user tests""
    t = Template(""Username is {{ user }}."")
    c = RequestContext(request, {})
    return HttpResponse(t.render(c))

def auth_processor_no_attr_access(request):
    r1 = render_to_response('context_processors/auth_attrs_no_access.html',
        RequestContext(request, {}, processors=[context_processors.auth]))
    # *After* rendering, we check whether the session was accessed
    return render_to_response('context_processors/auth_attrs_test_access.html',
        {'session_accessed':request.session.accessed})

def auth_processor_attr_access(request):
    r1 = render_to_response('context_processors/auth_attrs_access.html',
        RequestContext(request, {}, processors=[context_processors.auth]))
    return render_to_response('context_processors/auth_attrs_test_access.html',
        {'session_accessed':request.session.accessed})

def auth_processor_user(request):
    return render_to_response('context_processors/auth_attrs_user.html',
        RequestContext(request, {}, processors=[context_processors.auth]))

def auth_processor_perms(request):
    return render_to_response('context_processors/auth_attrs_perms.html',
        RequestContext(request, {}, processors=[context_processors.auth]))

def auth_processor_perm_in_perms(request):
    return render_to_response('context_processors/auth_attrs_perm_in_perms.html',
        RequestContext(request, {}, processors=[context_processors.auth]))

def auth_processor_messages(request):
    info(request, ""Message 1"")
    return render_to_response('context_processors/auth_attrs_messages.html',
         RequestContext(request, {}, processors=[context_processors.auth]))

def userpage(request):
    pass

# special urls for auth test cases
urlpatterns = urlpatterns + patterns('',
    (r'^logout/custom_query/$', 'django.contrib.auth.views.logout', dict(redirect_field_name='follow')),
    (r'^logout/next_page/$', 'django.contrib.auth.views.logout', dict(next_page='/somewhere/')),
    (r'^remote_user/$', remote_user_auth_view),
    (r'^password_reset_from_email/$', 'django.contrib.auth.views.password_reset', dict(from_email='staffmember@example.com')),
    (r'^login_required/$', login_required(password_reset)),
    (r'^login_required_login_url/$', login_required(password_reset, login_url='/somewhere/')),

    (r'^auth_processor_no_attr_access/$', auth_processor_no_attr_access),
    (r'^auth_processor_attr_access/$', auth_processor_attr_access),
    (r'^auth_processor_user/$', auth_processor_user),
    (r'^auth_processor_perms/$', auth_processor_perms),
    (r'^auth_processor_perm_in_perms/$', auth_processor_perm_in_perms),
    (r'^auth_processor_messages/$', auth_processor_messages),
    url(r'^userpage/(.+)/$', userpage, name=""userpage""),
)

",CWE-20,70.0,1
"from django.contrib.postgres.fields import ArrayField, JSONField
from django.db.models.aggregates import Aggregate

from .mixins import OrderableAggMixin

__all__ = [
    'ArrayAgg', 'BitAnd', 'BitOr', 'BoolAnd', 'BoolOr', 'JSONBAgg', 'StringAgg',
]


class ArrayAgg(OrderableAggMixin, Aggregate):
    function = 'ARRAY_AGG'
    template = '%(function)s(%(distinct)s%(expressions)s %(ordering)s)'
    allow_distinct = True

    @property
    def output_field(self):
        return ArrayField(self.source_expressions[0].output_field)

    def convert_value(self, value, expression, connection):
        if not value:
            return []
        return value


class BitAnd(Aggregate):
    function = 'BIT_AND'


class BitOr(Aggregate):
    function = 'BIT_OR'


class BoolAnd(Aggregate):
    function = 'BOOL_AND'


class BoolOr(Aggregate):
    function = 'BOOL_OR'


class JSONBAgg(Aggregate):
    function = 'JSONB_AGG'
    output_field = JSONField()

    def convert_value(self, value, expression, connection):
        if not value:
            return []
        return value


class StringAgg(OrderableAggMixin, Aggregate):
    function = 'STRING_AGG'
    template = ""%(function)s(%(distinct)s%(expressions)s, '%(delimiter)s'%(ordering)s)""
    allow_distinct = True

    def __init__(self, expression, delimiter, **extra):
        super().__init__(expression, delimiter=delimiter, **extra)

    def convert_value(self, value, expression, connection):
        if not value:
            return ''
        return value
",CWE-89,64.0,1
"from django.db.models.expressions import F, OrderBy


class OrderableAggMixin:

    def __init__(self, expression, ordering=(), **extra):
        if not isinstance(ordering, (list, tuple)):
            ordering = [ordering]
        ordering = ordering or []
        # Transform minus sign prefixed strings into an OrderBy() expression.
        ordering = (
            (OrderBy(F(o[1:]), descending=True) if isinstance(o, str) and o[0] == '-' else o)
            for o in ordering
        )
        super().__init__(expression, **extra)
        self.ordering = self._parse_expressions(*ordering)

    def resolve_expression(self, *args, **kwargs):
        self.ordering = [expr.resolve_expression(*args, **kwargs) for expr in self.ordering]
        return super().resolve_expression(*args, **kwargs)

    def as_sql(self, compiler, connection):
        if self.ordering:
            ordering_params = []
            ordering_expr_sql = []
            for expr in self.ordering:
                expr_sql, expr_params = expr.as_sql(compiler, connection)
                ordering_expr_sql.append(expr_sql)
                ordering_params.extend(expr_params)
            sql, sql_params = super().as_sql(compiler, connection, ordering=(
                'ORDER BY ' + ', '.join(ordering_expr_sql)
            ))
            return sql, sql_params + ordering_params
        return super().as_sql(compiler, connection, ordering='')

    def set_source_expressions(self, exprs):
        # Extract the ordering expressions because ORDER BY clause is handled
        # in a custom way.
        self.ordering = exprs[self._get_ordering_expressions_index():]
        return super().set_source_expressions(exprs[:self._get_ordering_expressions_index()])

    def get_source_expressions(self):
        return super().get_source_expressions() + self.ordering

    def _get_ordering_expressions_index(self):
        """"""Return the index at which the ordering expressions start.""""""
        source_expressions = self.get_source_expressions()
        return len(source_expressions) - len(self.ordering)
",CWE-89,49.0,1
"<?php
/**
 * Horde_Text_Filter_Xss tests.
 *
 * @author     Michael Slusarz <slusarz@horde.org>
 * @category   Horde
 * @license    http://www.horde.org/licenses/lgpl21 LGPL 2.1
 * @package    Text_Filter
 * @subpackage UnitTests
 */

class Horde_Text_Filter_XssTest extends PHPUnit_Framework_TestCase
{
    /**
     * Test cases from http://ha.ckers.org/xss.html
     *
     * @dataProvider xssProvider
     */
    public function testXss($key, $val)
    {
        $this->assertEquals(
            $val,
            trim(Horde_Text_Filter::filter($key, 'xss'))
        );
    }

    public function xssProvider()
    {
        $framedata = <<<EOT
<frameset rows=""15,15,15,15,15,15,15,15,15,*"">
<frame src=""mailbox.php?page=1&amp;actionID=delete_messages&amp;targetMbox=&amp;newMbox=0&amp;flag=&amp;indices%5B%5D=199&amp;indices%5B%5D=200&amp;indices%5B%5D=201&amp;indices%5B%5D=202&amp;indices%5B%5D=203&amp;indices%5B%5D=204&amp;indices%5B%5D=205&amp;indices%5B%5D=206&amp;indices%5B%5D=207&amp;indices%5B%5D=208&amp;indices%5B%5D=209&amp;indices%5B%5D=210&amp;indices%5B%5D=211&amp;indices%5B%5D=212&amp;indices%5B%5D=213&amp;indices%5B%5D=214&amp;indices%5B%5D=215&amp;indices%5B%5D=216&amp;indices%5B%5D=217&amp;indices%5B%5D=218&amp;indices%5B%5D=219&amp;indices%5B%5D=220&amp;indices%5B%5D=221&amp;indices%5B%5D=222&amp;indices%5B%5D=223&amp;indices%5B%5D=224&amp;indices%5B%5D=225&amp;indices%5B%5D=226&amp;indices%5B%5D=227&amp;indices%5B%5D=228&amp;indices%5B%5D=229&amp;indices%5B%5D=230&amp;indices%5B%5D=231&amp;indices%5B%5D=232&amp;indices%5B%5D=233&amp;indices%5B%5D=234&amp;indices%5B%5D=235&amp;indices%5B%5D=236&amp;indices%5B%5D=237&amp;indices%5B%5D=238&amp;indices%5B%5D=239&amp;indices%5B%5D=240&amp;indices%5B%5D=241&amp;indices%5B%5D=242&amp;indices%5B%5D=243&amp;indices%5B%5D=244&amp;indices%5B%5D=245&amp;indices%5B%5D=246&amp;indices%5B%5D=247&amp;indices%5B%5D=248&amp;indices%5B%5D=249&amp;indices%5B%5D=250&amp;indices%5B%5D=251&amp;indices%5B%5D=252&amp;indices%5B%5D=253&amp;indices%5B%5D=254&amp;indices%5B%5D=255&amp;indices%5B%5D=256&amp;indices%5B%5D=257&amp;indices%5B%5D=258&amp;indices%5B%5D=259&amp;indices%5B%5D=260&amp;indices%5B%5D=261&amp;indices%5B%5D=262&amp;indices%5B%5D=263&amp;indices%5B%5D=264&amp;indices%5B%5D=265&amp;indices%5B%5D=266&amp;indices%5B%5D=267&amp;indices%5B%5D=268&amp;indices%5B%5D=269&amp;indices%5B%5D=270&amp;indices%5B%5D=271&amp;indices%5B%5D=272&amp;indices%5B%5D=273&amp;indices%5B%5D=274&amp;indices%5B%5D=275&amp;indices%5B%5D=276&amp;indices%5B%5D=277&amp;indices%5B%5D=278&amp;indices%5B%5D=279&amp;indices%5B%5D=280&amp;indices%5B%5D=281&amp;indices%5B%5D=282&amp;indices%5B%5D=283&amp;indices%5B%5D=284&amp;indices%5B%5D=285&amp;indices%5B%5D=286&amp;indices%5B%5D=287&amp;indices%5B%5D=288&amp;indices%5B%5D=289&amp;indices%5B%5D=290&amp;indices%5B%5D=291&amp;indices%5B%5D=292&amp;indices%5B%5D=293&amp;indices%5B%5D=294&amp;indices%5B%5D=295&amp;indices%5B%5D=296&amp;indices%5B%5D=297&amp;indices%5B%5D=298"">
<frame src=""mailbox.php?page=1&amp;actionID=delete_messages&amp;targetMbox=&amp;newMbox=0&amp;flag=&amp;indices%5B%5D=299&amp;indices%5B%5D=300&amp;indices%5B%5D=301&amp;indices%5B%5D=302&amp;indices%5B%5D=303&amp;indices%5B%5D=304&amp;indices%5B%5D=305&amp;indices%5B%5D=306&amp;indices%5B%5D=307&amp;indices%5B%5D=308&amp;indices%5B%5D=309&amp;indices%5B%5D=310&amp;indices%5B%5D=311&amp;indices%5B%5D=312&amp;indices%5B%5D=313&amp;indices%5B%5D=314&amp;indices%5B%5D=315&amp;indices%5B%5D=316&amp;indices%5B%5D=317&amp;indices%5B%5D=318&amp;indices%5B%5D=319&amp;indices%5B%5D=320&amp;indices%5B%5D=321&amp;indices%5B%5D=322&amp;indices%5B%5D=323&amp;indices%5B%5D=324&amp;indices%5B%5D=325&amp;indices%5B%5D=326&amp;indices%5B%5D=327&amp;indices%5B%5D=328&amp;indices%5B%5D=329&amp;indices%5B%5D=330&amp;indices%5B%5D=331&amp;indices%5B%5D=332&amp;indices%5B%5D=333&amp;indices%5B%5D=334&amp;indices%5B%5D=335&amp;indices%5B%5D=336&amp;indices%5B%5D=337&amp;indices%5B%5D=338&amp;indices%5B%5D=339&amp;indices%5B%5D=340&amp;indices%5B%5D=341&amp;indices%5B%5D=342&amp;indices%5B%5D=343&amp;indices%5B%5D=344&amp;indices%5B%5D=345&amp;indices%5B%5D=346&amp;indices%5B%5D=347&amp;indices%5B%5D=348&amp;indices%5B%5D=349&amp;indices%5B%5D=350&amp;indices%5B%5D=351&amp;indices%5B%5D=352&amp;indices%5B%5D=353&amp;indices%5B%5D=354&amp;indices%5B%5D=355&amp;indices%5B%5D=356&amp;indices%5B%5D=357&amp;indices%5B%5D=358&amp;indices%5B%5D=359&amp;indices%5B%5D=360&amp;indices%5B%5D=361&amp;indices%5B%5D=362&amp;indices%5B%5D=363&amp;indices%5B%5D=364&amp;indices%5B%5D=365&amp;indices%5B%5D=366&amp;indices%5B%5D=367&amp;indices%5B%5D=368&amp;indices%5B%5D=369&amp;indices%5B%5D=370&amp;indices%5B%5D=371&amp;indices%5B%5D=372&amp;indices%5B%5D=373&amp;indices%5B%5D=374&amp;indices%5B%5D=375&amp;indices%5B%5D=376&amp;indices%5B%5D=377&amp;indices%5B%5D=378&amp;indices%5B%5D=379&amp;indices%5B%5D=380&amp;indices%5B%5D=381&amp;indices%5B%5D=382&amp;indices%5B%5D=383&amp;indices%5B%5D=384&amp;indices%5B%5D=385&amp;indices%5B%5D=386&amp;indices%5B%5D=387&amp;indices%5B%5D=388&amp;indices%5B%5D=389&amp;indices%5B%5D=390&amp;indices%5B%5D=391&amp;indices%5B%5D=392&amp;indices%5B%5D=393&amp;indices%5B%5D=394&amp;indices%5B%5D=395&amp;indices%5B%5D=396&amp;indices%5B%5D=397&amp;indices%5B%5D=398"">
<frame src=""mailbox.php?page=1&amp;actionID=delete_messages&amp;targetMbox=&amp;newMbox=0&amp;flag=&amp;indices%5B%5D=399&amp;indices%5B%5D=400&amp;indices%5B%5D=401&amp;indices%5B%5D=402&amp;indices%5B%5D=403&amp;indices%5B%5D=404&amp;indices%5B%5D=405&amp;indices%5B%5D=406&amp;indices%5B%5D=407&amp;indices%5B%5D=408&amp;indices%5B%5D=409&amp;indices%5B%5D=410&amp;indices%5B%5D=411&amp;indices%5B%5D=412&amp;indices%5B%5D=413&amp;indices%5B%5D=414&amp;indices%5B%5D=415&amp;indices%5B%5D=416&amp;indices%5B%5D=417&amp;indices%5B%5D=418&amp;indices%5B%5D=419&amp;indices%5B%5D=420&amp;indices%5B%5D=421&amp;indices%5B%5D=422&amp;indices%5B%5D=423&amp;indices%5B%5D=424&amp;indices%5B%5D=425&amp;indices%5B%5D=426&amp;indices%5B%5D=427&amp;indices%5B%5D=428&amp;indices%5B%5D=429&amp;indices%5B%5D=430&amp;indices%5B%5D=431&amp;indices%5B%5D=432&amp;indices%5B%5D=433&amp;indices%5B%5D=434&amp;indices%5B%5D=435&amp;indices%5B%5D=436&amp;indices%5B%5D=437&amp;indices%5B%5D=438&amp;indices%5B%5D=439&amp;indices%5B%5D=440&amp;indices%5B%5D=441&amp;indices%5B%5D=442&amp;indices%5B%5D=443&amp;indices%5B%5D=444&amp;indices%5B%5D=445&amp;indices%5B%5D=446&amp;indices%5B%5D=447&amp;indices%5B%5D=448&amp;indices%5B%5D=449&amp;indices%5B%5D=450&amp;indices%5B%5D=451&amp;indices%5B%5D=452&amp;indices%5B%5D=453&amp;indices%5B%5D=454&amp;indices%5B%5D=455&amp;indices%5B%5D=456&amp;indices%5B%5D=457&amp;indices%5B%5D=458&amp;indices%5B%5D=459&amp;indices%5B%5D=460&amp;indices%5B%5D=461&amp;indices%5B%5D=462&amp;indices%5B%5D=463&amp;indices%5B%5D=464&amp;indices%5B%5D=465&amp;indices%5B%5D=466&amp;indices%5B%5D=467&amp;indices%5B%5D=468&amp;indices%5B%5D=469&amp;indices%5B%5D=470&amp;indices%5B%5D=471&amp;indices%5B%5D=472&amp;indices%5B%5D=473&amp;indices%5B%5D=474&amp;indices%5B%5D=475&amp;indices%5B%5D=476&amp;indices%5B%5D=477&amp;indices%5B%5D=478&amp;indices%5B%5D=479&amp;indices%5B%5D=480&amp;indices%5B%5D=481&amp;indices%5B%5D=482&amp;indices%5B%5D=483&amp;indices%5B%5D=484&amp;indices%5B%5D=485&amp;indices%5B%5D=486&amp;indices%5B%5D=487&amp;indices%5B%5D=488&amp;indices%5B%5D=489&amp;indices%5B%5D=490&amp;indices%5B%5D=491&amp;indices%5B%5D=492&amp;indices%5B%5D=493&amp;indices%5B%5D=494&amp;indices%5B%5D=495&amp;indices%5B%5D=496&amp;indices%5B%5D=497&amp;indices%5B%5D=498"">
<frame src=""mailbox.php?page=1&amp;actionID=delete_messages&amp;targetMbox=&amp;newMbox=0&amp;flag=&amp;indices%5B%5D=499&amp;indices%5B%5D=500&amp;indices%5B%5D=501&amp;indices%5B%5D=502&amp;indices%5B%5D=503&amp;indices%5B%5D=504&amp;indices%5B%5D=505&amp;indices%5B%5D=506&amp;indices%5B%5D=507&amp;indices%5B%5D=508&amp;indices%5B%5D=509&amp;indices%5B%5D=510&amp;indices%5B%5D=511&amp;indices%5B%5D=512&amp;indices%5B%5D=513&amp;indices%5B%5D=514&amp;indices%5B%5D=515&amp;indices%5B%5D=516&amp;indices%5B%5D=517&amp;indices%5B%5D=518&amp;indices%5B%5D=519&amp;indices%5B%5D=520&amp;indices%5B%5D=521&amp;indices%5B%5D=522&amp;indices%5B%5D=523&amp;indices%5B%5D=524&amp;indices%5B%5D=525&amp;indices%5B%5D=526&amp;indices%5B%5D=527&amp;indices%5B%5D=528&amp;indices%5B%5D=529&amp;indices%5B%5D=530&amp;indices%5B%5D=531&amp;indices%5B%5D=532&amp;indices%5B%5D=533&amp;indices%5B%5D=534&amp;indices%5B%5D=535&amp;indices%5B%5D=536&amp;indices%5B%5D=537&amp;indices%5B%5D=538&amp;indices%5B%5D=539&amp;indices%5B%5D=540&amp;indices%5B%5D=541&amp;indices%5B%5D=542&amp;indices%5B%5D=543&amp;indices%5B%5D=544&amp;indices%5B%5D=545&amp;indices%5B%5D=546&amp;indices%5B%5D=547&amp;indices%5B%5D=548&amp;indices%5B%5D=549&amp;indices%5B%5D=550&amp;indices%5B%5D=551&amp;indices%5B%5D=552&amp;indices%5B%5D=553&amp;indices%5B%5D=554&amp;indices%5B%5D=555&amp;indices%5B%5D=556&amp;indices%5B%5D=557&amp;indices%5B%5D=558&amp;indices%5B%5D=559&amp;indices%5B%5D=560&amp;indices%5B%5D=561&amp;indices%5B%5D=562&amp;indices%5B%5D=563&amp;indices%5B%5D=564&amp;indices%5B%5D=565&amp;indices%5B%5D=566&amp;indices%5B%5D=567&amp;indices%5B%5D=568&amp;indices%5B%5D=569&amp;indices%5B%5D=570&amp;indices%5B%5D=571&amp;indices%5B%5D=572&amp;indices%5B%5D=573&amp;indices%5B%5D=574&amp;indices%5B%5D=575&amp;indices%5B%5D=576&amp;indices%5B%5D=577&amp;indices%5B%5D=578&amp;indices%5B%5D=579&amp;indices%5B%5D=580&amp;indices%5B%5D=581&amp;indices%5B%5D=582&amp;indices%5B%5D=583&amp;indices%5B%5D=584&amp;indices%5B%5D=585&amp;indices%5B%5D=586&amp;indices%5B%5D=587&amp;indices%5B%5D=588&amp;indices%5B%5D=589&amp;indices%5B%5D=590&amp;indices%5B%5D=591&amp;indices%5B%5D=592&amp;indices%5B%5D=593&amp;indices%5B%5D=594&amp;indices%5B%5D=595&amp;indices%5B%5D=596&amp;indices%5B%5D=597&amp;indices%5B%5D=598"">
<frame src=""mailbox.php?page=1&amp;actionID=delete_messages&amp;targetMbox=&amp;newMbox=0&amp;flag=&amp;indices%5B%5D=599&amp;indices%5B%5D=600&amp;indices%5B%5D=601&amp;indices%5B%5D=602&amp;indices%5B%5D=603&amp;indices%5B%5D=604&amp;indices%5B%5D=605&amp;indices%5B%5D=606&amp;indices%5B%5D=607&amp;indices%5B%5D=608&amp;indices%5B%5D=609&amp;indices%5B%5D=610&amp;indices%5B%5D=611&amp;indices%5B%5D=612&amp;indices%5B%5D=613&amp;indices%5B%5D=614&amp;indices%5B%5D=615&amp;indices%5B%5D=616&amp;indices%5B%5D=617&amp;indices%5B%5D=618&amp;indices%5B%5D=619&amp;indices%5B%5D=620&amp;indices%5B%5D=621&amp;indices%5B%5D=622&amp;indices%5B%5D=623&amp;indices%5B%5D=624&amp;indices%5B%5D=625&amp;indices%5B%5D=626&amp;indices%5B%5D=627&amp;indices%5B%5D=628&amp;indices%5B%5D=629&amp;indices%5B%5D=630&amp;indices%5B%5D=631&amp;indices%5B%5D=632&amp;indices%5B%5D=633&amp;indices%5B%5D=634&amp;indices%5B%5D=635&amp;indices%5B%5D=636&amp;indices%5B%5D=637&amp;indices%5B%5D=638&amp;indices%5B%5D=639&amp;indices%5B%5D=640&amp;indices%5B%5D=641&amp;indices%5B%5D=642&amp;indices%5B%5D=643&amp;indices%5B%5D=644&amp;indices%5B%5D=645&amp;indices%5B%5D=646&amp;indices%5B%5D=647&amp;indices%5B%5D=648&amp;indices%5B%5D=649&amp;indices%5B%5D=650&amp;indices%5B%5D=651&amp;indices%5B%5D=652&amp;indices%5B%5D=653&amp;indices%5B%5D=654&amp;indices%5B%5D=655&amp;indices%5B%5D=656&amp;indices%5B%5D=657&amp;indices%5B%5D=658&amp;indices%5B%5D=659&amp;indices%5B%5D=660&amp;indices%5B%5D=661&amp;indices%5B%5D=662&amp;indices%5B%5D=663&amp;indices%5B%5D=664&amp;indices%5B%5D=665&amp;indices%5B%5D=666&amp;indices%5B%5D=667&amp;indices%5B%5D=668&amp;indices%5B%5D=669&amp;indices%5B%5D=670&amp;indices%5B%5D=671&amp;indices%5B%5D=672&amp;indices%5B%5D=673&amp;indices%5B%5D=674&amp;indices%5B%5D=675&amp;indices%5B%5D=676&amp;indices%5B%5D=677&amp;indices%5B%5D=678&amp;indices%5B%5D=679&amp;indices%5B%5D=680&amp;indices%5B%5D=681&amp;indices%5B%5D=682&amp;indices%5B%5D=683&amp;indices%5B%5D=684&amp;indices%5B%5D=685&amp;indices%5B%5D=686&amp;indices%5B%5D=687&amp;indices%5B%5D=688&amp;indices%5B%5D=689&amp;indices%5B%5D=690&amp;indices%5B%5D=691&amp;indices%5B%5D=692&amp;indices%5B%5D=693&amp;indices%5B%5D=694&amp;indices%5B%5D=695&amp;indices%5B%5D=696&amp;indices%5B%5D=697&amp;indices%5B%5D=698"">
<frame src=""mailbox.php?page=1&amp;actionID=expunge_mailbox"">
<frame src=""mailbox.php?page=1&amp;actionID=expunge_mailbox"">
<frame src=""mailbox.php?page=1&amp;actionID=expunge_mailbox"">
<frame src=""mailbox.php?page=1&amp;actionID=expunge_mailbox"">
<frame src=""http://secunia.com/"">
</frameset>
EOT;

        // Format: Input, expected
        return array(
            array('<SCRIPT SRC=http://ha.ckers.org/xss.js></SCRIPT>', ''),
            array('<IMG SRC=""javascript:alert(\'XSS\');"">', '<img/>'),
            array('<IMG SRC=javascript:alert(\'XSS\')>', '<img/>'),
            array('<IMG SRC=JaVaScRiPt:alert(\'XSS\')>', '<img/>'),
            array('<IMG SRC=javascript:alert(&quot;XSS&quot;)>', '<img/>'),
            array('<IMG SRC=`javascript:alert(""RSnake says, \'XSS\'"")`>', '<img says=""""/>'),
            array('<IMG """"""><SCRIPT>alert(""XSS"")</SCRIPT>"">', '<img/>""&gt;'),
            array('<IMG SRC=javascript:alert(String.fromCharCode(88,83,83))>', '<img/>'),
            array('<IMG SRC=&#106;&#97;&#118;&#97;&#115;&#99;&#114;&#105;&#112;&#116;&#58;&#97;&#108;&#101;&#114;&#116;&#40;&#39;&#88;&#83;&#83;&#39;&#41>', '<img/>'),
            array('<IMG SRC=&#0000106&#0000097&#0000118&#0000097&#0000115&#0000099&#0000114&#0000105&#0000112&#0000116&#0000058&#0000097&#0000108&#0000101&#0000114&#0000116&#0000040&#0000039&#0000088&#0000083&#0000083&#0000039&#0000041>', '<img/>'),
            array('<IMG SRC=&#x6A&#x61&#x76&#x61&#x73&#x63&#x72&#x69&#x70&#x74&#x3A&#x61&#x6C&#x65&#x72&#x74&#x28&#x27&#x58&#x53&#x53&#x27&#x29>', '<img/>'),
            array('<IMG SRC=""jav	ascript:alert(\'XSS\');"">', '<img/>'),
            array('<IMG SRC=""jav&#x09;ascript:alert(\'XSS\');"">', '<img/>'),
            array('<IMG SRC=""jav&#x0A;ascript:alert(\'XSS\');"">', '<img/>'),
            array('<IMG SRC=""jav&#x0D;ascript:alert(\'XSS\');"">', '<img/>'),
            array(""<IMG\nSRC\n=\nj\na\nv\na\ns\nc\nr\ni\np\nt\n:\na\nl\ne\nr\nt\n(\n'\nX\nS\nS\n'\n)\n\""\n>"", '<img src=""j"" a="""" v="""" s="""" c="""" r="""" i="""" p="""" t="""" :="""" l="""" e="""" x=""""/>'),
            /* Disable these. Handling broke/change as of PHP 5.6.8, 5.5.24,
             * and 5.4.40 (https://bugs.php.net/bug.php?id=69353). */
            //array(""<IMG SRC=java\0script:alert(\""XSS\"")>"", '<img src=""java""/>'),
            //array(""<SCR\0IPT>alert(\""XSS\"")</SCR\0IPT>"", '<scr/>'),
            array('<IMG SRC="" &#14;  javascript:alert(\'XSS\');"">', '<img src="" ""/>'),
            array('<SCRIPT/XSS SRC=""http://ha.ckers.org/xss.js""></SCRIPT>', ''),
            array('<BODY onload!#$%&()*~+-_.,:;?@[/|\]^`=alert(""XSS"")>', ''),
            array('<SCRIPT/SRC=""http://ha.ckers.org/xss.js""></SCRIPT>', ''),
            array('<<SCRIPT>alert(""XSS"");//<</SCRIPT>', '<p>alert(""XSS"");//</p>'),
            array('<SCRIPT SRC=http://ha.ckers.org/xss.js?<B>', ''),
            array('<SCRIPT SRC=//ha.ckers.org/.j>', ''),
            array('<IMG SRC=""javascript:alert(\'XSS\')""', '<img/>'),
            array('<iframe src=http://ha.ckers.org/scriptlet.html <', ''),
            array(""<SCRIPT>a=/XSS/\nalert(a.source)</SCRIPT>"", ''),
            array('</TITLE><SCRIPT>alert(""XSS"");</SCRIPT>', ''),
            array('<INPUT TYPE=""IMAGE"" SRC=""javascript:alert(\'XSS\');"">', '<input type=""IMAGE""/>'),
            array('<BODY BACKGROUND=""javascript:alert(\'XSS\')"">', ''),
            array('<BODY ONLOAD=alert(\'XSS\')>', ''),
            array('<IMG DYNSRC=""javascript:alert(\'XSS\')"">', '<img/>'),
            array('<IMG LOWSRC=""javascript:alert(\'XSS\')"">', '<img/>'),
            array('<BGSOUND SRC=""javascript:alert(\'XSS\');"">', ''),
            array('<BR SIZE=""&{alert(\'XSS\')}"">', '<br/>'),
            array('<LAYER SRC=""http://ha.ckers.org/scriptlet.html""></LAYER>', ''),
            array('<LINK REL=""stylesheet"" HREF=""javascript:alert(\'XSS\');"">', ''),
            array('<LINK REL=""stylesheet"" HREF=""http://ha.ckers.org/xss.css"">', ''),
            array('<STYLE>@import\'http://ha.ckers.org/xss.css\';</STYLE>', ''),
            array('<META HTTP-EQUIV=""Link"" Content=""<http://ha.ckers.org/xss.css>; REL=stylesheet"">', ''),
            array('<STYLE>BODY{-moz-binding:url(""http://ha.ckers.org/xssmoz.xml#xss"")}</STYLE>', ''),
            array('<XSS STYLE=""behavior: url(xss.htc);"">', '<xss/>'),
            array('<STYLE>li {list-style-image: url(""javascript:alert(\'XSS\')"");}</STYLE><UL><LI>XSS', '<ul><li>XSS</li></ul>'),
            array('<IMG SRC=\'vbscript:msgbox(""XSS"")\'>', '<img/>'),
            array('<IMG SRC=""mocha:[code]"">', '<img/>'),
            array('<IMG SRC=""livescript:[code]"">', '<img/>'),
            array('<META HTTP-EQUIV=""refresh"" CONTENT=""0;url=javascript:alert(\'XSS\');"">', ''),
            array('<META HTTP-EQUIV=""refresh"" CONTENT=""0;url=data:text/html;base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K"">', ''),
            array('<META HTTP-EQUIV=""refresh"" CONTENT=""0; URL=http://;URL=javascript:alert(\'XSS\');"">', ''),
            array('<IFRAME SRC=javascript:alert(\'XSS\')></IFRAME>', ''),
            array('<FRAMESET><FRAME SRC=javascript:alert(\'XSS\')></FRAME></FRAMESET>', ''),
            array('<TABLE BACKGROUND=""javascript:alert(\'XSS\')"">', '<table/>'),
            array('<TABLE><TD BACKGROUND=""javascript:alert(\'XSS\')"">', '<table><td/></table>'),
            array('<DIV STYLE=""background-image: url(javascript:alert(\'XSS\'))"">', '<div/>'),
            array('<DIV STYLE=""background-image:\0075\0072\006C\0028\'\006a\0061\0076\0061\0073\0063\0072\0069\0070\0074\003a\0061\006c\0065\0072\0074\0028.1027\0058.1053\0053\0027\0029\'\0029"">', '<div/>'),
            array('<DIV STYLE=""background-image: url(&#1;javascript:alert(\'XSS\'))"">', '<div/>'),
            array('<DIV STYLE=""width: expression(alert(\'XSS\'));"">', '<div/>'),
            array('<STYLE>@im\port\'\ja\vasc\ript:alert(""XSS"")\';</STYLE>', ''),
            array('<IMG STYLE=""xss:expr/*XSS*/ession(alert(\'XSS\'))"">', '<img/>'),
            array('<XSS STYLE=""xss:expression(alert(\'XSS\'))"">', '<xss/>'),
            array(""exp/*<A STYLE='no\xss:noxss(\""*//*\"");\nxss:&#101;x&#x2F;*XSS*//*/*/pression(alert(\""XSS\""))'>"", '<p>exp/*<a/></p>'),
            array('<STYLE TYPE=""text/javascript"">alert(\'XSS\');</STYLE>', ''),
            // This test fails on Travis for some reason. It returns an
            // empty string. There is nothing malicious about the A
            // tag in and of itself.
            // array('<STYLE>.XSS{background-image:url(""javascript:alert(\'XSS\')"");}</STYLE><A CLASS=XSS></A>', '<a class=""XSS""/>'),
            array('<STYLE>.XSS{background-image:url(""javascript:alert(\'XSS\')"");}</STYLE>', ''),
            array('<STYLE type=""text/css"">BODY{background:url(""javascript:alert(\'XSS\')"")}</STYLE>', ''),
            array(""<!--[if gte IE 4]>\n<SCRIPT>alert('XSS');</SCRIPT>\n<![endif]-->"", ''),
            array('<BASE HREF=""javascript:alert(\'XSS\');//"">', ''),
            array('<OBJECT TYPE=""text/x-scriptlet"" DATA=""http://ha.ckers.org/scriptlet.html""></OBJECT>', ''),
            array('<OBJECT classid=clsid:ae24fdae-03c6-11d1-8b76-0080c744f389><param name=url value=javascript:alert(\'XSS\')></OBJECT>', ''),
            array('<EMBED SRC=""http://ha.ckers.org/xss.swf"" AllowScriptAccess=""always""></EMBED>', ''),
            array('<EMBED SRC=""data:image/svg+xml;base64,PHN2ZyB4bWxuczpzdmc9Imh0dH A6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcv MjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hs aW5rIiB2ZXJzaW9uPSIxLjAiIHg9IjAiIHk9IjAiIHdpZHRoPSIxOTQiIGhlaWdodD0iMjAw IiBpZD0ieHNzIj48c2NyaXB0IHR5cGU9InRleHQvZWNtYXNjcmlwdCI+YWxlcnQoIlh TUyIpOzwvc2NyaXB0Pjwvc3ZnPg=="" type=""image/svg+xml"" AllowScriptAccess=""always""></EMBED>', ''),
            array(""<HTML xmlns:xss>\n<?import namespace=\""xss\"" implementation=\""http://ha.ckers.org/xss.htc\"">\n<xss:xss>XSS</xss:xss>\n</HTML>"", '<xss>XSS</xss>'),
            array(""<XML ID=I><X><C><![CDATA[<IMG SRC=\""javas]]><![CDATA[cript:alert('XSS');\"">]]>\n</C></X></xml><SPAN DATASRC=#I DATAFLD=C DATAFORMATAS=HTML></SPAN>"", '<span datasrc=""#I"" datafld=""C"" dataformatas=""HTML""/>'),
            array(""<XML ID=\""xss\""><I><B>&lt;IMG SRC=\""javas<!-- -->cript:alert('XSS')\""&gt;</B></I></XML>\n<SPAN DATASRC=\""#xss\"" DATAFLD=\""B\"" DATAFORMATAS=\""HTML\""></SPAN>"", '<span datasrc=""#xss"" datafld=""B"" dataformatas=""HTML""/>'),
            array(""<XML SRC=\""xsstest.xml\"" ID=I></XML>\n<SPAN DATASRC=#I DATAFLD=C DATAFORMATAS=HTML></SPAN>"", '<span datasrc=""#I"" datafld=""C"" dataformatas=""HTML""/>'),
            array(""<HTML><BODY><?xml:namespace prefix=\""t\"" ns=\""urn:schemas-microsoft-com:time\""><?import namespace=\""t\"" implementation=\""#default#time2\"">\n<t:set attributeName=\""innerHTML\"" to=\""XSS&lt;SCRIPT DEFER&gt;alert(&quot;XSS&quot;)&lt;/SCRIPT&gt;\""></BODY></HTML>"", ""<?xml:namespace prefix=\""t\"" ns=\""urn:schemas-microsoft-com:time\""?><?import namespace=\""t\"" implementation=\""#default#time2\""?>""),
            array('<SCRIPT SRC=""http://ha.ckers.org/xss.jpg""><SCRIPT>', ''),
            array('<IMG SRC=""javascript:alert(\'XSS\')""', '<img/>'),
            array('<SCRIPT a="">"" SRC=""http://xss.com/a.js""></SCRIPT>', ''),
            array('<SCRIPT ="">"" SRC=""http://xss.com/a.js""></SCRIPT>', ''),
            array('<SCRIPT a="">"" \'\' SRC=""http://xss.com/a.js""></SCRIPT>', ''),
            array('<SCRIPT ""a=\'>\'"" SRC=""http://xss.com/a.js""></SCRIPT>', ''),
            array('<SCRIPT a=`>` SRC=""http://ha.ckers.org/xss.js""></SCRIPT>', ''),
            array('<SCRIPT a="">\'>"" SRC=""http://ha.ckers.org/xss.js""></SCRIPT>', ''),
            array('<SCRIPT>document.write(""<SCRI"");</SCRIPT>PT SRC=""http://ha.ckers.org/a.js""></SCRIPT>', '<p>PT SRC=""http://ha.ckers.org/a.js""&gt;</p>'),
            array('<a href=""data:text/html;base64,PGh0bWw+PGhlYWQ+PHRpdGxlPnRlc3Q8L3RpdGxlPjwvaGVhZD48Ym9keT48c2NyaXB0PmFsZXJ0KCd4c3M6ICcgKyBkb2N1bWVudC5jb29raWUpPC9zY3JpcHQ+PC9ib2R5PjwvaHRtbD4="" href=""data:text/html;base64,PGh0bWw+PGhlYWQ+PHRpdGxlPnRlc3Q8L3RpdGxlPjwvaGVhZD48Ym9keT48c2NyaXB0PmFsZXJ0KCd4c3M6ICcgKyBkb2N1bWVudC5jb29raWUpPC9zY3JpcHQ+PC9ib2R5PjwvaHRtbD4="">Click me</a>', '<a>Click me</a>'),
            array('<a href=""data:text/html;base64,PGh0bWw+PGhlYWQ+PHRpdGxlPnRlc3Q8L3RpdGxlPjwvaGVhZD48Ym9keT48c2NyaXB0PmFsZXJ0KCd4c3M6ICcgKyBkb2N1bWVudC5jb29raWUpPC9zY3JpcHQ+PC9ib2R5PjwvaHRtbD4="">Click me</a>', '<a>Click me</a>'),
            array('<body/onload=alert(/xss/)>', ''),
            array('<img src=""""> <BODY ONLOAD=""a();""><SCRIPT>function a(){alert(\'XSS\');}</SCRIPT><"""" />', '<img src=""""/>'),
            array('<img src=\'blank.jpg\'style=\'width:expression(alert(""xssed""))\'>', '<img src=""blank.jpg""/>'),
            array($framedata, '')
        );
    }

    public function testStyleXss()
    {
        $tests = array(
            '<BASE HREF=""javascript:alert(\'XSS\');//"">' => ''
        );

        foreach ($tests as $key => $val) {
            $this->assertEquals(
                $val,
                Horde_Text_Filter::filter($key, 'xss', array(
                    'strip_styles' => false
                ))
            );
        }
    }

    public function testBug9567()
    {
        $text = quoted_printable_decode(
            ""pr=E9parer =E0 vendre d\342\200\231ao=FBt""
        );

        $this->assertEquals(
            $text,
            Horde_Text_Filter::filter('<html><body>' . $text . '</body></html>', 'xss', array(
                'charset' => 'iso-8859-1'
            ))
        );

        $this->assertEquals(
            $text,
            Horde_Text_Filter::filter('<html><head><meta http-equiv=""Content-Type"" content=""text/html; charset=iso-8859-1""></head><body>' . $text . '</body></html>', 'xss', array(
                'charset' => 'iso-8859-1'
            ))
        );

        $text = Horde_String::convertCharset(quoted_printable_decode(
            ""pr=E9parer =E0 vendre d&#8217;ao=FBt&nbsp;;""
        ), 'windows-1252', 'UTF-8');
        $expected = ""pr\303\251parer \303\240 vendre d\342\200\231ao\303\273t\302\240;"";

        $this->assertEquals(
            $expected,
            Horde_Text_Filter::filter('<html><body>' . $text . '</body></html>', 'xss', array(
                'charset' => 'utf-8'
            ))
        );
    }

}
",CWE-79,196.0,1
"# Fail2Ban configuration file
#
# Author: Cyril Jaquier
#
#

[Definition]

# Option:  failregex
# Notes.:  regex to match the password failures messages in the logfile. The
#          host must be matched by a group named ""host"". The tag ""<HOST>"" can
#          be used for standard IP/hostname matching and is only an alias for
#          (?:::f{4,6}:)?(?P<host>[\w\-.^_]+)
# Values:  TEXT
#
failregex = reject: RCPT from (.*)\[<HOST>\]: 554
            reject: RCPT from (.*)\[<HOST>\]: 450 4\.7\.1 : Helo command rejected: Host not found; from=<> to=<> proto=ESMTP helo= *$

# Option:  ignoreregex
# Notes.:  regex to ignore. If this regex matches, the line is ignored.
# Values:  TEXT
#
ignoreregex = 
",CWE-20,24.0,1
"# Fail2Ban configuration file
#
# Author: Jan Wagner <waja@cyconet.org>
#
#

[Definition]

# Option:  failregex
# Notes.:  regex to match the password failures messages in the logfile. The
#          host must be matched by a group named ""host"". The tag ""<HOST>"" can
#          be used for standard IP/hostname matching and is only an alias for
#          (?:::f{4,6}:)?(?P<host>[\w\-.^_]+)
# Values:  TEXT
#
failregex = : badlogin: .*\[<HOST>\] plaintext .*SASL\(-13\): authentication failure: checkpass failed$
	    : badlogin: .*\[<HOST>\] LOGIN \[SASL\(-13\): authentication failure: checkpass failed\]$
	    : badlogin: .*\[<HOST>\] (?:CRAM-MD5|NTLM) \[SASL\(-13\): authentication failure: incorrect (?:digest|NTLM) response\]$
	    : badlogin: .*\[<HOST>\] DIGEST-MD5 \[SASL\(-13\): authentication failure: client response doesn't match what we generated\]$

# Option:  ignoreregex
# Notes.:  regex to ignore. If this regex matches, the line is ignored.
# Values:  TEXT
#
ignoreregex = 
",CWE-20,26.0,1
"# Read about fixtures at http://ar.rubyonrails.org/classes/Fixtures.html

# This model initially had no columns defined.  If you add columns to the
# model remove the '{}' from the fixture names and add the columns immediately
# below each fixture, per the syntax in the comments below
#
one:
  taxonomy: location1
  taxable: one
  taxable_type: ""Subnet""

two:
  taxonomy: location1
  taxable: one
  taxable_type: ""SmartProxy""

three:
  taxonomy: organization1
  taxable: one
  taxable_type: ""Subnet""

four:
  taxonomy: organization1
  taxable: one
  taxable_type: ""SmartProxy""

five:
  taxonomy: location1
  taxable: production
  taxable_type: ""Environment""

six:
  taxonomy: organization1
  taxable: production
  taxable_type: ""Environment""

seven:
  taxonomy: location1
  taxable: mydomain
  taxable_type: ""Domain""

eight:
  taxonomy: location1
  taxable: yourdomain
  taxable_type: ""Domain""

eight2:
  taxonomy: organization1
  taxable: yourdomain
  taxable_type: ""Domain""

nine:
  taxonomy: organization1
  taxable: mydomain
  taxable_type: ""Domain""

ten:
  taxonomy: location1
  taxable: one
  taxable_type: ""Medium""

ten2:
  taxonomy: organization1
  taxable: one
  taxable_type: ""Medium""

eleven:
  taxonomy: location1
  taxable: one
  taxable_type: ""ComputeResource""

twelve:
  taxonomy: organization1
  taxable: one
  taxable_type: ""ComputeResource""

thirteen:
  taxonomy: location1
  taxable: mystring2
  taxable_type: ""Template""

fourteen:
  taxonomy: organization1
  taxable: mystring2
  taxable_type: ""Template""

fifteen:
  taxonomy: location1
  taxable: two
  taxable_type: ""SmartProxy""

sixteen:
  taxonomy: organization1
  taxable: two
  taxable_type: ""SmartProxy""

seventeen:
  taxonomy: location1
  taxable: three
  taxable_type: ""SmartProxy""

eighteen:
  taxonomy: organization1
  taxable: three
  taxable_type: ""SmartProxy""

nineteen:
  taxonomy: location1
  taxable: puppetmaster
  taxable_type: ""SmartProxy""

twenty:
  taxonomy: organization1
  taxable: puppetmaster
  taxable_type: ""SmartProxy""

twentyone:
  taxonomy: location1
  taxable: realm
  taxable_type: ""SmartProxy""

twentytwo:
  taxonomy: organization1
  taxable: realm
  taxable_type: ""SmartProxy""

twentythree:
  taxonomy: location1
  taxable: myrealm
  taxable_type: Realm

twentyfour:
  taxonomy: organization1
  taxable: myrealm
  taxable_type: Realm

twentyfive:
  taxonomy: organization1
  taxable: Location 1
  taxable_type: Taxonomy

twentysix:
  taxonomy: organization2
  taxable: Location 2
  taxable_type: Taxonomy

scoped_user_organization1:
  taxonomy: organization1
  taxable: scoped
  taxable_type: User

scoped_user_location1:
  taxonomy: location1
  taxable: scoped
  taxable_type: User
",CWE-200,156.0,1
"# -*- coding: utf-8 -*-
from pysqlite2 import dbapi2 as sqlite3
import os.path

class mod_fun(object):
    def __init__(self,parent,config):
        self.config = config
        self.parent = parent
        parent.register_callback(u'!snack', self.snack, 'Several small fuckups')
        for key in config['items'].keys():
            words = config['items'][key]
            parent.register_callback('+%s'%key,self.factory('+',key, words),config['help']+"" (%s verweist auf %s)"" % (key, config['items'][key]))
            parent.register_callback('-%s'%key,self.factory('-',key, words),config['help']+"" (%s verweist auf %s)"" % (key, config['items'][key]))
            parent.register_callback('?%s'%key,self.factory('?',key, words),config['help']+"" (%s verweist auf %s)"" % (key, config['items'][key]))
        #parent.register_callback('+keks',self.keks,u'Verschenke einen Keks!')
        #parent.register_callback('-keks',self.klauen,u'Klaue jemanden einen Keks!')
        #parent.register_callback('?keks',self.readkeks,u'Sieh nach wieviele Kekse jemand hat.')
        
        dbpath = os.path.join(os.path.dirname(__file__), config['dbpath']).replace('\\','/')
        self.connectDB(dbpath)
        
    def factory(self, cmd, name, words):
        if (cmd=='+'):
            func = self.geben
        elif (cmd=='-'):
            func = self.klauen
        else:
            func = self.lesen
        def rss_func(params):
            func(params, name, words)
        return rss_func

    def connectDB(self, dbpath):
        self.parent.print_notice(""SQLite-Database: ""+dbpath)
        self.DBconn = sqlite3.connect(dbpath)
        self.DBcursor = self.DBconn.cursor()

    def snack(self, params):
        self.parent.privmsg(u':)', params.channel)

    def geben(self, params, name, words):
        if (self.check_name(params.args[0], params.channel)):
            return
        if len(params.args) == 1:
            if params.target == params.args[0]:
                keks = self.aendern(params.target, 0, name)
                self.parent.privmsg(u'Sei nicht so selbstschtig! Du hast bereits %i %s.' % (keks, words['plural']), params.channel)
                return
            keks = self.aendern(params.args[0], 1, name)
            self.parent.privmsg(u'%s hat jetzt %i %s.' % (params.args[0], keks, words['plural']), params.channel)
        else:
            self.parent.privmsg(u'hast du nicht was vergessen? (Du hast %i %s)' % (self.aendern(params.target, 0, name), words['plural']), params.channel)
    
    def klauen(self, params, name, words):
        if (self.check_name(params.args[0], params.channel)):
            return
        if len(params.args) == 1:
            if params.target == params.args[0]:
                self.parent.privmsg(u'Du klaust dir selber 1 %s. Das war eine drastische nderung. NICHT!' % words['singular'], params.channel)
                return
            keks = self.aendern(params.args[0], -1, name)
            if (keks!=-999):
                keks2 = self.aendern(params.target, 1, name)
                if (keks == 0):
                    self.parent.privmsg(u'Na toll, du hast %s allerletztes %s geklaut. Du hast jetzt %i %s.' % (params.args[0], words['singular'], keks2, words['plural']), params.channel)
                else:
                    self.parent.privmsg(u'Du klaust %s einen %s (hat jetzt %i). Du hast jetzt %i %s' % (params.args[0], words['singular'], keks, keks2, words['plural']), params.channel)
            else:
                self.parent.privmsg(u'Geht nicht!', params.channel)
        else:
            self.parent.privmsg(u'hast du nicht was vergessen?', params.channel)
    
    def aendern(self, name, amount, item):
        keks = self.DBcursor.execute(u""SELECT nickname, count from kekse WHERE nickname like '%s' AND item =='%s' LIMIT 1"" % (name, item)).fetchall()
        if(len(keks)>0 and len(keks[0]) > 1):
            keks = keks[0][1]
            if amount == 0:
                return keks
            keks2 = keks+amount
            if (keks2 >= 1):
                self.DBcursor.execute(u""UPDATE kekse set count=? WHERE item==? AND nickname like ?"", (keks2, item, name))
                self.DBconn.commit()
                return keks2
            else:
                self.DBcursor.execute(u""UPDATE kekse set count=? WHERE nickname like ? AND item==?"", (0, name, item))
                self.DBconn.commit()
                if keks>0:
                    return 0
                return -999
        else:
            if (amount >= 0):
                self.DBcursor.execute(u""INSERT INTO kekse (nickname, count, item) VALUES (?, ?, ?)"", (name, amount, item))
                self.DBconn.commit()
                return amount
            else:
                return -999;
    
    def lesen(self, params, name, words):
        if len(params.args) == 1:
            keks = 0
            anrede = u""Du hast""
            if params.args[0]==params.target:
                keks = self.aendern(params.target, 0, name)
            else:
                keks = self.aendern(params.args[0],0, name)
                anrede=u""%s hat"" % params.args[0]
            self.parent.privmsg(u""%s %i %s."" % (anrede, keks, words['plural']), params.channel)
        elif len(params.args) == 0:
            keks = self.DBcursor.execute(u""SELECT `nickname`, `count` from kekse WHERE item=='%s' AND `count`>=1 ORDER BY `count` DESC LIMIT 10"" % (name)).fetchall()
            if len(keks) <= 0:
                self.parent.privmsg(u""Es gibt noch keine %s?"" % words['plural'], params.channel)
                return
            kekst = u""[Top-%s-Sammler] "" % words['singular']
            first = True
            for keksi in keks:
                if len(keksi) > 1:
                    if first:
                        kekst += u""%s hat %i"" % keksi
                        first = False
                    else:
                        kekst += u"", %s hat %i"" %keksi
            self.parent.privmsg(kekst, params.channel)
        else:
            self.parent.privmsg(u""Ich hab keine Ahnung was du mir damit sagen willst..."", params.channel)
            return

    def check_name(self, target, channel):
        valid_names = self.parent.channels[channel]
        invalid = target not in valid_names
        if (invalid):
            self.parent.privmsg(u'%s ist gar nicht hier...' % target, channel)
        return invalid",CWE-89,132.0,1
"# -*- coding: ascii -*-
#
#  FortunaAccumulator.py : Fortuna's internal accumulator
#
# Written in 2008 by Dwayne C. Litzenberger <dlitz@dlitz.net>
#
# ===================================================================
# The contents of this file are dedicated to the public domain.  To
# the extent that dedication to the public domain is not available,
# everyone is granted a worldwide, perpetual, royalty-free,
# non-exclusive license to exercise all rights associated with the
# contents of this file for any purpose whatsoever.
# No rights are reserved.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# ===================================================================

__revision__ = ""$Id$""

import sys
if sys.version_info[0] == 2 and sys.version_info[1] == 1:
    from Crypto.Util.py21compat import *
from Crypto.Util.py3compat import *
    
from binascii import b2a_hex
import time
import warnings

from Crypto.pct_warnings import ClockRewindWarning
import SHAd256

import FortunaGenerator

class FortunaPool(object):
    """"""Fortuna pool type

    This object acts like a hash object, with the following differences:

        - It keeps a count (the .length attribute) of the number of bytes that
          have been added to the pool
        - It supports a .reset() method for in-place reinitialization
        - The method to add bytes to the pool is .append(), not .update().
    """"""

    digest_size = SHAd256.digest_size

    def __init__(self):
        self.reset()

    def append(self, data):
        self._h.update(data)
        self.length += len(data)

    def digest(self):
        return self._h.digest()

    def hexdigest(self):
        if sys.version_info[0] == 2:
            return b2a_hex(self.digest())
        else:
            return b2a_hex(self.digest()).decode()

    def reset(self):
        self._h = SHAd256.new()
        self.length = 0

def which_pools(r):
    """"""Return a list of pools indexes (in range(32)) that are to be included during reseed number r.

    According to _Practical Cryptography_, chapter 10.5.2 ""Pools"":

        ""Pool P_i is included if 2**i is a divisor of r.  Thus P_0 is used
        every reseed, P_1 every other reseed, P_2 every fourth reseed, etc.""
    """"""
    # This is a separate function so that it can be unit-tested.
    assert r >= 1
    retval = []
    mask = 0
    for i in range(32):
        # ""Pool P_i is included if 2**i is a divisor of [reseed_count]""
        if (r & mask) == 0:
            retval.append(i)
        else:
            break   # optimization.  once this fails, it always fails
        mask = (mask << 1) | 1L
    return retval

class FortunaAccumulator(object):

    min_pool_size = 64      # TODO: explain why
    reseed_interval = 0.100   # 100 ms    TODO: explain why

    def __init__(self):
        self.reseed_count = 0
        self.generator = FortunaGenerator.AESGenerator()
        self.last_reseed = None

        # Initialize 32 FortunaPool instances.
        # NB: This is _not_ equivalent to [FortunaPool()]*32, which would give
        # us 32 references to the _same_ FortunaPool instance (and cause the
        # assertion below to fail).
        self.pools = [FortunaPool() for i in range(32)]     # 32 pools
        assert(self.pools[0] is not self.pools[1])

    def random_data(self, bytes):
        current_time = time.time()
        if (self.last_reseed is not None and self.last_reseed > current_time): # Avoid float comparison to None to make Py3k happy
            warnings.warn(""Clock rewind detected. Resetting last_reseed."", ClockRewindWarning)
            self.last_reseed = None
        if (self.pools[0].length >= self.min_pool_size and
            (self.last_reseed is None or
             current_time > self.last_reseed + self.reseed_interval)):
            self._reseed(current_time)
        # The following should fail if we haven't seeded the pool yet.
        return self.generator.pseudo_random_data(bytes)

    def _reseed(self, current_time=None):
        if current_time is None:
            current_time = time.time()
        seed = []
        self.reseed_count += 1
        self.last_reseed = current_time
        for i in which_pools(self.reseed_count):
            seed.append(self.pools[i].digest())
            self.pools[i].reset()

        seed = b("""").join(seed)
        self.generator.reseed(seed)

    def add_random_event(self, source_number, pool_number, data):
        assert 1 <= len(data) <= 32
        assert 0 <= source_number <= 255
        assert 0 <= pool_number <= 31
        self.pools[pool_number].append(bchr(source_number))
        self.pools[pool_number].append(bchr(len(data)))
        self.pools[pool_number].append(data)

# vim:set ts=4 sw=4 sts=4 expandtab:
",CWE-310,146.0,1
"# -*- coding: utf-8 -*-
#
#  SelfTest/Random/__init__.py: Self-test for random number generation modules
#
# Written in 2008 by Dwayne C. Litzenberger <dlitz@dlitz.net>
#
# ===================================================================
# The contents of this file are dedicated to the public domain.  To
# the extent that dedication to the public domain is not available,
# everyone is granted a worldwide, perpetual, royalty-free,
# non-exclusive license to exercise all rights associated with the
# contents of this file for any purpose whatsoever.
# No rights are reserved.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# ===================================================================

""""""Self-test for random number generators""""""

__revision__ = ""$Id$""

def get_tests(config={}):
    tests = []
    from Crypto.SelfTest.Random import Fortuna;             tests += Fortuna.get_tests(config=config)
    from Crypto.SelfTest.Random import OSRNG;               tests += OSRNG.get_tests(config=config)
    from Crypto.SelfTest.Random import test_random;         tests += test_random.get_tests(config=config)
    from Crypto.SelfTest.Random import test_rpoolcompat;    tests += test_rpoolcompat.get_tests(config=config)
    return tests

if __name__ == '__main__':
    import unittest
    suite = lambda: unittest.TestSuite(get_tests())
    unittest.main(defaultTest='suite')

# vim:set ts=4 sw=4 sts=4 expandtab:
",CWE-310,43.0,1
,CWE-310,,1
"import os
import os.path
import mimetypes

import requests
from zope.interface import implements
from pyramid.interfaces import ITemplateRenderer


class ReleaseFileRenderer(object):
    implements(ITemplateRenderer)

    def __init__(self, repository_root):
        self.repository_root = repository_root

    def __call__(self, value, system):

        if 'request' in system:
            request = system['request']

            mime, encoding = mimetypes.guess_type(value['filename'])
            request.response_content_type = mime
            if encoding:
                request.response_encoding = encoding

            f = os.path.join(self.repository_root,
                             value['filename'][0].lower(),
                             value['filename'])

            if not os.path.exists(f):
                dir_ = os.path.join(self.repository_root,
                             value['filename'][0].lower())
                if not os.path.exists(dir_):
                    os.makedirs(dir_, 0750)

                resp = requests.get(value['url'])
                with open(f, 'wb') as rf:
                    rf.write(resp.content)
                return resp.content
            else:
                data = ''
                with open(f, 'rb') as rf:
                    data = ''
                    while True:
                        content = rf.read(2<<16)
                        if not content:
                            break
                        data += content
                return data


def renderer_factory(info):
    return ReleaseFileRenderer(info.settings['pyshop.repository'])
",CWE-20,54.0,1
"# -*- coding: utf-8 -*-
from pyshop.models import DBSession, ReleaseFile


def get_release_file(root, request):
    session = DBSession()

    f = ReleaseFile.by_id(session, int(request.matchdict['file_id']))
    rv = {'id': f.id,
          'url': f.url,
          'filename': f.filename,
          }
    f.downloads += 1
    f.release.downloads += 1
    f.release.package.downloads += 1
    session.add(f.release.package)
    session.add(f.release)
    session.add(f)
    return rv
",CWE-20,20.0,1
,CWE-79,,1
,CWE-79,,1
"/*
 * Table of command-line options
 *
 * The first column specifies the short name, if any, or 0 if none.
 * The second column specifies the long name.
 * The third column specifies whether it takes a parameter.
 * The fourth column is the documentation.
 *
 * N.B. The long options' order must correspond to the code in file.c,
 * and OPTSTRING must be kept up-to-date with the short options.
 * Pay particular attention to the numbers of long-only options in the
 * switch statement!
 */

OPT_LONGONLY(""help"", 0, ""                 display this help and exit\n"")
OPT('v', ""version"", 0, ""              output version information and exit\n"")
OPT('m', ""magic-file"", 1, "" LIST      use LIST as a colon-separated list of magic\n""
    ""                               number files\n"")
OPT('z', ""uncompress"", 0, ""           try to look inside compressed files\n"")
OPT('b', ""brief"", 0, ""                do not prepend filenames to output lines\n"")
OPT('c', ""checking-printout"", 0, ""    print the parsed form of the magic file, use in\n""
    ""                               conjunction with -m to debug a new magic file\n""
    ""                               before installing it\n"")
OPT('e', ""exclude"", 1, "" TEST         exclude TEST from the list of test to be\n""
    ""                               performed for file. Valid tests are:\n""
    ""                               %o\n"")
OPT('f', ""files-from"", 1, "" FILE      read the filenames to be examined from FILE\n"")
OPT('F', ""separator"", 1, "" STRING     use string as separator instead of `:'\n"")
OPT('i', ""mime"", 0, ""                 output MIME type strings (--mime-type and\n""
    ""                               --mime-encoding)\n"")
OPT_LONGONLY(""apple"", 0, ""                output the Apple CREATOR/TYPE\n"")
OPT_LONGONLY(""mime-type"", 0, ""            output the MIME type\n"")
OPT_LONGONLY(""mime-encoding"", 0, ""        output the MIME encoding\n"")
OPT('k', ""keep-going"", 0, ""           don't stop at the first match\n"")
OPT('l', ""list"", 0, ""                 list magic strength\n"")
#ifdef S_IFLNK
OPT('L', ""dereference"", 0, ""          follow symlinks (default)\n"")
OPT('h', ""no-dereference"", 0, ""       don't follow symlinks\n"")
#endif
OPT('n', ""no-buffer"", 0, ""            do not buffer output\n"")
OPT('N', ""no-pad"", 0, ""               do not pad output\n"")
OPT('0', ""print0"", 0, ""               terminate filenames with ASCII NUL\n"")
#if defined(HAVE_UTIME) || defined(HAVE_UTIMES)
OPT('p', ""preserve-date"", 0, ""        preserve access times on files\n"")
#endif
OPT('P', ""parameter"", 0, ""            set file engine parameter limits\n""
    ""                               indir        15 recursion limit for indirection\n""
    ""                               name         30 use limit for name/use magic\n""
    ""                               elf_phnum   128 max ELF prog sections processed\n""
    ""                               elf_shnum 32768 max ELF sections processed\n"")
OPT('r', ""raw"", 0, ""                  don't translate unprintable chars to \\ooo\n"")
OPT('s', ""special-files"", 0, ""        treat special (block/char devices) files as\n""
    ""                             ordinary ones\n"")
OPT('C', ""compile"", 0, ""              compile file specified by -m\n"")
OPT('d', ""debug"", 0, ""                print debugging messages\n"")
",CWE-399,56.0,1
"from flask import Flask, render_template, request, session, redirect
import os, sys
import requests
import jwt

CLIENT_ID = 'valtech.idp.testclient.local'
CLIENT_SECRET = os.environ.get('CLIENT_SECRET')

if CLIENT_SECRET is None:
  print 'CLIENT_SECRET missing. Start using ""CLIENT_SECRET=very_secret_secret python main.py""'
  sys.exit(-1)

app = Flask(__name__, static_url_path='')

@app.route('/')
def index():
  signed_in = session.get('signed_in') != None
  header = 'Not signed in'
  text = 'Click the button below to sign in.'

  if signed_in:
    header = 'Welcome!'
    text = 'Signed in as %s.' % session['email']

  return render_template('index.html', header=header, text=text)

@app.route('/sign-in')
def sign_in():
  if session.get('signed_in') != None: return redirect('/')
  authorize_url = 'https://stage-id.valtech.com/oauth2/authorize?response_type=%s&client_id=%s&scope=%s' % ('code', CLIENT_ID, 'email openid')
  return redirect(authorize_url)

@app.route('/sign-in/callback')
def sign_in_callback():
  code = request.args.get('code')

  # as both scope openid and email was requested on authorize request above, the client
  # will receive both an access_token (according to OAuth 2) AND an id_token (according to OpenID Connect)
  tokens = exchange_code_for_tokens(code)

  # if the client only need authentication (and not authorization), the access token can be ignored
  # (but it is still possible to use it if client wants to, and is left here for documentation)
  #user_info = fetch_user_info(tokens['access_token'])

  # as this example app is only interested in who logged in, we will parse the id_token.
  # currently, IDP does not sign id_tokens, but as IDP uses https this is no problem
  # (but the id_token should not be passed around in plaintext where it can be modified by a man-in-the-middle)
  user_info = jwt.decode(tokens[""id_token""], verify=False)

  session['signed_in'] = True
  session['email'] = user_info['email']
  
  return redirect('/')

@app.route('/sign-out')
def sign_out():
  session.clear()
  return redirect('https://stage-id.valtech.com/oidc/end-session?client_id=%s' % CLIENT_ID)

def exchange_code_for_tokens(code):
  data = {
    'grant_type': 'authorization_code',
    'code': code,
    'client_id': CLIENT_ID,
    'client_secret': CLIENT_SECRET
  }

  res = requests.post('https://stage-id.valtech.com/oauth2/token', data=data)
  return res.json()

def fetch_user_info(access_token):
  res = requests.get('https://stage-id.valtech.com/api/users/me', headers={ 'Authorization': 'Bearer %s' % access_token })
  return res.json()

if __name__ == '__main__':
  app.secret_key = 'someverysecretkey'
  app.run(host='0.0.0.0', debug=True)
",CWE-352,78.0,1
"import logging
logger = logging.getLogger(__name__)

from bottle import route, get, post, put, delete
from bottle import request, response

def error(code, message):
    response.status = code
    message['status'] = code
    return message


get_user_table = lambda db: db.get_table('users', primary_id='userid', primary_type='String(100)')


@delete('/groups/<group_name>')
def delete_group(db, group_name):
    groups_table = db.get_table('groups')
    group = groups_table.find_one(name=group_name)
    if not group:
        return error(404, {'error': 'group not found'})
    else:
        groups_table.delete(name=group_name)
        return {'status': 200}


@get('/groups/<group_name>')
def get_group(db, group_name):
    groups_table = db.get_table('groups')
    group = groups_table.find(name=group_name)
    rows = [x for x in group]
    if not rows:
        return error(404, {'error': 'Not a valid group'})

    userids = [""'%s'"" % x['userid'] for x in rows if x['userid']]
    users = db.query(""SELECT * FROM users WHERE userid IN (%s) "" % ','.join(userids))
    ret = {group_name: list(users) }
    return ret


@route('/groups/<group_name>', method=['POST', 'PUT'])
def post_group(db, group_name):
    groups_table = db.get_table('groups')
    group_exist = groups_table.find_one(name=group_name)
    #CREATE
    if request.method=='POST':
        if group_exist:
            return error(409, {'error': 'Group already exists'})
        else:
            groups_table.insert(dict(name=group_name, userid=None))
            return {'status': 200}

    #UPDATE
    elif request.method == 'PUT':
        if not group_exist:
            return error(400, {'error': 'Group does not exist'})
        else:
            userids = request.json.get('userids')
            if not userids:
                return error(400, {'error': 'Need a userids key'})

            user_table = get_user_table(db)
            groups_table.delete(name=group_name)
            unknown_users = []
            for userid in userids:
                user = user_table.find_one(userid=userid)
                if not user:
                    unknown_users.append(userid)
                else:
                    groups_table.insert(dict(name=group_name, userid=userid))

            ret = {'status': 200}
            if unknown_users:
                ret = { 'status': 207, 'unknown_users': unknown_users }
            return ret
",CWE-89,76.0,1
"
import logging
logger = logging.getLogger(__name__)

from bottle import route, get, post, delete
from bottle import request, response


def error(code, message):
    response.status = code
    message['status'] = code
    return message


get_user_table = lambda db: db.get_table('users', primary_id='userid', primary_type='String(100)')

@get('/users/<userid>')
def get_user(db, userid):
    user_table = get_user_table(db)
    user = user_table.find_one(userid=userid)
    if not user: 
        return error(404, {'error': 'Not a valid user'})
    else: 
        group_table = db.get_table('groups')
        groups = group_table.distinct('name', userid=userid)
        user['groups'] =sorted( [x['name'] for x in groups] )
        return user

@delete('/users/<userid>')
def delete_user(db, userid):
    user_table = get_user_table(db)
    user = user_table.find_one(userid=userid)
    if not user:
        return error(404, {'error': 'userid not found'})
    else:
        user_table.delete(userid=userid)
        return {'status': 200}


@route('/users/<userid>', method=['POST', 'PUT'])
def create__update_user(db, userid):
    data = request.json
    data_keys = data.keys()
    required_fields = ['first_name', 'last_name', 'userid', 'groups']
    missing_fields = [x for x in required_fields if x not in data_keys]
    extra_fields = [x for x in data_keys if x not in required_fields]
    if missing_fields:
        return error(400, {'error': 'Missing fields (%s)' % (','.join(missing_fields)) })
    if extra_fields:
        return error(400, {'error': 'Extra fields (%s)' % (','.join(extra_fields)) })

    user_table = get_user_table(db)
    existing_user = user_table.find_one(userid=data['userid'])
    if request.method == 'POST' and existing_user:
        return error(409, {'error': 'User already exists'})
    if request.method == 'PUT' and not existing_user:
        return error(404, {'error': 'User does not exist'})

    #update this user's group membership
    userid = data.get('userid')
    groups = data.pop('groups')
    groups_table = db.get_table('groups')

    if request.method == 'POST':
        user_insert = user_table.insert(data)
    elif request.method == 'PUT':
        user_update = user_table.update(data, ['userid'])

    for name in groups:
        groups_table.upsert(dict(name=name, userid=userid), ['name','userid'])

    if request.method == 'PUT':
        #get rid of any old groups for this user
        q = '''DELETE FROM groups 
                WHERE userid='{userid}'
                            AND name not in ({group_names})
              '''.format(userid=userid, group_names=','.join([""'%s'"" % x for x in groups]))
        db.query(q)

    return {'status': 200, 'user': get_user(db, userid)}
",CWE-89,81.0,1
"import logging
logging.basicConfig(level=logging.DEBUG)
import json

from webtest import TestApp #Docs: http://webtest.pythonpaste.org/en/latest/
from auth import simpleauth


app = TestApp(simpleauth.app)

def test_users():
    headers = [('Content-type', 'application/json')]
    payload = { ""first_name"": ""Joe"",
	    ""last_name"": ""Smith"",
	    ""userid"": ""jsmith"",
	    ""groups"": [""admins"", ""users""] }


    #GET (test for error - user doesn't exist yet)
    get_user = app.get('/users/%s' % payload.get('userid'), status=404)
    user = get_user.json
    assert user.get('error')

    #POST
    create_user = app.post('/users/%s' % payload.get('userid'),
                              content_type='application/json',
                              headers=headers,
                              params=json.dumps(payload))
    
    user = create_user.json.get('user') if create_user.json else None

    assert user
    assert user.get('userid') == payload.get('userid')

    #GET
    get_user = app.get('/users/%s' % payload.get('userid'))
    user = get_user.json
    assert user
    assert sorted(user.get('groups')) == sorted(payload.get('groups'))
    
    #PUT
    payload['groups'] = ['admins', 'users', 'new']
    update_user = app.put('/users/%s' % payload.get('userid'),
                              content_type='application/json',
                              headers=headers,
                              params=json.dumps(payload))

    get_user = app.get('/users/%s' % payload.get('userid'))
    user = get_user.json
    assert user
    assert sorted(user.get('groups')) == sorted(payload.get('groups'))
    
    #DELETE
    delete_user = app.delete('/users/%s' % payload.get('userid'))
    assert delete_user.status == '200 OK'


def test_groups():
    headers = [('Content-type', 'application/json')]
    payload = { ""first_name"": ""Joe"",
        ""last_name"": ""Smith"",
        ""userid"": ""jsmith2"",
        ""groups"": [""admins"", ""users""] }

    create_user = app.post('/users/%s' % payload.get('userid'),
                          content_type='application/json',
                          headers=headers,
                          params=json.dumps(payload))

    user = create_user.json.get('user') if create_user.json else None

    assert user
    assert user.get('userid') == payload.get('userid')

    for group in payload.get('groups'):
        resp = app.get('/groups/%s' % group)
        group_resp = resp.json
        assert group_resp
        assert group in group_resp

    app.delete('/groups/admins')
    app.get('/groups/admins', status=404)
    app.post('/groups/admins')
    app.get('/groups/admins', status=200)

    group_payload = {""userids"": [payload.get('userid')]}
    update_groups = app.put('/groups/admins',
                                                 content_type='application/json',
                                                  headers=headers,
                                                  params=json.dumps(group_payload))
    assert update_groups.json.get('status') == 200

    get_user = app.get('/users/%s' % payload.get('userid'))
    user = get_user.json
    assert 'admins' in user.get('groups')
    delete_user = app.delete('/users/%s' % payload.get('userid'))
",CWE-89,97.0,1
,CWE-89,,1
"# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

from django.template import defaultfilters
from django.utils.translation import ugettext_lazy as _

from horizon import messages
from horizon import tables

from openstack_dashboard import api


ENABLE = 0
DISABLE = 1


class CreateUserLink(tables.LinkAction):
    name = ""create""
    verbose_name = _(""Create User"")
    url = ""horizon:admin:users:create""
    classes = (""ajax-modal"", ""btn-create"")
    policy_rules = (('identity', 'identity:create_grant'),
                    (""identity"", ""identity:create_user""),
                    (""identity"", ""identity:list_roles""),
                    (""identity"", ""identity:list_projects""),)

    def allowed(self, request, user):
        return api.keystone.keystone_can_edit_user()


class EditUserLink(tables.LinkAction):
    name = ""edit""
    verbose_name = _(""Edit"")
    url = ""horizon:admin:users:update""
    classes = (""ajax-modal"", ""btn-edit"")
    policy_rules = ((""identity"", ""identity:update_user""),
                    (""identity"", ""identity:list_projects""),)

    def get_policy_target(self, request, user):
        return {""user_id"": user.id}

    def allowed(self, request, user):
        return api.keystone.keystone_can_edit_user()


class ToggleEnabled(tables.BatchAction):
    name = ""toggle""
    action_present = (_(""Enable""), _(""Disable""))
    action_past = (_(""Enabled""), _(""Disabled""))
    data_type_singular = _(""User"")
    data_type_plural = _(""Users"")
    classes = (""btn-toggle"",)
    policy_rules = ((""identity"", ""identity:update_user""),)

    def get_policy_target(self, request, user=None):
        if user:
            return {""user_id"": user.id}
        return {}

    def allowed(self, request, user=None):
        if not api.keystone.keystone_can_edit_user():
            return False

        self.enabled = True
        if not user:
            return self.enabled
        self.enabled = user.enabled
        if self.enabled:
            self.current_present_action = DISABLE
        else:
            self.current_present_action = ENABLE
        return True

    def update(self, request, user=None):
        super(ToggleEnabled, self).update(request, user)
        if user and user.id == request.user.id:
            self.attrs[""disabled""] = ""disabled""

    def action(self, request, obj_id):
        if obj_id == request.user.id:
            messages.info(request, _('You cannot disable the user you are '
                                     'currently logged in as.'))
            return
        if self.enabled:
            api.keystone.user_update_enabled(request, obj_id, False)
            self.current_past_action = DISABLE
        else:
            api.keystone.user_update_enabled(request, obj_id, True)
            self.current_past_action = ENABLE


class DeleteUsersAction(tables.DeleteAction):
    data_type_singular = _(""User"")
    data_type_plural = _(""Users"")
    policy_rules = ((""identity"", ""identity:delete_user""),)

    def allowed(self, request, datum):
        if not api.keystone.keystone_can_edit_user() or \
                (datum and datum.id == request.user.id):
            return False
        return True

    def delete(self, request, obj_id):
        api.keystone.user_delete(request, obj_id)


class UserFilterAction(tables.FilterAction):
    def filter(self, table, users, filter_string):
        """"""Naive case-insensitive search.""""""
        q = filter_string.lower()
        return [user for user in users
                if q in user.name.lower()
                or q in getattr(user, 'email', '').lower()]


class UsersTable(tables.DataTable):
    STATUS_CHOICES = (
        (""true"", True),
        (""false"", False)
    )
    name = tables.Column('name', verbose_name=_('User Name'))
    email = tables.Column('email', verbose_name=_('Email'),
                          filters=(lambda v: defaultfilters
                                   .default_if_none(v, """"),
                                   defaultfilters.urlize))
    # Default tenant is not returned from Keystone currently.
    #default_tenant = tables.Column('default_tenant',
    #                               verbose_name=_('Default Project'))
    id = tables.Column('id', verbose_name=_('User ID'))
    enabled = tables.Column('enabled', verbose_name=_('Enabled'),
                            status=True,
                            status_choices=STATUS_CHOICES,
                            empty_value=""False"")

    class Meta:
        name = ""users""
        verbose_name = _(""Users"")
        row_actions = (EditUserLink, ToggleEnabled, DeleteUsersAction)
        table_actions = (UserFilterAction, CreateUserLink, DeleteUsersAction)
",CWE-79,149.0,1
"# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import logging

from django.utils.translation import ugettext_lazy as _

from horizon import messages
from horizon import tabs
from openstack_dashboard import api

from openstack_dashboard.dashboards.project.stacks \
    import api as project_api
from openstack_dashboard.dashboards.project.stacks import mappings
from openstack_dashboard.dashboards.project.stacks \
    import tables as project_tables


LOG = logging.getLogger(__name__)


class StackTopologyTab(tabs.Tab):
    name = _(""Topology"")
    slug = ""topology""
    template_name = ""project/stacks/_detail_topology.html""
    preload = False

    def get_context_data(self, request):
        context = {}
        stack = self.tab_group.kwargs['stack']
        context['stack_id'] = stack.id
        context['d3_data'] = project_api.d3_data(request, stack_id=stack.id)
        return context


class StackOverviewTab(tabs.Tab):
    name = _(""Overview"")
    slug = ""overview""
    template_name = ""project/stacks/_detail_overview.html""

    def get_context_data(self, request):
        return {""stack"": self.tab_group.kwargs['stack']}


class ResourceOverviewTab(tabs.Tab):
    name = _(""Overview"")
    slug = ""resource_overview""
    template_name = ""project/stacks/_resource_overview.html""

    def get_context_data(self, request):
        resource = self.tab_group.kwargs['resource']
        resource_url = mappings.resource_to_url(resource)
        return {
            ""resource"": resource,
            ""resource_url"": resource_url,
            ""metadata"": self.tab_group.kwargs['metadata']}


class StackEventsTab(tabs.Tab):
    name = _(""Events"")
    slug = ""events""
    template_name = ""project/stacks/_detail_events.html""
    preload = False

    def get_context_data(self, request):
        stack = self.tab_group.kwargs['stack']
        try:
            stack_identifier = '%s/%s' % (stack.stack_name, stack.id)
            events = api.heat.events_list(self.request, stack_identifier)
            LOG.debug('got events %s' % events)
        except Exception:
            events = []
            messages.error(request, _(
                'Unable to get events for stack ""%s"".') % stack.stack_name)
        return {""stack"": stack,
                ""table"": project_tables.EventsTable(request, data=events), }


class StackResourcesTab(tabs.Tab):
    name = _(""Resources"")
    slug = ""resources""
    template_name = ""project/stacks/_detail_resources.html""
    preload = False

    def get_context_data(self, request):
        stack = self.tab_group.kwargs['stack']
        try:
            stack_identifier = '%s/%s' % (stack.stack_name, stack.id)
            resources = api.heat.resources_list(self.request, stack_identifier)
            LOG.debug('got resources %s' % resources)
        except Exception:
            resources = []
            messages.error(request, _(
                'Unable to get resources for stack ""%s"".') % stack.stack_name)
        return {""stack"": stack,
                ""table"": project_tables.ResourcesTable(
                    request, data=resources, stack=stack), }


class StackDetailTabs(tabs.TabGroup):
    slug = ""stack_details""
    tabs = (StackTopologyTab, StackOverviewTab, StackResourcesTab,
            StackEventsTab)
    sticky = True


class ResourceDetailTabs(tabs.TabGroup):
    slug = ""resource_details""
    tabs = (ResourceOverviewTab,)
    sticky = True
",CWE-79,122.0,1
"#    Licensed under the Apache License, Version 2.0 (the ""License""); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from django.template import defaultfilters as filters
from django.utils.translation import ugettext_lazy as _

from horizon import tables

from openstack_dashboard import api
from openstack_dashboard.dashboards.admin.aggregates import constants


class DeleteAggregateAction(tables.DeleteAction):
    data_type_singular = _(""Host Aggregate"")
    data_type_plural = _(""Host Aggregates"")

    def delete(self, request, obj_id):
        api.nova.aggregate_delete(request, obj_id)


class CreateAggregateAction(tables.LinkAction):
    name = ""create""
    verbose_name = _(""Create Host Aggregate"")
    url = constants.AGGREGATES_CREATE_URL
    classes = (""ajax-modal"", ""btn-create"")


class ManageHostsAction(tables.LinkAction):
    name = ""manage""
    verbose_name = _(""Manage Hosts"")
    url = constants.AGGREGATES_MANAGE_HOSTS_URL
    classes = (""ajax-modal"", ""btn-create"")


class UpdateAggregateAction(tables.LinkAction):
    name = ""update""
    verbose_name = _(""Edit Host Aggregate"")
    url = constants.AGGREGATES_UPDATE_URL
    classes = (""ajax-modal"", ""btn-edit"")


class AggregateFilterAction(tables.FilterAction):
    def filter(self, table, aggregates, filter_string):
        q = filter_string.lower()

        def comp(aggregate):
            return q in aggregate.name.lower()

        return filter(comp, aggregates)


class AvailabilityZoneFilterAction(tables.FilterAction):
    def filter(self, table, availability_zones, filter_string):
        q = filter_string.lower()

        def comp(availabilityZone):
            return q in availabilityZone.name.lower()

        return filter(comp, availability_zones)


def get_aggregate_hosts(aggregate):
    return [host for host in aggregate.hosts]


def get_metadata(aggregate):
    return [' = '.join([key, val]) for key, val
            in aggregate.metadata.iteritems()]


def get_available(zone):
    return zone.zoneState['available']


def get_zone_hosts(zone):
    hosts = zone.hosts
    host_details = []
    if hosts is None:
        return []
    for name, services in hosts.items():
        up = all(s['active'] and s['available'] for s in services.values())
        up = _(""Services Up"") if up else _(""Services Down"")
        host_details.append(""%(host)s (%(up)s)"" % {'host': name, 'up': up})
    return host_details


class HostAggregatesTable(tables.DataTable):
    name = tables.Column('name', verbose_name=_('Name'))
    availability_zone = tables.Column('availability_zone',
                                      verbose_name=_('Availability Zone'))
    hosts = tables.Column(get_aggregate_hosts,
                          verbose_name=_(""Hosts""),
                          wrap_list=True,
                          filters=(filters.unordered_list,))
    metadata = tables.Column(get_metadata,
                             verbose_name=_(""Metadata""),
                             wrap_list=True,
                             filters=(filters.unordered_list,))

    class Meta:
        name = ""host_aggregates""
        verbose_name = _(""Host Aggregates"")
        table_actions = (AggregateFilterAction,
                         CreateAggregateAction,
                         DeleteAggregateAction)
        row_actions = (UpdateAggregateAction,
                       ManageHostsAction,
                       DeleteAggregateAction)


class AvailabilityZonesTable(tables.DataTable):
    name = tables.Column('zoneName',
                         verbose_name=_('Availability Zone Name'))
    hosts = tables.Column(get_zone_hosts,
                          verbose_name=_('Hosts'),
                          wrap_list=True,
                          filters=(filters.unordered_list,))
    available = tables.Column(get_available,
                              verbose_name=_('Available'),
                              status=True,
                              filters=(filters.yesno, filters.capfirst))

    def get_object_id(self, zone):
        return zone.zoneName

    class Meta:
        name = ""availability_zones""
        verbose_name = _(""Availability Zones"")
        table_actions = (AggregateFilterAction,)
        multi_select = False
",CWE-79,140.0,1
"#encoding=utf-8
# test for flask

import MySQLdb
import time
from flask import Flask
from flask import render_template
from flask import request, jsonify


COLOR_CHART = [""#F7464A"",""#46BFBD"",""#FDB45C"",""#949FB1"",""#C7604C"",\
				""#4D5360"",""#7D4F6D"",""#9D9B7F"",""#21323D"",""#1874CD"",\
				""#218868"",""#8E8E38""]
conn=MySQLdb.connect(host=""localhost"",user=""root"",passwd="""",db=""db_vote_web"",charset=""utf8"")
app = Flask(__name__)


def parse_req():
	title = request.form[""title""]
	n = len(request.form)-1
	l_dsc = []
	for i in range(1,n):
		l_dsc.append(request.form[""opt""+str(i)])
	return title, n-1, l_dsc

@app.route('/')
def hello_world():
    return render_template(""index.html"")

@app.route('/error')
def error():
    return render_template(""error.html"")

@app.route('/create', methods=['POST'])
def create_poll():
	try:
		cursor = conn.cursor()  
		uid = request.remote_addr
		import pdb
		pdb.set_trace()
		vid = str(int(time.time()*100))
		title, optn, l_dsc = parse_req()
		optdsc = '|'.join(l_dsc)
		optnum = '|'.join(['0']*optn)
		sql = ""insert into t_vote_info(FUid, FVoteId, FTitle, FOptionNum, \
				FOptionDesc, FOptionVoteNum, FState, FCreateTime, FEndTime) \
				values(\""%s\"",\""%s\"",\""%s\"",%d,\""%s\"",\""%s\"",0,now(),now()+interval 1 day);"" 
		param = (uid, vid, title, optn, optdsc, optnum) 
		res = cursor.execute(sql%param)
		conn.commit()
		cursor.close()
	except Exception,e:
		return jsonify({""return_code"":21, ""return_msg"":str(e), ""p_id"":0})
	return jsonify({""p_id"":vid})

@app.route('/poll', methods=['POST','GET'])
def do_poll():
	if ""p_id"" in request.args:
		p_id = request.args['p_id']
		cursor = conn.cursor()
		sql_s = ""select FTitle, FOptionDesc from t_vote_info where FVoteId=%s;""%p_id
		res = cursor.execute(sql_s)
		r = cursor.fetchone()
		cursor.close()
		title = r[0]
		opts_desc = r[1].split('|')
		return render_template(""poll.html"", title=title, opts=opts_desc)

	if ""p_id"" not in request.form:
		return render_template(""poll.html"")
	if ""opt_idx"" not in request.form:
		return render_template(""poll.html"")

	o_id = int(request.form['opt_idx'])-1
	p_id = request.form['p_id']
	try:
		cursor = conn.cursor()
		sql_s = ""select FOptionVoteNum from t_vote_info where FVoteId=%s;""%p_id
		res = cursor.execute(sql_s)
		opt_pre = cursor.fetchone()[0].split('|')
		opt_pre[o_id] = str(int(opt_pre[o_id])+1)
		opt_new = '|'.join(opt_pre)
		sql_u = ""update t_vote_info set FOptionVoteNum=\""%s\"" where FVoteId=\""%s\"";""%(opt_new,p_id)
		res = cursor.execute(sql_u)
		conn.commit()
		cursor.close()
	except Exception,e:
		cursor.close()
		return jsonify({""result_code"":""-1"", ""result_msg"":""error"", ""p_id"":0})
	return jsonify({""result_code"":""0"", ""result_msg"":""success"", ""p_id"":p_id})

@app.route('/show')
def show_poll():
	title = ""error""
	if ""p_id"" not in request.args:
		return render_template(""show.html"", title=title)
	p_id = request.args['p_id']
	rows = []
	try:
		cursor = conn.cursor()
		sql_s = ""select FTitle,FOptionDesc,FOptionVoteNum,FState,FEndTime from t_vote_info where FVoteId=%s;""%p_id
		res = cursor.execute(sql_s)
		r = cursor.fetchone()
		cursor.close()
		title = r[0]
		opts_desc = r[1].split('|')
		opts_num = r[2].split('|')
		opts_col = COLOR_CHART[:len(opts_desc)]
		for i in range(len(opts_desc)):
			rows.append([opts_desc[i], opts_num[i], opts_col[i]])
	except Exception,e:
		return render_template(""show.html"", title=title)
	#poll_id = request.args['p_id']
	return render_template(""show.html"", title=title, opts=rows)

@app.route('/refresh', methods=['POST'])
def show_refresh():
	if ""p_id"" not in request.form:
		return jsonify({""result_code"":""-1"", ""result_msg"":""refresh error""})
	p_id = request.form['p_id']
	rows = []
	try:
		cursor = conn.cursor()
		sql_s = ""select FTitle,FOptionDesc,FOptionVoteNum,FState,FEndTime from t_vote_info where FVoteId=%s;""%p_id
		res = cursor.execute(sql_s)
		r = cursor.fetchone()
		cursor.close()
		title = r[0]
		opts_desc = r[1].split('|')
		opts_num = r[2].split('|')
		opts_col = COLOR_CHART[:len(opts_desc)]
		for i in range(len(opts_desc)):
			rows.append({""label"":opts_desc[i], ""value"":int(opts_num[i]), ""color"":opts_col[i]})
		return jsonify({""result_code"":""0"", ""result_msg"":""success"", ""rows"":rows})
	except Exception,e:
		return jsonify({""result_code"":""-1"", ""result_msg"":""refresh error""})


if __name__ == '__main__':
    app.debug = True
    app.run()
    conn.close()

",CWE-89,144.0,1
"#!/usr/bin/python
""""""
Spellchecker

URI: http://www.w3.org/2002/01/spellchecker
Maintainer: dom@w3.org

See also a version that features recursive checking:
http://www.w3.org/mid/1ce6d0230912160806x1ee6f25dgafc73865140b239e@mail.gmail.com

Share and Enjoy. Open Source license:
Copyright (c) 2001-2005 W3C (MIT, ERCIM, Keio)
http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231
$Id$
 branched from v 1.46
""""""

import os
import cgi
import sys
import string
import urlparse
import popen2

customized_dico=""/usr/local/share/aspell/w3c.dat""
languages = {""en_US"":""English"",""fr"":""French""}
def format_option(a,b,c):
        if a:
                selected=""""
                if a==c:
                        selected="" selected='selected'""
                return ""<option value='%s'%s>%s</option>"" % (a,selected,b)

def concat(a,b):
        return a+b


Page1 =""""""Content-Type:text/html; charset=utf-8


<?xml version=""1.0"" encoding=""utf-8""?>
<!DOCTYPE html PUBLIC ""-//W3C//DTD XHTML 1.0 Transitional//EN""
    ""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"">
<html xmlns=""http://www.w3.org/1999/xhtml"" xml:lang=""en-US"" lang=""en-US"">
<head>
  %s
  <title>W3C Spell Checker %s</title>
  <link rel=""stylesheet"" href=""http://www.w3.org/Stylesheets/base""/>
  <link rel=""stylesheet"" href=""http://www.w3.org/2001/11/results""/>
  <style type=""text/css"">
   ul.suggestions { height:5em; overflow:auto; width:10em;}
   
  </style>
</head>

<body>
<p><a href=""http://www.w3.org""><img src=""http://www.w3.org/Icons/w3c_home"" alt=""W3C""/></a></p>

<h1>W3C Spell Checker %s</h1>

<h2>Status</h2>
<p>This tool allows you to check the spelling of a web page. It currently only supports English and French.</p>

<h2>Usage</h2>
<form action="""" method=""get""><p><label>URI of the document to be checked:<input type=""text"" value=""%s"" name=""uri""/></label><br />
<label>Language of the document: <select name=""lang"">%s</select><br />
<label>Presents possible corrections: <input type=""checkbox"" name=""suggest""%s /></label><br />
<input type=""submit"" value=""Get results""/></p></form>
""""""

Page2 = """"""
<h2>See also</h2>
<ul>
<li><a href=""http://www.w3.org/QA/Tools"">the QA Toolbox</a></li>
</ul>

<h2>References</h2>
<ul>
<li><a href=""http://aspell.sourceforge.net"">Aspell</a> is used in the back-end</li>
<li>The front-end is coded in <a href=""http://www.python.org"">Python</a></li>
</ul>
<h2>Known bugs and limitations</h2>
<ul>
<li>Doesn't handle language switching on the <code>lang</code> and <code>xml:lang</code> attributes</li>
<li>Doesn't check textual attributes (e.g. <code>title</code>, <code>alt</code>)</li>
</ul>
<hr/>
<address><a href=""http://www.w3.org/People/Dom/"">Dominique Haza&euml;l-Massieux</a><br/>
Last Modified: $Date$
</address>
</body>
</html>
""""""

def format(fp,suggest):
	line = fp.readline()
	words = {}
	count = 0
	while line!="""":
		if line!=""\n"" and line !=""*\n"" and line[0]!=""@"":
			line = line[:-1]
			parts = string.split(line,"": "")
			fields = string.split(parts[0],"" "")
			if fields[0]==""&"":
				values = string.split(parts[1],"", "")
				if (not words.has_key(fields[1])):
					words[fields[1]]=values
			elif fields[0]==""#"":
				if (not words.has_key(fields[1])):
					words[fields[1]]=[]
		elif line==""\n"":
			count = count + 1
		line = fp.readline()
	offsets = {}
	count = 0
	if len(words):
                keys = words.keys()
                keys.sort()
		print ""<form action=\""http://www.w3.org/Team/update_dictionary\"" method=\""post\""><ol>""
		for error in keys:
			print ""<li>\""<span class='no'>%s</span>\"" (<input type=\""checkbox\"" name=\""list[]\"" value=\""%s\""/> add to the dictionary)"" % (error,error)

			if len(words[error]) and suggest:
				print ""; suggestions:<ul class='suggestions'>""
				for option in words[error]:
					print ""<li>%s</li>"" % option
				print ""</ul>""				
			print ""</li>""
		print ""</ol><p><label><input type=\""submit\"" value=\""Update dictionary\""/> (W3C Comm Team only)</label></p></form>""
	else:
		print ""<p><span class='yes'>No errors</span> found.</p>""

if __name__ == '__main__':
	if  os.environ.has_key('SCRIPT_NAME'):
		fields = cgi.FieldStorage()
		uri ="""" 
		uri_text =""""
		uri_text1=""""
		suggest=0
		suggest_txt=''
		if fields.has_key('uri'):
			uri = fields['uri'].value
                elif fields.has_key('referrer') and os.environ.has_key('HTTP_REFERER'):
                        uri = os.environ['HTTP_REFERER']
                if uri:
			uri_text1=""for %s"" % (cgi.escape(uri))
			uri_text="" for <a href=\""%s\"">%s</a>"" %(cgi.escape(uri),cgi.escape(uri))
                lang = ""en_US""
                if fields.has_key('lang') and fields['lang'].value in languages.keys():
                        lang=fields['lang'].value
                languages_options = reduce(concat,map(format_option,languages.keys(),languages.values(),[lang for x in languages.keys()]))

		if fields.has_key('suggest'):
			if fields['suggest'].value=='on':
				suggest=1
				suggest_txt="" checked='checked'""
		if uri:
			import http_auth
			url_opener = http_auth.ProxyAuthURLopener()
			try:
				fp = url_opener.open(uri)
			except IOError as e:
				url_opener.error = ""I/O error: %s %s"" % (e.errno,e.strerror)
				fp = None
			print Page1 % ('<meta name=""ROBOTS"" content=""NOINDEX,NOFOLLOW""/>',uri_text1,uri_text,cgi.escape(uri),languages_options,suggest_txt)
			if fp:
                                personal = ""--personal=%s"" % customized_dico
                                if lang!=""en_US"":
                                        personal = """"
                                headers = fp.info()
                                charset_opt = """"
                                if headers.has_key('Content-Type'):
                                        contentType = cgi.parse_header(headers[""Content-Type""])
                                        if contentType[1].has_key('charset'):
                                                charset_opt = ""-assume_charset=%s"" % contentType[1]['charset']
	        		command = ""/usr/bin/lynx  %s -cfg=/usr/local/lib/lynx.cfg -nolist -dump -stdin|/usr/bin/aspell --encoding=utf-8 --lang %s -a %s --sug-mode=fast"" % (charset_opt,lang,personal)

        	                (piperfd,pipewfd,pipeErr) = popen2.popen3(command)

				pipewfd.write(fp.read())
				fp.close()
				pipewfd.close()
				# Need to find a way to display any errors if relevant
				processingErrors=""""
				if (processingErrors):
					print ""<p>The following error occurred when trying to process your request :</p><pre class='no'>""
					print ""</pre>""
					pipeErr.close()
				if (piperfd):
					print ""<h2>Errors found in the page</h2>""
					format(piperfd,suggest)
					piperfd.close()
			else:
				print ""<p><span class='no'>Unable to read</span> <a href='%s'>%s</a> (%s). Sorry, check the URI.</p>"" % (cgi.escape(uri),cgi.escape(uri), url_opener.error)
		else:
			print Page1 % ('',uri_text1,uri_text,cgi.escape(uri),languages_options,suggest_txt)
		print Page2



",CWE-79,201.0,1
,CWE-22,,1
,CWE-22,,1
,CWE-787,,1
,CWE-125,,1
,CWE-190,,1
,CWE-787,,1
,CWE-125,,1
,CWE-190,,1
"from __future__ import division, absolute_import, print_function

import sys
from tempfile import NamedTemporaryFile, TemporaryFile, mktemp
import os

from numpy import memmap
from numpy import arange, allclose, asarray
from numpy.testing import *

class TestMemmap(TestCase):
    def setUp(self):
        self.tmpfp = NamedTemporaryFile(prefix='mmap')
        self.shape = (3, 4)
        self.dtype = 'float32'
        self.data = arange(12, dtype=self.dtype)
        self.data.resize(self.shape)

    def tearDown(self):
        self.tmpfp.close()

    def test_roundtrip(self):
        # Write data to file
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp[:] = self.data[:]
        del fp # Test __del__ machinery, which handles cleanup

        # Read data back from file
        newfp = memmap(self.tmpfp, dtype=self.dtype, mode='r',
                       shape=self.shape)
        assert_(allclose(self.data, newfp))
        assert_array_equal(self.data, newfp)

    def test_open_with_filename(self):
        tmpname = mktemp('', 'mmap')
        fp = memmap(tmpname, dtype=self.dtype, mode='w+',
                       shape=self.shape)
        fp[:] = self.data[:]
        del fp
        os.unlink(tmpname)

    def test_unnamed_file(self):
        with TemporaryFile() as f:
            fp = memmap(f, dtype=self.dtype, shape=self.shape)
            del fp

    def test_attributes(self):
        offset = 1
        mode = ""w+""
        fp = memmap(self.tmpfp, dtype=self.dtype, mode=mode,
                    shape=self.shape, offset=offset)
        self.assertEqual(offset, fp.offset)
        self.assertEqual(mode, fp.mode)
        del fp

    def test_filename(self):
        tmpname = mktemp('', 'mmap')
        fp = memmap(tmpname, dtype=self.dtype, mode='w+',
                       shape=self.shape)
        abspath = os.path.abspath(tmpname)
        fp[:] = self.data[:]
        self.assertEqual(abspath, fp.filename)
        b = fp[:1]
        self.assertEqual(abspath, b.filename)
        del b
        del fp
        os.unlink(tmpname)

    def test_filename_fileobj(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode=""w+"",
                    shape=self.shape)
        self.assertEqual(fp.filename, self.tmpfp.name)

    @dec.knownfailureif(sys.platform=='gnu0', ""This test is known to fail on hurd"")
    def test_flush(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp[:] = self.data[:]
        assert_equal(fp[0], self.data[0])
        fp.flush()

    def test_del(self):
        # Make sure a view does not delete the underlying mmap
        fp_base = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp_base[0] = 5
        fp_view = fp_base[0:1]
        assert_equal(fp_view[0], 5)
        del fp_view
        # Should still be able to access and assign values after
        # deleting the view
        assert_equal(fp_base[0], 5)
        fp_base[0] = 6
        assert_equal(fp_base[0], 6)

    def test_arithmetic_drops_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        tmp = (fp + 10)
        if isinstance(tmp, memmap):
            assert tmp._mmap is not fp._mmap

    def test_indexing_drops_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        tmp = fp[[(1, 2), (2, 3)]]
        if isinstance(tmp, memmap):
            assert tmp._mmap is not fp._mmap

    def test_slicing_keeps_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        assert fp[:2, :2]._mmap is fp._mmap

    def test_view(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, shape=self.shape)
        new1 = fp.view()
        new2 = new1.view()
        assert(new1.base is fp)
        assert(new2.base is fp)
        new_array = asarray(fp)
        assert(new_array.base is fp)

if __name__ == ""__main__"":
    run_module_suite()
",CWE-20,127.0,1
"from __future__ import division, absolute_import, print_function

import sys
from tempfile import NamedTemporaryFile, TemporaryFile, mktemp
import os

from numpy import memmap
from numpy import arange, allclose, asarray
from numpy.testing import *

class TestMemmap(TestCase):
    def setUp(self):
        self.tmpfp = NamedTemporaryFile(prefix='mmap')
        self.shape = (3, 4)
        self.dtype = 'float32'
        self.data = arange(12, dtype=self.dtype)
        self.data.resize(self.shape)

    def tearDown(self):
        self.tmpfp.close()

    def test_roundtrip(self):
        # Write data to file
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp[:] = self.data[:]
        del fp # Test __del__ machinery, which handles cleanup

        # Read data back from file
        newfp = memmap(self.tmpfp, dtype=self.dtype, mode='r',
                       shape=self.shape)
        assert_(allclose(self.data, newfp))
        assert_array_equal(self.data, newfp)

    def test_open_with_filename(self):
        tmpname = mktemp('', 'mmap')
        fp = memmap(tmpname, dtype=self.dtype, mode='w+',
                       shape=self.shape)
        fp[:] = self.data[:]
        del fp
        os.unlink(tmpname)

    def test_unnamed_file(self):
        with TemporaryFile() as f:
            fp = memmap(f, dtype=self.dtype, shape=self.shape)
            del fp

    def test_attributes(self):
        offset = 1
        mode = ""w+""
        fp = memmap(self.tmpfp, dtype=self.dtype, mode=mode,
                    shape=self.shape, offset=offset)
        self.assertEqual(offset, fp.offset)
        self.assertEqual(mode, fp.mode)
        del fp

    def test_filename(self):
        tmpname = mktemp('', 'mmap')
        fp = memmap(tmpname, dtype=self.dtype, mode='w+',
                       shape=self.shape)
        abspath = os.path.abspath(tmpname)
        fp[:] = self.data[:]
        self.assertEqual(abspath, fp.filename)
        b = fp[:1]
        self.assertEqual(abspath, b.filename)
        del b
        del fp
        os.unlink(tmpname)

    def test_filename_fileobj(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode=""w+"",
                    shape=self.shape)
        self.assertEqual(fp.filename, self.tmpfp.name)

    @dec.knownfailureif(sys.platform=='gnu0', ""This test is known to fail on hurd"")
    def test_flush(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp[:] = self.data[:]
        assert_equal(fp[0], self.data[0])
        fp.flush()

    def test_del(self):
        # Make sure a view does not delete the underlying mmap
        fp_base = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        fp_base[0] = 5
        fp_view = fp_base[0:1]
        assert_equal(fp_view[0], 5)
        del fp_view
        # Should still be able to access and assign values after
        # deleting the view
        assert_equal(fp_base[0], 5)
        fp_base[0] = 6
        assert_equal(fp_base[0], 6)

    def test_arithmetic_drops_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        tmp = (fp + 10)
        if isinstance(tmp, memmap):
            assert tmp._mmap is not fp._mmap

    def test_indexing_drops_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        tmp = fp[[(1, 2), (2, 3)]]
        if isinstance(tmp, memmap):
            assert tmp._mmap is not fp._mmap

    def test_slicing_keeps_references(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, mode='w+',
                    shape=self.shape)
        assert fp[:2, :2]._mmap is fp._mmap

    def test_view(self):
        fp = memmap(self.tmpfp, dtype=self.dtype, shape=self.shape)
        new1 = fp.view()
        new2 = new1.view()
        assert(new1.base is fp)
        assert(new2.base is fp)
        new_array = asarray(fp)
        assert(new_array.base is fp)

if __name__ == ""__main__"":
    run_module_suite()
",CWE-59,127.0,1
"#!/usr/bin/env python
from __future__ import division, absolute_import, print_function

__all__ = ['run_main', 'compile', 'f2py_testing']

import os
import sys
import subprocess

from . import f2py2e
from . import f2py_testing
from . import diagnose

from .info import __doc__

run_main = f2py2e.run_main
main = f2py2e.main

def compile(source,
            modulename = 'untitled',
            extra_args = '',
            verbose = 1,
            source_fn = None
            ):
    ''' Build extension module from processing source with f2py.
    Read the source of this function for more information.
    '''
    from numpy.distutils.exec_command import exec_command
    import tempfile
    if source_fn is None:
        fname = os.path.join(tempfile.mktemp()+'.f')
    else:
        fname = source_fn

    f = open(fname, 'w')
    f.write(source)
    f.close()

    args = ' -c -m %s %s %s'%(modulename, fname, extra_args)
    c = '%s -c ""import numpy.f2py as f2py2e;f2py2e.main()"" %s' %(sys.executable, args)
    s, o = exec_command(c)
    if source_fn is None:
        try: os.remove(fname)
        except OSError: pass
    return s

from numpy.testing import Tester
test = Tester().test
bench = Tester().bench
",CWE-20,50.0,1
"#!/usr/bin/env python
from __future__ import division, absolute_import, print_function

__all__ = ['run_main', 'compile', 'f2py_testing']

import os
import sys
import subprocess

from . import f2py2e
from . import f2py_testing
from . import diagnose

from .info import __doc__

run_main = f2py2e.run_main
main = f2py2e.main

def compile(source,
            modulename = 'untitled',
            extra_args = '',
            verbose = 1,
            source_fn = None
            ):
    ''' Build extension module from processing source with f2py.
    Read the source of this function for more information.
    '''
    from numpy.distutils.exec_command import exec_command
    import tempfile
    if source_fn is None:
        fname = os.path.join(tempfile.mktemp()+'.f')
    else:
        fname = source_fn

    f = open(fname, 'w')
    f.write(source)
    f.close()

    args = ' -c -m %s %s %s'%(modulename, fname, extra_args)
    c = '%s -c ""import numpy.f2py as f2py2e;f2py2e.main()"" %s' %(sys.executable, args)
    s, o = exec_command(c)
    if source_fn is None:
        try: os.remove(fname)
        except OSError: pass
    return s

from numpy.testing import Tester
test = Tester().test
bench = Tester().bench
",CWE-59,50.0,1
"import re
import random
import datetime
from django.utils.translation import ugettext as _
from django.utils.translation import ungettext

def get_from_dict_or_object(source, key):
    try:
        return source[key]
    except:
        return getattr(source, key)


def enumerate_string_list(strings):
    """"""for a list or a tuple ('one', 'two',) return
    a list formatted as ['1) one', '2) two',]
    """"""
    numbered_strings = enumerate(strings, start = 1)
    return [ '%d) %s' % item for item in numbered_strings ]

def pad_string(text):
    """"""Inserts one space between words,
    including one space before the first word
    and after the last word.
    String without words is collapsed to ''
    """"""
    words = text.strip().split()
    if len(words) > 0:
        return ' ' + ' '.join(words) + ' '
    else:
        return ''

def split_list(text):
    """"""Takes text, representing a loosely formatted
    list (comma, semicolon, empty space separated
    words) and returns a list() of words.
    """"""
    text = text.replace(',', ' ').replace(';', ' ')
    return text.strip().split()

def is_iterable(thing):
    if hasattr(thing, '__iter__'):
        return True
    else:
        return isinstance(thing, basestring)

BOT_REGEX = re.compile(
    r'bot|http|\.com|crawl|spider|python|curl|yandex'
)
BROWSER_REGEX = re.compile(
    r'^(Mozilla.*(Gecko|KHTML|MSIE|Presto|Trident)|Opera).*$'
)
MOBILE_REGEX = re.compile(
    r'(BlackBerry|HTC|LG|MOT|Nokia|NOKIAN|PLAYSTATION|PSP|SAMSUNG|SonyEricsson)'
)


def strip_plus(text):
    """"""returns text with redundant spaces replaced with just one,
    and stripped leading and the trailing spaces""""""
    return re.sub('\s+', ' ', text).strip()


def not_a_robot_request(request):

    if 'HTTP_ACCEPT_LANGUAGE' not in request.META:
        return False

    user_agent = request.META.get('HTTP_USER_AGENT', None)
    if user_agent is None:
        return False

    if BOT_REGEX.match(user_agent, re.IGNORECASE):
        return False

    if MOBILE_REGEX.match(user_agent):
        return True

    if BROWSER_REGEX.search(user_agent):
        return True

    return False

def diff_date(date, use_on_prefix = False):
    now = datetime.datetime.now()#datetime(*time.localtime()[0:6])#???
    diff = now - date
    days = diff.days
    hours = int(diff.seconds/3600)
    minutes = int(diff.seconds/60)

    if days > 2:
        if date.year == now.year:
            date_token = date.strftime(""%b %d"")
        else:
            date_token = date.strftime(""%b %d '%y"")
        if use_on_prefix:
            return _('on %(date)s') % { 'date': date_token }
        else:
            return date_token
    elif days == 2:
        return _('2 days ago')
    elif days == 1:
        return _('yesterday')
    elif minutes >= 60:
        return ungettext(
            '%(hr)d hour ago',
            '%(hr)d hours ago',
            hours
        ) % {'hr':hours}
    else:
        return ungettext(
            '%(min)d min ago',
            '%(min)d mins ago',
            minutes
        ) % {'min':minutes}

#todo: this function may need to be removed to simplify the paginator functionality
LEADING_PAGE_RANGE_DISPLAYED = TRAILING_PAGE_RANGE_DISPLAYED = 5
LEADING_PAGE_RANGE = TRAILING_PAGE_RANGE = 4
NUM_PAGES_OUTSIDE_RANGE = 1
ADJACENT_PAGES = 2
def setup_paginator(context):
    """"""
    custom paginator tag
    Inspired from http://blog.localkinegrinds.com/2007/09/06/digg-style-pagination-in-django/
    """"""
    if (context[""is_paginated""]):
        "" Initialize variables ""
        in_leading_range = in_trailing_range = False
        pages_outside_leading_range = pages_outside_trailing_range = range(0)

        if (context[""pages""] <= LEADING_PAGE_RANGE_DISPLAYED):
            in_leading_range = in_trailing_range = True
            page_numbers = [n for n in range(1, context[""pages""] + 1) if n > 0 and n <= context[""pages""]]
        elif (context[""current_page_number""] <= LEADING_PAGE_RANGE):
            in_leading_range = True
            page_numbers = [n for n in range(1, LEADING_PAGE_RANGE_DISPLAYED + 1) if n > 0 and n <= context[""pages""]]
            pages_outside_leading_range = [n + context[""pages""] for n in range(0, -NUM_PAGES_OUTSIDE_RANGE, -1)]
        elif (context[""current_page_number""] > context[""pages""] - TRAILING_PAGE_RANGE):
            in_trailing_range = True
            page_numbers = [n for n in range(context[""pages""] - TRAILING_PAGE_RANGE_DISPLAYED + 1, context[""pages""] + 1) if n > 0 and n <= context[""pages""]]
            pages_outside_trailing_range = [n + 1 for n in range(0, NUM_PAGES_OUTSIDE_RANGE)]
        else:
            page_numbers = [n for n in range(context[""current_page_number""] - ADJACENT_PAGES, context[""current_page_number""] + ADJACENT_PAGES + 1) if n > 0 and n <= context[""pages""]]
            pages_outside_leading_range = [n + context[""pages""] for n in range(0, -NUM_PAGES_OUTSIDE_RANGE, -1)]
            pages_outside_trailing_range = [n + 1 for n in range(0, NUM_PAGES_OUTSIDE_RANGE)]

        page_object = context['page_object']
        #patch for change in django 1.5
        if page_object.has_previous():
            previous_page_number = page_object.previous_page_number()
        else:
            previous_page_number = None

        if page_object.has_next():
            next_page_number = page_object.next_page_number()
        else:
            next_page_number = None

        return {
            ""base_url"": context[""base_url""],
            ""is_paginated"": context[""is_paginated""],
            ""previous"": previous_page_number,
            ""has_previous"": page_object.has_previous(),
            ""next"": next_page_number,
            ""has_next"": page_object.has_next(),
            ""page"": context[""current_page_number""],
            ""pages"": context[""pages""],
            ""page_numbers"": page_numbers,
            ""in_leading_range"" : in_leading_range,
            ""in_trailing_range"" : in_trailing_range,
            ""pages_outside_leading_range"": pages_outside_leading_range,
            ""pages_outside_trailing_range"": pages_outside_trailing_range,
        }

def get_admin():
    """"""Returns an admin users, usefull for raising flags""""""
    try:
        from django.contrib.auth.models import User
        return User.objects.filter(is_superuser=True)[0]
    except:
        raise Exception('there is no admin users')

def generate_random_key(length=16):
    """"""return random string, length is number of characters""""""
    random.seed()
    assert(isinstance(length, int))
    format_string = '%0' + str(2*length) + 'x'
    return format_string % random.getrandbits(length*8)
",CWE-79,190.0,1
"import socketio
import traceback

from ajenti.http import HttpHandler
from ajenti.api import BasePlugin, plugin, persistent, rootcontext
from ajenti.api.http import HttpPlugin, SocketPlugin
from ajenti.plugins import manager
from ajenti.profiler import *


class SocketIORouteHandler (HttpHandler):
    def __init__(self):
        self.namespaces = {}
        for cls in SocketPlugin.get_classes():
            self.namespaces[cls.name] = cls

    def handle(self, context):
        return str(socketio.socketio_manage(context.env, self.namespaces, context))


class InvalidRouteHandler (HttpHandler):
    def handle(self, context):
        context.respond_not_found()
        return 'Invalid URL'


@plugin
@persistent
@rootcontext
class CentralDispatcher (BasePlugin, HttpHandler):
    def __init__(self):
        self.invalid = InvalidRouteHandler()
        self.io = SocketIORouteHandler()

    @profiled(lambda a, k: 'HTTP %s' % a[1].path)
    def handle(self, context):
        """"""
        Dispatch the request to every HttpPlugin
        """"""

        if hasattr(context.session, 'appcontext'):
            self.context = context.session.appcontext
        else:
            self.context = manager.context

        if context.path.startswith('/ajenti:socket'):
            return context.fallthrough(self.io)

        if not hasattr(self.context, 'http_handlers'):
            self.context.http_handlers = HttpPlugin.get_all()

        for instance in self.context.http_handlers:
            try:
                output = instance.handle(context)
            except Exception, e:
                return [self.respond_error(context, e)]
            if output is not None:
                return output
        return context.fallthrough(self.invalid)

    def respond_error(self, context, exception):
        context.respond_server_error()
        stack = traceback.format_exc()
        return """"""
        <html>
            <body>

                <style>
                    body {
                        font-family: sans-serif;
                        color: #888;
                        text-align: center;
                    }

                    body pre {
                        width: 600px;
                        text-align: left;
                        margin: auto;
                        font-family: monospace;
                    }
                </style>

                <img src=""/ajenti:static/main/error.jpeg"" />
                <br/>
                <p>
                    Server error
                </p>
                <pre>
%s
                </pre>
            </body>
        </html>
        """""" % stack
",CWE-79,94.0,1
"# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.

import os
import pwd
import sys
import ConfigParser
from string import ascii_letters, digits

# copied from utils, avoid circular reference fun :)
def mk_boolean(value):
    if value is None:
        return False
    val = str(value)
    if val.lower() in [ ""true"", ""t"", ""y"", ""1"", ""yes"" ]:
        return True
    else:
        return False

def get_config(p, section, key, env_var, default, boolean=False, integer=False, floating=False):
    ''' return a configuration variable with casting '''
    value = _get_config(p, section, key, env_var, default)
    if boolean:
        return mk_boolean(value)
    if value and integer:
        return int(value)
    if value and floating:
        return float(value)
    return value

def _get_config(p, section, key, env_var, default):
    ''' helper function for get_config '''
    if env_var is not None:
        value = os.environ.get(env_var, None)
        if value is not None:
            return value
    if p is not None:
        try:
            return p.get(section, key, raw=True)
        except:
            return default
    return default

def load_config_file():
    ''' Load Config File order(first found is used): ENV, CWD, HOME, /etc/ansible '''

    p = ConfigParser.ConfigParser()

    path0 = os.getenv(""ANSIBLE_CONFIG"", None)
    if path0 is not None:
        path0 = os.path.expanduser(path0)
    path1 = os.getcwd() + ""/ansible.cfg""
    path2 = os.path.expanduser(""~/.ansible.cfg"")
    path3 = ""/etc/ansible/ansible.cfg""

    for path in [path0, path1, path2, path3]:
        if path is not None and os.path.exists(path):
            p.read(path)
            return p
    return None

def shell_expand_path(path):
    ''' shell_expand_path is needed as os.path.expanduser does not work
        when path is None, which is the default for ANSIBLE_PRIVATE_KEY_FILE '''
    if path:
        path = os.path.expanduser(path)
    return path

p = load_config_file()

active_user   = pwd.getpwuid(os.geteuid())[0]

# Needed so the RPM can call setup.py and have modules land in the
# correct location. See #1277 for discussion
if getattr(sys, ""real_prefix"", None):
    # in a virtualenv
    DIST_MODULE_PATH = os.path.join(sys.prefix, 'share/ansible/')
else:
    DIST_MODULE_PATH = '/usr/share/ansible/'

# check all of these extensions when looking for yaml files for things like
# group variables -- really anything we can load
YAML_FILENAME_EXTENSIONS = [ """", "".yml"", "".yaml"", "".json"" ]

# sections in config file
DEFAULTS='defaults'

# configurable things
DEFAULT_HOST_LIST         = shell_expand_path(get_config(p, DEFAULTS, 'hostfile', 'ANSIBLE_HOSTS', '/etc/ansible/hosts'))
DEFAULT_MODULE_PATH       = get_config(p, DEFAULTS, 'library',          'ANSIBLE_LIBRARY',          DIST_MODULE_PATH)
DEFAULT_ROLES_PATH        = shell_expand_path(get_config(p, DEFAULTS, 'roles_path',       'ANSIBLE_ROLES_PATH',       '/etc/ansible/roles'))
DEFAULT_REMOTE_TMP        = shell_expand_path(get_config(p, DEFAULTS, 'remote_tmp',       'ANSIBLE_REMOTE_TEMP',      '$HOME/.ansible/tmp'))
DEFAULT_MODULE_NAME       = get_config(p, DEFAULTS, 'module_name',      None,                       'command')
DEFAULT_PATTERN           = get_config(p, DEFAULTS, 'pattern',          None,                       '*')
DEFAULT_FORKS             = get_config(p, DEFAULTS, 'forks',            'ANSIBLE_FORKS',            5, integer=True)
DEFAULT_MODULE_ARGS       = get_config(p, DEFAULTS, 'module_args',      'ANSIBLE_MODULE_ARGS',      '')
DEFAULT_MODULE_LANG       = get_config(p, DEFAULTS, 'module_lang',      'ANSIBLE_MODULE_LANG',      'en_US.UTF-8')
DEFAULT_TIMEOUT           = get_config(p, DEFAULTS, 'timeout',          'ANSIBLE_TIMEOUT',          10, integer=True)
DEFAULT_POLL_INTERVAL     = get_config(p, DEFAULTS, 'poll_interval',    'ANSIBLE_POLL_INTERVAL',    15, integer=True)
DEFAULT_REMOTE_USER       = get_config(p, DEFAULTS, 'remote_user',      'ANSIBLE_REMOTE_USER',      active_user)
DEFAULT_ASK_PASS          = get_config(p, DEFAULTS, 'ask_pass',  'ANSIBLE_ASK_PASS',    False, boolean=True)
DEFAULT_PRIVATE_KEY_FILE  = shell_expand_path(get_config(p, DEFAULTS, 'private_key_file', 'ANSIBLE_PRIVATE_KEY_FILE', None))
DEFAULT_SUDO_USER         = get_config(p, DEFAULTS, 'sudo_user',        'ANSIBLE_SUDO_USER',        'root')
DEFAULT_ASK_SUDO_PASS     = get_config(p, DEFAULTS, 'ask_sudo_pass',    'ANSIBLE_ASK_SUDO_PASS',    False, boolean=True)
DEFAULT_REMOTE_PORT       = get_config(p, DEFAULTS, 'remote_port',      'ANSIBLE_REMOTE_PORT',      None, integer=True)
DEFAULT_ASK_VAULT_PASS    = get_config(p, DEFAULTS, 'ask_vault_pass',    'ANSIBLE_ASK_VAULT_PASS',    False, boolean=True)
DEFAULT_TRANSPORT         = get_config(p, DEFAULTS, 'transport',        'ANSIBLE_TRANSPORT',        'smart')
DEFAULT_SCP_IF_SSH        = get_config(p, 'ssh_connection', 'scp_if_ssh',       'ANSIBLE_SCP_IF_SSH',       False, boolean=True)
DEFAULT_MANAGED_STR       = get_config(p, DEFAULTS, 'ansible_managed',  None,           'Ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host}')
DEFAULT_SYSLOG_FACILITY   = get_config(p, DEFAULTS, 'syslog_facility',  'ANSIBLE_SYSLOG_FACILITY', 'LOG_USER')
DEFAULT_KEEP_REMOTE_FILES = get_config(p, DEFAULTS, 'keep_remote_files', 'ANSIBLE_KEEP_REMOTE_FILES', False, boolean=True)
DEFAULT_SUDO              = get_config(p, DEFAULTS, 'sudo', 'ANSIBLE_SUDO', False, boolean=True)
DEFAULT_SUDO_EXE          = get_config(p, DEFAULTS, 'sudo_exe', 'ANSIBLE_SUDO_EXE', 'sudo')
DEFAULT_SUDO_FLAGS        = get_config(p, DEFAULTS, 'sudo_flags', 'ANSIBLE_SUDO_FLAGS', '-H')
DEFAULT_HASH_BEHAVIOUR    = get_config(p, DEFAULTS, 'hash_behaviour', 'ANSIBLE_HASH_BEHAVIOUR', 'replace')
DEFAULT_JINJA2_EXTENSIONS = get_config(p, DEFAULTS, 'jinja2_extensions', 'ANSIBLE_JINJA2_EXTENSIONS', None)
DEFAULT_EXECUTABLE        = get_config(p, DEFAULTS, 'executable', 'ANSIBLE_EXECUTABLE', '/bin/sh')
DEFAULT_SU_EXE = get_config(p, DEFAULTS, 'su_exe', 'ANSIBLE_SU_EXE', 'su')
DEFAULT_SU = get_config(p, DEFAULTS, 'su', 'ANSIBLE_SU', False, boolean=True)
DEFAULT_SU_FLAGS = get_config(p, DEFAULTS, 'su_flags', 'ANSIBLE_SU_FLAGS', '')
DEFAULT_SU_USER = get_config(p, DEFAULTS, 'su_user', 'ANSIBLE_SU_USER', 'root')
DEFAULT_ASK_SU_PASS = get_config(p, DEFAULTS, 'ask_su_pass', 'ANSIBLE_ASK_SU_PASS', False, boolean=True)
DEFAULT_GATHERING = get_config(p, DEFAULTS, 'gathering', 'ANSIBLE_GATHERING', 'implicit').lower()

DEFAULT_ACTION_PLUGIN_PATH     = get_config(p, DEFAULTS, 'action_plugins',     'ANSIBLE_ACTION_PLUGINS', '/usr/share/ansible_plugins/action_plugins')
DEFAULT_CALLBACK_PLUGIN_PATH   = get_config(p, DEFAULTS, 'callback_plugins',   'ANSIBLE_CALLBACK_PLUGINS', '/usr/share/ansible_plugins/callback_plugins')
DEFAULT_CONNECTION_PLUGIN_PATH = get_config(p, DEFAULTS, 'connection_plugins', 'ANSIBLE_CONNECTION_PLUGINS', '/usr/share/ansible_plugins/connection_plugins')
DEFAULT_LOOKUP_PLUGIN_PATH     = get_config(p, DEFAULTS, 'lookup_plugins',     'ANSIBLE_LOOKUP_PLUGINS', '/usr/share/ansible_plugins/lookup_plugins')
DEFAULT_VARS_PLUGIN_PATH       = get_config(p, DEFAULTS, 'vars_plugins',       'ANSIBLE_VARS_PLUGINS', '/usr/share/ansible_plugins/vars_plugins')
DEFAULT_FILTER_PLUGIN_PATH     = get_config(p, DEFAULTS, 'filter_plugins',     'ANSIBLE_FILTER_PLUGINS', '/usr/share/ansible_plugins/filter_plugins')
DEFAULT_LOG_PATH               = shell_expand_path(get_config(p, DEFAULTS, 'log_path',           'ANSIBLE_LOG_PATH', ''))

ANSIBLE_FORCE_COLOR            = get_config(p, DEFAULTS, 'force_color', 'ANSIBLE_FORCE_COLOR', None, boolean=True)
ANSIBLE_NOCOLOR                = get_config(p, DEFAULTS, 'nocolor', 'ANSIBLE_NOCOLOR', None, boolean=True)
ANSIBLE_NOCOWS                 = get_config(p, DEFAULTS, 'nocows', 'ANSIBLE_NOCOWS', None, boolean=True)
DISPLAY_SKIPPED_HOSTS          = get_config(p, DEFAULTS, 'display_skipped_hosts', 'DISPLAY_SKIPPED_HOSTS', True, boolean=True)
DEFAULT_UNDEFINED_VAR_BEHAVIOR = get_config(p, DEFAULTS, 'error_on_undefined_vars', 'ANSIBLE_ERROR_ON_UNDEFINED_VARS', True, boolean=True)
HOST_KEY_CHECKING              = get_config(p, DEFAULTS, 'host_key_checking',  'ANSIBLE_HOST_KEY_CHECKING',    True, boolean=True)
SYSTEM_WARNINGS                = get_config(p, DEFAULTS, 'system_warnings', 'ANSIBLE_SYSTEM_WARNINGS', True, boolean=True)
DEPRECATION_WARNINGS           = get_config(p, DEFAULTS, 'deprecation_warnings', 'ANSIBLE_DEPRECATION_WARNINGS', True, boolean=True)

# CONNECTION RELATED
ANSIBLE_SSH_ARGS               = get_config(p, 'ssh_connection', 'ssh_args', 'ANSIBLE_SSH_ARGS', None)
ANSIBLE_SSH_CONTROL_PATH       = get_config(p, 'ssh_connection', 'control_path', 'ANSIBLE_SSH_CONTROL_PATH', ""%(directory)s/ansible-ssh-%%h-%%p-%%r"")
ANSIBLE_SSH_PIPELINING         = get_config(p, 'ssh_connection', 'pipelining', 'ANSIBLE_SSH_PIPELINING', False, boolean=True)
PARAMIKO_RECORD_HOST_KEYS      = get_config(p, 'paramiko_connection', 'record_host_keys', 'ANSIBLE_PARAMIKO_RECORD_HOST_KEYS', True, boolean=True)
# obsolete -- will be formally removed in 1.6
ZEROMQ_PORT                    = get_config(p, 'fireball_connection', 'zeromq_port', 'ANSIBLE_ZEROMQ_PORT', 5099, integer=True)
ACCELERATE_PORT                = get_config(p, 'accelerate', 'accelerate_port', 'ACCELERATE_PORT', 5099, integer=True)
ACCELERATE_TIMEOUT             = get_config(p, 'accelerate', 'accelerate_timeout', 'ACCELERATE_TIMEOUT', 30, integer=True)
ACCELERATE_CONNECT_TIMEOUT     = get_config(p, 'accelerate', 'accelerate_connect_timeout', 'ACCELERATE_CONNECT_TIMEOUT', 1.0, floating=True)
ACCELERATE_DAEMON_TIMEOUT      = get_config(p, 'accelerate', 'accelerate_daemon_timeout', 'ACCELERATE_DAEMON_TIMEOUT', 30, integer=True)
ACCELERATE_KEYS_DIR            = get_config(p, 'accelerate', 'accelerate_keys_dir', 'ACCELERATE_KEYS_DIR', '~/.fireball.keys')
ACCELERATE_KEYS_DIR_PERMS      = get_config(p, 'accelerate', 'accelerate_keys_dir_perms', 'ACCELERATE_KEYS_DIR_PERMS', '700')
ACCELERATE_KEYS_FILE_PERMS     = get_config(p, 'accelerate', 'accelerate_keys_file_perms', 'ACCELERATE_KEYS_FILE_PERMS', '600')
ACCELERATE_MULTI_KEY           = get_config(p, 'accelerate', 'accelerate_multi_key', 'ACCELERATE_MULTI_KEY', False, boolean=True)
PARAMIKO_PTY                   = get_config(p, 'paramiko_connection', 'pty', 'ANSIBLE_PARAMIKO_PTY', True, boolean=True)

# characters included in auto-generated passwords
DEFAULT_PASSWORD_CHARS = ascii_letters + digits + "".,:-_""

# non-configurable things
DEFAULT_SUDO_PASS         = None
DEFAULT_REMOTE_PASS       = None
DEFAULT_SUBSET            = None
DEFAULT_SU_PASS           = None
VAULT_VERSION_MIN         = 1.0
VAULT_VERSION_MAX         = 1.0
",CWE-74,183.0,1
"# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.

#############################################

import os
import subprocess
import ansible.constants as C
from ansible.inventory.host import Host
from ansible.inventory.group import Group
from ansible import utils
from ansible import errors
import sys

class InventoryScript(object):
    ''' Host inventory parser for ansible using external inventory scripts. '''

    def __init__(self, filename=C.DEFAULT_HOST_LIST):

        # Support inventory scripts that are not prefixed with some
        # path information but happen to be in the current working
        # directory when '.' is not in PATH.
        self.filename = os.path.abspath(filename)
        cmd = [ self.filename, ""--list"" ]
        try:
            sp = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        except OSError, e:
            raise errors.AnsibleError(""problem running %s (%s)"" % (' '.join(cmd), e))
        (stdout, stderr) = sp.communicate()
        self.data = stdout
        # see comment about _meta below
        self.host_vars_from_top = None
        self.groups = self._parse(stderr)

    def _parse(self, err):

        all_hosts = {}
        self.raw  = utils.parse_json(self.data)
        all       = Group('all')
        groups    = dict(all=all)
        group     = None


        if 'failed' in self.raw:
            sys.stderr.write(err + ""\n"")
            raise errors.AnsibleError(""failed to parse executable inventory script results: %s"" % self.raw)

        for (group_name, data) in self.raw.items():
 
            # in Ansible 1.3 and later, a ""_meta"" subelement may contain
            # a variable ""hostvars"" which contains a hash for each host
            # if this ""hostvars"" exists at all then do not call --host for each
            # host.  This is for efficiency and scripts should still return data
            # if called with --host for backwards compat with 1.2 and earlier.

            if group_name == '_meta':
                if 'hostvars' in data:
                    self.host_vars_from_top = data['hostvars']
                    continue

            if group_name != all.name:
                group = groups[group_name] = Group(group_name)
            else:
                group = all
            host = None

            if not isinstance(data, dict):
                data = {'hosts': data}
            elif not any(k in data for k in ('hosts','vars')):
                data = {'hosts': [group_name], 'vars': data}

            if 'hosts' in data:

                for hostname in data['hosts']:
                    if not hostname in all_hosts:
                        all_hosts[hostname] = Host(hostname)
                    host = all_hosts[hostname]
                    group.add_host(host)

            if 'vars' in data:
                for k, v in data['vars'].iteritems():
                    if group.name == all.name:
                        all.set_variable(k, v)
                    else:
                        group.set_variable(k, v)
            if group.name != all.name:
                all.add_child_group(group)

        # Separate loop to ensure all groups are defined
        for (group_name, data) in self.raw.items():
            if group_name == '_meta':
                continue
            if isinstance(data, dict) and 'children' in data:
                for child_name in data['children']:
                    if child_name in groups:
                        groups[group_name].add_child_group(groups[child_name])
        return groups

    def get_host_variables(self, host):
        """""" Runs <script> --host <hostname> to determine additional host variables """"""
        if self.host_vars_from_top is not None:
            got = self.host_vars_from_top.get(host.name, {})
            return got


        cmd = [self.filename, ""--host"", host.name]
        try:
            sp = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        except OSError, e:
            raise errors.AnsibleError(""problem running %s (%s)"" % (' '.join(cmd), e))
        (out, err) = sp.communicate()
        return utils.parse_json(out)
",CWE-20,127.0,1
"# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.

from ansible import utils

class ReturnData(object):
    ''' internal return class for runner execute methods, not part of public API signature '''

    __slots__ = [ 'result', 'comm_ok', 'host', 'diff' ]

    def __init__(self, conn=None, host=None, result=None, 
        comm_ok=True, diff=dict()):

        # which host is this ReturnData about?
        if conn is not None:
            self.host = conn.host
            delegate = getattr(conn, 'delegate', None)
            if delegate is not None:
                self.host = delegate

        else:
            self.host = host

        self.result = result
        self.comm_ok = comm_ok

        # if these values are set and used with --diff we can show
        # changes made to particular files
        self.diff = diff

        if type(self.result) in [ str, unicode ]:
            self.result = utils.parse_json(self.result)


        if self.host is None:
            raise Exception(""host not set"")
        if type(self.result) != dict:
            raise Exception(""dictionary result expected"")

    def communicated_ok(self):
        return self.comm_ok

    def is_successful(self):
        return self.comm_ok and (self.result.get('failed', False) == False) and ('failed_when_result' in self.result and [not self.result['failed_when_result']] or [self.result.get('rc',0) == 0])[0]

",CWE-20,60.0,1
"# Based on local.py (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>
# and chroot.py     (c) 2013, Maykel Moya <mmoya@speedyrails.com>
# (c) 2013, Michael Scherer <misc@zarb.org>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import distutils.spawn
import traceback
import os
import shutil
import subprocess
from ansible import errors
from ansible.callbacks import vvv
import ansible.constants as C

class Connection(object):
    ''' Local chroot based connections '''

    def _search_executable(self, executable):
        cmd = distutils.spawn.find_executable(executable)
        if not cmd:
            raise errors.AnsibleError(""%s command not found in PATH"") % executable
        return cmd

    def list_jails(self):
        p = subprocess.Popen([self.jls_cmd, '-q', 'name'],
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()

        return stdout.split()

    def get_jail_path(self):
        p = subprocess.Popen([self.jls_cmd, '-j', self.jail, '-q', 'path'],
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()
        # remove \n
        return stdout[:-1]

 
        
    def __init__(self, runner, host, port, *args, **kwargs):
        self.jail = host
        self.runner = runner
        self.host = host
        self.has_pipelining = False
        self.become_methods_supported=C.BECOME_METHODS

        if os.geteuid() != 0:
            raise errors.AnsibleError(""jail connection requires running as root"")

        self.jls_cmd = self._search_executable('jls')
        self.jexec_cmd = self._search_executable('jexec')
        
        if not self.jail in self.list_jails():
            raise errors.AnsibleError(""incorrect jail name %s"" % self.jail)


        self.host = host
        # port is unused, since this is local
        self.port = port

    def connect(self, port=None):
        ''' connect to the chroot; nothing to do here '''

        vvv(""THIS IS A LOCAL CHROOT DIR"", host=self.jail)

        return self

    # a modifier
    def _generate_cmd(self, executable, cmd):
        if executable:
            local_cmd = [self.jexec_cmd, self.jail, executable, '-c', cmd]
        else:
            local_cmd = '%s ""%s"" %s' % (self.jexec_cmd, self.jail, cmd)
        return local_cmd

    def exec_command(self, cmd, tmp_path, become_user=None, sudoable=False, executable='/bin/sh', in_data=None):
        ''' run a command on the chroot '''

        if sudoable and self.runner.become and self.runner.become_method not in self.become_methods_supported:
            raise errors.AnsibleError(""Internal Error: this module does not support running commands via %s"" % self.runner.become_method)

        if in_data:
            raise errors.AnsibleError(""Internal Error: this module does not support optimized module pipelining"")

        # Ignores privilege escalation
        local_cmd = self._generate_cmd(executable, cmd)

        vvv(""EXEC %s"" % (local_cmd), host=self.jail)
        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()
        return (p.returncode, '', stdout, stderr)

    def _normalize_path(self, path, prefix):
        if not path.startswith(os.path.sep):
            path = os.path.join(os.path.sep, path)
        normpath = os.path.normpath(path)
        return os.path.join(prefix, normpath[1:])

    def _copy_file(self, in_path, out_path):
        if not os.path.exists(in_path):
            raise errors.AnsibleFileNotFound(""file or module does not exist: %s"" % in_path)
        try:
            shutil.copyfile(in_path, out_path)
        except shutil.Error:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to copy: %s and %s are the same"" % (in_path, out_path))
        except IOError:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to transfer file to %s"" % out_path)

    def put_file(self, in_path, out_path):
        ''' transfer a file from local to chroot '''

        out_path = self._normalize_path(out_path, self.get_jail_path())
        vvv(""PUT %s TO %s"" % (in_path, out_path), host=self.jail)

        self._copy_file(in_path, out_path)

    def fetch_file(self, in_path, out_path):
        ''' fetch a file from chroot to local '''

        in_path = self._normalize_path(in_path, self.get_jail_path())
        vvv(""FETCH %s TO %s"" % (in_path, out_path), host=self.jail)

        self._copy_file(in_path, out_path)

    def close(self):
        ''' terminate the connection; nothing to do here '''
        pass
",CWE-59,156.0,1
"# Based on local.py (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>
# and chroot.py     (c) 2013, Maykel Moya <mmoya@speedyrails.com>
# and jail.py       (c) 2013, Michael Scherer <misc@zarb.org>
# (c) 2015, Dagobert Michelsen <dam@baltic-online.de>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import distutils.spawn
import traceback
import os
import shutil
import subprocess
from subprocess import Popen,PIPE
from ansible import errors
from ansible.callbacks import vvv
import ansible.constants as C

class Connection(object):
    ''' Local zone based connections '''

    def _search_executable(self, executable):
        cmd = distutils.spawn.find_executable(executable)
        if not cmd:
            raise errors.AnsibleError(""%s command not found in PATH"") % executable
        return cmd

    def list_zones(self):
        pipe = subprocess.Popen([self.zoneadm_cmd, 'list', '-ip'],
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        #stdout, stderr = p.communicate()
        zones = []
        for l in pipe.stdout.readlines():
          # 1:work:running:/zones/work:3126dc59-9a07-4829-cde9-a816e4c5040e:native:shared
          s = l.split(':')
          if s[1] != 'global':
            zones.append(s[1])

        return zones

    def get_zone_path(self):
        #solaris10vm# zoneadm -z cswbuild list -p         
        #-:cswbuild:installed:/zones/cswbuild:479f3c4b-d0c6-e97b-cd04-fd58f2c0238e:native:shared
        pipe = subprocess.Popen([self.zoneadm_cmd, '-z', self.zone, 'list', '-p'],
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        #stdout, stderr = p.communicate()
        path = pipe.stdout.readlines()[0].split(':')[3]
        return path + '/root'
        
    def __init__(self, runner, host, port, *args, **kwargs):
        self.zone = host
        self.runner = runner
        self.host = host
        self.has_pipelining = False
        self.become_methods_supported=C.BECOME_METHODS

        if os.geteuid() != 0:
            raise errors.AnsibleError(""zone connection requires running as root"")

        self.zoneadm_cmd = self._search_executable('zoneadm')
        self.zlogin_cmd = self._search_executable('zlogin')
        
        if not self.zone in self.list_zones():
            raise errors.AnsibleError(""incorrect zone name %s"" % self.zone)


        self.host = host
        # port is unused, since this is local
        self.port = port

    def connect(self, port=None):
        ''' connect to the zone; nothing to do here '''

        vvv(""THIS IS A LOCAL ZONE DIR"", host=self.zone)

        return self

    # a modifier
    def _generate_cmd(self, executable, cmd):
        if executable:
            local_cmd = [self.zlogin_cmd, self.zone, executable, cmd]
        else:
            local_cmd = '%s ""%s"" %s' % (self.zlogin_cmd, self.zone, cmd)
        return local_cmd

    def exec_command(self, cmd, tmp_path, become_user=None, sudoable=False, executable=None, in_data=None):
        ''' run a command on the zone '''

        if sudoable and self.runner.become and self.runner.become_method not in self.become_methods_supported:
            raise errors.AnsibleError(""Internal Error: this module does not support running commands via %s"" % self.runner.become_method)

        if in_data:
            raise errors.AnsibleError(""Internal Error: this module does not support optimized module pipelining"")

        # We happily ignore privilege escalation
        if executable == '/bin/sh':
          executable = None
        local_cmd = self._generate_cmd(executable, cmd)

        vvv(""EXEC %s"" % (local_cmd), host=self.zone)
        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()
        return (p.returncode, '', stdout, stderr)

    def _normalize_path(self, path, prefix):
        if not path.startswith(os.path.sep):
            path = os.path.join(os.path.sep, path)
        normpath = os.path.normpath(path)
        return os.path.join(prefix, normpath[1:])

    def _copy_file(self, in_path, out_path):
        if not os.path.exists(in_path):
            raise errors.AnsibleFileNotFound(""file or module does not exist: %s"" % in_path)
        try:
            shutil.copyfile(in_path, out_path)
        except shutil.Error:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to copy: %s and %s are the same"" % (in_path, out_path))
        except IOError:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to transfer file to %s"" % out_path)

    def put_file(self, in_path, out_path):
        ''' transfer a file from local to zone '''

        out_path = self._normalize_path(out_path, self.get_zone_path())
        vvv(""PUT %s TO %s"" % (in_path, out_path), host=self.zone)

        self._copy_file(in_path, out_path)

    def fetch_file(self, in_path, out_path):
        ''' fetch a file from zone to local '''

        in_path = self._normalize_path(in_path, self.get_zone_path())
        vvv(""FETCH %s TO %s"" % (in_path, out_path), host=self.zone)

        self._copy_file(in_path, out_path)

    def close(self):
        ''' terminate the connection; nothing to do here '''
        pass
",CWE-59,165.0,1
"# Based on local.py (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>
# (c) 2013, Maykel Moya <mmoya@speedyrails.com>
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import distutils.spawn
import traceback
import os
import shutil
import subprocess
from ansible import errors
from ansible import utils
from ansible.callbacks import vvv
import ansible.constants as C

class Connection(object):
    ''' Local chroot based connections '''

    def __init__(self, runner, host, port, *args, **kwargs):
        self.chroot = host
        self.has_pipelining = False
        self.become_methods_supported=C.BECOME_METHODS

        if os.geteuid() != 0:
            raise errors.AnsibleError(""chroot connection requires running as root"")

        # we're running as root on the local system so do some
        # trivial checks for ensuring 'host' is actually a chroot'able dir
        if not os.path.isdir(self.chroot):
            raise errors.AnsibleError(""%s is not a directory"" % self.chroot)

        chrootsh = os.path.join(self.chroot, 'bin/sh')
        if not utils.is_executable(chrootsh):
            raise errors.AnsibleError(""%s does not look like a chrootable dir (/bin/sh missing)"" % self.chroot)

        self.chroot_cmd = distutils.spawn.find_executable('chroot')
        if not self.chroot_cmd:
            raise errors.AnsibleError(""chroot command not found in PATH"")

        self.runner = runner
        self.host = host
        # port is unused, since this is local
        self.port = port

    def connect(self, port=None):
        ''' connect to the chroot; nothing to do here '''

        vvv(""THIS IS A LOCAL CHROOT DIR"", host=self.chroot)

        return self

    def exec_command(self, cmd, tmp_path, become_user=None, sudoable=False, executable='/bin/sh', in_data=None):
        ''' run a command on the chroot '''

        if sudoable and self.runner.become and self.runner.become_method not in self.become_methods_supported:
            raise errors.AnsibleError(""Internal Error: this module does not support running commands via %s"" % self.runner.become_method)

        if in_data:
            raise errors.AnsibleError(""Internal Error: this module does not support optimized module pipelining"")

        # We enter chroot as root so we ignore privlege escalation?

        if executable:
            local_cmd = [self.chroot_cmd, self.chroot, executable, '-c', cmd]
        else:
            local_cmd = '%s ""%s"" %s' % (self.chroot_cmd, self.chroot, cmd)

        vvv(""EXEC %s"" % (local_cmd), host=self.chroot)
        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),
                             cwd=self.runner.basedir,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()
        return (p.returncode, '', stdout, stderr)

    def put_file(self, in_path, out_path):
        ''' transfer a file from local to chroot '''

        if not out_path.startswith(os.path.sep):
            out_path = os.path.join(os.path.sep, out_path)
        normpath = os.path.normpath(out_path)
        out_path = os.path.join(self.chroot, normpath[1:])

        vvv(""PUT %s TO %s"" % (in_path, out_path), host=self.chroot)
        if not os.path.exists(in_path):
            raise errors.AnsibleFileNotFound(""file or module does not exist: %s"" % in_path)
        try:
            shutil.copyfile(in_path, out_path)
        except shutil.Error:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to copy: %s and %s are the same"" % (in_path, out_path))
        except IOError:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to transfer file to %s"" % out_path)

    def fetch_file(self, in_path, out_path):
        ''' fetch a file from chroot to local '''

        if not in_path.startswith(os.path.sep):
            in_path = os.path.join(os.path.sep, in_path)
        normpath = os.path.normpath(in_path)
        in_path = os.path.join(self.chroot, normpath[1:])

        vvv(""FETCH %s TO %s"" % (in_path, out_path), host=self.chroot)
        if not os.path.exists(in_path):
            raise errors.AnsibleFileNotFound(""file or module does not exist: %s"" % in_path)
        try:
            shutil.copyfile(in_path, out_path)
        except shutil.Error:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to copy: %s and %s are the same"" % (in_path, out_path))
        except IOError:
            traceback.print_exc()
            raise errors.AnsibleError(""failed to transfer file to %s"" % out_path)

    def close(self):
        ''' terminate the connection; nothing to do here '''
        pass
",CWE-59,135.0,1
,CWE-20,,1
,CWE-119,,1
,CWE-119,,1
"import pytest

from PIL import FliImagePlugin, Image

from .helper import assert_image_equal_tofile, is_pypy

# created as an export of a palette image from Gimp2.6
# save as...-> hopper.fli, default options.
static_test_file = ""Tests/images/hopper.fli""

# From https://samples.libav.org/fli-flc/
animated_test_file = ""Tests/images/a.fli""


def test_sanity():
    with Image.open(static_test_file) as im:
        im.load()
        assert im.mode == ""P""
        assert im.size == (128, 128)
        assert im.format == ""FLI""
        assert not im.is_animated

    with Image.open(animated_test_file) as im:
        assert im.mode == ""P""
        assert im.size == (320, 200)
        assert im.format == ""FLI""
        assert im.info[""duration""] == 71
        assert im.is_animated


@pytest.mark.skipif(is_pypy(), reason=""Requires CPython"")
def test_unclosed_file():
    def open():
        im = Image.open(static_test_file)
        im.load()

    pytest.warns(ResourceWarning, open)


def test_closed_file():
    with pytest.warns(None) as record:
        im = Image.open(static_test_file)
        im.load()
        im.close()

    assert not record


def test_context_manager():
    with pytest.warns(None) as record:
        with Image.open(static_test_file) as im:
            im.load()

    assert not record


def test_tell():
    # Arrange
    with Image.open(static_test_file) as im:

        # Act
        frame = im.tell()

        # Assert
        assert frame == 0


def test_invalid_file():
    invalid_file = ""Tests/images/flower.jpg""

    with pytest.raises(SyntaxError):
        FliImagePlugin.FliImageFile(invalid_file)


def test_n_frames():
    with Image.open(static_test_file) as im:
        assert im.n_frames == 1
        assert not im.is_animated

    with Image.open(animated_test_file) as im:
        assert im.n_frames == 384
        assert im.is_animated


def test_eoferror():
    with Image.open(animated_test_file) as im:
        n_frames = im.n_frames

        # Test seeking past the last frame
        with pytest.raises(EOFError):
            im.seek(n_frames)
        assert im.tell() < n_frames

        # Test that seeking to the last frame does not raise an error
        im.seek(n_frames - 1)


def test_seek_tell():
    with Image.open(animated_test_file) as im:

        layer_number = im.tell()
        assert layer_number == 0

        im.seek(0)
        layer_number = im.tell()
        assert layer_number == 0

        im.seek(1)
        layer_number = im.tell()
        assert layer_number == 1

        im.seek(2)
        layer_number = im.tell()
        assert layer_number == 2

        im.seek(1)
        layer_number = im.tell()
        assert layer_number == 1


def test_seek():
    with Image.open(animated_test_file) as im:
        im.seek(50)

        assert_image_equal_tofile(im, ""Tests/images/a_fli.png"")
",CWE-835,126.0,1
"#
# djblets_js.py -- JavaScript-related template tags
#
# Copyright (c) 2007-2009  Christian Hammond
# Copyright (c) 2007-2009  David Trowbridge
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# ""Software""), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

from __future__ import unicode_literals

import json

from django import template
from django.core.serializers import serialize
from django.db.models.query import QuerySet
from django.utils import six
from django.utils.safestring import mark_safe

from djblets.util.serializers import DjbletsJSONEncoder


register = template.Library()


@register.simple_tag
def form_dialog_fields(form):
    """"""
    Translates a Django Form object into a JavaScript list of fields.
    The resulting list of fields can be used to represent the form
    dynamically.
    """"""
    s = ''

    for field in form:
        s += ""{ name: '%s', "" % field.name

        if field.is_hidden:
            s += ""hidden: true, ""
        else:
            s += ""label: '%s', "" % field.label_tag(field.label + "":"")

            if field.field.required:
                s += ""required: true, ""

            if field.field.help_text:
                s += ""help_text: '%s', "" % field.field.help_text

        s += ""widget: '%s' },"" % six.text_type(field)

    # Chop off the last ','
    return ""[ %s ]"" % s[:-1]


@register.filter
def json_dumps(value, indent=None):
    if isinstance(value, QuerySet):
        result = serialize('json', value, indent=indent)
    else:
        result = json.dumps(value, indent=indent, cls=DjbletsJSONEncoder)

    return mark_safe(result)


@register.filter
def json_dumps_items(d, append=''):
    """"""Dumps a list of keys/values from a dictionary, without braces.

    This works very much like ``json_dumps``, but doesn't output the
    surrounding braces. This allows it to be used within a JavaScript
    object definition alongside other custom keys.

    If the dictionary is not empty, and ``append`` is passed, it will be
    appended onto the results. This is most useful when you want to append
    a comma after all the dictionary items, in order to provide further
    keys in the template.
    """"""
    if not d:
        return ''

    return mark_safe(json_dumps(d)[1:-1] + append)
",CWE-79,98.0,1
,CWE-79,,1
"#
# gravatars.py -- Decorational template tags
#
# Copyright (c) 2008-2009  Christian Hammond
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# ""Software""), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

from __future__ import unicode_literals

from django import template

from djblets.gravatars import (get_gravatar_url,
                               get_gravatar_url_for_email)
from djblets.util.decorators import basictag


register = template.Library()


@register.tag
@basictag(takes_context=True)
def gravatar(context, user, size=None):
    """"""
    Outputs the HTML for displaying a user's gravatar.

    This can take an optional size of the image (defaults to 80 if not
    specified).

    This is also influenced by the following settings:

        GRAVATAR_SIZE    - Default size for gravatars
        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)
        GRAVATAR_DEFAULT - Default image set to show if the user hasn't
                           specified a gravatar (identicon, monsterid, wavatar)

    See http://www.gravatar.com/ for more information.
    """"""
    url = get_gravatar_url(context['request'], user, size)

    if url:
        return ('<img src=""%s"" width=""%s"" height=""%s"" alt=""%s"" '
                '     class=""gravatar""/>' %
                (url, size, size, user.get_full_name() or user.username))
    else:
        return ''


@register.tag
@basictag(takes_context=True)
def gravatar_url(context, email, size=None):
    """"""
    Outputs the URL for a gravatar for the given email address.

    This can take an optional size of the image (defaults to 80 if not
    specified).

    This is also influenced by the following settings:

        GRAVATAR_SIZE    - Default size for gravatars
        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)
        GRAVATAR_DEFAULT - Default image set to show if the user hasn't
                           specified a gravatar (identicon, monsterid, wavatar)

    See http://www.gravatar.com/ for more information.
    """"""
    return get_gravatar_url_for_email(context['request'], email, size)
",CWE-79,84.0,1
,CWE-79,,1
,CWE-835,,1
"IS-IS, length 1497
	L1 Lan IIH, hlen: 27, v: 1, pdu-v: 1, sys-id-len: 6 (0), max-area: 3 (0)
	  source-id: 3333.3333.3333,  holding time: 10s, Flags: [unknown circuit type 0x21]
	  lan-id:    3333.5a33.3333.02, Priority: 64, PDU length: 1497
	    Multi-Topology Capability TLV #144, length: 1
	      O: 1, RES: 4, MTID(s): 3073
	      unknown subTLV #4, length: 3
	      unknown subTLV #73, length: 0
	      unknown subTLV #10, length: 132
	      unknown subTLV #4, length: 10
	      unknown subTLV #0, length: 10
	      unknown subTLV #0, length: 55
	      SPBM Service Identifier and Unicast Address subTLV #3, length: 0
	        BMAC: 00000606c201, RES: 2, VID: 2456
	      unknown subTLV #204, length: 83
	      unknown subTLV #8, length: 191
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #82, length: 0
	      unknown subTLV #0, length: 86
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 37
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 108
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #48, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #172, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #76, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 90
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 90
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 107
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 37
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #2, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 92
	      unknown subTLV #0, length: 0
	      unknown subTLV #113, length: 90
	      unknown subTLV #0, length: 230
	      unknown subTLV #0, length: 0
	      unknown subTLV #79, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #234, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #64, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #37, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #2, length: 0
	      unknown subTLV #0, length: 0
	      unknown subTLV #0, length: 0
	    Area address(es) TLV #1, length: 4
	      Area address (length: 3): 49.000a
	    IPv4 Interface address(es) TLV #132, length: 4
	      IPv4 interface address: 10.0.10.0
	    unknown TLV #55, length: 3
		0x0000:  0000 00
	    IS Neighbor(s) TLV #6, length: 6
	      SNPA: c201.2998.cc53
	    Padding TLV #8, length: 191
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 37
		0x0000:  0000 0000 0000 0025 0000 0000 0000 0000
		0x0010:  0000 0002 0000 0000 0000 0000 0000 0000
		0x0020:  0000 7300 1e
	    unknown TLV #0, length: 0
	    unknown TLV #0, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170
		0x0000:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0010:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0020:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0030:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0040:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0050:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0060:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0070:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0080:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x0090:  aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa
		0x00a0:  aaaa aaaa aaaa aaaa aaaa
	    unknown TLV #170, length: 170 [|isis]
",CWE-125,223.0,1
"from __future__ import absolute_import, division, print_function, with_statement

import traceback

from tornado.concurrent import Future
from tornado.httpclient import HTTPError, HTTPRequest
from tornado.log import gen_log
from tornado.testing import AsyncHTTPTestCase, gen_test, bind_unused_port, ExpectLog
from tornado.test.util import unittest, skipOnTravis
from tornado.web import Application, RequestHandler

try:
    import tornado.websocket
except ImportError:
    # The unittest module presents misleading errors on ImportError
    # (it acts as if websocket_test could not be found, hiding the underlying
    # error).  If we get an ImportError here (which could happen due to
    # TORNADO_EXTENSION=1), print some extra information before failing.
    traceback.print_exc()
    raise

from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, _websocket_mask_python

try:
    from tornado import speedups
except ImportError:
    speedups = None


class TestWebSocketHandler(WebSocketHandler):
    """"""Base class for testing handlers that exposes the on_close event.

    This allows for deterministic cleanup of the associated socket.
    """"""
    def initialize(self, close_future):
        self.close_future = close_future

    def on_close(self):
        self.close_future.set_result(None)


class EchoHandler(TestWebSocketHandler):
    def on_message(self, message):
        self.write_message(message, isinstance(message, bytes))


class HeaderHandler(TestWebSocketHandler):
    def open(self):
        self.write_message(self.request.headers.get('X-Test', ''))


class NonWebSocketHandler(RequestHandler):
    def get(self):
        self.write('ok')


class WebSocketTest(AsyncHTTPTestCase):
    def get_app(self):
        self.close_future = Future()
        return Application([
            ('/echo', EchoHandler, dict(close_future=self.close_future)),
            ('/non_ws', NonWebSocketHandler),
            ('/header', HeaderHandler, dict(close_future=self.close_future)),
        ])

    @gen_test
    def test_websocket_gen(self):
        ws = yield websocket_connect(
            'ws://localhost:%d/echo' % self.get_http_port(),
            io_loop=self.io_loop)
        ws.write_message('hello')
        response = yield ws.read_message()
        self.assertEqual(response, 'hello')
        ws.close()
        yield self.close_future

    def test_websocket_callbacks(self):
        websocket_connect(
            'ws://localhost:%d/echo' % self.get_http_port(),
            io_loop=self.io_loop, callback=self.stop)
        ws = self.wait().result()
        ws.write_message('hello')
        ws.read_message(self.stop)
        response = self.wait().result()
        self.assertEqual(response, 'hello')
        ws.close()
        yield self.close_future

    @gen_test
    def test_websocket_http_fail(self):
        with self.assertRaises(HTTPError) as cm:
            yield websocket_connect(
                'ws://localhost:%d/notfound' % self.get_http_port(),
                io_loop=self.io_loop)
        self.assertEqual(cm.exception.code, 404)

    @gen_test
    def test_websocket_http_success(self):
        with self.assertRaises(WebSocketError):
            yield websocket_connect(
                'ws://localhost:%d/non_ws' % self.get_http_port(),
                io_loop=self.io_loop)

    @skipOnTravis
    @gen_test
    def test_websocket_network_timeout(self):
        sock, port = bind_unused_port()
        sock.close()
        with self.assertRaises(HTTPError) as cm:
            with ExpectLog(gen_log, "".*""):
                yield websocket_connect(
                    'ws://localhost:%d/' % port,
                    io_loop=self.io_loop,
                    connect_timeout=0.01)
        self.assertEqual(cm.exception.code, 599)

    @gen_test
    def test_websocket_network_fail(self):
        sock, port = bind_unused_port()
        sock.close()
        with self.assertRaises(HTTPError) as cm:
            with ExpectLog(gen_log, "".*""):
                yield websocket_connect(
                    'ws://localhost:%d/' % port,
                    io_loop=self.io_loop,
                    connect_timeout=3600)
        self.assertEqual(cm.exception.code, 599)

    @gen_test
    def test_websocket_close_buffered_data(self):
        ws = yield websocket_connect(
            'ws://localhost:%d/echo' % self.get_http_port())
        ws.write_message('hello')
        ws.write_message('world')
        ws.stream.close()
        yield self.close_future

    @gen_test
    def test_websocket_headers(self):
        # Ensure that arbitrary headers can be passed through websocket_connect.
        ws = yield websocket_connect(
            HTTPRequest('ws://localhost:%d/header' % self.get_http_port(),
                        headers={'X-Test': 'hello'}))
        response = yield ws.read_message()
        self.assertEqual(response, 'hello')
        ws.close()
        yield self.close_future


class MaskFunctionMixin(object):
    # Subclasses should define self.mask(mask, data)
    def test_mask(self):
        self.assertEqual(self.mask(b'abcd', b''), b'')
        self.assertEqual(self.mask(b'abcd', b'b'), b'\x03')
        self.assertEqual(self.mask(b'abcd', b'54321'), b'TVPVP')
        self.assertEqual(self.mask(b'ZXCV', b'98765432'), b'c`t`olpd')
        # Include test cases with \x00 bytes (to ensure that the C
        # extension isn't depending on null-terminated strings) and
        # bytes with the high bit set (to smoke out signedness issues).
        self.assertEqual(self.mask(b'\x00\x01\x02\x03',
                                   b'\xff\xfb\xfd\xfc\xfe\xfa'),
                         b'\xff\xfa\xff\xff\xfe\xfb')
        self.assertEqual(self.mask(b'\xff\xfb\xfd\xfc',
                                   b'\x00\x01\x02\x03\x04\x05'),
                         b'\xff\xfa\xff\xff\xfb\xfe')


class PythonMaskFunctionTest(MaskFunctionMixin, unittest.TestCase):
    def mask(self, mask, data):
        return _websocket_mask_python(mask, data)


@unittest.skipIf(speedups is None, ""tornado.speedups module not present"")
class CythonMaskFunctionTest(MaskFunctionMixin, unittest.TestCase):
    def mask(self, mask, data):
        return speedups.websocket_mask(mask, data)
",CWE-203,177.0,1
"from flask import current_app, request
from flask_restful import Resource, abort
from dns import reversename, rdatatype
from dns.resolver import NXDOMAIN, NoNameservers

from resolverapi.util import is_valid_hostname, is_valid_rdtype, is_valid_ip
from resolverapi.util.dns_query import parse_query
from resolverapi import dns_resolver

import time
from dns.exception import Timeout


class LookupRecordType(Resource):

    def get(self, rdtype, domain):
        t1 = time.time()

        rdtype = rdtype.upper()
        current_app.logger.info(
            'Request from %s - %s %s', request.remote_addr, rdtype, domain)
        self.valid_args(rdtype, domain)

        # Iterate through nameservers so that we can tell which one gets used.
        nameservers = current_app.config['RESOLVERS']
        for nameserver in nameservers:
            dns_resolver.nameservers = [nameserver]
            try:
                answer = dns_resolver.query(
                    domain, rdtype, raise_on_no_answer=False)
                # Successful query
                break
            except (NoNameservers, NXDOMAIN):
                # TODO: this should still follow the RFC
                return {'message': ""No nameservers for %s"" % domain}, 404
            except Timeout as e:
                # Communication fail or timeout - try next nameserver
                if nameserver is nameservers[-1]:
                    current_app.logger.info(e)
                    return {'message': 'All nameservers timed out.'}, 503
                continue
            except Exception as e:
                current_app.logger.error(e)
                return {'message': 'An unexpected error occured.'}, 500

        t2 = time.time()
        duration = t2 - t1

        return parse_query(answer, nameserver, duration)

    def valid_args(self, rdtype, domain):
        if not is_valid_rdtype(rdtype):
            abort(400, message=""%s type is not supported"" % rdtype)
        if not is_valid_hostname(domain):
            abort(400, message=""%s is not a valid domain name"" % domain)


class ReverseLookup(Resource):

    def get(self, ip):
        t1 = time.time()
        self.valid_args(ip)

        # Iterate through nameservers so that we can tell which one gets used.
        nameservers = current_app.config['RESOLVERS']
        for nameserver in nameservers:
            dns_resolver.nameservers = [nameserver]
            try:
                # http://stackoverflow.com/a/19867936/1707152
                answer = dns_resolver.query(
                    reversename.from_address(ip), rdatatype.PTR,
                    raise_on_no_answer=False)
                # Successful query
                break
            except Timeout as e:
                # Communication fail or timeout - try next nameserver
                if nameserver is nameservers[-1]:
                    current_app.logger.info(e)
                    return {'message': 'All nameservers timed out.'}, 503
                continue
            except NXDOMAIN:
                return {'message': 'No nameserver found for %s' % ip}, 404
            except Exception as e:
                current_app.logger.error(e)
                return {'message': 'An unexpected error occured.'}, 500

        t2 = time.time()
        duration = t2 - t1

        if answer is None:
            return {'message': 'An unexpected error occured.'}, 500
        return parse_query(answer, nameserver, duration)

    def valid_args(self, ip):
        if not is_valid_ip(ip):
            abort(400, message=""%s is not a valid ip address"" % ip)
",CWE-116,97.0,1
"from flask import current_app, request
from flask_restful import Resource, abort
from dns import reversename, rdatatype
from dns.resolver import NXDOMAIN, NoNameservers

from resolverapi.util import is_valid_hostname, is_valid_rdtype, is_valid_ip
from resolverapi.util.dns_query import parse_query
from resolverapi import dns_resolver

import time
from dns.exception import Timeout


class LookupRecordType(Resource):

    def get(self, rdtype, domain):
        t1 = time.time()

        rdtype = rdtype.upper()
        current_app.logger.info(
            'Request from %s - %s', request.remote_addr, rdtype)
        self.valid_args(rdtype, domain)

        # Iterate through nameservers so that we can tell which one gets used.
        nameservers = current_app.config['RESOLVERS']
        for nameserver in nameservers:
            dns_resolver.nameservers = [nameserver]
            try:
                answer = dns_resolver.query(
                    domain, rdtype, raise_on_no_answer=False)
                # Successful query
                break
            except (NoNameservers, NXDOMAIN):
                # TODO: this should still follow the RFC
                return {'message': ""No nameservers for %s"" % domain}, 404
            except Timeout as e:
                # Communication fail or timeout - try next nameserver
                if nameserver is nameservers[-1]:
                    current_app.logger.info(e)
                    return {'message': 'All nameservers timed out.'}, 503
                continue
            except Exception as e:
                current_app.logger.error(e)
                return {'message': 'An unexpected error occured.'}, 500

        t2 = time.time()
        duration = t2 - t1

        return parse_query(answer, nameserver, duration)

    def valid_args(self, rdtype, domain):
        if not is_valid_rdtype(rdtype):
            abort(400, message=""%s type is not supported"" % rdtype)
        if not is_valid_hostname(domain):
            abort(400, message=""%s is not a valid domain name"" % domain)


class ReverseLookup(Resource):

    def get(self, ip):
        t1 = time.time()
        self.valid_args(ip)

        # Iterate through nameservers so that we can tell which one gets used.
        nameservers = current_app.config['RESOLVERS']
        for nameserver in nameservers:
            dns_resolver.nameservers = [nameserver]
            try:
                # http://stackoverflow.com/a/19867936/1707152
                answer = dns_resolver.query(
                    reversename.from_address(ip), rdatatype.PTR,
                    raise_on_no_answer=False)
                # Successful query
                break
            except Timeout as e:
                # Communication fail or timeout - try next nameserver
                if nameserver is nameservers[-1]:
                    current_app.logger.info(e)
                    return {'message': 'All nameservers timed out.'}, 503
                continue
            except NXDOMAIN:
                return {'message': 'No nameserver found for %s' % ip}, 404
            except Exception as e:
                current_app.logger.error(e)
                return {'message': 'An unexpected error occured.'}, 500

        t2 = time.time()
        duration = t2 - t1

        if answer is None:
            return {'message': 'An unexpected error occured.'}, 500
        return parse_query(answer, nameserver, duration)

    def valid_args(self, ip):
        if not is_valid_ip(ip):
            abort(400, message=""%s is not a valid ip address"" % ip)
",CWE-79,97.0,1
"# coding=utf-8
import praw
import sqlite3
import time

con = sqlite3.connect('estados_municipios.db')
cursor = con.cursor()

def dbLookup(msg):
    if len(msg.split(',')) != 2:
        #procura na lista de paises
        query = 'SELECT id FROM paises WHERE nome == ""%s""' % (msg)
        cursor.execute(query)
        if cursor.fetchone():
            return True
        else:
            return False
    else:
        cidade = msg.split(',')[0].strip()
        estado = msg.split(',')[1].strip()
        #check cidade pertence ao estado
        query = 'SELECT estados.id FROM municipios JOIN estados ON municipios.estados_id == estados.id WHERE municipios.nome == ""%s"" AND estados.uf == ""%s"";' % (cidade, estado)
        cursor.execute(query)
        if not cursor.fetchone():
            return False
            
    return True
    

def main():
    r = praw.Reddit(user_agent='flairbotbr')
    r.login('botbr', 'apassword')
    if r.is_logged_in():
        print 'logged in'
    else:
        print 'failed to log in'
        return
    while True:
        time.sleep(0.5)
        for msg in r.get_unread(limit=None):
            try:
                print 'AUTHOR: %s - SUBJECT: %s - BODY: %s' % (msg.author, msg.subject, msg.body)
            except UnicodeEncodeError:
                print 'AUTHOR: %s - unprintable chars' % (msg.author)
            sub = r.get_subreddit('brasil')
            if msg.subject == 'flair':
                if dbLookup(msg.body):
                    estado = 'world' if len(msg.body.split(',')) < 2 else msg.body.split(',')[1].strip()
                    sub.set_flair(msg.author,msg.body,estado)
                    r.send_message(msg.author,'flair','Flair configurado.')
                    print('flair ok')
                else:
                    r.send_message(msg.author,'flair','Configurao de flair falhou.')
                    print('flair fail')
            if msg.subject == 'remover flair':
                sub.set_flair(msg.author,'','')
                r.send_message(msg.author,'flair','Flair removido.')
                print('remove flair ok')
                
            msg.mark_as_read()

if __name__ == '__main__':
    main()
    ",CWE-89,64.0,1
"from django.shortcuts import render
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseNotFound
from models import Record,Store
from django.db import connection
from recordstoreapp.forms import RecordForm,StoreForm
from django.shortcuts import redirect
from django.core.urlresolvers import reverse

def index(request):
	context_dict = {}
	return render(request, 'index.html', context_dict)

def about(request):
	context_dict = {}
	return render(request, 'about.html', context_dict)

def faq(request):
	context_dict = {}
	return render(request, 'faq.html', context_dict)

def contact(request):
	context_dict = {}
	return render(request, 'contact.html', context_dict)

def search(request):
	context_dict = {}
	if 'q' in request.GET and request.GET['q'] != '':
		q = request.GET['q']
		cursor = connection.cursor()
		cursor.execute(""SELECT id,title,artist,cover FROM recordstoreapp_record WHERE title like '%"" + q + ""%' or artist like '%"" + q + ""%' or label like '%"" + q + ""%' or cat_no like '%"" + q + ""%';"")
		rec_list=cursor.fetchall()
		
		total=len(rec_list)
		pg=int(request.GET['page']) if 'page' in request.GET else 1
		ub=min(pg*12, total)

		context_dict['rec_list'] = rec_list[(pg-1)*12:ub]
		maxrange = int(total/12)
		if total%12 > 0: 
			maxrange = maxrange + 1
		if maxrange == 1: 
			maxrange = 0
		context_dict['range'] = range(1,maxrange+1)
		print total
		context_dict['q'] = q

	return render(request, 'search.html', context_dict)


def new_releases(request):
	context_dict = {}
	
	rec_list = Record.objects.all()
	total=len(rec_list)
	pg=int(request.GET['page']) if 'page' in request.GET else 1
	ub=min(pg*12, total)

	context_dict['rec_list'] = rec_list[(pg-1)*12:ub]
	maxrange = int(total/12)
	if total%12 > 0: 
		maxrange = maxrange + 1
	if maxrange == 1: 
		maxrange = 0
	context_dict['range'] = range(1,maxrange+1)

	return render(request, 'releases.html', context_dict)


def record_view(request):
	page_id = None
	context_dict = {}
	if request.method == 'GET':
		if 'record_id' in request.GET:
			record_id = request.GET['record_id']
			if record_id:
				record = Record.objects.get(id=record_id)
				context_dict['stores']=Store.objects.filter(record=record)#record.stores.all()
				context_dict['record'] = record
	return render(request, 'record.html', context_dict)
	
def add_record(request):
	if request.method == 'POST':
		form = RecordForm(request.POST)

		if form.is_valid():
			form.save(commit=True)

			return index(request)
		else:
			print form.errors
	else:
		form = RecordForm()

	return render(request, 'add_record.html', {'form': form})
	
def add_store(request, record_id):
	try:
	    if not isinstance(record_id, int):
	        rec = None
	    else:
		    rec = Record.objects.get(id=record_id)
	except:
		rec = None
	if request.method == 'POST':
		form = StoreForm(request.POST)
		if form.is_valid():
			if rec:
				s = form.save(commit=False)
				s.save()
				rec.stores.add(s)
				return redirect(reverse('records') + '?record_id=' + record_id)
		else:
			print form.errors
	else:
		form = StoreForm()

	context_dict = {'form': form, 'record': rec}

	return render(request, 'add_store.html', context_dict)",CWE-89,119.0,1
"from django.shortcuts import render
from django.views.generic import TemplateView, View
from haystack.query import SearchQuerySet
from haystack.utils.geo import Point
from django.http import HttpResponse
from django.contrib.gis.measure import D
from django.contrib.gis.geos import GEOSGeometry
from django.db import connection

from Data.models import BestBikeTrails, MinnesotaBikeTrails

from requests import get
import xml.etree.ElementTree as ET
from json import dumps, loads


class MainPage(TemplateView):
    def get(self, request, *args, **kwargs):
        return render(request, 'index.html')


class SearchAjax(TemplateView):
    def get(self, request, *args, **kwargs):
        lat = float(request.GET.get('lat',''))
        lng = float(request.GET.get('lng',''))
        qs = SearchQuerySet().filter(content_auto=request.GET.get('q',"""")).distance('geometry',Point(lng,lat,srid=4326)).order_by('distance')
        if len(qs)>6:
            qs = qs[:5]
        json = [(q.content_auto,"" ""+(""%.2f"" % (q.distance.m if q.distance.m<1000 else q.distance.mi))+("" meters"" if q.distance.m<1000 else "" miles""),q.source,q.target,GEOSGeometry(q.geometry).coords[1], GEOSGeometry(q.geometry).coords[0]) for q in qs]
        return HttpResponse(dumps(json),content_type=""application/json"")



class GeoJsonAjax(View):
    def get(self,request, *args, **kwargs):
        lat = float(request.GET.get('lat1','45'))
        lng = float(request.GET.get('lng1','-93.265'))
        qs = BestBikeTrails.objects.filter(the_geom__distance_lte=(Point(lng,lat,srid=4326),D(mi=2)))
        gj = []
        for item in qs:
            poly = GEOSGeometry(item.the_geom,srid=4326)
            gj.append(loads(poly.geojson))
        return HttpResponse(dumps(gj),content_type=""application/json"")


class RouterAjax(View):
    def get(self, request, *args, **kwargs):
        id1 =  request.GET.get('bid')
        id2 = request.GET.get('eid')
        sql_inside_of_function = ""select id, source, target, cost * (4-rtng_ccpx) * (4-rtng_mean) * (4-rtng_cbf7) as cost,cost * (4-rtng_ccpx)*(4-rtng_mean)*(4-rtng_cbf7) * case when one_way=0 then 1 else one_way END as reverse_cost from \""Data_minnesotabiketrails\""\'""
        sql_function = ""select ccp_name, the_geom from pgr_dijkstra(\'""

        cursor = connection.cursor()
        cursor.execute(sql_function+sql_inside_of_function+"",""+str(id1)+"",""+str(id2)+"", true,true) join \""Data_minnesotabiketrails\"" as bt on bt.id=id2"")
        all = cursor.fetchall()
        names = []
        gj = []
        for item in all:
            names.append(item[0])
            gj.append(loads(GEOSGeometry(item[1]).geojson))
        return HttpResponse(dumps({'names':names,'geojson':gj}),content_type=""application/json; charset='utf-8'"")


class NiceRideAjax(View):
    def get(self, request, *args, **kwargs):
        r = get(url=""https://secure.niceridemn.org/data2/bikeStations.xml"")
        doc = ET.fromstring(r.text)
        stations = doc.findall('station')
        # this isn't really json it is a bunch of  python dicts inside a python list
        json = [{item.tag: item.text for item in station} for station in stations]  #look at that beauty there
        gj = []
        for d in json:
            if d['public']=='true':
                lat = d['lat']
                long = d['long']
                del d['lat']
                del d['long']
                gj.append({'type': 'Point', 'coordinates': [long, lat], 'properties': d})
        return HttpResponse(dumps(gj), content_type=""application/json; charset='utf-8'"")
",CWE-89,80.0,1
"""""""
Functionality for dealing with dbkeys.
""""""
#dbkeys read from disk using builds.txt
from galaxy.util import read_dbnames
from galaxy.util.json import loads
import os.path


class GenomeBuilds( object ):
    default_value = ""?""
    default_name = ""unspecified (?)""

    def __init__( self, app, data_table_name=""__dbkeys__"", load_old_style=True ):
        self._app = app
        self._data_table_name = data_table_name
        self._static_chrom_info_path = app.config.len_file_path
        # A dbkey can be listed multiple times, but with different names, so we can't use dictionaries for lookups
        if load_old_style:
            self._static_dbkeys = list( read_dbnames( app.config.builds_file_path ) )
        else:
            self._static_dbkeys = []

    def get_genome_build_names( self, trans=None ):
        # FIXME: how to deal with key duplicates?
        rval = []
        # load user custom genome builds
        if trans is not None:
            if trans.history:
                # This is a little bit Odd. We are adding every .len file in the current history to dbkey list,
                # but this is previous behavior from trans.db_names, so we'll continue to do it.
                # It does allow one-off, history specific dbkeys to be created by a user. But we are not filtering,
                # so a len file will be listed twice (as the build name and again as dataset name), 
                # if custom dbkey creation/conversion occurred within the current history.
                datasets = trans.sa_session.query( self._app.model.HistoryDatasetAssociation ) \
                                          .filter_by( deleted=False, history_id=trans.history.id, extension=""len"" )
                for dataset in datasets:
                    rval.append( ( dataset.dbkey, ""%s (%s) [History]"" % ( dataset.name, dataset.dbkey ) ) )
            user = trans.user
            if user and 'dbkeys' in user.preferences:
                user_keys = loads( user.preferences['dbkeys'] )
                for key, chrom_dict in user_keys.iteritems():
                    rval.append( ( key, ""%s (%s) [Custom]"" % ( chrom_dict['name'], key ) ) )
        # Load old builds.txt static keys
        rval.extend( self._static_dbkeys )
        #load dbkeys from dbkey data table
        dbkey_table = self._app.tool_data_tables.get( self._data_table_name, None )
        if dbkey_table is not None:
            for field_dict in dbkey_table.get_named_fields_list():
                rval.append( ( field_dict[ 'value' ], field_dict[ 'name' ] ) )
        return rval

    def get_chrom_info( self, dbkey, trans=None, custom_build_hack_get_len_from_fasta_conversion=True ):
        # FIXME: flag to turn off custom_build_hack_get_len_from_fasta_conversion should not be required 
        chrom_info = None
        db_dataset = None
        # Collect chromInfo from custom builds
        if trans:
            db_dataset = trans.db_dataset_for( dbkey )
            if db_dataset:
                chrom_info = db_dataset.file_name
            else:
                # Do Custom Build handling
                if trans.user and ( 'dbkeys' in trans.user.preferences ) and ( dbkey in loads( trans.user.preferences[ 'dbkeys' ] ) ):
                    custom_build_dict = loads( trans.user.preferences[ 'dbkeys' ] )[ dbkey ]
                    # HACK: the attempt to get chrom_info below will trigger the
                    # fasta-to-len converter if the dataset is not available or,
                    # which will in turn create a recursive loop when
                    # running the fasta-to-len tool. So, use a hack in the second
                    # condition below to avoid getting chrom_info when running the
                    # fasta-to-len converter.
                    if 'fasta' in custom_build_dict and custom_build_hack_get_len_from_fasta_conversion:
                        # Build is defined by fasta; get len file, which is obtained from converting fasta.
                        build_fasta_dataset = trans.sa_session.query( trans.app.model.HistoryDatasetAssociation ).get( custom_build_dict[ 'fasta' ] )
                        chrom_info = build_fasta_dataset.get_converted_dataset( trans, 'len' ).file_name
                    elif 'len' in custom_build_dict:
                        # Build is defined by len file, so use it.
                        chrom_info = trans.sa_session.query( trans.app.model.HistoryDatasetAssociation ).get( custom_build_dict[ 'len' ] ).file_name
        # Check Data table
        if not chrom_info:
            dbkey_table = self._app.tool_data_tables.get( self._data_table_name, None )
            if dbkey_table is not None:
                chrom_info = dbkey_table.get_entry( 'value', dbkey, 'len_path', default=None )
        # use configured server len path
        if not chrom_info:
            # Default to built-in build.
            chrom_info = os.path.join( self._static_chrom_info_path, ""%s.len"" % dbkey )
        chrom_info = os.path.abspath( chrom_info )
        return ( chrom_info, db_dataset )
",CWE-74,90.0,1
,CWE-20,,1
"# --------------------------------------------------------------------------- #
# Project Info
#   Defaults shown. Learn more about these options by running
#   `fontcustom help` or visiting <http://fontcustom.com>.
# --------------------------------------------------------------------------- #

font_name: Genericons

# default font metrics
#font_design_size: 16
#font_em: 512
#font_ascent: 448
#font_descent: 64

# upscaled
font_design_size: 16
font_em: 2048
font_ascent: 2048
font_descent: 0

css_selector: .genericon-{{glyph}}
preprocessor_path: """"
autowidth: false
no_hash: true
force: true
debug: false
quiet: false


# --------------------------------------------------------------------------- #
# Input Paths
# --------------------------------------------------------------------------- #

input:
  vectors: svg
  templates: fontcustom-templates


# --------------------------------------------------------------------------- #
# Output Paths
# --------------------------------------------------------------------------- #

output:
  fonts: fontcustom-webfont/
  css: fontcustom-webfont/


# --------------------------------------------------------------------------- #
# Templates
#   Included in Font Custom: preview, css, scss, scss-rails
#   Custom templates should be saved in the INPUT[:templates] directory and
#   referenced by their baserame.
# --------------------------------------------------------------------------- #

templates:
 - example.html
 - genericons.css
",CWE-79,58.0,1
"# -*- coding: utf-8 -*-
#
# Copyright  2012 Red Hat, Inc.
#
# This software is licensed to you under the GNU General Public
# License as published by the Free Software Foundation; either version
# 2 of the License (GPLv2) or (at your option) any later version.
# There is NO WARRANTY for this software, express or implied,
# including the implied warranties of MERCHANTABILITY,
# NON-INFRINGEMENT, or FITNESS FOR A PARTICULAR PURPOSE. You should
# have received a copy of GPLv2 along with this software; if not, see
# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.

from pulp.bindings.actions import ActionsAPI
from pulp.bindings.content import OrphanContentAPI, ContentSourceAPI, ContentCatalogAPI
from pulp.bindings.event_listeners import EventListenerAPI
from pulp.bindings.repo_groups import *
from pulp.bindings.repository import *
from pulp.bindings.consumer_groups import *
from pulp.bindings.consumer import *
from pulp.bindings.server_info import ServerInfoAPI
from pulp.bindings.tasks import TasksAPI, TaskSearchAPI
from pulp.bindings.upload import UploadAPI
from pulp.bindings.auth import *


class Bindings(object):

    def __init__(self, pulp_connection):
        """"""
        @type:   pulp_connection: pulp.bindings.server.PulpConnection
        """"""

        # Please keep the following in alphabetical order to ease reading
        self.actions = ActionsAPI(pulp_connection)
        self.bind = BindingsAPI(pulp_connection)
        self.bindings = BindingSearchAPI(pulp_connection)
        self.profile = ProfilesAPI(pulp_connection)
        self.consumer = ConsumerAPI(pulp_connection)
        self.consumer_content = ConsumerContentAPI(pulp_connection)
        self.consumer_content_schedules = ConsumerContentSchedulesAPI(pulp_connection)
        self.consumer_group = ConsumerGroupAPI(pulp_connection)
        self.consumer_group_search = ConsumerGroupSearchAPI(pulp_connection)
        self.consumer_group_actions = ConsumerGroupActionAPI(pulp_connection)
        self.consumer_group_bind = ConsumerGroupBindAPI(pulp_connection)
        self.consumer_group_content = ConsumerGroupContentAPI(pulp_connection)
        self.consumer_history = ConsumerHistoryAPI(pulp_connection)
        self.consumer_search = ConsumerSearchAPI(pulp_connection)
        self.content_orphan = OrphanContentAPI(pulp_connection)
        self.content_source = ContentSourceAPI(pulp_connection)
        self.content_catalog = ContentCatalogAPI(pulp_connection)
        self.event_listener = EventListenerAPI(pulp_connection)
        self.permission = PermissionAPI(pulp_connection)
        self.repo = RepositoryAPI(pulp_connection)
        self.repo_actions = RepositoryActionsAPI(pulp_connection)
        self.repo_distributor = RepositoryDistributorAPI(pulp_connection)
        self.repo_group = RepoGroupAPI(pulp_connection)
        self.repo_group_actions = RepoGroupActionAPI(pulp_connection)
        self.repo_group_distributor = RepoGroupDistributorAPI(pulp_connection)
        self.repo_group_distributor_search = RepoGroupSearchAPI(pulp_connection)
        self.repo_group_search = RepoGroupSearchAPI(pulp_connection)
        self.repo_history = RepositoryHistoryAPI(pulp_connection)
        self.repo_importer = RepositoryImporterAPI(pulp_connection)
        self.repo_publish_schedules = RepositoryPublishSchedulesAPI(pulp_connection)
        self.repo_search = RepositorySearchAPI(pulp_connection)
        self.repo_sync_schedules = RepositorySyncSchedulesAPI(pulp_connection)
        self.repo_unit = RepositoryUnitAPI(pulp_connection)
        self.role = RoleAPI(pulp_connection)
        self.server_info = ServerInfoAPI(pulp_connection)
        self.tasks = TasksAPI(pulp_connection)
        self.tasks_search = TaskSearchAPI(pulp_connection)
        self.uploads = UploadAPI(pulp_connection)
        self.user = UserAPI(pulp_connection)
        self.user_search = UserSearchAPI(pulp_connection)
",CWE-295,75.0,1
,CWE-295,,1
,CWE-295,,1
,CWE-295,,1
"import base64
import os
import time
from gluon import portalocker
from gluon.admin import apath
from gluon.fileutils import read_file
from gluon.utils import web2py_uuid
# ###########################################################
# ## make sure administrator is on localhost or https
# ###########################################################


http_host = request.env.http_host.split(':')[0]

if request.env.web2py_runtime_gae:
    session_db = DAL('gae')
    session.connect(request, response, db=session_db)
    hosts = (http_host, )
    is_gae = True
else:
    is_gae = False

if request.is_https:
    session.secure()
elif not request.is_local and not DEMO_MODE:
    raise HTTP(200, T('Admin is disabled because insecure channel'))

try:
    _config = {}
    port = int(request.env.server_port or 0)
    restricted(
        read_file(apath('../parameters_%i.py' % port, request)), _config)

    if not 'password' in _config or not _config['password']:
        raise HTTP(200, T('admin disabled because no admin password'))
except IOError:
    import gluon.fileutils
    if is_gae:
        if gluon.fileutils.check_credentials(request):
            session.authorized = True
            session.last_time = time.time()
        else:
            raise HTTP(200,
                       T('admin disabled because not supported on google app engine'))
    else:
        raise HTTP(
            200, T('admin disabled because unable to access password file'))


def verify_password(password):
    session.pam_user = None
    if DEMO_MODE:
        ret = True
    elif not _config.get('password'):
        ret - False
    elif _config['password'].startswith('pam_user:'):
        session.pam_user = _config['password'][9:].strip()
        import gluon.contrib.pam
        ret = gluon.contrib.pam.authenticate(session.pam_user, password)
    else:
        ret = _config['password'] == CRYPT()(password)[0]
    if ret:
        session.hmac_key = web2py_uuid()
    return ret


# ###########################################################
# ## handle brute-force login attacks
# ###########################################################

deny_file = os.path.join(request.folder, 'private', 'hosts.deny')
allowed_number_of_attempts = 5
expiration_failed_logins = 3600


def read_hosts_deny():
    import datetime
    hosts = {}
    if os.path.exists(deny_file):
        hosts = {}
        f = open(deny_file, 'r')
        portalocker.lock(f, portalocker.LOCK_SH)
        for line in f.readlines():
            if not line.strip() or line.startswith('#'):
                continue
            fields = line.strip().split()
            if len(fields) > 2:
                hosts[fields[0].strip()] = (  # ip
                    int(fields[1].strip()),  # n attemps
                    int(fields[2].strip())   # last attempts
                    )
        portalocker.unlock(f)
        f.close()
    return hosts


def write_hosts_deny(denied_hosts):
    f = open(deny_file, 'w')
    portalocker.lock(f, portalocker.LOCK_EX)
    for key, val in denied_hosts.items():
        if time.time() - val[1] < expiration_failed_logins:
            line = '%s %s %s\n' % (key, val[0], val[1])
            f.write(line)
    portalocker.unlock(f)
    f.close()


def login_record(success=True):
    denied_hosts = read_hosts_deny()
    val = (0, 0)
    if success and request.client in denied_hosts:
        del denied_hosts[request.client]
    elif not success and not request.is_local:
        val = denied_hosts.get(request.client, (0, 0))
        if time.time() - val[1] < expiration_failed_logins \
            and val[0] >= allowed_number_of_attempts:
            return val[0]  # locked out
        time.sleep(2 ** val[0])
        val = (val[0] + 1, int(time.time()))
        denied_hosts[request.client] = val
    write_hosts_deny(denied_hosts)
    return val[0]


# ###########################################################
# ## session expiration
# ###########################################################

t0 = time.time()
if session.authorized:

    if session.last_time and session.last_time < t0 - EXPIRATION:
        session.flash = T('session expired')
        session.authorized = False
    else:
        session.last_time = t0


if request.vars.is_mobile in ('true', 'false', 'auto'):
    session.is_mobile = request.vars.is_mobile or 'auto'
if request.controller == 'default' and request.function == 'index':
    if not request.vars.is_mobile:
        session.is_mobile = 'auto'
if not session.is_mobile:
    session.is_mobile = 'auto'
if session.is_mobile == 'true':
    is_mobile = True
elif session.is_mobile == 'false':
    is_mobile = False
else:
    is_mobile = request.user_agent().get('is_mobile',False)

if DEMO_MODE:
    session.authorized = True
    session.forget()

if request.controller == ""webservices"":
    basic = request.env.http_authorization
    if not basic or not basic[:6].lower() == 'basic ':
        raise HTTP(401, ""Wrong credentials"")
    (username, password) = base64.b64decode(basic[6:]).split(':')
    if not verify_password(password) or MULTI_USER_MODE:
        time.sleep(10)
        raise HTTP(403, ""Not authorized"")
elif not session.authorized and not \
    (request.controller + '/' + request.function in
     ('default/index', 'default/user', 'plugin_jqmobile/index', 'plugin_jqmobile/about')):

    if request.env.query_string:
        query_string = '?' + request.env.query_string
    else:
        query_string = ''

    if request.env.web2py_original_uri:
        url = request.env.web2py_original_uri
    else:
        url = request.env.path_info + query_string
    redirect(URL(request.application, 'default', 'index', vars=dict(send=url)))
elif session.authorized and \
     request.controller == 'default' and \
     request.function == 'index':
    redirect(URL(request.application, 'default', 'site'))

if request.controller == 'appadmin' and DEMO_MODE:
    session.flash = 'Appadmin disabled in demo mode'
    redirect(URL('default', 'sites'))
",CWE-254,187.0,1
"##############################################################################
#
# Copyright (c) 2001 Zope Foundation and Contributors.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################
"""""" Basic user registration tool.
""""""

from random import choice
import re

from AccessControl.requestmethod import postonly
from AccessControl.SecurityInfo import ClassSecurityInfo
from App.class_init import InitializeClass
from App.special_dtml import DTMLFile
from OFS.SimpleItem import SimpleItem
from zope.component import getUtility
from zope.interface import implements

from Products.CMFCore.interfaces import IMembershipTool
from Products.CMFCore.interfaces import IRegistrationTool
from Products.CMFCore.permissions import AddPortalMember
from Products.CMFCore.permissions import MailForgottenPassword
from Products.CMFCore.permissions import ManagePortal
from Products.CMFCore.utils import _checkPermission
from Products.CMFCore.utils import _dtmldir
from Products.CMFCore.utils import _limitGrantedRoles
from Products.CMFCore.utils import Message as _
from Products.CMFCore.utils import registerToolInterface
from Products.CMFCore.utils import UniqueObject


class RegistrationTool(UniqueObject, SimpleItem):

    """""" Create and modify users by making calls to portal_membership.
    """"""

    implements(IRegistrationTool)

    id = 'portal_registration'
    meta_type = 'CMF Registration Tool'
    member_id_pattern = ''
    default_member_id_pattern = ""^[A-Za-z][A-Za-z0-9_]*$""
    _ALLOWED_MEMBER_ID_PATTERN = re.compile(default_member_id_pattern)

    security = ClassSecurityInfo()

    manage_options = ( ({'label': 'Overview',
                         'action': 'manage_overview'},
                        {'label': 'Configure',
                         'action': 'manage_configuration'})
                     + SimpleItem.manage_options
                     )

    #
    #   ZMI methods
    #
    security.declareProtected(ManagePortal, 'manage_overview')
    manage_overview = DTMLFile( 'explainRegistrationTool', _dtmldir )

    security.declareProtected(ManagePortal, 'manage_configuration')
    manage_configuration = DTMLFile('configureRegistrationTool', _dtmldir)

    security.declareProtected(ManagePortal, 'manage_editIDPattern')
    def manage_editIDPattern(self, pattern, REQUEST=None):
        """"""Edit the allowable member ID pattern TTW""""""
        pattern.strip()

        if len(pattern) > 0:
            self.member_id_pattern = pattern
            self._ALLOWED_MEMBER_ID_PATTERN = re.compile(pattern)
        else:
            self.member_id_pattern = ''
            self._ALLOWED_MEMBER_ID_PATTERN = re.compile(
                                                self.default_member_id_pattern)

        if REQUEST is not None:
            msg = 'Member ID Pattern changed'
            return self.manage_configuration(manage_tabs_message=msg)

    security.declareProtected(ManagePortal, 'getIDPattern')
    def getIDPattern(self):
        """""" Return the currently-used member ID pattern """"""
        return self.member_id_pattern

    security.declareProtected(ManagePortal, 'getDefaultIDPattern')
    def getDefaultIDPattern(self):
        """""" Return the currently-used member ID pattern """"""
        return self.default_member_id_pattern


    #
    #   'portal_registration' interface methods
    #
    security.declarePublic('isRegistrationAllowed')
    def isRegistrationAllowed(self, REQUEST):
        '''Returns a boolean value indicating whether the user
        is allowed to add a member to the portal.
        '''
        return _checkPermission(AddPortalMember, self.aq_inner.aq_parent)

    security.declarePublic('testPasswordValidity')
    def testPasswordValidity(self, password, confirm=None):
        '''If the password is valid, returns None.  If not, returns
        a string explaining why.
        '''
        return None

    security.declarePublic('testPropertiesValidity')
    def testPropertiesValidity(self, new_properties, member=None):
        '''If the properties are valid, returns None.  If not, returns
        a string explaining why.
        '''
        return None

    security.declarePublic('generatePassword')
    def generatePassword(self):
        """""" Generate a valid password.
        """"""
        # we don't use these to avoid typos: OQ0Il1
        chars = 'ABCDEFGHJKLMNPRSTUVWXYZabcdefghijkmnopqrstuvwxyz23456789'
        return ''.join( [ choice(chars) for i in range(6) ] )

    security.declareProtected(AddPortalMember, 'addMember')
    @postonly
    def addMember(self, id, password, roles=('Member',), domains='',
                  properties=None, REQUEST=None):
        '''Creates a PortalMember and returns it. The properties argument
        can be a mapping with additional member properties. Raises an
        exception if the given id already exists, the password does not
        comply with the policy in effect, or the authenticated user is not
        allowed to grant one of the roles listed (where Member is a special
        role that can always be granted); these conditions should be
        detected before the fact so that a cleaner message can be printed.
        '''
        if not self.isMemberIdAllowed(id):
            raise ValueError(_(u'The login name you selected is already in '
                               u'use or is not valid. Please choose another.'))

        failMessage = self.testPasswordValidity(password)
        if failMessage is not None:
            raise ValueError(failMessage)

        if properties is not None:
            failMessage = self.testPropertiesValidity(properties)
            if failMessage is not None:
                raise ValueError(failMessage)

        # Limit the granted roles.
        # Anyone is always allowed to grant the 'Member' role.
        _limitGrantedRoles(roles, self, ('Member',))

        mtool = getUtility(IMembershipTool)
        mtool.addMember(id, password, roles, domains, properties)

        member = mtool.getMemberById(id)
        self.afterAdd(member, id, password, properties)
        return member

    security.declareProtected(AddPortalMember, 'isMemberIdAllowed')
    def isMemberIdAllowed(self, id):
        '''Returns 1 if the ID is not in use and is not reserved.
        '''
        if len(id) < 1 or id == 'Anonymous User':
            return 0
        if not self._ALLOWED_MEMBER_ID_PATTERN.match( id ):
            return 0
        mtool = getUtility(IMembershipTool)
        if mtool.getMemberById(id) is not None:
            return 0
        return 1

    security.declarePublic('afterAdd')
    def afterAdd(self, member, id, password, properties):
        '''Called by portal_registration.addMember()
        after a member has been added successfully.'''
        pass

    security.declareProtected(MailForgottenPassword, 'mailPassword')
    def mailPassword(self, forgotten_userid, REQUEST):
        '''Email a forgotten password to a member.  Raises an exception
        if user ID is not found.
        '''
        raise NotImplementedError

InitializeClass(RegistrationTool)
registerToolInterface('portal_registration', IRegistrationTool)
",CWE-284,195.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Radicale Server - Calendar Server
# Copyright  2008 Nicolas Kandel
# Copyright  2008 Pascal Halter
# Copyright  2008-2013 Guillaume Ayoub
#
# This library is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.

""""""
Rights management.

Rights are based on a regex-based file whose name is specified in the config
(section ""right"", key ""file"").

Authentication login is matched against the ""user"" key, and collection's path
is matched against the ""collection"" key. You can use Python's ConfigParser
interpolation values %(login)s and %(path)s. You can also get groups from the
user regex in the collection with {0}, {1}, etc.

For example, for the ""user"" key, "".+"" means ""authenticated user"" and "".*""
means ""anybody"" (including anonymous users).

Section names are only used for naming the rule.

Leading or ending slashes are trimmed from collection's path.

""""""

import re
import sys
import os.path

from .. import config, log

# Manage Python2/3 different modules
if sys.version_info[0] == 2:
    from ConfigParser import ConfigParser
    from StringIO import StringIO
else:
    from configparser import ConfigParser
    from io import StringIO


DEFINED_RIGHTS = {
    ""authenticated"": ""[rw]\nuser:.+\ncollection:.*\npermission:rw"",
    ""owner_write"": ""[r]\nuser:.+\ncollection:.*\npermission:r\n""
                   ""[w]\nuser:.+\ncollection:^%(login)s(/.*)?$\npermission:w"",
    ""owner_only"": ""[rw]\nuser:.+\ncollection:^%(login)s(/.*)?$\npermission:rw"",
}


def _read_from_sections(user, collection_url, permission):
    """"""Get regex sections.""""""
    filename = os.path.expanduser(config.get(""rights"", ""file""))
    rights_type = config.get(""rights"", ""type"").lower()
    regex = ConfigParser({""login"": user, ""path"": collection_url})
    if rights_type in DEFINED_RIGHTS:
        log.LOGGER.debug(""Rights type '%s'"" % rights_type)
        regex.readfp(StringIO(DEFINED_RIGHTS[rights_type]))
    elif rights_type == ""from_file"":
        log.LOGGER.debug(""Reading rights from file %s"" % filename)
        if not regex.read(filename):
            log.LOGGER.error(""File '%s' not found for rights"" % filename)
            return False
    else:
        log.LOGGER.error(""Unknown rights type '%s'"" % rights_type)
        return False

    for section in regex.sections():
        re_user = regex.get(section, ""user"")
        re_collection = regex.get(section, ""collection"")
        log.LOGGER.debug(
            ""Test if '%s:%s' matches against '%s:%s' from section '%s'"" % (
                user, collection_url, re_user, re_collection, section))
        user_match = re.match(re_user, user)
        if user_match:
            re_collection = re_collection.format(*user_match.groups())
            if re.match(re_collection, collection_url):
                log.LOGGER.debug(""Section '%s' matches"" % section)
                if permission in regex.get(section, ""permission""):
                    return True
            else:
                log.LOGGER.debug(""Section '%s' does not match"" % section)
    return False


def authorized(user, collection, permission):
    """"""Check if the user is allowed to read or write the collection.

       If the user is empty it checks for anonymous rights
    """"""
    collection_url = collection.url.rstrip(""/"") or ""/""
    if collection_url in ("".well-known/carddav"", "".well-known/caldav""):
        return permission == ""r""
    rights_type = config.get(""rights"", ""type"").lower()
    return (
        rights_type == ""none"" or
        _read_from_sections(user or """", collection_url, permission))
",CWE-264,111.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Radicale Server - Calendar Server
#
# This library is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.

""""""
Helper functions for working with paths

""""""

import posixpath


def sanitize_path(path):
    """"""Make absolute (with leading slash) to prevent access to other data.
       Preserves an potential trailing slash.""""""
    trailing_slash = ""/"" if path.endswith(""/"") else """"
    path = posixpath.normpath(path)
    new_path = ""/""
    for part in path.split(""/""):
        if not part or part in (""."", ""..""):
            continue
        new_path = posixpath.join(new_path, part)
    trailing_slash = """" if new_path.endswith(""/"") else trailing_slash
    return new_path + trailing_slash",CWE-21,37.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Radicale Server - Calendar Server
# Copyright  2012-2015 Guillaume Ayoub
#
# This library is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.

""""""
Filesystem storage backend.

""""""

import codecs
import os
import posixpath
import json
import time
import sys
from contextlib import contextmanager
from .. import config, ical


FOLDER = os.path.expanduser(config.get(""storage"", ""filesystem_folder""))
FILESYSTEM_ENCODING = sys.getfilesystemencoding()

try:
    from dulwich.repo import Repo
    GIT_REPOSITORY = Repo(FOLDER)
except:
    GIT_REPOSITORY = None


# This function overrides the builtin ``open`` function for this module
# pylint: disable=W0622
@contextmanager
def open(path, mode=""r""):
    """"""Open a file at ``path`` with encoding set in the configuration.""""""
    # On enter
    abs_path = os.path.join(FOLDER, path.replace(""/"", os.sep))
    with codecs.open(abs_path, mode, config.get(""encoding"", ""stock"")) as fd:
        yield fd
    # On exit
    if GIT_REPOSITORY and mode == ""w"":
        path = os.path.relpath(abs_path, FOLDER)
        GIT_REPOSITORY.stage([path])
        committer = config.get(""git"", ""committer"")
        GIT_REPOSITORY.do_commit(
            path.encode(""utf-8""), committer=committer.encode(""utf-8""))
# pylint: enable=W0622


class Collection(ical.Collection):
    """"""Collection stored in a flat ical file.""""""
    @property
    def _path(self):
        """"""Absolute path of the file at local ``path``.""""""
        return os.path.join(FOLDER, self.path.replace(""/"", os.sep))

    @property
    def _props_path(self):
        """"""Absolute path of the file storing the collection properties.""""""
        return self._path + "".props""

    def _create_dirs(self):
        """"""Create folder storing the collection if absent.""""""
        if not os.path.exists(os.path.dirname(self._path)):
            os.makedirs(os.path.dirname(self._path))

    def save(self, text):
        self._create_dirs()
        with open(self._path, ""w"") as fd:
            fd.write(text)

    def delete(self):
        os.remove(self._path)
        os.remove(self._props_path)

    @property
    def text(self):
        try:
            with open(self._path) as fd:
                return fd.read()
        except IOError:
            return """"

    @classmethod
    def children(cls, path):
        abs_path = os.path.join(FOLDER, path.replace(""/"", os.sep))
        _, directories, files = next(os.walk(abs_path))
        for filename in directories + files:
            rel_filename = posixpath.join(path, filename)
            if cls.is_node(rel_filename) or cls.is_leaf(rel_filename):
                yield cls(rel_filename)

    @classmethod
    def is_node(cls, path):
        abs_path = os.path.join(FOLDER, path.replace(""/"", os.sep))
        return os.path.isdir(abs_path)

    @classmethod
    def is_leaf(cls, path):
        abs_path = os.path.join(FOLDER, path.replace(""/"", os.sep))
        return os.path.isfile(abs_path) and not abs_path.endswith("".props"")

    @property
    def last_modified(self):
        modification_time = time.gmtime(os.path.getmtime(self._path))
        return time.strftime(""%a, %d %b %Y %H:%M:%S +0000"", modification_time)

    @property
    @contextmanager
    def props(self):
        # On enter
        properties = {}
        if os.path.exists(self._props_path):
            with open(self._props_path) as prop_file:
                properties.update(json.load(prop_file))
        old_properties = properties.copy()
        yield properties
        # On exit
        self._create_dirs()
        if old_properties != properties:
            with open(self._props_path, ""w"") as prop_file:
                json.dump(properties, prop_file)
",CWE-21,136.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Radicale Server - Calendar Server
# Copyright  2014 Jean-Marc Martins
# Copyright  2014-2015 Guillaume Ayoub
#
# This library is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.

""""""
Multi files per calendar filesystem storage backend.

""""""

import os
import shutil
import time
import sys

from . import filesystem
from .. import ical
from .. import log


class Collection(filesystem.Collection):
    """"""Collection stored in several files per calendar.""""""
    def _create_dirs(self):
        if not os.path.exists(self._path):
            os.makedirs(self._path)

    @property
    def headers(self):
        return (
            ical.Header(""PRODID:-//Radicale//NONSGML Radicale Server//EN""),
            ical.Header(""VERSION:%s"" % self.version))

    def write(self):
        self._create_dirs()
        for component in self.components:
            text = ical.serialize(
                self.tag, self.headers, [component] + self.timezones)
            name = (
                component.name if sys.version_info[0] >= 3 else
                component.name.encode(filesystem.FILESYSTEM_ENCODING))
            path = os.path.join(self._path, name)
            with filesystem.open(path, ""w"") as fd:
                fd.write(text)

    def delete(self):
        shutil.rmtree(self._path)
        os.remove(self._props_path)

    def remove(self, name):
        if os.path.exists(os.path.join(self._path, name)):
            os.remove(os.path.join(self._path, name))

    @property
    def text(self):
        components = (
            ical.Timezone, ical.Event, ical.Todo, ical.Journal, ical.Card)
        items = set()
        try:
            filenames = os.listdir(self._path)
        except (OSError, IOError) as e:
            log.LOGGER.info('Error while reading collection %r: %r'
                            % (self._path, e))
            return """"

        for filename in filenames:
            path = os.path.join(self._path, filename)
            try:
                with filesystem.open(path) as fd:
                    items.update(self._parse(fd.read(), components))
            except (OSError, IOError) as e:
                log.LOGGER.warning('Error while reading item %r: %r'
                                   % (path, e))

        return ical.serialize(
            self.tag, self.headers, sorted(items, key=lambda x: x.name))

    @classmethod
    def is_node(cls, path):
        path = os.path.join(filesystem.FOLDER, path.replace(""/"", os.sep))
        return os.path.isdir(path) and not os.path.exists(path + "".props"")

    @classmethod
    def is_leaf(cls, path):
        path = os.path.join(filesystem.FOLDER, path.replace(""/"", os.sep))
        return os.path.isdir(path) and os.path.exists(path + "".props"")

    @property
    def last_modified(self):
        last = max([
            os.path.getmtime(os.path.join(self._path, filename))
            for filename in os.listdir(self._path)] or [0])
        return time.strftime(""%a, %d %b %Y %H:%M:%S +0000"", time.gmtime(last))
",CWE-21,107.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Radicale Server - Calendar Server
# Copyright  2014 Jean-Marc Martins
# Copyright  2014-2015 Guillaume Ayoub
#
# This library is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Radicale.  If not, see <http://www.gnu.org/licenses/>.

""""""
Multi files per calendar filesystem storage backend.

""""""

import os
import shutil
import time
import sys

from . import filesystem
from .. import ical
from .. import log
from .. import pathutils


class Collection(filesystem.Collection):
    """"""Collection stored in several files per calendar.""""""
    def _create_dirs(self):
        if not os.path.exists(self._filesystem_path):
            os.makedirs(self._filesystem_path)

    @property
    def headers(self):
        return (
            ical.Header(""PRODID:-//Radicale//NONSGML Radicale Server//EN""),
            ical.Header(""VERSION:%s"" % self.version))

    def write(self):
        self._create_dirs()
        for component in self.components:
            text = ical.serialize(
                self.tag, self.headers, [component] + self.timezones)
            name = (
                component.name if sys.version_info[0] >= 3 else
                component.name.encode(filesystem.FILESYSTEM_ENCODING))
            filesystem_path = os.path.join(self._filesystem_path, name)
            with filesystem.open(filesystem_path, ""w"") as fd:
                fd.write(text)

    def delete(self):
        shutil.rmtree(self._filesystem_path)
        os.remove(self._props_path)

    def remove(self, name):
        filesystem_path = os.path.join(self._filesystem_path, name)
        if os.path.exists(filesystem_path):
            os.remove(filesystem_path)

    @property
    def text(self):
        components = (
            ical.Timezone, ical.Event, ical.Todo, ical.Journal, ical.Card)
        items = set()
        try:
            filenames = os.listdir(self._filesystem_path)
        except (OSError, IOError) as e:
            log.LOGGER.info('Error while reading collection %r: %r'
                            % (self._filesystem_path, e))
            return """"

        for filename in filenames:
            path = os.path.join(self._filesystem_path, filename)
            try:
                with filesystem.open(path) as fd:
                    items.update(self._parse(fd.read(), components))
            except (OSError, IOError) as e:
                log.LOGGER.warning('Error while reading item %r: %r'
                                   % (path, e))

        return ical.serialize(
            self.tag, self.headers, sorted(items, key=lambda x: x.name))

    @classmethod
    def is_node(cls, path):
        filesystem_path = pathutils.path_to_filesystem(path,
                                                       filesystem.FOLDER)
        return (os.path.isdir(filesystem_path) and
                not os.path.exists(filesystem_path + "".props""))

    @classmethod
    def is_leaf(cls, path):
        filesystem_path = pathutils.path_to_filesystem(path,
                                                       filesystem.FOLDER)
        return (os.path.isdir(filesystem_path) and
                os.path.exists(path + "".props""))

    @property
    def last_modified(self):
        last = max([
            os.path.getmtime(os.path.join(self._filesystem_path, filename))
            for filename in os.listdir(self._filesystem_path)] or [0])
        return time.strftime(""%a, %d %b %Y %H:%M:%S +0000"", time.gmtime(last))
",CWE-20,113.0,1
"# -*- coding: utf-8 -*-
#
# Copyright  2014  Red Hat, Inc.
#
# This copyrighted material is made available to anyone wishing to use,
# modify, copy, or redistribute it subject to the terms and conditions
# of the GNU General Public License v.2, or (at your option) any later
# version.  This program is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY expressed or implied, including the
# implied warranties of MERCHANTABILITY or FITNESS FOR A PARTICULAR
# PURPOSE.  See the GNU General Public License for more details.  You
# should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# Any Red Hat trademarks that are incorporated in the source
# code or documentation are not subject to the GNU General Public
# License and may only be used or replicated with the express permission
# of Red Hat, Inc.
#

'''
MirrorManager2 xmlrpc controller.
'''

import base64
import pickle
import bz2

import flask
from flaskext.xmlrpc import XMLRPCHandler, Fault

from mirrormanager2.app import APP, ADMIN, SESSION
from mirrormanager2.lib import model
from mirrormanager2.lib.hostconfig import read_host_config


XMLRPC = XMLRPCHandler('xmlrpc')
XMLRPC.connect(APP, '/xmlrpc')


@XMLRPC.register
def checkin(pickledata):
    config = pickle.loads(bz2.decompress(base64.urlsafe_b64decode(pickledata)))
    r, message = read_host_config(SESSION, config)
    if r is not None:
        return message + 'checked in successful'
    else:
        return message + 'error checking in'
",CWE-94,50.0,1
"#!/usr/bin/env python
import re

import sys

from setuptools import setup
from setuptools.command.test import test as TestCommand

install_requires = [
    # core dependencies
    'decorator',
    'requests >= 1.0.0',
    'future',
    'paste',
    'zope.interface',
    'repoze.who',
    'pycryptodomex',
    'pytz',
    'pyOpenSSL',
    'python-dateutil',
    'six'
]

version = ''
with open('src/saml2/__init__.py', 'r') as fd:
    version = re.search(r'^__version__\s*=\s*[\'""]([^\'""]*)[\'""]',
                        fd.read(), re.MULTILINE).group(1)

setup(
    name='pysaml2',
    version=version,
    description='Python implementation of SAML Version 2',
    # long_description = read(""README""),
    author='Roland Hedberg',
    author_email='roland.hedberg@adm.umu.se',
    license='Apache 2.0',
    url='https://github.com/rohe/pysaml2',

    packages=['saml2', 'saml2/xmldsig', 'saml2/xmlenc', 'saml2/s2repoze',
              'saml2/s2repoze.plugins', ""saml2/profile"", ""saml2/schema"",
              ""saml2/extension"", ""saml2/attributemaps"", ""saml2/authn_context"",
              ""saml2/entity_category"", ""saml2/userinfo"", ""saml2/ws""],

    package_dir={'': 'src'},
    package_data={'': ['xml/*.xml']},
    classifiers=[
        ""Development Status :: 4 - Beta"",
        ""License :: OSI Approved :: Apache Software License"",
        ""Topic :: Software Development :: Libraries :: Python Modules"",
        ""Programming Language :: Python :: 2.7"",
        ""Programming Language :: Python :: 3.4"",
        ""Programming Language :: Python :: 3.5""
    ],

    scripts=[""tools/parse_xsd2.py"", ""tools/make_metadata.py"",
             ""tools/mdexport.py"", ""tools/merge_metadata.py""],
    install_requires=install_requires,
    zip_safe=False,
)
",CWE-611,60.0,1
"#!/usr/bin/env python

try:
    from xml.etree import cElementTree as ElementTree
    if ElementTree.VERSION < '1.3.0':
        # cElementTree has no support for register_namespace
        # neither _namespace_map, thus we sacrify performance
        # for correctness
        from xml.etree import ElementTree
except ImportError:
    try:
        import cElementTree as ElementTree
    except ImportError:
        from elementtree import ElementTree

import saml2.samlp as samlp
from saml2.samlp import NAMESPACE as SAMLP_NAMESPACE

NAMESPACE = ""http://schemas.xmlsoap.org/soap/envelope/""

example = """"""<Envelope xmlns=""http://schemas.xmlsoap.org/soap/envelope/"">
    <Body>
        <samlp:Response xmlns:samlp=""urn:oasis:names:tc:SAML:2.0:protocol"" 
            xmlns:saml=""urn:oasis:names:tc:SAML:2.0:assertion"" 
            ID=""_6c3a4f8b9c2d"" Version=""2.0"" IssueInstant=""2004-03-27T08:42:00Z"">
        <saml:Issuer>https://www.example.com/SAML</saml:Issuer>
        <Status>
        <StatusCode Value='urn:oasis:names:tc:SAML:2.0:status:Success'/>
        </Status>
        <saml:Assertion>
        <saml:Subject></saml:Subject>
        <saml:AttributeStatement></saml:AttributeStatement>
        </saml:Assertion>
        </samlp:Response>
    </Body>
</Envelope>
""""""


def test_parse_soap_envelope():
    envelope = ElementTree.fromstring(example)
    assert envelope.tag == '{%s}Envelope' % NAMESPACE
    # How to check that it's the right type ?
    assert len(envelope) == 1
    body = envelope[0]
    assert body.tag == '{%s}Body' % NAMESPACE
    assert len(body) == 1
    saml_part = body[0]
    assert saml_part.tag == '{%s}Response' % SAMLP_NAMESPACE
    # {http://schemas.xmlsoap.org/soap/envelope/}Envelope


def test_make_soap_envelope():
    envelope = ElementTree.Element('')
    envelope.tag = '{%s}Envelope' % NAMESPACE
    body = ElementTree.Element('')
    body.tag = '{%s}Body' % NAMESPACE
    envelope.append(body)    
    request = samlp.AuthnRequest()
    request.become_child_element_of(body)

    assert envelope.tag == '{%s}Envelope' % NAMESPACE
    assert len(envelope) == 1
    body = envelope[0]
    assert body.tag == '{%s}Body' % NAMESPACE
    assert len(body) == 1
    saml_part = body[0]
    assert saml_part.tag == '{%s}AuthnRequest' % SAMLP_NAMESPACE
",CWE-611,69.0,1
"# -*- coding: utf-8 -*-
""""""
    jinja2.testsuite.security
    ~~~~~~~~~~~~~~~~~~~~~~~~~

    Checks the sandbox and other security features.

    :copyright: (c) 2010 by the Jinja Team.
    :license: BSD, see LICENSE for more details.
""""""
import pytest

from jinja2 import Environment
from jinja2.sandbox import SandboxedEnvironment, \
     ImmutableSandboxedEnvironment, unsafe
from jinja2 import Markup, escape
from jinja2.exceptions import SecurityError, TemplateSyntaxError, \
     TemplateRuntimeError
from jinja2._compat import text_type


class PrivateStuff(object):

    def bar(self):
        return 23

    @unsafe
    def foo(self):
        return 42

    def __repr__(self):
        return 'PrivateStuff'


class PublicStuff(object):
    bar = lambda self: 23
    _foo = lambda self: 42

    def __repr__(self):
        return 'PublicStuff'


@pytest.mark.sandbox
class TestSandbox():

    def test_unsafe(self, env):
        env = SandboxedEnvironment()
        pytest.raises(SecurityError, env.from_string(""{{ foo.foo() }}"").render,
                      foo=PrivateStuff())
        assert env.from_string(""{{ foo.bar() }}"").render(foo=PrivateStuff()) == '23'

        pytest.raises(SecurityError,
                      env.from_string(""{{ foo._foo() }}"").render,
                      foo=PublicStuff())
        assert env.from_string(""{{ foo.bar() }}"").render(foo=PublicStuff()) == '23'
        assert env.from_string(""{{ foo.__class__ }}"").render(foo=42) == ''
        assert env.from_string(""{{ foo.func_code }}"").render(foo=lambda:None) == ''
        # security error comes from __class__ already.
        pytest.raises(SecurityError, env.from_string(
            ""{{ foo.__class__.__subclasses__() }}"").render, foo=42)

    def test_immutable_environment(self, env):
        env = ImmutableSandboxedEnvironment()
        pytest.raises(SecurityError, env.from_string(
            '{{ [].append(23) }}').render)
        pytest.raises(SecurityError, env.from_string(
            '{{ {1:2}.clear() }}').render)

    def test_restricted(self, env):
        env = SandboxedEnvironment()
        pytest.raises(TemplateSyntaxError, env.from_string,
                      ""{% for item.attribute in seq %}...{% endfor %}"")
        pytest.raises(TemplateSyntaxError, env.from_string,
                      ""{% for foo, bar.baz in seq %}...{% endfor %}"")

    def test_markup_operations(self, env):
        # adding two strings should escape the unsafe one
        unsafe = '<script type=""application/x-some-script"">alert(""foo"");</script>'
        safe = Markup('<em>username</em>')
        assert unsafe + safe == text_type(escape(unsafe)) + text_type(safe)

        # string interpolations are safe to use too
        assert Markup('<em>%s</em>') % '<bad user>' == \
            '<em>&lt;bad user&gt;</em>'
        assert Markup('<em>%(username)s</em>') % {
            'username': '<bad user>'
        } == '<em>&lt;bad user&gt;</em>'

        # an escaped object is markup too
        assert type(Markup('foo') + 'bar') is Markup

        # and it implements __html__ by returning itself
        x = Markup(""foo"")
        assert x.__html__() is x

        # it also knows how to treat __html__ objects
        class Foo(object):
            def __html__(self):
                return '<em>awesome</em>'

            def __unicode__(self):
                return 'awesome'
        assert Markup(Foo()) == '<em>awesome</em>'
        assert Markup('<strong>%s</strong>') % Foo() == \
            '<strong><em>awesome</em></strong>'

        # escaping and unescaping
        assert escape('""<>&\'') == '&#34;&lt;&gt;&amp;&#39;'
        assert Markup(""<em>Foo &amp; Bar</em>"").striptags() == ""Foo & Bar""
        assert Markup(""&lt;test&gt;"").unescape() == ""<test>""

    def test_template_data(self, env):
        env = Environment(autoescape=True)
        t = env.from_string('{% macro say_hello(name) %}'
                            '<p>Hello {{ name }}!</p>{% endmacro %}'
                            '{{ say_hello(""<blink>foo</blink>"") }}')
        escaped_out = '<p>Hello &lt;blink&gt;foo&lt;/blink&gt;!</p>'
        assert t.render() == escaped_out
        assert text_type(t.module) == escaped_out
        assert escape(t.module) == escaped_out
        assert t.module.say_hello('<blink>foo</blink>') == escaped_out
        assert escape(t.module.say_hello('<blink>foo</blink>')) == escaped_out

    def test_attr_filter(self, env):
        env = SandboxedEnvironment()
        tmpl = env.from_string('{{ cls|attr(""__subclasses__"")() }}')
        pytest.raises(SecurityError, tmpl.render, cls=int)

    def test_binary_operator_intercepting(self, env):
        def disable_op(left, right):
            raise TemplateRuntimeError('that operator so does not work')
        for expr, ctx, rv in ('1 + 2', {}, '3'), ('a + 2', {'a': 2}, '4'):
            env = SandboxedEnvironment()
            env.binop_table['+'] = disable_op
            t = env.from_string('{{ %s }}' % expr)
            assert t.render(ctx) == rv
            env.intercepted_binops = frozenset(['+'])
            t = env.from_string('{{ %s }}' % expr)
            try:
                t.render(ctx)
            except TemplateRuntimeError as e:
                pass
            else:
                assert False, 'expected runtime error'

    def test_unary_operator_intercepting(self, env):
        def disable_op(arg):
            raise TemplateRuntimeError('that operator so does not work')
        for expr, ctx, rv in ('-1', {}, '-1'), ('-a', {'a': 2}, '-2'):
            env = SandboxedEnvironment()
            env.unop_table['-'] = disable_op
            t = env.from_string('{{ %s }}' % expr)
            assert t.render(ctx) == rv
            env.intercepted_unops = frozenset(['-'])
            t = env.from_string('{{ %s }}' % expr)
            try:
                t.render(ctx)
            except TemplateRuntimeError as e:
                pass
            else:
                assert False, 'expected runtime error'
",CWE-134,162.0,1
"#
# Copyright (C) 2006-2011 Red Hat, Inc.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
#

import selinux
from stat import *
import gettext
translation=gettext.translation('setroubleshoot-plugins', fallback=True)
_=translation.gettext

from setroubleshoot.util import *
from setroubleshoot.Plugin import Plugin

class plugin(Plugin):
    summary =_('''
    SELinux is preventing $SOURCE_PATH from loading $TARGET_PATH which requires text relocation.
    ''')
    
    problem_description = _('''
    The $SOURCE application attempted to load $TARGET_PATH which
    requires text relocation.  This is a potential security problem.
    Most libraries do not need this permission. Libraries are
    sometimes coded incorrectly and request this permission.  The
    <a href=""http://people.redhat.com/drepper/selinux-mem.html"">SELinux Memory Protection Tests</a>
    web page explains how to remove this requirement.  You can configure
    SELinux temporarily to allow $TARGET_PATH to use relocation as a
    workaround, until the library is fixed. Please file a 
bug report.
    ''')
    
    unsafe_problem_description = _('''
    The $SOURCE application attempted to load $TARGET_PATH which
    requires text relocation.  This is a potential security problem.
    Most libraries should not need this permission.   The   
    <a href=""http://people.redhat.com/drepper/selinux-mem.html"">
    SELinux Memory Protection Tests</a>
    web page explains this check.  This tool examined the library and it looks 
    like it was built correctly. So setroubleshoot can not determine if this 
    application is compromized or not.  This could be a serious issue. Your 
    system may very well be compromised.

    Contact your security administrator and report this issue.

    ''')
    
    unsafe_fix_description = ""Contact your security administrator and report this issue."" 

    fix_description = _('''
    If you trust $TARGET_PATH to run correctly, you can change the
    file context to textrel_shlib_t. ""chcon -t textrel_shlib_t
    '$TARGET_PATH'""
    You must also change the default file context files on the system in order to preserve them even on a full relabel.  ""semanage fcontext -a -t textrel_shlib_t '$FIX_TARGET_PATH'""
    
    ''')

    unsafe_then_text = """"""
setroubleshoot examined '$FIX_TARGET_PATH' to make sure it was built correctly, but can not determine if this application has been compromized.  This alert could be a serious issue and your system could be compromised.
""""""
    unsafe_do_text = ""Contact your security administrator and report this issue."" 

    then_text = ""You need to change the label on '$FIX_TARGET_PATH'""
    do_text = """"""# semanage fcontext -a -t textrel_shlib_t '$FIX_TARGET_PATH'
# restorecon -v '$FIX_TARGET_PATH'""""""

    def get_then_text(self, avc, args):
        if len(args) > 0:
            return self.unsafe_then_text
        return self.then_text

    def get_do_text(self, avc, args):
        if len(args) > 0:
            return self.unsafe_do_text
        return self.do_text

    def __init__(self):
        Plugin.__init__(self,__name__)
        self.set_priority(10)

    def analyze(self, avc):
        import commands
        if avc.has_any_access_in(['execmod']):
            # MATCH
            if (commands.getstatusoutput(""eu-readelf -d %s | fgrep -q TEXTREL"" % avc.tpath)[0] == 1):
                return self.report((""unsafe""))

            mcon = selinux.matchpathcon(avc.tpath.strip('""'), S_IFREG)[1]
            if mcon.split("":"")[2] == ""lib_t"":
                return self.report()
        return None
",CWE-77,104.0,1
"from ceph_volume.util import encryption


class TestStatus(object):

    def test_skips_unuseful_lines(self, stub_call):
        out = ['some line here', '  device: /dev/sdc1']
        stub_call((out, '', 0))
        assert encryption.status('/dev/sdc1') == {'device': '/dev/sdc1'}

    def test_removes_extra_quotes(self, stub_call):
        out = ['some line here', '  device: ""/dev/sdc1""']
        stub_call((out, '', 0))
        assert encryption.status('/dev/sdc1') == {'device': '/dev/sdc1'}

    def test_ignores_bogus_lines(self, stub_call):
        out = ['some line here', '  ']
        stub_call((out, '', 0))
        assert encryption.status('/dev/sdc1') == {}


class TestDmcryptClose(object):

    def test_mapper_exists(self, fake_run, tmpfile):
        file_name = tmpfile(name='mapper-device')
        encryption.dmcrypt_close(file_name)
        arguments = fake_run.calls[0]['args'][0]
        assert arguments[0] == 'cryptsetup'
        assert arguments[1] == 'remove'
        assert arguments[2].startswith('/')

    def test_mapper_does_not_exist(self, fake_run):
        file_name = '/path/does/not/exist'
        encryption.dmcrypt_close(file_name)
        assert fake_run.calls == []


class TestDmcryptKey(object):

    def test_dmcrypt_with_default_size(self, conf_ceph_stub):
        conf_ceph_stub('[global]\nfsid=asdf-lkjh')
        result = encryption.create_dmcrypt_key()
        assert len(result) == 172

    def test_dmcrypt_with_custom_size(self, conf_ceph_stub):
        conf_ceph_stub('''
        [global]
        fsid=asdf
        [osd]
        osd_dmcrypt_size=8
        ''')
        result = encryption.create_dmcrypt_key()
        assert len(result) == 172
",CWE-287,54.0,1
"# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import print_function
import os
import os.path
import yaml
import logging
import glob
from build_pack_utils import FileUtil


_log = logging.getLogger('helpers')


class FakeBuilder(object):
    def __init__(self, ctx):
        self._ctx = ctx


class FakeInstaller(object):
    def __init__(self, builder, installer):
        self._installer = installer
        self.builder = builder


def setup_webdir_if_it_doesnt_exist(ctx):
    if is_web_app(ctx):
        webdirPath = os.path.join(ctx['BUILD_DIR'], ctx['WEBDIR'])
        if not os.path.exists(webdirPath):
            fu = FileUtil(FakeBuilder(ctx), move=True)
            fu.under('BUILD_DIR')
            fu.into('WEBDIR')
            fu.where_name_does_not_match(
                '^%s/.*$' % os.path.join(ctx['BUILD_DIR'], '.bp'))
            fu.where_name_does_not_match(
                '^%s/.*$' % os.path.join(ctx['BUILD_DIR'], '.extensions'))
            fu.where_name_does_not_match(
                '^%s/.*$' % os.path.join(ctx['BUILD_DIR'], '.bp-config'))
            fu.where_name_does_not_match(
                '^%s$' % os.path.join(ctx['BUILD_DIR'], 'manifest.yml'))
            fu.where_name_does_not_match(
                '^%s/.*$' % os.path.join(ctx['BUILD_DIR'], ctx['LIBDIR']))
            fu.where_name_does_not_match(
                '^%s/.*$' % os.path.join(ctx['BUILD_DIR'], '.profile.d'))
            fu.done()


def log_bp_version(ctx):
    version_file = os.path.join(ctx['BP_DIR'], 'VERSION')
    if os.path.exists(version_file):
        print('-------> Buildpack version %s' % open(version_file).read())


def setup_log_dir(ctx):
    os.makedirs(os.path.join(ctx['BUILD_DIR'], 'logs'))


def load_manifest(ctx):
    manifest_path = os.path.join(ctx['BP_DIR'], 'manifest.yml')
    _log.debug('Loading manifest from %s', manifest_path)
    return yaml.load(open(manifest_path))


def find_all_php_versions(dependencies):
    versions = []

    for dependency in dependencies:
        if dependency['name'] == 'php':
            versions.append(dependency['version'])

    return versions


def validate_php_version(ctx):
    if ctx['PHP_VERSION'] in ctx['ALL_PHP_VERSIONS']:
        _log.debug('App selected PHP [%s]', ctx['PHP_VERSION'])
    else:
        _log.warning('Selected version of PHP [%s] not available.  Defaulting'
                     ' to the latest version [%s]',
                     ctx['PHP_VERSION'], ctx['PHP_55_LATEST'])
        ctx['PHP_VERSION'] = ctx['PHP_55_LATEST']


def _get_supported_php_extensions(ctx):
    php_extensions = []
    php_extension_glob = os.path.join(ctx[""PHP_INSTALL_PATH""], 'lib', 'php', 'extensions', 'no-debug-non-zts-*')
    php_extension_directory = glob.glob(php_extension_glob)[0]
    for root, dirs, files in os.walk(php_extension_directory):
        for f in files:
            if '.so' in f:
                php_extensions.append(f.replace('.so', ''))
    return php_extensions


def validate_php_extensions(ctx):
    filtered_extensions = []
    requested_extensions = ctx['PHP_EXTENSIONS']
    supported_extensions = _get_supported_php_extensions(ctx)

    for extension in requested_extensions:
        if extension not in supported_extensions:
            print(""The extension '%s' is not provided by this buildpack."" % extension, file=os.sys.stderr)
        else:
            filtered_extensions.append(extension)
    ctx['PHP_EXTENSIONS'] = filtered_extensions


def convert_php_extensions(ctx):
    _log.debug('Converting PHP extensions')
    SKIP = ('cli', 'pear', 'cgi')
    ctx['PHP_EXTENSIONS'] = \
        ""\n"".join([""extension=%s.so"" % ex
                   for ex in ctx['PHP_EXTENSIONS'] if ex not in SKIP])
    path = ''
    ctx['ZEND_EXTENSIONS'] = \
        ""\n"".join(['zend_extension=""%s""' % os.path.join(path, ""%s.so"" % ze)
                   for ze in ctx['ZEND_EXTENSIONS']])


def is_web_app(ctx):
    return ctx.get('WEB_SERVER', '') != 'none'


def find_stand_alone_app_to_run(ctx):
    app = ctx.get('APP_START_CMD', None)
    if not app:
        possible_files = ('app.php', 'main.php', 'run.php', 'start.php')
        for pf in possible_files:
            if os.path.exists(os.path.join(ctx['BUILD_DIR'], pf)):
                app = pf
                break
        if not app:
            print('Build pack could not find a PHP file to execute!')
            _log.info('Build pack could not find a file to execute.  Either '
                      'set ""APP_START_CMD"" or include one of these files [%s]',
                      "", "".join(possible_files))
            app = 'app.php'
    return app
",CWE-254,151.0,1
"# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from __future__ import absolute_import, division, print_function

import six

from cryptography import utils
from cryptography.exceptions import (
    AlreadyFinalized, InvalidKey, UnsupportedAlgorithm, _Reasons
)
from cryptography.hazmat.backends.interfaces import HMACBackend
from cryptography.hazmat.primitives import constant_time, hmac
from cryptography.hazmat.primitives.kdf import KeyDerivationFunction


@utils.register_interface(KeyDerivationFunction)
class HKDF(object):
    def __init__(self, algorithm, length, salt, info, backend):
        if not isinstance(backend, HMACBackend):
            raise UnsupportedAlgorithm(
                ""Backend object does not implement HMACBackend."",
                _Reasons.BACKEND_MISSING_INTERFACE
            )

        self._algorithm = algorithm

        if not (salt is None or isinstance(salt, bytes)):
            raise TypeError(""salt must be bytes."")

        if salt is None:
            salt = b""\x00"" * (self._algorithm.digest_size // 8)

        self._salt = salt

        self._backend = backend

        self._hkdf_expand = HKDFExpand(self._algorithm, length, info, backend)

    def _extract(self, key_material):
        h = hmac.HMAC(self._salt, self._algorithm, backend=self._backend)
        h.update(key_material)
        return h.finalize()

    def derive(self, key_material):
        if not isinstance(key_material, bytes):
            raise TypeError(""key_material must be bytes."")

        return self._hkdf_expand.derive(self._extract(key_material))

    def verify(self, key_material, expected_key):
        if not constant_time.bytes_eq(self.derive(key_material), expected_key):
            raise InvalidKey


@utils.register_interface(KeyDerivationFunction)
class HKDFExpand(object):
    def __init__(self, algorithm, length, info, backend):
        if not isinstance(backend, HMACBackend):
            raise UnsupportedAlgorithm(
                ""Backend object does not implement HMACBackend."",
                _Reasons.BACKEND_MISSING_INTERFACE
            )

        self._algorithm = algorithm

        self._backend = backend

        max_length = 255 * (algorithm.digest_size // 8)

        if length > max_length:
            raise ValueError(
                ""Can not derive keys larger than {0} octets."".format(
                    max_length
                ))

        self._length = length

        if not (info is None or isinstance(info, bytes)):
            raise TypeError(""info must be bytes."")

        if info is None:
            info = b""""

        self._info = info

        self._used = False

    def _expand(self, key_material):
        output = [b""""]
        counter = 1

        while (self._algorithm.digest_size // 8) * len(output) < self._length:
            h = hmac.HMAC(key_material, self._algorithm, backend=self._backend)
            h.update(output[-1])
            h.update(self._info)
            h.update(six.int2byte(counter))
            output.append(h.finalize())
            counter += 1

        return b"""".join(output)[:self._length]

    def derive(self, key_material):
        if not isinstance(key_material, bytes):
            raise TypeError(""key_material must be bytes."")

        if self._used:
            raise AlreadyFinalized

        self._used = True
        return self._expand(key_material)

    def verify(self, key_material, expected_key):
        if not constant_time.bytes_eq(self.derive(key_material), expected_key):
            raise InvalidKey
",CWE-20,117.0,1
"from __future__ import absolute_import

from django.conf import settings
from django.core.exceptions import ValidationError
from django.http import HttpRequest, HttpResponse
from django.utils.translation import ugettext as _
from typing import List, Optional, Set, Text

from zerver.decorator import authenticated_json_post_view
from zerver.lib.actions import do_invite_users, do_refer_friend, \
    get_default_subs, internal_send_message
from zerver.lib.request import REQ, has_request_variables, JsonableError
from zerver.lib.response import json_success, json_error
from zerver.lib.streams import access_stream_by_name
from zerver.lib.validator import check_string, check_list
from zerver.models import PreregistrationUser, Stream, UserProfile

import re

@authenticated_json_post_view
@has_request_variables
def json_invite_users(request, user_profile,
                      invitee_emails_raw=REQ(""invitee_emails""),
                      body=REQ(""custom_body"", default=None)):
    # type: (HttpRequest, UserProfile, str, Optional[str]) -> HttpResponse
    if not invitee_emails_raw:
        return json_error(_(""You must specify at least one email address.""))
    if body == '':
        body = None

    invitee_emails = get_invitee_emails_set(invitee_emails_raw)

    stream_names = request.POST.getlist('stream')
    if not stream_names:
        return json_error(_(""You must specify at least one stream for invitees to join.""))

    # We unconditionally sub you to the notifications stream if it
    # exists and is public.
    notifications_stream = user_profile.realm.notifications_stream  # type: Optional[Stream]
    if notifications_stream and not notifications_stream.invite_only:
        stream_names.append(notifications_stream.name)

    streams = []  # type: List[Stream]
    for stream_name in stream_names:
        try:
            (stream, recipient, sub) = access_stream_by_name(user_profile, stream_name)
        except JsonableError:
            return json_error(_(""Stream does not exist: %s. No invites were sent."") % (stream_name,))
        streams.append(stream)

    ret_error, error_data = do_invite_users(user_profile, invitee_emails, streams, body)

    if ret_error is not None:
        return json_error(data=error_data, msg=ret_error)
    else:
        return json_success()

def get_invitee_emails_set(invitee_emails_raw):
    # type: (str) -> Set[str]
    invitee_emails_list = set(re.split(r'[,\n]', invitee_emails_raw))
    invitee_emails = set()
    for email in invitee_emails_list:
        is_email_with_name = re.search(r'<(?P<email>.*)>', email)
        if is_email_with_name:
            email = is_email_with_name.group('email')
        invitee_emails.add(email.strip())
    return invitee_emails

@authenticated_json_post_view
@has_request_variables
def json_refer_friend(request, user_profile, email=REQ()):
    # type: (HttpRequest, UserProfile, str) -> HttpResponse
    if not email:
        return json_error(_(""No email address specified""))
    if user_profile.invites_granted - user_profile.invites_used <= 0:
        return json_error(_(""Insufficient invites""))

    do_refer_friend(user_profile, email)

    return json_success()
",CWE-862,81.0,1
"#!/usr/local/bin/python3

""""""
    Copyright (c) 2015-2019 Ad Schellevis <ad@opnsense.org>
    All rights reserved.

    Redistribution and use in source and binary forms, with or without
    modification, are permitted provided that the following conditions are met:

    1. Redistributions of source code must retain the above copyright notice,
     this list of conditions and the following disclaimer.

    2. Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in the
     documentation and/or other materials provided with the distribution.

    THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
    AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
    AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
    POSSIBILITY OF SUCH DAMAGE.

    --------------------------------------------------------------------------------------
    overlay user web template package on installed default template, default template should be installed
    in /var/captiveportal/zone<zoneid>/htdocs/ first.
""""""
import os
import sys
import zipfile
import base64
from io import BytesIO
from lib import Config

if len(sys.argv) > 1:
    cnf = Config()
    zoneid = sys.argv[1]
    target_directory = '/var/captiveportal/zone%s/htdocs/' % zoneid
    template_data = cnf.fetch_template_data(sys.argv[1])
    if template_data is not None and len(template_data) > 20:
        print ('overlay user template package for zone %s' % zoneid)
        zip_content = base64.b64decode(template_data)
        input_data = BytesIO(zip_content)
        with zipfile.ZipFile(input_data, mode='r', compression=zipfile.ZIP_DEFLATED) as zf_in:
            for zf_info in zf_in.infolist():
                if zf_info.filename[-1] != '/':
                    target_filename = '%s%s' % (target_directory, zf_info.filename)
                    file_target_directory = '/'.join(target_filename.split('/')[:-1])
                    if not os.path.isdir(file_target_directory):
                        os.makedirs(file_target_directory)
                    with open(target_filename, 'wb') as f_out:
                        f_out.write(zf_in.read(zf_info.filename))
                    os.chmod(target_filename, 0o444)
    # write zone settings
    filename = '%sjs/zone.js' % target_directory
    with open(filename, 'wb') as f_out:
        f_out.write(('var zoneid = %s' % zoneid).encode())
    os.chmod(filename, 0o444)

sys.exit(0)
",CWE-22,65.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import sqlite3

class Database(object):
    def __init__(self):     
        self.conn = sqlite3.connect(""database.db"", check_same_thread=False)
        self.cursor = self.conn.cursor()
        
    def loadDatabase(self):
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""geo"" ( `id` TEXT, `city` TEXT, `country_code` TEXT, `country_name` TEXT, `ip` TEXT, `latitude` TEXT, `longitude` TEXT, `metro_code` TEXT, `region_code` TEXT, `region_name` TEXT, `time_zone` TEXT, `zip_code` TEXT, `isp` TEXT, `ua` TEXT, PRIMARY KEY(`id`) )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""networks"" ( `id` TEXT, `ip` TEXT, `public_ip` INTEGER, `network` TEXT, `date` TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""requests"" ( `id` TEXT, `user_id` TEXT, `site` TEXT, `fid` TEXT, `name` TEXT, `value` TEXT, `date` TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""victims"" ( `id` TEXT, `ip` TEXT, `date` TEXT, `time` REAL, `bVersion` TEXT, `browser` TEXT, `device` TEXT, `cpu` TEXT, `ports` TEXT, `status`  TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""clicks"" ( `id` TEXT, `site` TEXT, `date` TEXT )"""""")
        self.conn.commit()
        return True

    def sql_execute(self, sentence):
        self.cursor.execute(sentence)
        return self.cursor.fetchall()

    def sql_one_row(self, sentence, column):
        self.cursor.execute(sentence)
        return self.cursor.fetchone()[column]

    def sql_insert(self, sentence):
        self.cursor.execute(sentence)
        self.conn.commit()
        return True

    def prop_sentences_stats(self, type, vId = None):
        return {
            'get_data' : ""SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC"",
            'all_networks' : ""SELECT networks.* FROM networks ORDER BY id"",
            'get_preview' : ""SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = '%s'"" % (vId),
            'id_networks' : ""SELECT networks.* FROM networks WHERE id = '%s'"" % (vId),
            'get_requests' : ""SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id "",
            'get_sessions' : ""SELECT COUNT(*) AS Total FROM networks"",
            'get_clicks' : ""SELECT COUNT(*) AS Total FROM clicks"",
            'get_online' : ""SELECT COUNT(*) AS Total FROM victims WHERE status = '%s'"" % ('online')
        }.get(type, False)

    def sentences_stats(self, type, vId = None):
        return self.sql_execute(self.prop_sentences_stats(type, vId))

    def prop_sentences_victim(self, type, data = None):
        if type == 'count_victim':
            return ""SELECT COUNT(*) AS C FROM victims WHERE id = '%s'"" % (data)
        elif type == 'count_times':
            return ""SELECT COUNT(*) AS C FROM clicks WHERE id = '%s'"" % (data)
        elif type == 'update_victim':
            return ""UPDATE victims SET ip = '%s', date = '%s', bVersion = '%s', browser = '%s', device = '%s', ports = '%s', time = '%s', cpu = '%s', status = '%s' WHERE id = '%s'"" % (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1])
        elif type == 'update_victim_geo':
            return ""UPDATE geo SET city = '%s', country_code = '%s', country_name = '%s', ip = '%s', latitude = '%s', longitude = '%s', metro_code = '%s', region_code = '%s', region_name = '%s', time_zone = '%s', zip_code = '%s', isp = '%s', ua='%s' WHERE id = '%s'"" % (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1])
        elif type == 'insert_victim':
            return ""INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES('%s','%s', '%s','%s', '%s','%s', '%s', '%s', '%s', '%s')"" % (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online')
        elif type == 'insert_victim_geo':
            return ""INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')""  % (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua)
        elif type == 'count_victim_network':
            return ""SELECT COUNT(*) AS C FROM networks WHERE id = '%s' AND network = '%s'"" % (data[0], data[1])
        elif type == 'delete_networks':
            return ""DELETE FROM networks WHERE id = '%s'"" % (data[0])
        elif type == 'update_network':
            return ""UPDATE networks SET date = '%s' WHERE id = '%s' AND network = '%s'"" % (data[2], data[0], data[1])
        elif type == 'insert_networks':
            return ""INSERT INTO networks(id, public_ip, ip, network, date) VALUES('%s','%s', '%s', '%s','%s')"" % (data[0], data[1], data[2], data[3], data[4])
        elif type == 'insert_requests':
            return ""INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES('%s', '%s','%s', '%s', '%s','%s', '%s')"" % (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1])
        elif type == 'insert_click':
            return ""INSERT INTO clicks(id, site, date) VALUES('%s', '%s','%s')"" % (data[0], data[1], data[2])
        elif type == 'report_online':
            return ""UPDATE victims SET status = '%s' WHERE id = '%s'"" % ('online', data[0])
        elif type == 'clean_online':
            return ""UPDATE victims SET status = '%s' "" % ('offline')
        elif type == 'disconnect_victim':
            return ""UPDATE victims SET status = '%s' WHERE id = '%s'"" % ('offline', data)
        else:
            return False

    def sentences_victim(self, type, data = None, sRun = 1, column = 0):
        if sRun == 2:
            return self.sql_insert(self.prop_sentences_victim(type, data))
        elif sRun == 3:
            return self.sql_one_row(self.prop_sentences_victim(type, data), column)
        else:
            return self.sql_execute(self.prop_sentences_victim(type, data))

    def __del__(self):
        self.conn.close()",CWE-89,101.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import sqlite3

class Database(object):
    def __init__(self):     
        self.conn = sqlite3.connect(""database.db"", check_same_thread=False)
        self.cursor = self.conn.cursor()
        
    def loadDatabase(self):
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""geo"" ( `id` TEXT, `city` TEXT, `country_code` TEXT, `country_name` TEXT, `ip` TEXT, `latitude` TEXT, `longitude` TEXT, `metro_code` TEXT, `region_code` TEXT, `region_name` TEXT, `time_zone` TEXT, `zip_code` TEXT, `isp` TEXT, `ua` TEXT, PRIMARY KEY(`id`) )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""networks"" ( `id` TEXT, `ip` TEXT, `public_ip` INTEGER, `network` TEXT, `date` TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""requests"" ( `id` TEXT, `user_id` TEXT, `site` TEXT, `fid` TEXT, `name` TEXT, `value` TEXT, `date` TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""victims"" ( `id` TEXT, `ip` TEXT, `date` TEXT, `time` REAL, `bVersion` TEXT, `browser` TEXT, `device` TEXT, `cpu` TEXT, `ports` TEXT, `status`  TEXT )"""""")
        self.cursor.execute(""""""CREATE TABLE IF NOT EXISTS ""clicks"" ( `id` TEXT, `site` TEXT, `date` TEXT )"""""")
        self.conn.commit()
        return True

    def sql_execute(self, sentence):
        self.cursor.execute(sentence)
        return self.cursor.fetchall()

    def sql_one_row(self, sentence, column):
        self.cursor.execute(sentence)
        return self.cursor.fetchone()[column]

    def sql_insert(self, sentence):
        self.cursor.execute(sentence)
        self.conn.commit()
        return True

    def prop_sentences_stats(self, type, vId = None):
        return {
            'get_data' : ""SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC"",
            'all_networks' : ""SELECT networks.* FROM networks ORDER BY id"",
            'get_preview' : ""SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = '%s'"" % (vId),
            'id_networks' : ""SELECT networks.* FROM networks WHERE id = '%s'"" % (vId),
            'get_requests' : ""SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id "",
            'get_sessions' : ""SELECT COUNT(*) AS Total FROM networks"",
            'get_clicks' : ""SELECT COUNT(*) AS Total FROM clicks"",
            'get_online' : ""SELECT COUNT(*) AS Total FROM victims WHERE status = '%s'"" % ('online')
        }.get(type, False)

    def sentences_stats(self, type, vId = None):
        return self.sql_execute(self.prop_sentences_stats(type, vId))

    def prop_sentences_victim(self, type, data = None):
        if type == 'count_victim':
            return ""SELECT COUNT(*) AS C FROM victims WHERE id = '%s'"" % (data)
        elif type == 'count_times':
            return ""SELECT COUNT(*) AS C FROM clicks WHERE id = '%s'"" % (data)
        elif type == 'update_victim':
            return ""UPDATE victims SET ip = '%s', date = '%s', bVersion = '%s', browser = '%s', device = '%s', ports = '%s', time = '%s', cpu = '%s', status = '%s' WHERE id = '%s'"" % (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1])
        elif type == 'update_victim_geo':
            return ""UPDATE geo SET city = '%s', country_code = '%s', country_name = '%s', ip = '%s', latitude = '%s', longitude = '%s', metro_code = '%s', region_code = '%s', region_name = '%s', time_zone = '%s', zip_code = '%s', isp = '%s', ua='%s' WHERE id = '%s'"" % (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1])
        elif type == 'insert_victim':
            return ""INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES('%s','%s', '%s','%s', '%s','%s', '%s', '%s', '%s', '%s')"" % (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online')
        elif type == 'insert_victim_geo':
            return ""INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')""  % (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua)
        elif type == 'count_victim_network':
            return ""SELECT COUNT(*) AS C FROM networks WHERE id = '%s' AND network = '%s'"" % (data[0], data[1])
        elif type == 'delete_networks':
            return ""DELETE FROM networks WHERE id = '%s'"" % (data[0])
        elif type == 'update_network':
            return ""UPDATE networks SET date = '%s' WHERE id = '%s' AND network = '%s'"" % (data[2], data[0], data[1])
        elif type == 'insert_networks':
            return ""INSERT INTO networks(id, public_ip, ip, network, date) VALUES('%s','%s', '%s', '%s','%s')"" % (data[0], data[1], data[2], data[3], data[4])
        elif type == 'insert_requests':
            return ""INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES('%s', '%s','%s', '%s', '%s','%s', '%s')"" % (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1])
        elif type == 'insert_click':
            return ""INSERT INTO clicks(id, site, date) VALUES('%s', '%s','%s')"" % (data[0], data[1], data[2])
        elif type == 'report_online':
            return ""UPDATE victims SET status = '%s' WHERE id = '%s'"" % ('online', data[0])
        elif type == 'clean_online':
            return ""UPDATE victims SET status = '%s' "" % ('offline')
        elif type == 'disconnect_victim':
            return ""UPDATE victims SET status = '%s' WHERE id = '%s'"" % ('offline', data)
        else:
            return False

    def sentences_victim(self, type, data = None, sRun = 1, column = 0):
        if sRun == 2:
            return self.sql_insert(self.prop_sentences_victim(type, data))
        elif sRun == 3:
            return self.sql_one_row(self.prop_sentences_victim(type, data), column)
        else:
            return self.sql_execute(self.prop_sentences_victim(type, data))

    def __del__(self):
        self.conn.close()",CWE-79,101.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import urllib2
from flask import Flask, render_template, session, request, json
from core.trape import Trape
from core.db import Database

# Main parts, to generate relationships among others
trape = Trape()
app = Flask(__name__, template_folder='../templates', static_folder='../static')

# call database
db = Database()

# preview header tool in console
trape.header()

@app.route(""/"" + trape.stats_path)
def index():
    return render_template(""/login.html"")

@app.route(""/logout"")
def logout():
    return render_template(""/login.html"")

@app.route(""/login"", methods=[""POST""])
def login():
    id = request.form['id']
    if id == trape.stats_key:
        return json.dumps({'status':'OK', 'path' : trape.home_path, 'victim_path' : trape.victim_path, 'url_to_clone' : trape.url_to_clone, 'app_port' : trape.app_port, 'date_start' : trape.date_start, 'user_ip' : '127.0.0.1'});
    else:
      return json.dumps({'status':'NOPE', 'path' : '/'});

@app.route(""/get_data"", methods=[""POST""])
def home_get_dat():
    d = db.sentences_stats('get_data')
    n = db.sentences_stats('all_networks')

    ('clean_online')
    rows = db.sentences_stats('get_clicks')
    c = rows[0][0]
    rows = db.sentences_stats('get_sessions')
    s = rows[0][0]
    rows = db.sentences_stats('get_online')
    o = rows[0][0]

    return json.dumps({'status' : 'OK', 'd' : d, 'n' : n, 'c' : c, 's' : s, 'o' : o});

@app.route(""/get_preview"", methods=[""POST""])
def home_get_preview():
    vId = request.form['vId']
    d = db.sentences_stats('get_preview', vId)
    n = db.sentences_stats('id_networks', vId)
    return json.dumps({'status' : 'OK', 'vId' : vId, 'd' : d, 'n' : n});

@app.route(""/get_title"", methods=[""POST""])
def home_get_title():
    opener = urllib2.build_opener()
    html = opener.open(trape.url_to_clone).read()
    html = html[html.find('<title>') + 7 : html.find('</title>')]
    return json.dumps({'status' : 'OK', 'title' : html});

@app.route(""/get_requests"", methods=[""POST""])
def home_get_requests():
    d = db.sentences_stats('get_requests')

    return json.dumps({'status' : 'OK', 'd' : d});",CWE-89,78.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import urllib2
from flask import Flask, render_template, session, request, json
from core.trape import Trape
from core.db import Database

# Main parts, to generate relationships among others
trape = Trape()
app = Flask(__name__, template_folder='../templates', static_folder='../static')

# call database
db = Database()

# preview header tool in console
trape.header()

@app.route(""/"" + trape.stats_path)
def index():
    return render_template(""/login.html"")

@app.route(""/logout"")
def logout():
    return render_template(""/login.html"")

@app.route(""/login"", methods=[""POST""])
def login():
    id = request.form['id']
    if id == trape.stats_key:
        return json.dumps({'status':'OK', 'path' : trape.home_path, 'victim_path' : trape.victim_path, 'url_to_clone' : trape.url_to_clone, 'app_port' : trape.app_port, 'date_start' : trape.date_start, 'user_ip' : '127.0.0.1'});
    else:
      return json.dumps({'status':'NOPE', 'path' : '/'});

@app.route(""/get_data"", methods=[""POST""])
def home_get_dat():
    d = db.sentences_stats('get_data')
    n = db.sentences_stats('all_networks')

    ('clean_online')
    rows = db.sentences_stats('get_clicks')
    c = rows[0][0]
    rows = db.sentences_stats('get_sessions')
    s = rows[0][0]
    rows = db.sentences_stats('get_online')
    o = rows[0][0]

    return json.dumps({'status' : 'OK', 'd' : d, 'n' : n, 'c' : c, 's' : s, 'o' : o});

@app.route(""/get_preview"", methods=[""POST""])
def home_get_preview():
    vId = request.form['vId']
    d = db.sentences_stats('get_preview', vId)
    n = db.sentences_stats('id_networks', vId)
    return json.dumps({'status' : 'OK', 'vId' : vId, 'd' : d, 'n' : n});

@app.route(""/get_title"", methods=[""POST""])
def home_get_title():
    opener = urllib2.build_opener()
    html = opener.open(trape.url_to_clone).read()
    html = html[html.find('<title>') + 7 : html.find('</title>')]
    return json.dumps({'status' : 'OK', 'title' : html});

@app.route(""/get_requests"", methods=[""POST""])
def home_get_requests():
    d = db.sentences_stats('get_requests')

    return json.dumps({'status' : 'OK', 'd' : d});",CWE-79,78.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import time
import urllib2
from flask import Flask, render_template, session, request, json
from core.victim_objects import *
import core.stats
from core.utils import utils
from core.db import Database


# Main parts, to generate relationships among others
trape = core.stats.trape
app = core.stats.app

# call database
db = Database()

class victim_server(object):
    @app.route(""/"" + trape.victim_path)
    def homeVictim():
        opener = urllib2.build_opener()
        headers = victim_headers()
        opener.addheaders = headers
        html = victim_inject_code(opener.open(trape.url_to_clone).read(), 'lure')
        return html

    @app.route(""/register"", methods=[""POST""])
    def register():
        vId = request.form['vId']
        if vId == '':
          vId = utils.generateToken(5)

        victimConnect = victim(vId, request.environ['REMOTE_ADDR'], request.user_agent.platform, request.user_agent.browser, request.user_agent.version,  utils.portScanner(request.environ['REMOTE_ADDR']), request.form['cpu'], time.strftime(""%Y-%m-%d - %H:%M:%S""))
        victimGeo = victim_geo(vId, 'city', request.form['countryCode'], request.form['country'], request.form['query'], request.form['lat'], request.form['lon'], request.form['org'], request.form['region'], request.form['regionName'], request.form['timezone'], request.form['zip'], request.form['isp'], str(request.user_agent))

        utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" A victim has been connected from "" + utils.Color['blue'] + victimGeo.ip + utils.Color['white'] + ' with the following identifier: ' + utils.Color['green'] + vId + utils.Color['white'])
        cant = int(db.sentences_victim('count_times', vId, 3, 0))

        db.sentences_victim('insert_click', [vId, trape.url_to_clone, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        db.sentences_victim('delete_networks', [vId], 2)

        if cant > 0:
            utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" "" + ""It\'s his "" + str(cant + 1) + "" time"")
            db.sentences_victim('update_victim', [victimConnect, vId, time.time()], 2)
            db.sentences_victim('update_victim_geo', [victimGeo, vId], 2)
        else:
            utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" "" + ""It\'s his first time"")
            db.sentences_victim('insert_victim', [victimConnect, vId, time.time()], 2)
            db.sentences_victim('insert_victim_geo', [victimGeo, vId], 2)
        return json.dumps({'status' : 'OK', 'vId' : vId});

    @app.route(""/nr"", methods=[""POST""])
    def networkRegister():
        vId = request.form['vId']
        vIp = request.form['ip']
        vnetwork = request.form['red']
        if vId == '':
          vId = utils.generateToken(5)
        utils.Go(utils.Color['white'] + ""["" + utils.Color['greenBold'] + ""+"" + utils.Color['white'] + ""]"" + utils.Color['whiteBold'] + "" "" + vnetwork + utils.Color['white'] + "" session detected from "" + utils.Color['blue'] + vIp + utils.Color['white'] + ' ' + ""with ID: "" + utils.Color['green'] + vId + utils.Color['white'])

        cant = int(db.sentences_victim('count_victim_network', [vId, vnetwork], 3, 0))

        if cant > 0:
            db.sentences_victim('update_network', [vId, vnetwork, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        else:
            db.sentences_victim('insert_networks', [vId, vIp, request.environ['REMOTE_ADDR'], vnetwork, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        return json.dumps({'status' : 'OK', 'vId' : vId});

    @app.route(""/redv"")
    def redirectVictim():
        url = request.args.get('url')
        opener = urllib2.build_opener()
        headers = victim_headers()
        opener.addheaders = headers
        html = victim_inject_code(opener.open(url).read(), 'vscript')
        return html

    @app.route(""/regv"", methods=[""POST""])
    def registerRequest():
        vrequest = victim_request(request.form['vId'], request.form['site'], request.form['fid'], request.form['name'], request.form['value'], request.form['sId'])
        db.sentences_victim('insert_requests', [vrequest, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        utils.Go(utils.Color['white'] + ""["" + utils.Color['greenBold'] + ""="" + utils.Color['white'] + ""]"" + "" "" + 'Receiving data from: ' + utils.Color['green'] + vrequest.id + utils.Color['white']  + ' ' + 'on' + ' ' + utils.Color['blue'] + vrequest.site + utils.Color['white'] + '\t\n' + vrequest.fid + '\t' + vrequest.name + ':\t' + vrequest.value)
        return json.dumps({'status' : 'OK', 'vId' : vrequest.id});

    @app.route(""/tping"", methods=[""POST""])
    def receivePing():
        vrequest = request.form['id']
        db.sentences_victim('report_online', [vrequest])
        return json.dumps({'status' : 'OK', 'vId' : vrequest});
",CWE-89,102.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#**
#
#########
# trape #
#########
#
# trape depends of this file
# For full copyright information this visit: https://github.com/boxug/trape
#
# Copyright 2017 by boxug / <hey@boxug.com>
#**
import time
import urllib2
from flask import Flask, render_template, session, request, json
from core.victim_objects import *
import core.stats
from core.utils import utils
from core.db import Database


# Main parts, to generate relationships among others
trape = core.stats.trape
app = core.stats.app

# call database
db = Database()

class victim_server(object):
    @app.route(""/"" + trape.victim_path)
    def homeVictim():
        opener = urllib2.build_opener()
        headers = victim_headers()
        opener.addheaders = headers
        html = victim_inject_code(opener.open(trape.url_to_clone).read(), 'lure')
        return html

    @app.route(""/register"", methods=[""POST""])
    def register():
        vId = request.form['vId']
        if vId == '':
          vId = utils.generateToken(5)

        victimConnect = victim(vId, request.environ['REMOTE_ADDR'], request.user_agent.platform, request.user_agent.browser, request.user_agent.version,  utils.portScanner(request.environ['REMOTE_ADDR']), request.form['cpu'], time.strftime(""%Y-%m-%d - %H:%M:%S""))
        victimGeo = victim_geo(vId, 'city', request.form['countryCode'], request.form['country'], request.form['query'], request.form['lat'], request.form['lon'], request.form['org'], request.form['region'], request.form['regionName'], request.form['timezone'], request.form['zip'], request.form['isp'], str(request.user_agent))

        utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" A victim has been connected from "" + utils.Color['blue'] + victimGeo.ip + utils.Color['white'] + ' with the following identifier: ' + utils.Color['green'] + vId + utils.Color['white'])
        cant = int(db.sentences_victim('count_times', vId, 3, 0))

        db.sentences_victim('insert_click', [vId, trape.url_to_clone, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        db.sentences_victim('delete_networks', [vId], 2)

        if cant > 0:
            utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" "" + ""It\'s his "" + str(cant + 1) + "" time"")
            db.sentences_victim('update_victim', [victimConnect, vId, time.time()], 2)
            db.sentences_victim('update_victim_geo', [victimGeo, vId], 2)
        else:
            utils.Go(utils.Color['white'] + ""["" + utils.Color['blueBold'] + ""*"" + utils.Color['white'] + ""]"" + "" "" + ""It\'s his first time"")
            db.sentences_victim('insert_victim', [victimConnect, vId, time.time()], 2)
            db.sentences_victim('insert_victim_geo', [victimGeo, vId], 2)
        return json.dumps({'status' : 'OK', 'vId' : vId});

    @app.route(""/nr"", methods=[""POST""])
    def networkRegister():
        vId = request.form['vId']
        vIp = request.form['ip']
        vnetwork = request.form['red']
        if vId == '':
          vId = utils.generateToken(5)
        utils.Go(utils.Color['white'] + ""["" + utils.Color['greenBold'] + ""+"" + utils.Color['white'] + ""]"" + utils.Color['whiteBold'] + "" "" + vnetwork + utils.Color['white'] + "" session detected from "" + utils.Color['blue'] + vIp + utils.Color['white'] + ' ' + ""with ID: "" + utils.Color['green'] + vId + utils.Color['white'])

        cant = int(db.sentences_victim('count_victim_network', [vId, vnetwork], 3, 0))

        if cant > 0:
            db.sentences_victim('update_network', [vId, vnetwork, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        else:
            db.sentences_victim('insert_networks', [vId, vIp, request.environ['REMOTE_ADDR'], vnetwork, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        return json.dumps({'status' : 'OK', 'vId' : vId});

    @app.route(""/redv"")
    def redirectVictim():
        url = request.args.get('url')
        opener = urllib2.build_opener()
        headers = victim_headers()
        opener.addheaders = headers
        html = victim_inject_code(opener.open(url).read(), 'vscript')
        return html

    @app.route(""/regv"", methods=[""POST""])
    def registerRequest():
        vrequest = victim_request(request.form['vId'], request.form['site'], request.form['fid'], request.form['name'], request.form['value'], request.form['sId'])
        db.sentences_victim('insert_requests', [vrequest, time.strftime(""%Y-%m-%d - %H:%M:%S"")], 2)
        utils.Go(utils.Color['white'] + ""["" + utils.Color['greenBold'] + ""="" + utils.Color['white'] + ""]"" + "" "" + 'Receiving data from: ' + utils.Color['green'] + vrequest.id + utils.Color['white']  + ' ' + 'on' + ' ' + utils.Color['blue'] + vrequest.site + utils.Color['white'] + '\t\n' + vrequest.fid + '\t' + vrequest.name + ':\t' + vrequest.value)
        return json.dumps({'status' : 'OK', 'vId' : vrequest.id});

    @app.route(""/tping"", methods=[""POST""])
    def receivePing():
        vrequest = request.form['id']
        db.sentences_victim('report_online', [vrequest])
        return json.dumps({'status' : 'OK', 'vId' : vrequest});
",CWE-79,102.0,1
"from flask import jsonify, request, make_response, g
from sqlalchemy.exc import IntegrityError
from . import api
from .. import db, auth
from ..models import Song
from .errors import bad_request, route_not_found

@api.route('/songs/<name>')
def song(name):
    return jsonify(name=name)

@api.route('/songs/<int:id>')
def get_song(id):
    song = Song.query.filter_by(id=id).first()
    if not song:
        return route_not_found(song)
    return make_response(jsonify(song.to_json()), 200)

@api.route('/songs/', methods=['POST'])
@auth.login_required
def new_song():
    # check if json
    if request.headers['content_type'] == 'application/json':
        payload = request.get_json()

        # validate payload
        if not request.json or \
        not 'title' in payload or \
        not 'artist' in payload or \
        not 'url' in payload:
            message = 'the payload aint right'
            return bad_request(message)

        # validate that song doesn't already exist
        # TODO: this needs to be way more sophisticated
        if Song.query.filter_by(url=payload['url']).first():
            message = 'this song already exists'
            return bad_request(message)

        # add song
        try:
            song = Song(title=payload['title'], \
                        artist=payload['artist'], \
                        url=payload['url'], \
                        user=g.current_user)
            db.session.add(song)
            db.session.commit()
            return make_response(jsonify(song.to_json()), 200)
        except IntegrityError:
            message = 'this song already exists'
            return bad_request(message)
        except AssertionError as ex:
            return bad_request(ex.args[0])
        except Exception as ex:
            template = ""An exception of type {0} occured. Arguments:\n{1!r}""
            message = template.format(type(ex).__name__, ex.args)
            return bad_request(message)

    else:
        message = 'that aint json'
        return bad_request(message)

@api.route('/songs/<int:id>/related')
def get_song_relations(id):
    top = request.args.get('top')
    song = Song.query.filter_by(id=id).first()
    if not song:
        return route_not_found(song)
    return make_response(jsonify(song.get_related_songs_json(top)), 200)




",CWE-89,74.0,1
"import yaml
try:
    from ansible.utils.vault import VaultLib
except ImportError:
    # Ansible 2.0 has changed the vault location
    from ansible.parsing.vault import VaultLib


class Vault(object):
    '''R/W an ansible-vault yaml file'''

    def __init__(self, password):
        self.password = password
        self.vault = VaultLib(password)

    def load(self, stream):
        '''read vault steam and return python object'''
        return yaml.load(self.vault.decrypt(stream))

    def dump(self, data, stream=None):
        '''encrypt data and print stdout or write to stream'''
        yaml_text = yaml.dump(
            data,
            default_flow_style=False,
            allow_unicode=True)
        encrypted = self.vault.encrypt(yaml_text)
        if stream:
            stream.write(encrypted)
        else:
            return encrypted
",CWE-94,31.0,1
"import os
from tempfile import mkstemp

from testfixtures import ShouldRaise

from ansible.errors import AnsibleError


here = os.path.dirname(os.path.abspath(__file__))


class TestVaultLoad(object):
    def _getTargetClass(self):
        from ansible_vault import Vault
        return Vault

    def _makeOne(self, password):
        return self._getTargetClass()(password)

    def test_can(self):
        fpath = os.path.join(here, 'file', 'vault.txt')
        vault = self._makeOne('password')
        assert vault.load(open(fpath).read()) == 'test'

    def test_cannot(self):
        fpath = os.path.join(here, 'file', 'vault.txt')
        vault = self._makeOne('invalid-password')
        with ShouldRaise(AnsibleError('Decryption failed')):
            vault.load(open(fpath).read())


class TestVaultDump(object):
    def _getTargetClass(self):
        from ansible_vault import Vault
        return Vault

    def _makeOne(self, password):
        return self._getTargetClass()(password)

    def test_dump_file(self):
        fpath = mkstemp()[1]
        with open(fpath, 'w+b') as fp:
            write_vault = self._makeOne('password')
            write_vault.dump('test', fp)

        with open(fpath, 'r+b') as fp:
            read_vault = self._makeOne('password')
            assert read_vault.load(fp.read()) == 'test'

        os.remove(fpath)

    def test_dump_text(self):
        write_vault = self._makeOne('password')
        dumped = write_vault.dump('test')

        read_vault = self._makeOne('password')
        assert read_vault.load(dumped) == 'test'
",CWE-94,58.0,1
"import sys
import os

from setuptools import setup, find_packages
from setuptools.command.test import test as TestCommand


def _read(fname):
    here = os.path.dirname(os.path.abspath(__file__))
    return open(os.path.join(here, fname)).read()


class PyTest(TestCommand):
    user_options = [('pytest-args=', 'a', ""Arguments to pass to py.test"")]

    def initialize_options(self):
        TestCommand.initialize_options(self)
        self.pytest_args = []
        if len(sys.argv) == 2:
            self.pytest_args = ['ansible_vault']

    def finalize_options(self):
        TestCommand.finalize_options(self)
        self.test_args = []
        self.test_suite = True

    def run_tests(self):
        # import here, cause outside the eggs aren't loaded
        import pytest
        sys.exit(pytest.main(self.pytest_args))


setup(
    name='ansible-vault',
    version='1.0.4',
    author='Tomohiro NAKAMURA',
    author_email='quickness.net@gmail.com',
    url='https://github.com/jptomo/ansible-vault',
    description='R/W an ansible-vault yaml file',
    long_description=_read('README.rst'),
    packages=find_packages(),
    install_requires=['ansible'],
    tests_require=['pytest', 'testfixtures'],
    cmdclass={'test': PyTest},
    classifiers=[
        'Development Status :: 5 - Production/Stable',
        'License :: OSI Approved :: GNU General Public License v3 (GPLv3)',
    ],
    license='GPLv3',
)
",CWE-94,51.0,1
"""""""
    Slixmpp: The Slick XMPP Library
    Copyright (C) 2012 Nathanael C. Fritz, Lance J.T. Stout
    This file is part of Slixmpp.

    See the file LICENSE for copying permissio
""""""

import logging

import slixmpp
from slixmpp.stanza import Message, Iq
from slixmpp.xmlstream.handler import Callback
from slixmpp.xmlstream.matcher import StanzaPath
from slixmpp.xmlstream import register_stanza_plugin
from slixmpp.plugins import BasePlugin
from slixmpp.plugins.xep_0280 import stanza


log = logging.getLogger(__name__)


class XEP_0280(BasePlugin):

    """"""
    XEP-0280 Message Carbons
    """"""

    name = 'xep_0280'
    description = 'XEP-0280: Message Carbons'
    dependencies = {'xep_0030', 'xep_0297'}
    stanza = stanza

    def plugin_init(self):
        self.xmpp.register_handler(
            Callback('Carbon Received',
                     StanzaPath('message/carbon_received'),
                     self._handle_carbon_received))
        self.xmpp.register_handler(
            Callback('Carbon Sent',
                     StanzaPath('message/carbon_sent'),
                     self._handle_carbon_sent))

        register_stanza_plugin(Message, stanza.ReceivedCarbon)
        register_stanza_plugin(Message, stanza.SentCarbon)
        register_stanza_plugin(Message, stanza.PrivateCarbon)
        register_stanza_plugin(Iq, stanza.CarbonEnable)
        register_stanza_plugin(Iq, stanza.CarbonDisable)

        register_stanza_plugin(stanza.ReceivedCarbon,
                               self.xmpp['xep_0297'].stanza.Forwarded)
        register_stanza_plugin(stanza.SentCarbon,
                               self.xmpp['xep_0297'].stanza.Forwarded)

    def plugin_end(self):
        self.xmpp.remove_handler('Carbon Received')
        self.xmpp.remove_handler('Carbon Sent')
        self.xmpp.plugin['xep_0030'].del_feature(feature='urn:xmpp:carbons:2')

    def session_bind(self, jid):
        self.xmpp.plugin['xep_0030'].add_feature('urn:xmpp:carbons:2')

    def _handle_carbon_received(self, msg):
        self.xmpp.event('carbon_received', msg)

    def _handle_carbon_sent(self, msg):
        self.xmpp.event('carbon_sent', msg)

    def enable(self, ifrom=None, timeout=None, callback=None,
               timeout_callback=None):
        iq = self.xmpp.Iq()
        iq['type'] = 'set'
        iq['from'] = ifrom
        iq.enable('carbon_enable')
        return iq.send(timeout_callback=timeout_callback, timeout=timeout,
                       callback=callback)

    def disable(self, ifrom=None, timeout=None, callback=None,
                timeout_callback=None):
        iq = self.xmpp.Iq()
        iq['type'] = 'set'
        iq['from'] = ifrom
        iq.enable('carbon_disable')
        return iq.send(timeout_callback=timeout_callback, timeout=timeout,
                       callback=callback)
",CWE-20,86.0,1
"""""""
    Slixmpp: The Slick XMPP Library
    Copyright (C) 2012 Nathanael C. Fritz, Lance J.T. Stout
    This file is part of Slixmpp.

    See the file LICENSE for copying permissio
""""""

import logging

import slixmpp
from slixmpp.stanza import Message, Iq
from slixmpp.xmlstream.handler import Callback
from slixmpp.xmlstream.matcher import StanzaPath
from slixmpp.xmlstream import register_stanza_plugin
from slixmpp.plugins import BasePlugin
from slixmpp.plugins.xep_0280 import stanza


log = logging.getLogger(__name__)


class XEP_0280(BasePlugin):

    """"""
    XEP-0280 Message Carbons
    """"""

    name = 'xep_0280'
    description = 'XEP-0280: Message Carbons'
    dependencies = {'xep_0030', 'xep_0297'}
    stanza = stanza

    def plugin_init(self):
        self.xmpp.register_handler(
            Callback('Carbon Received',
                     StanzaPath('message/carbon_received'),
                     self._handle_carbon_received))
        self.xmpp.register_handler(
            Callback('Carbon Sent',
                     StanzaPath('message/carbon_sent'),
                     self._handle_carbon_sent))

        register_stanza_plugin(Message, stanza.ReceivedCarbon)
        register_stanza_plugin(Message, stanza.SentCarbon)
        register_stanza_plugin(Message, stanza.PrivateCarbon)
        register_stanza_plugin(Iq, stanza.CarbonEnable)
        register_stanza_plugin(Iq, stanza.CarbonDisable)

        register_stanza_plugin(stanza.ReceivedCarbon,
                               self.xmpp['xep_0297'].stanza.Forwarded)
        register_stanza_plugin(stanza.SentCarbon,
                               self.xmpp['xep_0297'].stanza.Forwarded)

    def plugin_end(self):
        self.xmpp.remove_handler('Carbon Received')
        self.xmpp.remove_handler('Carbon Sent')
        self.xmpp.plugin['xep_0030'].del_feature(feature='urn:xmpp:carbons:2')

    def session_bind(self, jid):
        self.xmpp.plugin['xep_0030'].add_feature('urn:xmpp:carbons:2')

    def _handle_carbon_received(self, msg):
        self.xmpp.event('carbon_received', msg)

    def _handle_carbon_sent(self, msg):
        self.xmpp.event('carbon_sent', msg)

    def enable(self, ifrom=None, timeout=None, callback=None,
               timeout_callback=None):
        iq = self.xmpp.Iq()
        iq['type'] = 'set'
        iq['from'] = ifrom
        iq.enable('carbon_enable')
        return iq.send(timeout_callback=timeout_callback, timeout=timeout,
                       callback=callback)

    def disable(self, ifrom=None, timeout=None, callback=None,
                timeout_callback=None):
        iq = self.xmpp.Iq()
        iq['type'] = 'set'
        iq['from'] = ifrom
        iq.enable('carbon_disable')
        return iq.send(timeout_callback=timeout_callback, timeout=timeout,
                       callback=callback)
",CWE-346,86.0,1
"#     Copyright 2014 Netflix, Inc.
#
#     Licensed under the Apache License, Version 2.0 (the ""License"");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an ""AS IS"" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.

from security_monkey import app, db
from flask_wtf.csrf import generate_csrf
from security_monkey.auth.models import RBACRole
from security_monkey.decorators import crossdomain

from flask_restful import fields, marshal, Resource, reqparse
from flask_login import current_user

ORIGINS = [
    'https://{}:{}'.format(app.config.get('FQDN'), app.config.get('WEB_PORT')),
    # Adding this next one so you can also access the dart UI by prepending /static to the path.
    'https://{}:{}'.format(app.config.get('FQDN'), app.config.get('API_PORT')),
    'https://{}:{}'.format(app.config.get('FQDN'), app.config.get('NGINX_PORT')),
    'https://{}:80'.format(app.config.get('FQDN'))
]

##### Marshal Datastructures #####

# Used by RevisionGet, RevisionList, ItemList
REVISION_FIELDS = {
    'id': fields.Integer,
    'date_created': fields.String,
    'date_last_ephemeral_change': fields.String,
    'active': fields.Boolean,
    'item_id': fields.Integer
}

# Used by RevisionList, ItemGet, ItemList
ITEM_FIELDS = {
    'id': fields.Integer,
    'region': fields.String,
    'name': fields.String
}

# Used by ItemList, Justify
AUDIT_FIELDS = {
    'id': fields.Integer,
    'score': fields.Integer,
    'issue': fields.String,
    'notes': fields.String,
    'justified': fields.Boolean,
    'justification': fields.String,
    'justified_date': fields.String,
    'item_id': fields.Integer
}

## Single Use Marshal Objects ##

# SINGLE USE - RevisionGet
REVISION_COMMENT_FIELDS = {
    'id': fields.Integer,
    'revision_id': fields.Integer,
    'date_created': fields.String,
    'text': fields.String
}

# SINGLE USE - ItemGet
ITEM_COMMENT_FIELDS = {
    'id': fields.Integer,
    'date_created': fields.String,
    'text': fields.String,
    'item_id': fields.Integer
}

# SINGLE USE - UserSettings
USER_SETTINGS_FIELDS = {
    # 'id': fields.Integer,
    'daily_audit_email': fields.Boolean,
    'change_reports': fields.String
}

# SINGLE USE - AccountGet
ACCOUNT_FIELDS = {
    'id': fields.Integer,
    'name': fields.String,
    'identifier': fields.String,
    'notes': fields.String,
    'active': fields.Boolean,
    'third_party': fields.Boolean,
    'account_type': fields.String
}

USER_FIELDS = {
    'id': fields.Integer,
    'active': fields.Boolean,
    'email': fields.String,
    'role': fields.String,
    'confirmed_at': fields.String,
    'daily_audit_email': fields.Boolean,
    'change_reports': fields.String,
    'last_login_at': fields.String,
    'current_login_at': fields.String,
    'login_count': fields.Integer,
    'last_login_ip': fields.String,
    'current_login_ip': fields.String
}

ROLE_FIELDS = {
    'id': fields.Integer,
    'name': fields.String,
    'description': fields.String,
}

WHITELIST_FIELDS = {
    'id': fields.Integer,
    'name': fields.String,
    'notes': fields.String,
    'cidr': fields.String
}

IGNORELIST_FIELDS = {
    'id': fields.Integer,
    'prefix': fields.String,
    'notes': fields.String,
}

AUDITORSETTING_FIELDS = {
    'id': fields.Integer,
    'disabled': fields.Boolean,
    'issue_text': fields.String
}

ITEM_LINK_FIELDS = {
    'id': fields.Integer,
    'name': fields.String
}

class AuthenticatedService(Resource):
    def __init__(self):
        self.reqparse = reqparse.RequestParser()
        super(AuthenticatedService, self).__init__()
        self.auth_dict = dict()
        if current_user.is_authenticated():
            roles_marshal = []
            for role in current_user.roles:
                roles_marshal.append(marshal(role.__dict__, ROLE_FIELDS))

            roles_marshal.append({""name"": current_user.role})

            for role in RBACRole.roles[current_user.role].get_parents():
                roles_marshal.append({""name"": role.name})

            self.auth_dict = {
                ""authenticated"": True,
                ""user"": current_user.email,
                ""roles"": roles_marshal
            }
        else:
            if app.config.get('FRONTED_BY_NGINX'):
                url = ""https://{}:{}{}"".format(app.config.get('FQDN'), app.config.get('NGINX_PORT'), '/login')
            else:
                url = ""http://{}:{}{}"".format(app.config.get('FQDN'), app.config.get('API_PORT'), '/login')
            self.auth_dict = {
                ""authenticated"": False,
                ""user"": None,
                ""url"": url
            }


@app.after_request
@crossdomain(allowed_origins=ORIGINS)
def after(response):
    response.set_cookie('XSRF-COOKIE', generate_csrf())
    return response
",CWE-601,179.0,1
"#     Copyright 2014 Netflix, Inc.
#
#     Licensed under the Apache License, Version 2.0 (the ""License"");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an ""AS IS"" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.

from flask_login import current_user, logout_user
from flask_restful import Resource


# End the Flask-Logins session
from security_monkey import rbac


class Logout(Resource):

    decorators = [rbac.exempt]

    def get(self):
        if not current_user.is_authenticated():
            return ""Must be logged in to log out"", 200

        logout_user()
        return ""Logged Out"", 200
",CWE-601,33.0,1
"#     Copyright 2014 Netflix, Inc.
#
#     Licensed under the Apache License, Version 2.0 (the ""License"");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an ""AS IS"" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
from setuptools import setup

setup(
    name='security_monkey',
    version='0.8.0',
    long_description=__doc__,
    packages=['security_monkey'],
    include_package_data=True,
    zip_safe=False,
    install_requires=[
        'APScheduler==2.1.2',
        'Flask==0.10.1',
        'Flask-Login==0.2.10',
        'Flask-Mail==0.9.0',
        'Flask-Migrate==1.3.1',
        'Flask-Principal==0.4.0',
        'Flask-RESTful==0.3.3',
        'Flask-SQLAlchemy==1.0',
        'Flask-Script==0.6.3',
        'Flask-Security==1.7.4',
        'Flask-WTF==0.9.5',
        'Jinja2==2.8',
        'SQLAlchemy==0.9.2',
        'boto>=2.41.0',
        'ipaddr==2.1.11',
        'itsdangerous==0.23',
        'psycopg2==2.5.2',
        'bcrypt==2.0.0',
        'Sphinx==1.2.2',
        'gunicorn==18.0',
        'cryptography==1.3.2',
        'boto3>=1.4.2',
        'botocore>=1.4.81',
        'dpath==1.3.2',
        'pyyaml==3.11',
        'jira==0.32',
        'cloudaux>=1.0.6',
        'joblib>=0.9.4',
        'pyjwt>=1.01',
    ],
    extras_require = {
        'onelogin': ['python-saml>=2.2.0'],
        'tests': [
            'nose==1.3.0',
            'mock==1.0.1',
            'moto==0.4.30',
            'freezegun>=0.3.7'
        ]
    }
)
",CWE-601,64.0,1
"AC_INIT([tpm2.0-tools],
    [m4_esyscmd_s([git describe --tags --always --dirty])])
AC_CONFIG_MACRO_DIR([m4])
AC_PROG_CC
LT_INIT
AM_INIT_AUTOMAKE([foreign
                  subdir-objects])
AC_CONFIG_FILES([Makefile])
PKG_CHECK_MODULES([SAPI],[sapi])
# disable libtcti-device selectively (enabled by default)
AC_ARG_WITH(
    [tcti-device],
    [AS_HELP_STRING([--with-tcti-device],
        [Build tools with support for the device TCTI.])],
    [],
    [with_tcti_device=check])
AS_IF(
    [test ""x$with_tcti_device"" != ""xno""],
    [PKG_CHECK_MODULES(
        [TCTI_DEV],
        [tcti-device],
        [AC_DEFINE([HAVE_TCTI_DEV],[1])
         with_tcti_device=yes],
        [if test ""x$with_tcti_device"" = ""xyes""; then
             AC_MSG_FAILURE([--with-tcti-device option provided but libtcti-device not detected.])
         fi])])
AM_CONDITIONAL([HAVE_TCTI_DEV],[test ""x$with_tcti_device"" = ""xyes""])
# disable libtcti-socket selectively (enabled by default)
AC_ARG_WITH(
    [tcti-socket],
    [AS_HELP_STRING([--with-tcti-socket],
        [Build tools with support for the socket TCTI.])],
    [],
    [with_tcti_socket=check])
AS_IF(
    [test ""x$with_tcti_socket"" != ""xno""],
    [PKG_CHECK_MODULES(
        [TCTI_SOCK],
        [tcti-socket],
        [AC_DEFINE([HAVE_TCTI_SOCK],[1])
         with_tcti_socket=yes],
        [if test ""x$with_tcti_socket"" = ""xyes""; then
             AC_MSG_FAILURE([--with-tcti-socket option provided but libtcti-socket not detected.])
         fi])])
AM_CONDITIONAL([HAVE_TCTI_SOCK],[test ""x$with_tcti_socket"" = ""xyes""])
# selectively disable libtcti-tabrmd
AC_ARG_WITH(
    [tcti-tabrmd],
    [AS_HELP_STRING([--with-tcti-tabrmd],
        [Build tools with support for the tabrmd TCTI.])],
    [],
    [with_tcti_tabrmd=check])
AS_IF(
    [test ""x$with_tcti_tabrmd"" != ""xno""],
    [PKG_CHECK_MODULES(
        [TCTI_TABRMD],
        [tcti-tabrmd],
        [AC_DEFINE([HAVE_TCTI_TABRMD], [1])
         with_tcti_tabrmd=yes],
        [if test ""x$with_tcti_tabrmd"" = ""xyes""; then
             AC_MSG_FAILURE([--with-tcti-tabrmd option provided but libtcti-tabrmd not detected.])
         fi])])
AM_CONDITIONAL([HAVE_TCTI_TABRMD],[test ""x$with_tcti_tabrmd"" = ""xyes""])
# ensure we have at least one TCTI enabled, can't do much without one
AS_IF(
    [test ""x$with_tcti_device"" != ""xyes"" -a \
          ""x$with_tcti_socket"" != ""xyes"" -a \
          ""x$with_tcti_tabrmd"" != ""xyes""],
    [AC_MSG_ERROR(
        [no TCTIs: at least one TCTI library must be enabled],
        [1])])
PKG_CHECK_MODULES([CURL],[libcurl libcrypto])
AC_ARG_ENABLE([unit],
            [AS_HELP_STRING([--enable-unit],
                            [build cmocka unit tests (default is no)])],
            [enable_unit=$enableval],
            [enable_unit=no])
AS_IF([test ""x$enable_unit"" != xno],
      [PKG_CHECK_MODULES([CMOCKA],
                         [cmocka],
                         [AC_DEFINE([HAVE_CMOCKA],
                                    [1])])])
AM_CONDITIONAL([UNIT], [test ""x$enable_unit"" != xno])

AC_ARG_ENABLE([hardening],
  [AS_HELP_STRING([--enable-hardening],
    [Enable compiler and linker options to frustrate memory corruption exploits @<:@yes@:>@])],
  [hardening=""$enableval""],
  [hardening=""yes""])

# Good information on adding flags, and dealing with compilers can be found here:
#   https://github.com/zcash/zcash/issues/1832
#   https://github.com/kmcallister/autoharden/
AS_IF([test x""$hardening"" != x""no""], [

  AC_DEFUN([add_hardened_c_flag], [
    AX_CHECK_COMPILE_FLAG([$1],
      [EXTRA_CFLAGS=""$EXTRA_CFLAGS $1""],
      [AC_MSG_ERROR([Cannot enable $1, consider configuring with --disable-hardening])]
    )
  ])

  AC_DEFUN([add_hardened_ld_flag], [
    AX_CHECK_LINK_FLAG([$1],
      [EXTRA_LDFLAGS=""$EXTRA_LDFLAGS $1""],
      [AC_MSG_ERROR([Cannot enable $1, consider configuring with --disable-hardening])]
    )
  ])

  AC_DEFUN([add_hardened_define_flag], [
    AX_CHECK_PREPROC_FLAG([$1],
      [EXTRA_CFLAGS=""$EXTRA_CFLAGS $1""],
      [AC_MSG_ERROR([Cannot enable $1, consider configuring with --disable-hardening])]
    )
  ])

  add_hardened_c_flag([-Wall])
  add_hardened_c_flag([-Wextra])
  add_hardened_c_flag([-Werror])

  add_hardened_c_flag([-Wformat])
  add_hardened_c_flag([-Wformat-security])
  add_hardened_c_flag([-Wstack-protector])
  add_hardened_c_flag([-fstack-protector-all])

  add_hardened_define_flag([-U_FORTIFY_SOURCE])
  add_hardened_define_flag([-D_FORTIFY_SOURCE=2])

  add_hardened_c_flag([-fPIC])
  add_hardened_ld_flag([[-shared]])

  add_hardened_c_flag([-fPIE])
  add_hardened_ld_flag([[-pie]])

  add_hardened_ld_flag([[-Wl,-z,relro]])
  add_hardened_ld_flag([[-Wl,-z,now]])

], [
  AC_MSG_WARN([Compiling with --disable-hardening is dangerous!
you should consider fixing the configure script compiler flags
and submitting patches upstream!])
])

# -D_GNU_SOURCE is required for execvpe() in options.c
AX_CHECK_PREPROC_FLAG([-D_GNU_SOURCE],
  [EXTRA_CFLAGS=""$EXTRA_CFLAGS -D_GNU_SOURCE""],
  [AC_MSG_ERROR([Cannot enable -D_GNU_SOURCE])]
)

# Best attempt, strip unused stuff from the binary to reduce size.
# Rather than nesting these and making them ugly just use a counter.
AX_CHECK_COMPILE_FLAG([-fdata-sections], [strip+=""y""])
AX_CHECK_COMPILE_FLAG([-ffunction-sections], [strip+=""y""])
AX_CHECK_LINK_FLAG([[-Wl,--gc-sections]], [strip+=""y""])

AS_IF([test x""$strip"" == x""yyy""], [
  EXTRA_CFLAGS=""$EXTRA_CFLAGS -fdata-sections -ffunction-sections""
  EXTRA_LDFLAGS=""$EXTRA_LDFLAGS -Wl,--gc-sections""
],
  AC_MSG_NOTICE([Not using compiler options to reduce binary size!])
)

AC_SUBST([EXTRA_CFLAGS])
AC_SUBST([EXTRA_LDFLAGS])

AC_OUTPUT
",CWE-522,167.0,1
"#!/usr/bin/python
# -*- coding: utf-8 -*-

import sys
import re

REG_LINE_GPERF = re.compile('#line .+gperf""')
REG_HASH_FUNC = re.compile('hash\s*\(register\s+const\s+char\s*\*\s*str,\s*register\s+unsigned\s+int\s+len\s*\)')
REG_STR_AT = re.compile('str\[(\d+)\]')
REG_UNFOLD_KEY = re.compile('unicode_unfold_key\s*\(register\s+const\s+char\s*\*\s*str,\s*register\s+unsigned\s+int\s+len\)')
REG_ENTRY = re.compile('\{"".+?"",\s*/\*(.+?)\*/\s*(-?\d+),\s*(\d)\}')
REG_EMPTY_ENTRY = re.compile('\{"""",\s*(-?\d+),\s*(\d)\}')
REG_IF_LEN = re.compile('if\s*\(\s*len\s*<=\s*MAX_WORD_LENGTH.+')
REG_GET_HASH = re.compile('(?:register\s+)?(?:unsigned\s+)?int\s+key\s*=\s*hash\s*\(str,\s*len\);')
REG_GET_CODE = re.compile('(?:register\s+)?const\s+char\s*\*\s*s\s*=\s*wordlist\[key\]\.name;')
REG_CODE_CHECK = re.compile('if\s*\(\*str\s*==\s*\*s\s*&&\s*!strncmp.+\)')

def parse_line(s):
    s = s.rstrip()

    r = re.sub(REG_LINE_GPERF, '', s)
    if r != s: return r
    r = re.sub(REG_HASH_FUNC, 'hash(OnigCodePoint codes[])', s)
    if r != s: return r
    r = re.sub(REG_STR_AT, 'onig_codes_byte_at(codes, \\1)', s)
    if r != s: return r
    r = re.sub(REG_UNFOLD_KEY, 'unicode_unfold_key(OnigCodePoint code)', s)
    if r != s: return r
    r = re.sub(REG_ENTRY, '{\\1, \\2, \\3}', s)
    if r != s: return r
    r = re.sub(REG_EMPTY_ENTRY, '{0xffffffff, \\1, \\2}', s)
    if r != s: return r
    r = re.sub(REG_IF_LEN, 'if (0 == 0)', s)
    if r != s: return r
    r = re.sub(REG_GET_HASH, 'int key = hash(&code);', s)
    if r != s: return r
    r = re.sub(REG_GET_CODE, 'OnigCodePoint gcode = wordlist[key].code;', s)
    if r != s: return r
    r = re.sub(REG_CODE_CHECK, 'if (code == gcode)', s)
    if r != s: return r

    return s

def parse_file(f):
    print ""/* This file was converted by gperf_unfold_key_conv.py\n      from gperf output file. */""

    line = f.readline()
    while line:
        s = parse_line(line)
        print s
        line = f.readline()


# main
parse_file(sys.stdin)
",CWE-787,56.0,1
"from importlib import import_module
from os import path, listdir
from string import lower

from debug import logger
import paths

class MsgBase(object):
    def encode(self):
        self.data = {"""": lower(type(self).__name__)}


def constructObject(data):
    try:
        classBase = eval(data[""""] + ""."" + data[""""].title())
    except NameError:
        logger.error(""Don't know how to handle message type: \""%s\"""", data[""""])
        return None
    try:
        returnObj = classBase()
        returnObj.decode(data)
    except KeyError as e:
        logger.error(""Missing mandatory key %s"", e)
        return None
    except:
        logger.error(""classBase fail"", exc_info=True)
        return None
    else:
        return returnObj

if paths.frozen is not None:
    import messagetypes.message
    import messagetypes.vote
else:
    for mod in listdir(path.dirname(__file__)):
        if mod == ""__init__.py"":
            continue
        splitted = path.splitext(mod)
        if splitted[1] != "".py"":
            continue
        try:
            import_module(""."" + splitted[0], ""messagetypes"")
        except ImportError:
            logger.error(""Error importing %s"", mod, exc_info=True)
        else:
            logger.debug(""Imported message type module %s"", mod)
",CWE-94,47.0,1
"import warnings

import six
from django.http import HttpResponse
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from django.views.generic import View

from ..exceptions import AnymailInsecureWebhookWarning, AnymailWebhookValidationFailure
from ..utils import get_anymail_setting, collect_all_methods, get_request_basic_auth


class AnymailBasicAuthMixin(object):
    """"""Implements webhook basic auth as mixin to AnymailBaseWebhookView.""""""

    # Whether to warn if basic auth is not configured.
    # For most ESPs, basic auth is the only webhook security,
    # so the default is True. Subclasses can set False if
    # they enforce other security (like signed webhooks).
    warn_if_no_basic_auth = True

    # List of allowable HTTP basic-auth 'user:pass' strings.
    basic_auth = None  # (Declaring class attr allows override by kwargs in View.as_view.)

    def __init__(self, **kwargs):
        self.basic_auth = get_anymail_setting('webhook_authorization', default=[],
                                              kwargs=kwargs)  # no esp_name -- auth is shared between ESPs
        # Allow a single string:
        if isinstance(self.basic_auth, six.string_types):
            self.basic_auth = [self.basic_auth]
        if self.warn_if_no_basic_auth and len(self.basic_auth) < 1:
            warnings.warn(
                ""Your Anymail webhooks are insecure and open to anyone on the web. ""
                ""You should set WEBHOOK_AUTHORIZATION in your ANYMAIL settings. ""
                ""See 'Securing webhooks' in the Anymail docs."",
                AnymailInsecureWebhookWarning)
        # noinspection PyArgumentList
        super(AnymailBasicAuthMixin, self).__init__(**kwargs)

    def validate_request(self, request):
        """"""If configured for webhook basic auth, validate request has correct auth.""""""
        if self.basic_auth:
            basic_auth = get_request_basic_auth(request)
            if basic_auth is None or basic_auth not in self.basic_auth:
                # noinspection PyUnresolvedReferences
                raise AnymailWebhookValidationFailure(
                    ""Missing or invalid basic auth in Anymail %s webhook"" % self.esp_name)


# Mixin note: Django's View.__init__ doesn't cooperate with chaining,
# so all mixins that need __init__ must appear before View in MRO.
class AnymailBaseWebhookView(AnymailBasicAuthMixin, View):
    """"""Base view for processing ESP event webhooks

    ESP-specific implementations should subclass
    and implement parse_events. They may also
    want to implement validate_request
    if additional security is available.
    """"""

    def __init__(self, **kwargs):
        super(AnymailBaseWebhookView, self).__init__(**kwargs)
        self.validators = collect_all_methods(self.__class__, 'validate_request')

    # Subclass implementation:

    # Where to send events: either ..signals.inbound or ..signals.tracking
    signal = None

    def validate_request(self, request):
        """"""Check validity of webhook post, or raise AnymailWebhookValidationFailure.

        AnymailBaseWebhookView includes basic auth validation.
        Subclasses can implement (or provide via mixins) if the ESP supports
        additional validation (such as signature checking).

        *All* definitions of this method in the class chain (including mixins)
        will be called. There is no need to chain to the superclass.
        (See self.run_validators and collect_all_methods.)
        """"""
        # if request.POST['signature'] != expected_signature:
        #     raise AnymailWebhookValidationFailure(""...message..."")
        # (else just do nothing)
        pass

    def parse_events(self, request):
        """"""Return a list of normalized AnymailWebhookEvent extracted from ESP post data.

        Subclasses must implement.
        """"""
        raise NotImplementedError()

    # HTTP handlers (subclasses shouldn't need to override):

    http_method_names = [""post"", ""head"", ""options""]

    @method_decorator(csrf_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super(AnymailBaseWebhookView, self).dispatch(request, *args, **kwargs)

    def head(self, request, *args, **kwargs):
        # Some ESPs verify the webhook with a HEAD request at configuration time
        return HttpResponse()

    def post(self, request, *args, **kwargs):
        # Normal Django exception handling will do the right thing:
        # - AnymailWebhookValidationFailure will turn into an HTTP 400 response
        #   (via Django SuspiciousOperation handling)
        # - Any other errors (e.g., in signal dispatch) will turn into HTTP 500
        #   responses (via normal Django error handling). ESPs generally
        #   treat that as ""try again later"".
        self.run_validators(request)
        events = self.parse_events(request)
        esp_name = self.esp_name
        for event in events:
            self.signal.send(sender=self.__class__, event=event, esp_name=esp_name)
        return HttpResponse()

    # Request validation (subclasses shouldn't need to override):

    def run_validators(self, request):
        for validator in self.validators:
            validator(self, request)

    @property
    def esp_name(self):
        """"""
        Read-only name of the ESP for this webhook view.

        Subclasses must override with class attr. E.g.:
            esp_name = ""Postmark""
            esp_name = ""SendGrid""  # (use ESP's preferred capitalization)
        """"""
        raise NotImplementedError(""%s.%s must declare esp_name class attr"" %
                                  (self.__class__.__module__, self.__class__.__name__))
",CWE-200,136.0,1
"from django.apps import AppConfig


class AnymailBaseConfig(AppConfig):
    name = 'anymail'
    verbose_name = ""Anymail""

    def ready(self):
        pass
",CWE-532,10.0,1
,CWE-532,,1
"import warnings

import six
from django.http import HttpResponse
from django.utils.crypto import constant_time_compare
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from django.views.generic import View

from ..exceptions import AnymailInsecureWebhookWarning, AnymailWebhookValidationFailure
from ..utils import get_anymail_setting, collect_all_methods, get_request_basic_auth


class AnymailBasicAuthMixin(object):
    """"""Implements webhook basic auth as mixin to AnymailBaseWebhookView.""""""

    # Whether to warn if basic auth is not configured.
    # For most ESPs, basic auth is the only webhook security,
    # so the default is True. Subclasses can set False if
    # they enforce other security (like signed webhooks).
    warn_if_no_basic_auth = True

    # List of allowable HTTP basic-auth 'user:pass' strings.
    basic_auth = None  # (Declaring class attr allows override by kwargs in View.as_view.)

    def __init__(self, **kwargs):
        self.basic_auth = get_anymail_setting('webhook_authorization', default=[],
                                              kwargs=kwargs)  # no esp_name -- auth is shared between ESPs
        # Allow a single string:
        if isinstance(self.basic_auth, six.string_types):
            self.basic_auth = [self.basic_auth]
        if self.warn_if_no_basic_auth and len(self.basic_auth) < 1:
            warnings.warn(
                ""Your Anymail webhooks are insecure and open to anyone on the web. ""
                ""You should set WEBHOOK_AUTHORIZATION in your ANYMAIL settings. ""
                ""See 'Securing webhooks' in the Anymail docs."",
                AnymailInsecureWebhookWarning)
        # noinspection PyArgumentList
        super(AnymailBasicAuthMixin, self).__init__(**kwargs)

    def validate_request(self, request):
        """"""If configured for webhook basic auth, validate request has correct auth.""""""
        if self.basic_auth:
            request_auth = get_request_basic_auth(request)
            # Use constant_time_compare to avoid timing attack on basic auth. (It's OK that any()
            # can terminate early: we're not trying to protect how many auth strings are allowed,
            # just the contents of each individual auth string.)
            auth_ok = any(constant_time_compare(request_auth, allowed_auth)
                          for allowed_auth in self.basic_auth)
            if not auth_ok:
                # noinspection PyUnresolvedReferences
                raise AnymailWebhookValidationFailure(
                    ""Missing or invalid basic auth in Anymail %s webhook"" % self.esp_name)


# Mixin note: Django's View.__init__ doesn't cooperate with chaining,
# so all mixins that need __init__ must appear before View in MRO.
class AnymailBaseWebhookView(AnymailBasicAuthMixin, View):
    """"""Base view for processing ESP event webhooks

    ESP-specific implementations should subclass
    and implement parse_events. They may also
    want to implement validate_request
    if additional security is available.
    """"""

    def __init__(self, **kwargs):
        super(AnymailBaseWebhookView, self).__init__(**kwargs)
        self.validators = collect_all_methods(self.__class__, 'validate_request')

    # Subclass implementation:

    # Where to send events: either ..signals.inbound or ..signals.tracking
    signal = None

    def validate_request(self, request):
        """"""Check validity of webhook post, or raise AnymailWebhookValidationFailure.

        AnymailBaseWebhookView includes basic auth validation.
        Subclasses can implement (or provide via mixins) if the ESP supports
        additional validation (such as signature checking).

        *All* definitions of this method in the class chain (including mixins)
        will be called. There is no need to chain to the superclass.
        (See self.run_validators and collect_all_methods.)

        Security note: use django.utils.crypto.constant_time_compare for string
        comparisons, to avoid exposing your validation to a timing attack.
        """"""
        # if not constant_time_compare(request.POST['signature'], expected_signature):
        #     raise AnymailWebhookValidationFailure(""...message..."")
        # (else just do nothing)
        pass

    def parse_events(self, request):
        """"""Return a list of normalized AnymailWebhookEvent extracted from ESP post data.

        Subclasses must implement.
        """"""
        raise NotImplementedError()

    # HTTP handlers (subclasses shouldn't need to override):

    http_method_names = [""post"", ""head"", ""options""]

    @method_decorator(csrf_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super(AnymailBaseWebhookView, self).dispatch(request, *args, **kwargs)

    def head(self, request, *args, **kwargs):
        # Some ESPs verify the webhook with a HEAD request at configuration time
        return HttpResponse()

    def post(self, request, *args, **kwargs):
        # Normal Django exception handling will do the right thing:
        # - AnymailWebhookValidationFailure will turn into an HTTP 400 response
        #   (via Django SuspiciousOperation handling)
        # - Any other errors (e.g., in signal dispatch) will turn into HTTP 500
        #   responses (via normal Django error handling). ESPs generally
        #   treat that as ""try again later"".
        self.run_validators(request)
        events = self.parse_events(request)
        esp_name = self.esp_name
        for event in events:
            self.signal.send(sender=self.__class__, event=event, esp_name=esp_name)
        return HttpResponse()

    # Request validation (subclasses shouldn't need to override):

    def run_validators(self, request):
        for validator in self.validators:
            validator(self, request)

    @property
    def esp_name(self):
        """"""
        Read-only name of the ESP for this webhook view.

        Subclasses must override with class attr. E.g.:
            esp_name = ""Postmark""
            esp_name = ""SendGrid""  # (use ESP's preferred capitalization)
        """"""
        raise NotImplementedError(""%s.%s must declare esp_name class attr"" %
                                  (self.__class__.__module__, self.__class__.__name__))
",CWE-532,145.0,1
,CWE-532,,1
"import base64

from django.test import override_settings, SimpleTestCase
from mock import create_autospec, ANY

from anymail.exceptions import AnymailInsecureWebhookWarning
from anymail.signals import tracking, inbound

from .utils import AnymailTestMixin, ClientWithCsrfChecks


def event_handler(sender, event, esp_name, **kwargs):
    """"""Prototypical webhook signal handler""""""
    pass


@override_settings(ANYMAIL={'WEBHOOK_AUTHORIZATION': 'username:password'})
class WebhookTestCase(AnymailTestMixin, SimpleTestCase):
    """"""Base for testing webhooks

    - connects webhook signal handlers
    - sets up basic auth by default (since most ESP webhooks warn if it's not enabled)
    """"""

    client_class = ClientWithCsrfChecks

    def setUp(self):
        super(WebhookTestCase, self).setUp()
        # Use correct basic auth by default (individual tests can override):
        self.set_basic_auth()

        # Install mocked signal handlers
        self.tracking_handler = create_autospec(event_handler)
        tracking.connect(self.tracking_handler)
        self.addCleanup(tracking.disconnect, self.tracking_handler)

        self.inbound_handler = create_autospec(event_handler)
        inbound.connect(self.inbound_handler)
        self.addCleanup(inbound.disconnect, self.inbound_handler)

    def set_basic_auth(self, username='username', password='password'):
        """"""Set basic auth for all subsequent test client requests""""""
        credentials = base64.b64encode(""{}:{}"".format(username, password).encode('utf-8')).decode('utf-8')
        self.client.defaults['HTTP_AUTHORIZATION'] = ""Basic {}"".format(credentials)

    def clear_basic_auth(self):
        self.client.defaults.pop('HTTP_AUTHORIZATION', None)

    def assert_handler_called_once_with(self, mockfn, *expected_args, **expected_kwargs):
        """"""Verifies mockfn was called with expected_args and at least expected_kwargs.

        Ignores *additional* actual kwargs (which might be added by Django signal dispatch).
        (This differs from mock.assert_called_once_with.)

        Returns the actual kwargs.
        """"""
        self.assertEqual(mockfn.call_count, 1)
        actual_args, actual_kwargs = mockfn.call_args
        self.assertEqual(actual_args, expected_args)
        for key, expected_value in expected_kwargs.items():
            if expected_value is ANY:
                self.assertIn(key, actual_kwargs)
            else:
                self.assertEqual(actual_kwargs[key], expected_value)
        return actual_kwargs

    def get_kwargs(self, mockfn):
        """"""Return the kwargs passed to the most recent call to mockfn""""""
        self.assertIsNotNone(mockfn.call_args)  # mockfn hasn't been called yet
        actual_args, actual_kwargs = mockfn.call_args
        return actual_kwargs


# noinspection PyUnresolvedReferences
class WebhookBasicAuthTestsMixin(object):
    """"""Common test cases for webhook basic authentication.

    Instantiate for each ESP's webhooks by:
    - mixing into WebhookTestCase
    - defining call_webhook to invoke the ESP's webhook
    """"""

    should_warn_if_no_auth = True  # subclass set False if other webhook verification used

    def call_webhook(self):
        # Concrete test cases should call a webhook via self.client.post,
        # and return the response
        raise NotImplementedError()

    @override_settings(ANYMAIL={})  # Clear the WEBHOOK_AUTH settings from superclass
    def test_warns_if_no_auth(self):
        if self.should_warn_if_no_auth:
            with self.assertWarns(AnymailInsecureWebhookWarning):
                response = self.call_webhook()
        else:
            with self.assertDoesNotWarn(AnymailInsecureWebhookWarning):
                response = self.call_webhook()
        self.assertEqual(response.status_code, 200)

    def test_verifies_basic_auth(self):
        response = self.call_webhook()
        self.assertEqual(response.status_code, 200)

    def test_verifies_bad_auth(self):
        self.set_basic_auth('baduser', 'wrongpassword')
        response = self.call_webhook()
        self.assertEqual(response.status_code, 400)

    def test_verifies_missing_auth(self):
        self.clear_basic_auth()
        response = self.call_webhook()
        self.assertEqual(response.status_code, 400)

    @override_settings(ANYMAIL={'WEBHOOK_AUTHORIZATION': ['cred1:pass1', 'cred2:pass2']})
    def test_supports_credential_rotation(self):
        """"""You can supply a list of basic auth credentials, and any is allowed""""""
        self.set_basic_auth('cred1', 'pass1')
        response = self.call_webhook()
        self.assertEqual(response.status_code, 200)

        self.set_basic_auth('cred2', 'pass2')
        response = self.call_webhook()
        self.assertEqual(response.status_code, 200)

        self.set_basic_auth('baduser', 'wrongpassword')
        response = self.call_webhook()
        self.assertEqual(response.status_code, 400)
",CWE-532,128.0,1
"{
  ""name"": ""joplin"",
  ""description"": ""Joplin CLI Client"",
  ""license"": ""MIT"",
  ""author"": ""Laurent Cozic"",
  ""scripts"": {
    ""postinstall"": ""patch-package""
  },
  ""bugs"": {
    ""url"": ""https://github.com/laurent22/joplin/issues""
  },
  ""repository"": {
    ""type"": ""git"",
    ""url"": ""https://github.com/laurent22/joplin""
  },
  ""copyright"": {
    ""title"": ""Joplin CLI"",
    ""years"": [
      2016,
      2017,
      2018,
      2019,
      2020
    ],
    ""owner"": ""Laurent Cozic""
  },
  ""version"": ""1.0.155"",
  ""bin"": {
    ""joplin"": ""./main.js""
  },
  ""engines"": {
    ""node"": "">=10.0.0""
  },
  ""dependencies"": {
    ""app-module-path"": ""^2.2.0"",
    ""async-mutex"": ""^0.1.3"",
    ""base-64"": ""^0.1.0"",
    ""base64-stream"": ""^1.0.0"",
    ""clean-html"": ""^1.5.0"",
    ""compare-version"": ""^0.1.2"",
    ""diacritics"": ""^1.3.0"",
    ""diff-match-patch"": ""^1.0.4"",
    ""es6-promise-pool"": ""^2.5.0"",
    ""file-uri-to-path"": ""^1.0.0"",
    ""follow-redirects"": ""^1.2.4"",
    ""font-awesome-filetypes"": ""^2.1.0"",
    ""form-data"": ""^2.1.4"",
    ""fs-extra"": ""^5.0.0"",
    ""highlight.js"": ""^9.17.1"",
    ""html-entities"": ""^1.2.1"",
    ""html-minifier"": ""^3.5.15"",
    ""image-data-uri"": ""^2.0.0"",
    ""image-type"": ""^3.0.0"",
    ""joplin-turndown"": ""^4.0.19"",
    ""joplin-turndown-plugin-gfm"": ""^1.0.12"",
    ""json-stringify-safe"": ""^5.0.1"",
    ""jssha"": ""^2.3.0"",
    ""katex"": ""^0.11.1"",
    ""levenshtein"": ""^1.0.5"",
    ""markdown-it"": ""^10.0.0"",
    ""markdown-it-abbr"": ""^1.0.4"",
    ""markdown-it-anchor"": ""^5.2.5"",
    ""markdown-it-deflist"": ""^2.0.3"",
    ""markdown-it-emoji"": ""^1.4.0"",
    ""markdown-it-expand-tabs"": ""^1.0.13"",
    ""markdown-it-footnote"": ""^3.0.2"",
    ""markdown-it-ins"": ""^3.0.0"",
    ""markdown-it-mark"": ""^3.0.0"",
    ""markdown-it-multimd-table"": ""^4.0.1"",
    ""markdown-it-sub"": ""^1.0.0"",
    ""markdown-it-sup"": ""^1.0.0"",
    ""markdown-it-toc-done-right"": ""^4.1.0"",
    ""md5"": ""^2.2.1"",
    ""md5-file"": ""^4.0.0"",
    ""mime"": ""^2.0.3"",
    ""moment"": ""^2.24.0"",
    ""multiparty"": ""^4.2.1"",
    ""node-emoji"": ""^1.8.1"",
    ""node-fetch"": ""^1.7.1"",
    ""node-persist"": ""^2.1.0"",
    ""patch-package"": ""^6.2.0"",
    ""promise"": ""^7.1.1"",
    ""proper-lockfile"": ""^2.0.1"",
    ""query-string"": ""4.3.4"",
    ""read-chunk"": ""^2.1.0"",
    ""redux"": ""^3.7.2"",
    ""request"": ""^2.88.0"",
    ""sax"": ""^1.2.4"",
    ""server-destroy"": ""^1.0.1"",
    ""sharp"": ""^0.23.2"",
    ""sprintf-js"": ""^1.1.1"",
    ""sqlite3"": ""^4.1.1"",
    ""string-padding"": ""^1.0.2"",
    ""string-to-stream"": ""^1.1.0"",
    ""strip-ansi"": ""^4.0.0"",
    ""syswide-cas"": ""^5.2.0"",
    ""tar"": ""^4.4.10"",
    ""tcp-port-used"": ""^0.1.2"",
    ""terminal-kit"": ""^1.30.0"",
    ""tkwidgets"": ""^0.5.26"",
    ""url-parse"": ""^1.4.7"",
    ""uslug"": ""^1.0.4"",
    ""uuid"": ""^3.0.1"",
    ""valid-url"": ""^1.0.9"",
    ""word-wrap"": ""^1.2.3"",
    ""xml2js"": ""^0.4.19"",
    ""yargs-parser"": ""^7.0.0""
  },
  ""devDependencies"": {
    ""jasmine"": ""^3.5.0""
  }
}
",CWE-79,113.0,1
"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2016-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

""""""A request interceptor taking care of adblocking and custom headers.""""""

from PyQt5.QtWebEngineCore import (QWebEngineUrlRequestInterceptor,
                                   QWebEngineUrlRequestInfo)

from qutebrowser.config import config
from qutebrowser.browser import shared
from qutebrowser.utils import utils, log, debug


class RequestInterceptor(QWebEngineUrlRequestInterceptor):

    """"""Handle ad blocking and custom headers.""""""

    def __init__(self, host_blocker, args, parent=None):
        super().__init__(parent)
        self._host_blocker = host_blocker
        self._args = args

    def install(self, profile):
        """"""Install the interceptor on the given QWebEngineProfile.""""""
        profile.setRequestInterceptor(self)

    # Gets called in the IO thread -> showing crash window will fail
    @utils.prevent_exceptions(None)
    def interceptRequest(self, info):
        """"""Handle the given request.

        Reimplementing this virtual function and setting the interceptor on a
        profile makes it possible to intercept URL requests. This function is
        executed on the IO thread, and therefore running long tasks here will
        block networking.

        info contains the information about the URL request and will track
        internally whether its members have been altered.

        Args:
            info: QWebEngineUrlRequestInfo &info
        """"""
        if 'log-requests' in self._args.debug_flags:
            resource_type = debug.qenum_key(QWebEngineUrlRequestInfo,
                                            info.resourceType())
            navigation_type = debug.qenum_key(QWebEngineUrlRequestInfo,
                                              info.navigationType())
            log.webview.debug(""{} {}, first-party {}, resource {}, ""
                              ""navigation {}"".format(
                                  bytes(info.requestMethod()).decode('ascii'),
                                  info.requestUrl().toDisplayString(),
                                  info.firstPartyUrl().toDisplayString(),
                                  resource_type, navigation_type))

        url = info.requestUrl()

        # FIXME:qtwebengine only block ads for NavigationTypeOther?
        if self._host_blocker.is_blocked(url):
            log.webview.info(""Request to {} blocked by host blocker."".format(
                url.host()))
            info.block(True)

        for header, value in shared.custom_headers(url=url):
            info.setHttpHeader(header, value)

        user_agent = config.instance.get('content.headers.user_agent', url=url)
        if user_agent is not None:
            info.setHttpHeader(b'User-Agent', user_agent.encode('ascii'))
",CWE-352,85.0,1
"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2016-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

""""""QtWebEngine specific qute://* handlers and glue code.""""""

from PyQt5.QtCore import QBuffer, QIODevice
from PyQt5.QtWebEngineCore import (QWebEngineUrlSchemeHandler,
                                   QWebEngineUrlRequestJob)

from qutebrowser.browser import qutescheme
from qutebrowser.utils import log, qtutils


class QuteSchemeHandler(QWebEngineUrlSchemeHandler):

    """"""Handle qute://* requests on QtWebEngine.""""""

    def install(self, profile):
        """"""Install the handler for qute:// URLs on the given profile.""""""
        profile.installUrlSchemeHandler(b'qute', self)
        if qtutils.version_check('5.11', compiled=False):
            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-63378
            profile.installUrlSchemeHandler(b'chrome-error', self)
            profile.installUrlSchemeHandler(b'chrome-extension', self)

    def requestStarted(self, job):
        """"""Handle a request for a qute: scheme.

        This method must be reimplemented by all custom URL scheme handlers.
        The request is asynchronous and does not need to be handled right away.

        Args:
            job: QWebEngineUrlRequestJob
        """"""
        url = job.requestUrl()

        if url.scheme() in ['chrome-error', 'chrome-extension']:
            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-63378
            job.fail(QWebEngineUrlRequestJob.UrlInvalid)
            return

        assert job.requestMethod() == b'GET'
        assert url.scheme() == 'qute'
        log.misc.debug(""Got request for {}"".format(url.toDisplayString()))
        try:
            mimetype, data = qutescheme.data_for_url(url)
        except qutescheme.NoHandlerFound:
            log.misc.debug(""No handler found for {}"".format(
                url.toDisplayString()))
            job.fail(QWebEngineUrlRequestJob.UrlNotFound)
        except qutescheme.QuteSchemeOSError:
            # FIXME:qtwebengine how do we show a better error here?
            log.misc.exception(""OSError while handling qute://* URL"")
            job.fail(QWebEngineUrlRequestJob.UrlNotFound)
        except qutescheme.QuteSchemeError:
            # FIXME:qtwebengine how do we show a better error here?
            log.misc.exception(""Error while handling qute://* URL"")
            job.fail(QWebEngineUrlRequestJob.RequestFailed)
        except qutescheme.Redirect as e:
            qtutils.ensure_valid(e.url)
            job.redirect(e.url)
        else:
            log.misc.debug(""Returning {} data"".format(mimetype))

            # We can't just use the QBuffer constructor taking a QByteArray,
            # because that somehow segfaults...
            # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html
            buf = QBuffer(parent=self)
            buf.open(QIODevice.WriteOnly)
            buf.write(data)
            buf.seek(0)
            buf.close()
            job.reply(mimetype.encode('ascii'), buf)
",CWE-352,90.0,1
"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2014-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
# Copyright 2015-2018 Antoni Boucher (antoyo) <bouanto@zoho.com>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.
#
# pylint complains when using .render() on jinja templates, so we make it shut
# up for this whole module.

""""""Handler functions for file:... pages.""""""

import os

from qutebrowser.browser.webkit.network import networkreply
from qutebrowser.utils import jinja


def get_file_list(basedir, all_files, filterfunc):
    """"""Get a list of files filtered by a filter function and sorted by name.

    Args:
        basedir: The parent directory of all files.
        all_files: The list of files to filter and sort.
        filterfunc: The filter function.

    Return:
        A list of dicts. Each dict contains the name and absname keys.
    """"""
    items = []
    for filename in all_files:
        absname = os.path.join(basedir, filename)
        if filterfunc(absname):
            items.append({'name': filename, 'absname': absname})
    return sorted(items, key=lambda v: v['name'].lower())


def is_root(directory):
    """"""Check if the directory is the root directory.

    Args:
        directory: The directory to check.

    Return:
        Whether the directory is a root directory or not.
    """"""
    # If you're curious as why this works:
    # dirname('/') = '/'
    # dirname('/home') = '/'
    # dirname('/home/') = '/home'
    # dirname('/home/foo') = '/home'
    # basically, for files (no trailing slash) it removes the file part, and
    # for directories, it removes the trailing slash, so the only way for this
    # to be equal is if the directory is the root directory.
    return os.path.dirname(directory) == directory


def parent_dir(directory):
    """"""Return the parent directory for the given directory.

    Args:
        directory: The path to the directory.

    Return:
        The path to the parent directory.
    """"""
    return os.path.normpath(os.path.join(directory, os.pardir))


def dirbrowser_html(path):
    """"""Get the directory browser web page.

    Args:
        path: The directory path.

    Return:
        The HTML of the web page.
    """"""
    title = ""Browse directory: {}"".format(path)

    if is_root(path):
        parent = None
    else:
        parent = parent_dir(path)

    try:
        all_files = os.listdir(path)
    except OSError as e:
        html = jinja.render('error.html',
                            title=""Error while reading directory"",
                            url='file:///{}'.format(path), error=str(e))
        return html.encode('UTF-8', errors='xmlcharrefreplace')

    files = get_file_list(path, all_files, os.path.isfile)
    directories = get_file_list(path, all_files, os.path.isdir)
    html = jinja.render('dirbrowser.html', title=title, url=path,
                        parent=parent, files=files, directories=directories)
    return html.encode('UTF-8', errors='xmlcharrefreplace')


def handler(request):
    """"""Handler for a file:// URL.

    Args:
        request: QNetworkRequest to answer to.

    Return:
        A QNetworkReply for directories, None for files.
    """"""
    path = request.url().toLocalFile()
    try:
        if os.path.isdir(path):
            data = dirbrowser_html(path)
            return networkreply.FixedDataNetworkReply(
                request, data, 'text/html')
        return None
    except UnicodeEncodeError:
        return None
",CWE-352,132.0,1
"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2014-2018 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.

""""""QtWebKit specific qute://* handlers and glue code.""""""

import mimetypes

from PyQt5.QtNetwork import QNetworkReply

from qutebrowser.browser import pdfjs, qutescheme
from qutebrowser.browser.webkit.network import networkreply
from qutebrowser.utils import log, usertypes, qtutils


def handler(request):
    """"""Scheme handler for qute:// URLs.

    Args:
        request: QNetworkRequest to answer to.

    Return:
        A QNetworkReply.
    """"""
    try:
        mimetype, data = qutescheme.data_for_url(request.url())
    except qutescheme.NoHandlerFound:
        errorstr = ""No handler found for {}!"".format(
            request.url().toDisplayString())
        return networkreply.ErrorNetworkReply(
            request, errorstr, QNetworkReply.ContentNotFoundError)
    except qutescheme.QuteSchemeOSError as e:
        return networkreply.ErrorNetworkReply(
            request, str(e), QNetworkReply.ContentNotFoundError)
    except qutescheme.QuteSchemeError as e:
        return networkreply.ErrorNetworkReply(request, e.errorstring, e.error)
    except qutescheme.Redirect as e:
        qtutils.ensure_valid(e.url)
        return networkreply.RedirectNetworkReply(e.url)

    return networkreply.FixedDataNetworkReply(request, data, mimetype)


@qutescheme.add_handler('pdfjs', backend=usertypes.Backend.QtWebKit)
def qute_pdfjs(url):
    """"""Handler for qute://pdfjs. Return the pdf.js viewer.""""""
    try:
        data = pdfjs.get_pdfjs_res(url.path())
    except pdfjs.PDFJSNotFound as e:
        # Logging as the error might get lost otherwise since we're not showing
        # the error page if a single asset is missing. This way we don't lose
        # information, as the failed pdfjs requests are still in the log.
        log.misc.warning(
            ""pdfjs resource requested but not found: {}"".format(e.path))
        raise qutescheme.QuteSchemeError(""Can't find pdfjs resource ""
                                         ""'{}'"".format(e.path),
                                         QNetworkReply.ContentNotFoundError)
    else:
        mimetype, _encoding = mimetypes.guess_type(url.fileName())
        assert mimetype is not None, url
        return mimetype, data
",CWE-352,77.0,1
"# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:

# Copyright 2020-2021 Florian Bruhin (The Compiler) <mail@qutebrowser.org>
#
# This file is part of qutebrowser.
#
# qutebrowser is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# qutebrowser is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with qutebrowser.  If not, see <https://www.gnu.org/licenses/>.

""""""Tests for qutebrowser.qutebrowser.

(Mainly commandline flag parsing)
""""""

import pytest

from qutebrowser import qutebrowser


@pytest.fixture
def parser():
    return qutebrowser.get_argparser()


class TestDebugFlag:

    def test_valid(self, parser):
        args = parser.parse_args(['--debug-flag', 'chromium',
                                  '--debug-flag', 'stack'])
        assert args.debug_flags == ['chromium', 'stack']

    def test_invalid(self, parser, capsys):
        with pytest.raises(SystemExit):
            parser.parse_args(['--debug-flag', 'invalid'])

        _out, err = capsys.readouterr()
        assert 'Invalid debug flag - valid flags:' in err


class TestLogFilter:

    def test_valid(self, parser):
        args = parser.parse_args(['--logfilter', 'misc'])
        assert args.logfilter == 'misc'

    def test_invalid(self, parser, capsys):
        with pytest.raises(SystemExit):
            parser.parse_args(['--logfilter', 'invalid'])

        _out, err = capsys.readouterr()
        print(err)
        assert 'Invalid log category invalid - valid categories' in err


class TestJsonArgs:

    def test_partial(self, parser):
        """"""Make sure we can provide a subset of all arguments.

        This ensures that it's possible to restart into an older version of qutebrowser
        when a new argument was added.
        """"""
        args = parser.parse_args(['--json-args', '{""debug"": true}'])
        args = qutebrowser._unpack_json_args(args)
        # pylint: disable=no-member
        assert args.debug
        assert not args.temp_basedir
",CWE-77,78.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) Jean-Paul Calderone 2008-2015, All rights reserved
#

""""""
Installation script for the OpenSSL package.
""""""

import codecs
import os
import re

from setuptools import setup, find_packages


HERE = os.path.abspath(os.path.dirname(__file__))
META_PATH = os.path.join(""src"", ""OpenSSL"", ""version.py"")


def read_file(*parts):
    """"""
    Build an absolute path from *parts* and and return the contents of the
    resulting file.  Assume UTF-8 encoding.
    """"""
    with codecs.open(os.path.join(HERE, *parts), ""rb"", ""ascii"") as f:
        return f.read()


META_FILE = read_file(META_PATH)


def find_meta(meta):
    """"""
    Extract __*meta*__ from META_FILE.
    """"""
    meta_match = re.search(
        r""^__{meta}__ = ['\""]([^'\""]*)['\""]"".format(meta=meta),
        META_FILE, re.M
    )
    if meta_match:
        return meta_match.group(1)
    raise RuntimeError(""Unable to find __{meta}__ string."".format(meta=meta))


URI = find_meta(""uri"")
LONG = (
    read_file(""README.rst"") + ""\n\n"" +
    ""Release Information\n"" +
    ""===================\n\n"" +
    re.search(""(\d{2}.\d.\d \(.*?\)\n.*?)\n\n\n----\n"",
              read_file(""CHANGELOG.rst""), re.S).group(1) +
    ""\n\n`Full changelog "" +
    ""<{uri}en/stable/changelog.html>`_.\n\n""
).format(uri=URI)


if __name__ == ""__main__"":
    setup(
        name=find_meta(""title""),
        version=find_meta(""version""),
        description=find_meta(""summary""),
        long_description=LONG,
        author=find_meta(""author""),
        author_email=find_meta(""email""),
        maintainer=""Hynek Schlawack"",
        maintainer_email=""hs@ox.cx"",
        url=URI,
        license=find_meta(""license""),
        classifiers=[
            'Development Status :: 6 - Mature',
            'Intended Audience :: Developers',
            'License :: OSI Approved :: Apache Software License',
            'Operating System :: MacOS :: MacOS X',
            'Operating System :: Microsoft :: Windows',
            'Operating System :: POSIX',

            'Programming Language :: Python :: 2',
            'Programming Language :: Python :: 2.6',
            'Programming Language :: Python :: 2.7',
            'Programming Language :: Python :: 3',
            'Programming Language :: Python :: 3.4',
            'Programming Language :: Python :: 3.5',
            'Programming Language :: Python :: 3.6',

            'Programming Language :: Python :: Implementation :: CPython',
            'Programming Language :: Python :: Implementation :: PyPy',
            'Topic :: Security :: Cryptography',
            'Topic :: Software Development :: Libraries :: Python Modules',
            'Topic :: System :: Networking',
        ],

        packages=find_packages(where=""src""),
        package_dir={"""": ""src""},
        install_requires=[
            # Fix cryptographyMinimum in tox.ini when changing this!
            ""cryptography>=1.9"",
            ""six>=1.5.2""
        ],
        extras_require={
            ""test"": [
                ""flaky"",
                ""pretend"",
                # pytest 3.3 doesn't support Python 2.6 anymore.
                # Remove this pin once we drop Python 2.6 too.
                ""pytest>=3.0.1,<3.3.0"",
            ],
            ""docs"": [
                ""sphinx"",
                ""sphinx_rtd_theme"",
            ]
        },
    )
",CWE-416,115.0,1
"# -*- coding: utf-8 -*-
# Copyright 2014-2016 OpenMarket Ltd
# Copyright 2017 Vector Creations Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Contains constants from the specification.""""""


class Membership(object):

    """"""Represents the membership states of a user in a room.""""""
    INVITE = u""invite""
    JOIN = u""join""
    KNOCK = u""knock""
    LEAVE = u""leave""
    BAN = u""ban""
    LIST = (INVITE, JOIN, KNOCK, LEAVE, BAN)


class PresenceState(object):
    """"""Represents the presence state of a user.""""""
    OFFLINE = u""offline""
    UNAVAILABLE = u""unavailable""
    ONLINE = u""online""


class JoinRules(object):
    PUBLIC = u""public""
    KNOCK = u""knock""
    INVITE = u""invite""
    PRIVATE = u""private""


class LoginType(object):
    PASSWORD = u""m.login.password""
    EMAIL_IDENTITY = u""m.login.email.identity""
    MSISDN = u""m.login.msisdn""
    RECAPTCHA = u""m.login.recaptcha""
    DUMMY = u""m.login.dummy""

    # Only for C/S API v1
    APPLICATION_SERVICE = u""m.login.application_service""
    SHARED_SECRET = u""org.matrix.login.shared_secret""


class EventTypes(object):
    Member = ""m.room.member""
    Create = ""m.room.create""
    JoinRules = ""m.room.join_rules""
    PowerLevels = ""m.room.power_levels""
    Aliases = ""m.room.aliases""
    Redaction = ""m.room.redaction""
    ThirdPartyInvite = ""m.room.third_party_invite""

    RoomHistoryVisibility = ""m.room.history_visibility""
    CanonicalAlias = ""m.room.canonical_alias""
    RoomAvatar = ""m.room.avatar""
    GuestAccess = ""m.room.guest_access""

    # These are used for validation
    Message = ""m.room.message""
    Topic = ""m.room.topic""
    Name = ""m.room.name""


class RejectedReason(object):
    AUTH_ERROR = ""auth_error""
    REPLACED = ""replaced""
    NOT_ANCESTOR = ""not_ancestor""


class RoomCreationPreset(object):
    PRIVATE_CHAT = ""private_chat""
    PUBLIC_CHAT = ""public_chat""
    TRUSTED_PRIVATE_CHAT = ""trusted_private_chat""


class ThirdPartyEntityKind(object):
    USER = ""user""
    LOCATION = ""location""
",CWE-20,92.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Optional

from netaddr import IPSet

from synapse.config._base import Config, ConfigError
from synapse.config._util import validate_config


class FederationConfig(Config):
    section = ""federation""

    def read_config(self, config, **kwargs):
        # FIXME: federation_domain_whitelist needs sytests
        self.federation_domain_whitelist = None  # type: Optional[dict]
        federation_domain_whitelist = config.get(""federation_domain_whitelist"", None)

        if federation_domain_whitelist is not None:
            # turn the whitelist into a hash for speed of lookup
            self.federation_domain_whitelist = {}

            for domain in federation_domain_whitelist:
                self.federation_domain_whitelist[domain] = True

        self.federation_ip_range_blacklist = config.get(
            ""federation_ip_range_blacklist"", []
        )

        # Attempt to create an IPSet from the given ranges
        try:
            self.federation_ip_range_blacklist = IPSet(
                self.federation_ip_range_blacklist
            )

            # Always blacklist 0.0.0.0, ::
            self.federation_ip_range_blacklist.update([""0.0.0.0"", ""::""])
        except Exception as e:
            raise ConfigError(
                ""Invalid range(s) provided in federation_ip_range_blacklist: %s"" % e
            )

        federation_metrics_domains = config.get(""federation_metrics_domains"") or []
        validate_config(
            _METRICS_FOR_DOMAINS_SCHEMA,
            federation_metrics_domains,
            (""federation_metrics_domains"",),
        )
        self.federation_metrics_domains = set(federation_metrics_domains)

    def generate_config_section(self, config_dir_path, server_name, **kwargs):
        return """"""\
        ## Federation ##

        # Restrict federation to the following whitelist of domains.
        # N.B. we recommend also firewalling your federation listener to limit
        # inbound federation traffic as early as possible, rather than relying
        # purely on this application-layer restriction.  If not specified, the
        # default is to whitelist everything.
        #
        #federation_domain_whitelist:
        #  - lon.example.com
        #  - nyc.example.com
        #  - syd.example.com

        # Prevent federation requests from being sent to the following
        # blacklist IP address CIDR ranges. If this option is not specified, or
        # specified with an empty list, no ip range blacklist will be enforced.
        #
        # As of Synapse v1.4.0 this option also affects any outbound requests to identity
        # servers provided by user input.
        #
        # (0.0.0.0 and :: are always blacklisted, whether or not they are explicitly
        # listed here, since they correspond to unroutable addresses.)
        #
        federation_ip_range_blacklist:
          - '127.0.0.0/8'
          - '10.0.0.0/8'
          - '172.16.0.0/12'
          - '192.168.0.0/16'
          - '100.64.0.0/10'
          - '169.254.0.0/16'
          - '::1/128'
          - 'fe80::/64'
          - 'fc00::/7'

        # Report prometheus metrics on the age of PDUs being sent to and received from
        # the following domains. This can be used to give an idea of ""delay"" on inbound
        # and outbound federation, though be aware that any delay can be due to problems
        # at either end or with the intermediate network.
        #
        # By default, no domains are monitored in this way.
        #
        #federation_metrics_domains:
        #  - matrix.org
        #  - example.com
        """"""


_METRICS_FOR_DOMAINS_SCHEMA = {""type"": ""array"", ""items"": {""type"": ""string""}}
",CWE-601,114.0,1
"# -*- coding: utf-8 -*-
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from synapse.app.generic_worker import GenericWorkerServer

from tests.server import make_request
from tests.unittest import HomeserverTestCase


class FrontendProxyTests(HomeserverTestCase):
    def make_homeserver(self, reactor, clock):

        hs = self.setup_test_homeserver(
            http_client=None, homeserver_to_use=GenericWorkerServer
        )

        return hs

    def default_config(self):
        c = super().default_config()
        c[""worker_app""] = ""synapse.app.frontend_proxy""

        c[""worker_listeners""] = [
            {
                ""type"": ""http"",
                ""port"": 8080,
                ""bind_addresses"": [""0.0.0.0""],
                ""resources"": [{""names"": [""client""]}],
            }
        ]

        return c

    def test_listen_http_with_presence_enabled(self):
        """"""
        When presence is on, the stub servlet will not register.
        """"""
        # Presence is on
        self.hs.config.use_presence = True

        # Listen with the config
        self.hs._listen_http(self.hs.config.worker.worker_listeners[0])

        # Grab the resource from the site that was told to listen
        self.assertEqual(len(self.reactor.tcpServers), 1)
        site = self.reactor.tcpServers[0][1]

        _, channel = make_request(self.reactor, site, ""PUT"", ""presence/a/status"")

        # 400 + unrecognised, because nothing is registered
        self.assertEqual(channel.code, 400)
        self.assertEqual(channel.json_body[""errcode""], ""M_UNRECOGNIZED"")

    def test_listen_http_with_presence_disabled(self):
        """"""
        When presence is off, the stub servlet will register.
        """"""
        # Presence is off
        self.hs.config.use_presence = False

        # Listen with the config
        self.hs._listen_http(self.hs.config.worker.worker_listeners[0])

        # Grab the resource from the site that was told to listen
        self.assertEqual(len(self.reactor.tcpServers), 1)
        site = self.reactor.tcpServers[0][1]

        _, channel = make_request(self.reactor, site, ""PUT"", ""presence/a/status"")

        # 401, because the stub servlet still checks authentication
        self.assertEqual(channel.code, 401)
        self.assertEqual(channel.json_body[""errcode""], ""M_MISSING_TOKEN"")
",CWE-601,85.0,1
"# -*- coding: utf-8 -*-
# Copyright 2019 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from mock import Mock, patch

from parameterized import parameterized

from synapse.app.generic_worker import GenericWorkerServer
from synapse.app.homeserver import SynapseHomeServer
from synapse.config.server import parse_listener_def

from tests.server import make_request
from tests.unittest import HomeserverTestCase


class FederationReaderOpenIDListenerTests(HomeserverTestCase):
    def make_homeserver(self, reactor, clock):
        hs = self.setup_test_homeserver(
            http_client=None, homeserver_to_use=GenericWorkerServer
        )
        return hs

    def default_config(self):
        conf = super().default_config()
        # we're using FederationReaderServer, which uses a SlavedStore, so we
        # have to tell the FederationHandler not to try to access stuff that is only
        # in the primary store.
        conf[""worker_app""] = ""yes""

        return conf

    @parameterized.expand(
        [
            ([""federation""], ""auth_fail""),
            ([], ""no_resource""),
            ([""openid"", ""federation""], ""auth_fail""),
            ([""openid""], ""auth_fail""),
        ]
    )
    def test_openid_listener(self, names, expectation):
        """"""
        Test different openid listener configurations.

        401 is success here since it means we hit the handler and auth failed.
        """"""
        config = {
            ""port"": 8080,
            ""type"": ""http"",
            ""bind_addresses"": [""0.0.0.0""],
            ""resources"": [{""names"": names}],
        }

        # Listen with the config
        self.hs._listen_http(parse_listener_def(config))

        # Grab the resource from the site that was told to listen
        site = self.reactor.tcpServers[0][1]
        try:
            site.resource.children[b""_matrix""].children[b""federation""]
        except KeyError:
            if expectation == ""no_resource"":
                return
            raise

        _, channel = make_request(
            self.reactor, site, ""GET"", ""/_matrix/federation/v1/openid/userinfo""
        )

        self.assertEqual(channel.code, 401)


@patch(""synapse.app.homeserver.KeyApiV2Resource"", new=Mock())
class SynapseHomeserverOpenIDListenerTests(HomeserverTestCase):
    def make_homeserver(self, reactor, clock):
        hs = self.setup_test_homeserver(
            http_client=None, homeserver_to_use=SynapseHomeServer
        )
        return hs

    @parameterized.expand(
        [
            ([""federation""], ""auth_fail""),
            ([], ""no_resource""),
            ([""openid"", ""federation""], ""auth_fail""),
            ([""openid""], ""auth_fail""),
        ]
    )
    def test_openid_listener(self, names, expectation):
        """"""
        Test different openid listener configurations.

        401 is success here since it means we hit the handler and auth failed.
        """"""
        config = {
            ""port"": 8080,
            ""type"": ""http"",
            ""bind_addresses"": [""0.0.0.0""],
            ""resources"": [{""names"": names}],
        }

        # Listen with the config
        self.hs._listener_http(self.hs.get_config(), parse_listener_def(config))

        # Grab the resource from the site that was told to listen
        site = self.reactor.tcpServers[0][1]
        try:
            site.resource.children[b""_matrix""].children[b""federation""]
        except KeyError:
            if expectation == ""no_resource"":
                return
            raise

        _, channel = make_request(
            self.reactor, site, ""GET"", ""/_matrix/federation/v1/openid/userinfo""
        )

        self.assertEqual(channel.code, 401)
",CWE-601,129.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import logging

from mock import Mock

from twisted.internet import defer

from synapse.rest import admin
from synapse.rest.client.v1 import login, room

from tests.replication._base import BaseMultiWorkerStreamTestCase

logger = logging.getLogger(__name__)


class PusherShardTestCase(BaseMultiWorkerStreamTestCase):
    """"""Checks pusher sharding works
    """"""

    servlets = [
        admin.register_servlets_for_client_rest_resource,
        room.register_servlets,
        login.register_servlets,
    ]

    def prepare(self, reactor, clock, hs):
        # Register a user who sends a message that we'll get notified about
        self.other_user_id = self.register_user(""otheruser"", ""pass"")
        self.other_access_token = self.login(""otheruser"", ""pass"")

    def default_config(self):
        conf = super().default_config()
        conf[""start_pushers""] = False
        return conf

    def _create_pusher_and_send_msg(self, localpart):
        # Create a user that will get push notifications
        user_id = self.register_user(localpart, ""pass"")
        access_token = self.login(localpart, ""pass"")

        # Register a pusher
        user_dict = self.get_success(
            self.hs.get_datastore().get_user_by_access_token(access_token)
        )
        token_id = user_dict.token_id

        self.get_success(
            self.hs.get_pusherpool().add_pusher(
                user_id=user_id,
                access_token=token_id,
                kind=""http"",
                app_id=""m.http"",
                app_display_name=""HTTP Push Notifications"",
                device_display_name=""pushy push"",
                pushkey=""a@example.com"",
                lang=None,
                data={""url"": ""https://push.example.com/push""},
            )
        )

        self.pump()

        # Create a room
        room = self.helper.create_room_as(user_id, tok=access_token)

        # The other user joins
        self.helper.join(
            room=room, user=self.other_user_id, tok=self.other_access_token
        )

        # The other user sends some messages
        response = self.helper.send(room, body=""Hi!"", tok=self.other_access_token)
        event_id = response[""event_id""]

        return event_id

    def test_send_push_single_worker(self):
        """"""Test that registration works when using a pusher worker.
        """"""
        http_client_mock = Mock(spec_set=[""post_json_get_json""])
        http_client_mock.post_json_get_json.side_effect = lambda *_, **__: defer.succeed(
            {}
        )

        self.make_worker_hs(
            ""synapse.app.pusher"",
            {""start_pushers"": True},
            proxied_http_client=http_client_mock,
        )

        event_id = self._create_pusher_and_send_msg(""user"")

        # Advance time a bit, so the pusher will register something has happened
        self.pump()

        http_client_mock.post_json_get_json.assert_called_once()
        self.assertEqual(
            http_client_mock.post_json_get_json.call_args[0][0],
            ""https://push.example.com/push"",
        )
        self.assertEqual(
            event_id,
            http_client_mock.post_json_get_json.call_args[0][1][""notification""][
                ""event_id""
            ],
        )

    def test_send_push_multiple_workers(self):
        """"""Test that registration works when using sharded pusher workers.
        """"""
        http_client_mock1 = Mock(spec_set=[""post_json_get_json""])
        http_client_mock1.post_json_get_json.side_effect = lambda *_, **__: defer.succeed(
            {}
        )

        self.make_worker_hs(
            ""synapse.app.pusher"",
            {
                ""start_pushers"": True,
                ""worker_name"": ""pusher1"",
                ""pusher_instances"": [""pusher1"", ""pusher2""],
            },
            proxied_http_client=http_client_mock1,
        )

        http_client_mock2 = Mock(spec_set=[""post_json_get_json""])
        http_client_mock2.post_json_get_json.side_effect = lambda *_, **__: defer.succeed(
            {}
        )

        self.make_worker_hs(
            ""synapse.app.pusher"",
            {
                ""start_pushers"": True,
                ""worker_name"": ""pusher2"",
                ""pusher_instances"": [""pusher1"", ""pusher2""],
            },
            proxied_http_client=http_client_mock2,
        )

        # We choose a user name that we know should go to pusher1.
        event_id = self._create_pusher_and_send_msg(""user2"")

        # Advance time a bit, so the pusher will register something has happened
        self.pump()

        http_client_mock1.post_json_get_json.assert_called_once()
        http_client_mock2.post_json_get_json.assert_not_called()
        self.assertEqual(
            http_client_mock1.post_json_get_json.call_args[0][0],
            ""https://push.example.com/push"",
        )
        self.assertEqual(
            event_id,
            http_client_mock1.post_json_get_json.call_args[0][1][""notification""][
                ""event_id""
            ],
        )

        http_client_mock1.post_json_get_json.reset_mock()
        http_client_mock2.post_json_get_json.reset_mock()

        # Now we choose a user name that we know should go to pusher2.
        event_id = self._create_pusher_and_send_msg(""user4"")

        # Advance time a bit, so the pusher will register something has happened
        self.pump()

        http_client_mock1.post_json_get_json.assert_not_called()
        http_client_mock2.post_json_get_json.assert_called_once()
        self.assertEqual(
            http_client_mock2.post_json_get_json.call_args[0][0],
            ""https://push.example.com/push"",
        )
        self.assertEqual(
            event_id,
            http_client_mock2.post_json_get_json.call_args[0][1][""notification""][
                ""event_id""
            ],
        )
",CWE-601,194.0,1
"# -*- coding: utf-8 -*-
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from mock import Mock

from twisted.internet import defer

from synapse.rest.client.v1 import presence
from synapse.types import UserID

from tests import unittest


class PresenceTestCase(unittest.HomeserverTestCase):
    """""" Tests presence REST API. """"""

    user_id = ""@sid:red""

    user = UserID.from_string(user_id)
    servlets = [presence.register_servlets]

    def make_homeserver(self, reactor, clock):

        presence_handler = Mock()
        presence_handler.set_state.return_value = defer.succeed(None)

        hs = self.setup_test_homeserver(
            ""red"",
            http_client=None,
            federation_client=Mock(),
            presence_handler=presence_handler,
        )

        return hs

    def test_put_presence(self):
        """"""
        PUT to the status endpoint with use_presence enabled will call
        set_state on the presence handler.
        """"""
        self.hs.config.use_presence = True

        body = {""presence"": ""here"", ""status_msg"": ""beep boop""}
        request, channel = self.make_request(
            ""PUT"", ""/presence/%s/status"" % (self.user_id,), body
        )

        self.assertEqual(channel.code, 200)
        self.assertEqual(self.hs.get_presence_handler().set_state.call_count, 1)

    def test_put_presence_disabled(self):
        """"""
        PUT to the status endpoint with use_presence disabled will NOT call
        set_state on the presence handler.
        """"""
        self.hs.config.use_presence = False

        body = {""presence"": ""here"", ""status_msg"": ""beep boop""}
        request, channel = self.make_request(
            ""PUT"", ""/presence/%s/status"" % (self.user_id,), body
        )

        self.assertEqual(channel.code, 200)
        self.assertEqual(self.hs.get_presence_handler().set_state.call_count, 0)
",CWE-601,77.0,1
"# -*- coding: utf-8 -*-
# Copyright 2014-2016 OpenMarket Ltd
# Copyright 2018 New Vector
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Tests REST events for /rooms paths.""""""

from mock import Mock

from twisted.internet import defer

from synapse.rest.client.v1 import room
from synapse.types import UserID

from tests import unittest

PATH_PREFIX = ""/_matrix/client/api/v1""


class RoomTypingTestCase(unittest.HomeserverTestCase):
    """""" Tests /rooms/$room_id/typing/$user_id REST API. """"""

    user_id = ""@sid:red""

    user = UserID.from_string(user_id)
    servlets = [room.register_servlets]

    def make_homeserver(self, reactor, clock):

        hs = self.setup_test_homeserver(
            ""red"", http_client=None, federation_client=Mock(),
        )

        self.event_source = hs.get_event_sources().sources[""typing""]

        hs.get_federation_handler = Mock()

        async def get_user_by_access_token(token=None, allow_guest=False):
            return {
                ""user"": UserID.from_string(self.auth_user_id),
                ""token_id"": 1,
                ""is_guest"": False,
            }

        hs.get_auth().get_user_by_access_token = get_user_by_access_token

        async def _insert_client_ip(*args, **kwargs):
            return None

        hs.get_datastore().insert_client_ip = _insert_client_ip

        def get_room_members(room_id):
            if room_id == self.room_id:
                return defer.succeed([self.user])
            else:
                return defer.succeed([])

        @defer.inlineCallbacks
        def fetch_room_distributions_into(
            room_id, localusers=None, remotedomains=None, ignore_user=None
        ):
            members = yield get_room_members(room_id)
            for member in members:
                if ignore_user is not None and member == ignore_user:
                    continue

                if hs.is_mine(member):
                    if localusers is not None:
                        localusers.add(member)
                else:
                    if remotedomains is not None:
                        remotedomains.add(member.domain)

        hs.get_room_member_handler().fetch_room_distributions_into = (
            fetch_room_distributions_into
        )

        return hs

    def prepare(self, reactor, clock, hs):
        self.room_id = self.helper.create_room_as(self.user_id)
        # Need another user to make notifications actually work
        self.helper.join(self.room_id, user=""@jim:red"")

    def test_set_typing(self):
        request, channel = self.make_request(
            ""PUT"",
            ""/rooms/%s/typing/%s"" % (self.room_id, self.user_id),
            b'{""typing"": true, ""timeout"": 30000}',
        )
        self.assertEquals(200, channel.code)

        self.assertEquals(self.event_source.get_current_key(), 1)
        events = self.get_success(
            self.event_source.get_new_events(from_key=0, room_ids=[self.room_id])
        )
        self.assertEquals(
            events[0],
            [
                {
                    ""type"": ""m.typing"",
                    ""room_id"": self.room_id,
                    ""content"": {""user_ids"": [self.user_id]},
                }
            ],
        )

    def test_set_not_typing(self):
        request, channel = self.make_request(
            ""PUT"",
            ""/rooms/%s/typing/%s"" % (self.room_id, self.user_id),
            b'{""typing"": false}',
        )
        self.assertEquals(200, channel.code)

    def test_typing_timeout(self):
        request, channel = self.make_request(
            ""PUT"",
            ""/rooms/%s/typing/%s"" % (self.room_id, self.user_id),
            b'{""typing"": true, ""timeout"": 30000}',
        )
        self.assertEquals(200, channel.code)

        self.assertEquals(self.event_source.get_current_key(), 1)

        self.reactor.advance(36)

        self.assertEquals(self.event_source.get_current_key(), 2)

        request, channel = self.make_request(
            ""PUT"",
            ""/rooms/%s/typing/%s"" % (self.room_id, self.user_id),
            b'{""typing"": true, ""timeout"": 30000}',
        )
        self.assertEquals(200, channel.code)

        self.assertEquals(self.event_source.get_current_key(), 3)
",CWE-601,149.0,1
"# -*- coding: utf-8 -*-
# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from tests import unittest

# sample room_key data for use in the tests
room_key = {
    ""first_message_index"": 1,
    ""forwarded_count"": 1,
    ""is_verified"": False,
    ""session_data"": ""SSBBTSBBIEZJU0gK"",
}


class E2eRoomKeysHandlerTestCase(unittest.HomeserverTestCase):
    def make_homeserver(self, reactor, clock):
        hs = self.setup_test_homeserver(""server"", http_client=None)
        self.store = hs.get_datastore()
        return hs

    def test_room_keys_version_delete(self):
        # test that deleting a room key backup deletes the keys
        version1 = self.get_success(
            self.store.create_e2e_room_keys_version(
                ""user_id"", {""algorithm"": ""rot13"", ""auth_data"": {}}
            )
        )

        self.get_success(
            self.store.add_e2e_room_keys(
                ""user_id"", version1, [(""room"", ""session"", room_key)]
            )
        )

        version2 = self.get_success(
            self.store.create_e2e_room_keys_version(
                ""user_id"", {""algorithm"": ""rot13"", ""auth_data"": {}}
            )
        )

        self.get_success(
            self.store.add_e2e_room_keys(
                ""user_id"", version2, [(""room"", ""session"", room_key)]
            )
        )

        # make sure the keys were stored properly
        keys = self.get_success(self.store.get_e2e_room_keys(""user_id"", version1))
        self.assertEqual(len(keys[""rooms""]), 1)

        keys = self.get_success(self.store.get_e2e_room_keys(""user_id"", version2))
        self.assertEqual(len(keys[""rooms""]), 1)

        # delete version1
        self.get_success(self.store.delete_e2e_room_keys_version(""user_id"", version1))

        # make sure the key from version1 is gone, and the key from version2 is
        # still there
        keys = self.get_success(self.store.get_e2e_room_keys(""user_id"", version1))
        self.assertEqual(len(keys[""rooms""]), 0)

        keys = self.get_success(self.store.get_e2e_room_keys(""user_id"", version2))
        self.assertEqual(len(keys[""rooms""]), 1)
",CWE-601,76.0,1
"# -*- coding: utf-8 -*-
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from twisted.internet import defer

from synapse.api.errors import NotFoundError
from synapse.rest.client.v1 import room

from tests.unittest import HomeserverTestCase


class PurgeTests(HomeserverTestCase):

    user_id = ""@red:server""
    servlets = [room.register_servlets]

    def make_homeserver(self, reactor, clock):
        hs = self.setup_test_homeserver(""server"", http_client=None)
        return hs

    def prepare(self, reactor, clock, hs):
        self.room_id = self.helper.create_room_as(self.user_id)

    def test_purge(self):
        """"""
        Purging a room will delete everything before the topological point.
        """"""
        # Send four messages to the room
        first = self.helper.send(self.room_id, body=""test1"")
        second = self.helper.send(self.room_id, body=""test2"")
        third = self.helper.send(self.room_id, body=""test3"")
        last = self.helper.send(self.room_id, body=""test4"")

        store = self.hs.get_datastore()
        storage = self.hs.get_storage()

        # Get the topological token
        token = self.get_success(
            store.get_topological_token_for_event(last[""event_id""])
        )
        token_str = self.get_success(token.to_string(self.hs.get_datastore()))

        # Purge everything before this topological token
        self.get_success(
            storage.purge_events.purge_history(self.room_id, token_str, True)
        )

        # 1-3 should fail and last will succeed, meaning that 1-3 are deleted
        # and last is not.
        self.get_failure(store.get_event(first[""event_id""]), NotFoundError)
        self.get_failure(store.get_event(second[""event_id""]), NotFoundError)
        self.get_failure(store.get_event(third[""event_id""]), NotFoundError)
        self.get_success(store.get_event(last[""event_id""]))

    def test_purge_wont_delete_extrems(self):
        """"""
        Purging a room will delete everything before the topological point.
        """"""
        # Send four messages to the room
        first = self.helper.send(self.room_id, body=""test1"")
        second = self.helper.send(self.room_id, body=""test2"")
        third = self.helper.send(self.room_id, body=""test3"")
        last = self.helper.send(self.room_id, body=""test4"")

        storage = self.hs.get_datastore()

        # Set the topological token higher than it should be
        token = self.get_success(
            storage.get_topological_token_for_event(last[""event_id""])
        )
        event = ""t{}-{}"".format(token.topological + 1, token.stream + 1)

        # Purge everything before this topological token
        purge = defer.ensureDeferred(storage.purge_history(self.room_id, event, True))
        self.pump()
        f = self.failureResultOf(purge)
        self.assertIn(""greater than forward"", f.value.args[0])

        # Try and get the events
        self.get_success(storage.get_event(first[""event_id""]))
        self.get_success(storage.get_event(second[""event_id""]))
        self.get_success(storage.get_event(third[""event_id""]))
        self.get_success(storage.get_event(last[""event_id""]))
",CWE-601,96.0,1
"# -*- coding: utf-8 -*-
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from os import path

from synapse.config import ConfigError

from ._base import Config

DEFAULT_CONFIG = """"""\
# User Consent configuration
#
# for detailed instructions, see
# https://github.com/matrix-org/synapse/blob/master/docs/consent_tracking.md
#
# Parts of this section are required if enabling the 'consent' resource under
# 'listeners', in particular 'template_dir' and 'version'.
#
# 'template_dir' gives the location of the templates for the HTML forms.
# This directory should contain one subdirectory per language (eg, 'en', 'fr'),
# and each language directory should contain the policy document (named as
# '<version>.html') and a success page (success.html).
#
# 'version' specifies the 'current' version of the policy document. It defines
# the version to be served by the consent resource if there is no 'v'
# parameter.
#
# 'server_notice_content', if enabled, will send a user a ""Server Notice""
# asking them to consent to the privacy policy. The 'server_notices' section
# must also be configured for this to work. Notices will *not* be sent to
# guest users unless 'send_server_notice_to_guests' is set to true.
#
# 'block_events_error', if set, will block any attempts to send events
# until the user consents to the privacy policy. The value of the setting is
# used as the text of the error.
#
# 'require_at_registration', if enabled, will add a step to the registration
# process, similar to how captcha works. Users will be required to accept the
# policy before their account is created.
#
# 'policy_name' is the display name of the policy users will see when registering
# for an account. Has no effect unless `require_at_registration` is enabled.
# Defaults to ""Privacy Policy"".
#
#user_consent:
#  template_dir: res/templates/privacy
#  version: 1.0
#  server_notice_content:
#    msgtype: m.text
#    body: >-
#      To continue using this homeserver you must review and agree to the
#      terms and conditions at %(consent_uri)s
#  send_server_notice_to_guests: true
#  block_events_error: >-
#    To continue using this homeserver you must review and agree to the
#    terms and conditions at %(consent_uri)s
#  require_at_registration: false
#  policy_name: Privacy Policy
#
""""""


class ConsentConfig(Config):

    section = ""consent""

    def __init__(self, *args):
        super().__init__(*args)

        self.user_consent_version = None
        self.user_consent_template_dir = None
        self.user_consent_server_notice_content = None
        self.user_consent_server_notice_to_guests = False
        self.block_events_without_consent_error = None
        self.user_consent_at_registration = False
        self.user_consent_policy_name = ""Privacy Policy""

    def read_config(self, config, **kwargs):
        consent_config = config.get(""user_consent"")
        self.terms_template = self.read_templates([""terms.html""], autoescape=True)[0]

        if consent_config is None:
            return
        self.user_consent_version = str(consent_config[""version""])
        self.user_consent_template_dir = self.abspath(consent_config[""template_dir""])
        if not path.isdir(self.user_consent_template_dir):
            raise ConfigError(
                ""Could not find template directory '%s'""
                % (self.user_consent_template_dir,)
            )
        self.user_consent_server_notice_content = consent_config.get(
            ""server_notice_content""
        )
        self.block_events_without_consent_error = consent_config.get(
            ""block_events_error""
        )
        self.user_consent_server_notice_to_guests = bool(
            consent_config.get(""send_server_notice_to_guests"", False)
        )
        self.user_consent_at_registration = bool(
            consent_config.get(""require_at_registration"", False)
        )
        self.user_consent_policy_name = consent_config.get(
            ""policy_name"", ""Privacy Policy""
        )

    def generate_config_section(self, **kwargs):
        return DEFAULT_CONFIG
",CWE-79,121.0,1
"# Copyright 2018 New Vector Ltd
# Copyright 2019 Matrix.org Federation C.I.C
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import logging

from parameterized import parameterized

from synapse.events import make_event_from_dict
from synapse.federation.federation_server import server_matches_acl_event
from synapse.rest import admin
from synapse.rest.client.v1 import login, room

from tests import unittest


class FederationServerTests(unittest.FederatingHomeserverTestCase):

    servlets = [
        admin.register_servlets,
        room.register_servlets,
        login.register_servlets,
    ]

    @parameterized.expand([(b"""",), (b""foo"",), (b'{""limit"": Infinity}',)])
    def test_bad_request(self, query_content):
        """"""
        Querying with bad data returns a reasonable error code.
        """"""
        u1 = self.register_user(""u1"", ""pass"")
        u1_token = self.login(""u1"", ""pass"")

        room_1 = self.helper.create_room_as(u1, tok=u1_token)
        self.inject_room_member(room_1, ""@user:other.example.com"", ""join"")

        ""/get_missing_events/(?P<room_id>[^/]*)/?""

        channel = self.make_request(
            ""POST"",
            ""/_matrix/federation/v1/get_missing_events/%s"" % (room_1,),
            query_content,
        )
        self.assertEquals(400, channel.code, channel.result)
        self.assertEqual(channel.json_body[""errcode""], ""M_NOT_JSON"")


class ServerACLsTestCase(unittest.TestCase):
    def test_blacklisted_server(self):
        e = _create_acl_event({""allow"": [""*""], ""deny"": [""evil.com""]})
        logging.info(""ACL event: %s"", e.content)

        self.assertFalse(server_matches_acl_event(""evil.com"", e))
        self.assertFalse(server_matches_acl_event(""EVIL.COM"", e))

        self.assertTrue(server_matches_acl_event(""evil.com.au"", e))
        self.assertTrue(server_matches_acl_event(""honestly.not.evil.com"", e))

    def test_block_ip_literals(self):
        e = _create_acl_event({""allow_ip_literals"": False, ""allow"": [""*""]})
        logging.info(""ACL event: %s"", e.content)

        self.assertFalse(server_matches_acl_event(""1.2.3.4"", e))
        self.assertTrue(server_matches_acl_event(""1a.2.3.4"", e))
        self.assertFalse(server_matches_acl_event(""[1:2::]"", e))
        self.assertTrue(server_matches_acl_event(""1:2:3:4"", e))


class StateQueryTests(unittest.FederatingHomeserverTestCase):

    servlets = [
        admin.register_servlets,
        room.register_servlets,
        login.register_servlets,
    ]

    def test_without_event_id(self):
        """"""
        Querying v1/state/<room_id> without an event ID will return the current
        known state.
        """"""
        u1 = self.register_user(""u1"", ""pass"")
        u1_token = self.login(""u1"", ""pass"")

        room_1 = self.helper.create_room_as(u1, tok=u1_token)
        self.inject_room_member(room_1, ""@user:other.example.com"", ""join"")

        channel = self.make_request(
            ""GET"", ""/_matrix/federation/v1/state/%s"" % (room_1,)
        )
        self.assertEquals(200, channel.code, channel.result)

        self.assertEqual(
            channel.json_body[""room_version""],
            self.hs.config.default_room_version.identifier,
        )

        members = set(
            map(
                lambda x: x[""state_key""],
                filter(
                    lambda x: x[""type""] == ""m.room.member"", channel.json_body[""pdus""]
                ),
            )
        )

        self.assertEqual(members, {""@user:other.example.com"", u1})
        self.assertEqual(len(channel.json_body[""pdus""]), 6)

    def test_needs_to_be_in_room(self):
        """"""
        Querying v1/state/<room_id> requires the server
        be in the room to provide data.
        """"""
        u1 = self.register_user(""u1"", ""pass"")
        u1_token = self.login(""u1"", ""pass"")

        room_1 = self.helper.create_room_as(u1, tok=u1_token)

        channel = self.make_request(
            ""GET"", ""/_matrix/federation/v1/state/%s"" % (room_1,)
        )
        self.assertEquals(403, channel.code, channel.result)
        self.assertEqual(channel.json_body[""errcode""], ""M_FORBIDDEN"")


def _create_acl_event(content):
    return make_event_from_dict(
        {
            ""room_id"": ""!a:b"",
            ""event_id"": ""$a:b"",
            ""type"": ""m.room.server_acls"",
            ""sender"": ""@a:b"",
            ""content"": content,
        }
    )
",CWE-331,146.0,1
,CWE-331,,1
"""============================================================================
""File:        avrgcc.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  Karel <karelishere at gmail dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""
""============================================================================

if exists('g:loaded_syntastic_c_avrgcc_checker')
    finish
endif
let g:loaded_syntastic_c_avrgcc_checker = 1

if !exists('g:syntastic_avrgcc_config_file')
    let g:syntastic_avrgcc_config_file = '.syntastic_avrgcc_config'
endif

let s:save_cpo = &cpo
set cpo&vim

let s:opt_x = { 'c': 'c', 'cpp': 'c++' }

function! SyntaxCheckers_c_avrgcc_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'args_before': syntastic#c#ReadConfig(g:syntastic_avrgcc_config_file),
        \ 'args_after': '-x ' . get(s:opt_x, self.getFiletype(), '')  . ' -fsyntax-only' })

    let errorformat =
        \ '%-G%f:%s:,' .
        \ '%-G%f:%l: %#error: %#(Each undeclared identifier is reported only%.%#,' .
        \ '%-G%f:%l: %#error: %#for each function it appears%.%#,' .
        \ '%-GIn file included%.%#,' .
        \ '%-G %#from %f:%l\,,' .
        \ '%f:%l:%c: %trror: %m,' .
        \ '%f:%l:%c: %tarning: %m,' .
        \ '%f:%l:%c: %m,' .
        \ '%f:%l: %trror: %m,' .
        \ '%f:%l: %tarning: %m,'.
        \ '%f:%l: %m'

    return SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'postprocess': ['compressWhitespace'] })
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'avrgcc',
    \ 'exec': 'avr-gcc'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,60.0,1
"""============================================================================
""File:        clang_check.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  Benjamin Bannier <bbannier at gmail dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_clang_check_checker')
    finish
endif
let g:loaded_syntastic_c_clang_check_checker = 1

if !exists('g:syntastic_clang_check_config_file')
    let g:syntastic_clang_check_config_file = '.syntastic_clang_check_config'
endif

if !exists('g:syntastic_c_clang_check_sort')
    let g:syntastic_c_clang_check_sort = 1
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_clang_check_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'post_args':
        \   '-- ' .
        \   syntastic#c#ReadConfig(g:syntastic_clang_check_config_file) . ' ' .
        \   '-fshow-column ' .
        \   '-fshow-source-location ' .
        \   '-fno-caret-diagnostics ' .
        \   '-fno-color-diagnostics ' .
        \   '-fdiagnostics-format=clang' })

    let errorformat =
        \ '%E%f:%l:%c: fatal error: %m,' .
        \ '%E%f:%l:%c: error: %m,' .
        \ '%W%f:%l:%c: warning: %m,' .
        \ '%-G%\m%\%%(LLVM ERROR:%\|No compilation database found%\)%\@!%.%#,' .
        \ '%E%m'

    let env = syntastic#util#isRunningWindows() ? {} : { 'TERM': 'dumb' }

    return SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'env': env,
        \ 'defaults': {'bufnr': bufnr('')},
        \ 'returns': [0, 1] })
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'clang_check',
    \ 'exec': 'clang-check'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,65.0,1
"""============================================================================
""File:        clang_tidy.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  Benjamin Bannier <bbannier at gmail dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_clang_tidy_checker')
    finish
endif
let g:loaded_syntastic_c_clang_tidy_checker = 1

if !exists('g:syntastic_clang_tidy_config_file')
    let g:syntastic_clang_tidy_config_file = '.syntastic_clang_tidy_config'
endif

if !exists('g:syntastic_c_clang_tidy_sort')
    let g:syntastic_c_clang_tidy_sort = 1
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_clang_tidy_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'post_args':
        \   '-- ' .
        \   syntastic#c#ReadConfig(g:syntastic_clang_tidy_config_file) . ' ' .
        \   '-fshow-column ' .
        \   '-fshow-source-location ' .
        \   '-fno-caret-diagnostics ' .
        \   '-fno-color-diagnostics ' .
        \   '-fdiagnostics-format=clang' })

    let errorformat =
        \ '%E%f:%l:%c: fatal error: %m,' .
        \ '%E%f:%l:%c: error: %m,' .
        \ '%W%f:%l:%c: warning: %m,' .
        \ '%-G%\m%\%%(LLVM ERROR:%\|No compilation database found%\)%\@!%.%#,' .
        \ '%E%m'

    let env = syntastic#util#isRunningWindows() ? {} : { 'TERM': 'dumb' }

    return SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'env': env,
        \ 'defaults': {'bufnr': bufnr('')},
        \ 'returns': [0, 1] })
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'clang_tidy',
    \ 'exec': 'clang-tidy'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,65.0,1
"""============================================================================
""File:        cppcheck.vim
""Description: Syntax checking plugin for syntastic using cppcheck.pl
""Maintainer:  LCD 47 <lcd047 at gmail dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_cppcheck_checker')
    finish
endif
let g:loaded_syntastic_c_cppcheck_checker = 1

if !exists('g:syntastic_cppcheck_config_file')
    let g:syntastic_cppcheck_config_file = '.syntastic_cppcheck_config'
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_cppcheck_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'args': syntastic#c#ReadConfig(g:syntastic_cppcheck_config_file),
        \ 'args_after': '-q --enable=style' })

    let errorformat =
        \ '[%f:%l]: (%trror) %m,' .
        \ '[%f:%l]: (%tarning) %m,' .
        \ '[%f:%l]: (%ttyle) %m,' .
        \ '[%f:%l]: (%terformance) %m,' .
        \ '[%f:%l]: (%tortability) %m,' .
        \ '[%f:%l]: (%tnformation) %m,' .
        \ '[%f:%l]: (%tnconclusive) %m,' .
        \ '%-G%.%#'

    let loclist = SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'preprocess': 'cppcheck',
        \ 'returns': [0] })

    for e in loclist
        if e['type'] =~? '\m^[SPI]'
            let e['type'] = 'w'
            let e['subtype'] = 'Style'
        endif
    endfor

    return loclist
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'cppcheck'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,63.0,1
"""============================================================================
""File:        oclint.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  ""UnCO"" Lin <undercooled aT lavabit com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_oclint_checker')
    finish
endif
let g:loaded_syntastic_c_oclint_checker = 1

if !exists('g:syntastic_oclint_config_file')
    let g:syntastic_oclint_config_file = '.syntastic_oclint_config'
endif

if !exists('g:syntastic_c_oclint_sort')
    let g:syntastic_c_oclint_sort = 1
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_oclint_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'post_args': '-- -c ' . syntastic#c#ReadConfig(g:syntastic_oclint_config_file) })

    let errorformat =
        \ '%E%f:%l:%c: fatal error: %m,' .
        \ '%E%f:%l:%c: error: %m,' .
        \ '%W%f:%l:%c: warning: %m,' .
        \ '%E%f:%l:%c: %m,' .
        \ '%-G%.%#'

    let loclist = SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'subtype': 'Style',
        \ 'postprocess': ['compressWhitespace'],
        \ 'returns': [0, 3, 5] })

    for e in loclist
        if e['text'] =~# '\v P3( |$)'
            let e['type'] = 'W'
        endif

        let e['text'] = substitute(e['text'], '\m\C P[1-3]$', '', '')
        let e['text'] = substitute(e['text'], '\m\C P[1-3] ', ': ', '')
    endfor

    return loclist
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'oclint'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,66.0,1
"""============================================================================
""File:        pc_lint.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  Steve Bragg <steve at empresseffects dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""
""============================================================================

if exists('g:loaded_syntastic_c_pc_lint_checker')
    finish
endif
let g:loaded_syntastic_c_pc_lint_checker = 1

let s:save_cpo = &cpo
set cpo&vim

if !exists('g:syntastic_pc_lint_config_file')
    let g:syntastic_pc_lint_config_file = 'options.lnt'
endif

function! SyntaxCheckers_c_pc_lint_GetLocList() dict
    let buf = bufnr('')
    let config = syntastic#util#findFileInParent(g:syntastic_pc_lint_config_file, fnamemodify(bufname(buf), ':p:h'))
    call self.log('config =', config)

    "" -hFs1         - show filename, add space after messages, try to make message 1 line
    "" -width(0,0)   - make sure there are no line breaks
    "" -t            - set tab size
    "" -v            - turn off verbosity
    let makeprg = self.makeprgBuild({
        \ 'args': (filereadable(config) ? syntastic#util#shescape(fnamemodify(config, ':p')) : ''),
        \ 'args_after': ['-hFs1', '-width(0,0)', '-t' . &tabstop, '-format=%f:%l:%C:%t:%n:%m'] })

    let errorformat =
        \ '%E%f:%l:%v:Error:%n:%m,' .
        \ '%W%f:%l:%v:Warning:%n:%m,' .
        \ '%I%f:%l:%v:Info:%n:%m,' .
        \ '%-G%.%#'

    let loclist = SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'postprocess': ['cygwinRemoveCR'] })

    for e in loclist
        if e['type'] ==? 'I'
            let e['type'] = 'W'
            let e['subtype'] = 'Style'
        endif
    endfor

    return loclist
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'pc_lint',
    \ 'exec': 'lint-nt'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,68.0,1
"""============================================================================
""File:        sparse.vim
""Description: Syntax checking plugin for syntastic using sparse.pl
""Maintainer:  Daniel Walker <dwalker at fifo99 dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_sparse_checker')
    finish
endif
let g:loaded_syntastic_c_sparse_checker = 1

if !exists('g:syntastic_sparse_config_file')
    let g:syntastic_sparse_config_file = '.syntastic_sparse_config'
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_sparse_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'args': syntastic#c#ReadConfig(g:syntastic_sparse_config_file),
        \ 'args_after': '-ftabstop=' . &ts })

    let errorformat =
        \ '%f:%l:%v: %trror: %m,' .
        \ '%f:%l:%v: %tarning: %m,'

    let loclist = SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'defaults': {'bufnr': bufnr('')},
        \ 'returns': [0, 1] })
    return loclist
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'sparse'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,49.0,1
"""============================================================================
""File:        splint.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  LCD 47 <lcd047 at gmail dot com>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""============================================================================

if exists('g:loaded_syntastic_c_splint_checker')
    finish
endif
let g:loaded_syntastic_c_splint_checker = 1

if !exists('g:syntastic_splint_config_file')
    let g:syntastic_splint_config_file = '.syntastic_splint_config'
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_c_splint_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'args': syntastic#c#ReadConfig(g:syntastic_splint_config_file),
        \ 'args_after': '-showfunc -hints +quiet' })

    let errorformat =
        \ '%-G%f:%l:%v: %[%#]%[%#]%[%#] Internal Bug %.%#,' .
        \ '%-G%f(%l\,%v): %[%#]%[%#]%[%#] Internal Bug %.%#,' .
        \ '%W%f:%l:%v: %m,' .
        \ '%W%f(%l\,%v): %m,' .
        \ '%W%f:%l: %m,' .
        \ '%W%f(%l): %m,' .
        \ '%-C %\+In file included from %.%#,' .
        \ '%-C %\+from %.%#,' .
        \ '%+C %.%#'

    return SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'subtype': 'Style',
        \ 'postprocess': ['compressWhitespace'],
        \ 'defaults': {'type': 'W'} })
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'c',
    \ 'name': 'splint'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,56.0,1
"""============================================================================
""File:        verapp.vim
""Description: Syntax checking plugin for syntastic
""Maintainer:  Lucas Verney <phyks@phyks.me>
""License:     This program is free software. It comes without any warranty,
""             to the extent permitted by applicable law. You can redistribute
""             it and/or modify it under the terms of the Do What The Fuck You
""             Want To Public License, Version 2, as published by Sam Hocevar.
""             See http://sam.zoy.org/wtfpl/COPYING for more details.
""
"" Tested with Vera++ 1.3.0
""============================================================================

if exists('g:loaded_syntastic_cpp_verapp_checker')
    finish
endif
let g:loaded_syntastic_cpp_verapp_checker = 1

if !exists('g:syntastic_verapp_config_file')
    let g:syntastic_verapp_config_file = '.syntastic_verapp_config'
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_cpp_verapp_GetLocList() dict
    let makeprg = self.makeprgBuild({
        \ 'args': syntastic#c#ReadConfig(g:syntastic_verapp_config_file),
        \ 'args_after': '--show-rule --no-duplicate -S -c -' })

    let errorformat = '%f:%t:%l:%c:%m'

    return SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'preprocess': 'checkstyle',
        \ 'subtype': 'Style' })
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'cpp',
    \ 'name': 'verapp',
    \ 'exec': 'vera++'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,49.0,1
"""============================================================================
""File:        cuda.vim
""Description: Syntax checking plugin for syntastic
""Author:      Hannes Schulz <schulz at ais dot uni-bonn dot de>
""
""============================================================================

if exists('g:loaded_syntastic_cuda_nvcc_checker')
    finish
endif
let g:loaded_syntastic_cuda_nvcc_checker = 1

if !exists('g:syntastic_cuda_config_file')
    let g:syntastic_cuda_config_file = '.syntastic_cuda_config'
endif

let s:save_cpo = &cpo
set cpo&vim

function! SyntaxCheckers_cuda_nvcc_GetLocList() dict
    let buf = bufnr('')
    let arch_flag = syntastic#util#bufVar(buf, 'cuda_arch')
    if arch_flag !=# ''
        let arch_flag = '-arch=' . arch_flag
        call syntastic#log#oneTimeWarn('variable g:syntastic_cuda_arch is deprecated, ' .
            \ 'please add ' . string(arch_flag) . ' to g:syntastic_cuda_nvcc_args instead')
    endif

    let build_opts = {}
    let dummy = ''
    if index(['h', 'hpp', 'cuh'], fnamemodify(bufname(buf), ':e'), 0, 1) >= 0
        if syntastic#util#bufVar(buf, 'cuda_check_header', 0)
            let dummy = fnamemodify(bufname(buf), ':p:h') . syntastic#util#Slash() . '.syntastic_dummy.cu'
            let build_opts = {
                \ 'exe_before': 'echo > ' . syntastic#util#shescape(dummy) . ' ;',
                \ 'fname_before': '.syntastic_dummy.cu -include' }
        else
            return []
        endif
    endif

    call extend(build_opts, {
        \ 'args_before': arch_flag . ' --cuda -O0 -I .',
        \ 'args': syntastic#c#ReadConfig(g:syntastic_cuda_config_file),
        \ 'args_after': '-Xcompiler -fsyntax-only',
        \ 'tail_after': syntastic#c#NullOutput() })

    let makeprg = self.makeprgBuild(build_opts)

    let errorformat =
        \ '%*[^""]""%f""%*\D%l: %m,'.
        \ '""%f""%*\D%l: %m,'.
        \ '%-G%f:%l: (Each undeclared identifier is reported only once,'.
        \ '%-G%f:%l: for each function it appears in.),'.
        \ '%f:%l:%c:%m,'.
        \ '%f(%l):%m,'.
        \ '%f:%l:%m,'.
        \ '""%f""\, line %l%*\D%c%*[^ ] %m,'.
        \ '%D%*\a[%*\d]: Entering directory `%f'','.
        \ '%X%*\a[%*\d]: Leaving directory `%f'','.
        \ '%D%*\a: Entering directory `%f'','.
        \ '%X%*\a: Leaving directory `%f'','.
        \ '%DMaking %*\a in %f,'.
        \ '%f|%l| %m'

    let loclist = SyntasticMake({
        \ 'makeprg': makeprg,
        \ 'errorformat': errorformat,
        \ 'defaults': {'type': 'E'} })

    for e in loclist
        let pat = matchstr(e['text'], '\m\c^\s*warning:\s*\zs.*')
        if pat !=# ''
            let e['text'] = pat
            let e['type'] = 'W'
        endif
    endfor

    if dummy !=# ''
        call delete(dummy)
    endif

    return loclist
endfunction

call g:SyntasticRegistry.CreateAndRegisterChecker({
    \ 'filetype': 'cuda',
    \ 'name': 'nvcc'})

let &cpo = s:save_cpo
unlet s:save_cpo

"" vim: set sw=4 sts=4 et fdm=marker:
",CWE-22,94.0,1
"<?php
$sub_menu = ""100100"";
include_once('./_common.php');

check_demo();

auth_check($auth[$sub_menu], 'w');

if ($is_admin != 'super')
    alert('  .');

$mb = get_member($cf_admin);
if (!$mb['mb_id'])
    alert('   .');

check_admin_token();

//    ,     
if($_POST['cf_cert_use'] && !$_POST['cf_cert_ipin'] && !$_POST['cf_cert_hp'])
    alert('         ');

if(!$_POST['cf_cert_use']) {
    $_POST['cf_cert_ipin'] = '';
    $_POST['cf_cert_hp'] = '';
}

$cf_social_servicelist = !empty($_POST['cf_social_servicelist']) ? implode(',', $_POST['cf_social_servicelist']) : '';

$sql = "" update {$g5['config_table']}
            set cf_title = '{$_POST['cf_title']}',
                cf_admin = '{$_POST['cf_admin']}',
                cf_admin_email = '{$_POST['cf_admin_email']}',
                cf_admin_email_name = '{$_POST['cf_admin_email_name']}',
                cf_add_script = '{$_POST['cf_add_script']}',
                cf_use_point = '{$_POST['cf_use_point']}',
                cf_point_term = '{$_POST['cf_point_term']}',
                cf_use_copy_log = '{$_POST['cf_use_copy_log']}',
                cf_use_email_certify = '{$_POST['cf_use_email_certify']}',
                cf_login_point = '{$_POST['cf_login_point']}',
                cf_cut_name = '{$_POST['cf_cut_name']}',
                cf_nick_modify = '{$_POST['cf_nick_modify']}',
                cf_new_skin = '{$_POST['cf_new_skin']}',
                cf_new_rows = '{$_POST['cf_new_rows']}',
                cf_search_skin = '{$_POST['cf_search_skin']}',
                cf_connect_skin = '{$_POST['cf_connect_skin']}',
                cf_faq_skin = '{$_POST['cf_faq_skin']}',
                cf_read_point = '{$_POST['cf_read_point']}',
                cf_write_point = '{$_POST['cf_write_point']}',
                cf_comment_point = '{$_POST['cf_comment_point']}',
                cf_download_point = '{$_POST['cf_download_point']}',
                cf_write_pages = '{$_POST['cf_write_pages']}',
                cf_mobile_pages = '{$_POST['cf_mobile_pages']}',
                cf_link_target = '{$_POST['cf_link_target']}',
                cf_delay_sec = '{$_POST['cf_delay_sec']}',
                cf_filter = '{$_POST['cf_filter']}',
                cf_possible_ip = '"".trim($_POST['cf_possible_ip']).""',
                cf_intercept_ip = '"".trim($_POST['cf_intercept_ip']).""',
                cf_analytics = '{$_POST['cf_analytics']}',
                cf_add_meta = '{$_POST['cf_add_meta']}',
                cf_syndi_token = '{$_POST['cf_syndi_token']}',
                cf_syndi_except = '{$_POST['cf_syndi_except']}',
                cf_member_skin = '{$_POST['cf_member_skin']}',
                cf_use_homepage = '{$_POST['cf_use_homepage']}',
                cf_req_homepage = '{$_POST['cf_req_homepage']}',
                cf_use_tel = '{$_POST['cf_use_tel']}',
                cf_req_tel = '{$_POST['cf_req_tel']}',
                cf_use_hp = '{$_POST['cf_use_hp']}',
                cf_req_hp = '{$_POST['cf_req_hp']}',
                cf_use_addr = '{$_POST['cf_use_addr']}',
                cf_req_addr = '{$_POST['cf_req_addr']}',
                cf_use_signature = '{$_POST['cf_use_signature']}',
                cf_req_signature = '{$_POST['cf_req_signature']}',
                cf_use_profile = '{$_POST['cf_use_profile']}',
                cf_req_profile = '{$_POST['cf_req_profile']}',
                cf_register_level = '{$_POST['cf_register_level']}',
                cf_register_point = '{$_POST['cf_register_point']}',
                cf_icon_level = '{$_POST['cf_icon_level']}',
                cf_use_recommend = '{$_POST['cf_use_recommend']}',
                cf_recommend_point = '{$_POST['cf_recommend_point']}',
                cf_leave_day = '{$_POST['cf_leave_day']}',
                cf_search_part = '{$_POST['cf_search_part']}',
                cf_email_use = '{$_POST['cf_email_use']}',
                cf_email_wr_super_admin = '{$_POST['cf_email_wr_super_admin']}',
                cf_email_wr_group_admin = '{$_POST['cf_email_wr_group_admin']}',
                cf_email_wr_board_admin = '{$_POST['cf_email_wr_board_admin']}',
                cf_email_wr_write = '{$_POST['cf_email_wr_write']}',
                cf_email_wr_comment_all = '{$_POST['cf_email_wr_comment_all']}',
                cf_email_mb_super_admin = '{$_POST['cf_email_mb_super_admin']}',
                cf_email_mb_member = '{$_POST['cf_email_mb_member']}',
                cf_email_po_super_admin = '{$_POST['cf_email_po_super_admin']}',
                cf_prohibit_id = '{$_POST['cf_prohibit_id']}',
                cf_prohibit_email = '{$_POST['cf_prohibit_email']}',
                cf_new_del = '{$_POST['cf_new_del']}',
                cf_memo_del = '{$_POST['cf_memo_del']}',
                cf_visit_del = '{$_POST['cf_visit_del']}',
                cf_popular_del = '{$_POST['cf_popular_del']}',
                cf_use_member_icon = '{$_POST['cf_use_member_icon']}',
                cf_member_icon_size = '{$_POST['cf_member_icon_size']}',
                cf_member_icon_width = '{$_POST['cf_member_icon_width']}',
                cf_member_icon_height = '{$_POST['cf_member_icon_height']}',
                cf_member_img_size = '{$_POST['cf_member_img_size']}',
                cf_member_img_width = '{$_POST['cf_member_img_width']}',
                cf_member_img_height = '{$_POST['cf_member_img_height']}',
                cf_login_minutes = '{$_POST['cf_login_minutes']}',
                cf_image_extension = '{$_POST['cf_image_extension']}',
                cf_flash_extension = '{$_POST['cf_flash_extension']}',
                cf_movie_extension = '{$_POST['cf_movie_extension']}',
                cf_formmail_is_member = '{$_POST['cf_formmail_is_member']}',
                cf_page_rows = '{$_POST['cf_page_rows']}',
                cf_mobile_page_rows = '{$_POST['cf_mobile_page_rows']}',
                cf_stipulation = '{$_POST['cf_stipulation']}',
                cf_privacy = '{$_POST['cf_privacy']}',
                cf_open_modify = '{$_POST['cf_open_modify']}',
                cf_memo_send_point = '{$_POST['cf_memo_send_point']}',
                cf_mobile_new_skin = '{$_POST['cf_mobile_new_skin']}',
                cf_mobile_search_skin = '{$_POST['cf_mobile_search_skin']}',
                cf_mobile_connect_skin = '{$_POST['cf_mobile_connect_skin']}',
                cf_mobile_faq_skin = '{$_POST['cf_mobile_faq_skin']}',
                cf_mobile_member_skin = '{$_POST['cf_mobile_member_skin']}',
                cf_captcha_mp3 = '{$_POST['cf_captcha_mp3']}',
                cf_editor = '{$_POST['cf_editor']}',
                cf_cert_use = '{$_POST['cf_cert_use']}',
                cf_cert_ipin = '{$_POST['cf_cert_ipin']}',
                cf_cert_hp = '{$_POST['cf_cert_hp']}',
                cf_cert_kcb_cd = '{$_POST['cf_cert_kcb_cd']}',
                cf_cert_kcp_cd = '{$_POST['cf_cert_kcp_cd']}',
                cf_lg_mid = '{$_POST['cf_lg_mid']}',
                cf_lg_mert_key = '{$_POST['cf_lg_mert_key']}',
                cf_cert_limit = '{$_POST['cf_cert_limit']}',
                cf_cert_req = '{$_POST['cf_cert_req']}',
                cf_sms_use = '{$_POST['cf_sms_use']}',
                cf_sms_type = '{$_POST['cf_sms_type']}',
                cf_icode_id = '{$_POST['cf_icode_id']}',
                cf_icode_pw = '{$_POST['cf_icode_pw']}',
                cf_icode_server_ip = '{$_POST['cf_icode_server_ip']}',
                cf_icode_server_port = '{$_POST['cf_icode_server_port']}',
                cf_googl_shorturl_apikey = '{$_POST['cf_googl_shorturl_apikey']}',
                cf_kakao_js_apikey = '{$_POST['cf_kakao_js_apikey']}',
                cf_facebook_appid = '{$_POST['cf_facebook_appid']}',
                cf_facebook_secret = '{$_POST['cf_facebook_secret']}',
                cf_twitter_key = '{$_POST['cf_twitter_key']}',
                cf_twitter_secret = '{$_POST['cf_twitter_secret']}',
                cf_social_login_use = '{$_POST['cf_social_login_use']}',
                cf_naver_clientid = '{$_POST['cf_naver_clientid']}',
                cf_naver_secret = '{$_POST['cf_naver_secret']}',
                cf_google_clientid = '{$_POST['cf_google_clientid']}',
                cf_google_secret = '{$_POST['cf_google_secret']}',
                cf_kakao_rest_key = '{$_POST['cf_kakao_rest_key']}',
                cf_kakao_client_secret = '{$_POST['cf_kakao_client_secret']}',
                cf_social_servicelist   =   '{$cf_social_servicelist}',
                cf_captcha = '{$_POST['cf_captcha']}',
                cf_recaptcha_site_key = '{$_POST['cf_recaptcha_site_key']}',
                cf_recaptcha_secret_key   =   '{$_POST['cf_recaptcha_secret_key']}',
                cf_payco_clientid = '{$_POST['cf_payco_clientid']}',
                cf_payco_secret = '{$_POST['cf_payco_secret']}',
                cf_1_subj = '{$_POST['cf_1_subj']}',
                cf_2_subj = '{$_POST['cf_2_subj']}',
                cf_3_subj = '{$_POST['cf_3_subj']}',
                cf_4_subj = '{$_POST['cf_4_subj']}',
                cf_5_subj = '{$_POST['cf_5_subj']}',
                cf_6_subj = '{$_POST['cf_6_subj']}',
                cf_7_subj = '{$_POST['cf_7_subj']}',
                cf_8_subj = '{$_POST['cf_8_subj']}',
                cf_9_subj = '{$_POST['cf_9_subj']}',
                cf_10_subj = '{$_POST['cf_10_subj']}',
                cf_1 = '{$_POST['cf_1']}',
                cf_2 = '{$_POST['cf_2']}',
                cf_3 = '{$_POST['cf_3']}',
                cf_4 = '{$_POST['cf_4']}',
                cf_5 = '{$_POST['cf_5']}',
                cf_6 = '{$_POST['cf_6']}',
                cf_7 = '{$_POST['cf_7']}',
                cf_8 = '{$_POST['cf_8']}',
                cf_9 = '{$_POST['cf_9']}',
                cf_10 = '{$_POST['cf_10']}' "";
sql_query($sql);

//sql_query("" OPTIMIZE TABLE `$g5[config_table]` "");

goto_url('./config_form.php', false);
?>",CWE-79,181.0,1
"from __future__ import unicode_literals

from django.apps import apps
from django.utils.html import format_html_join

from .permissions import permission_cabinet_view


def jstree_data(node, selected_node):
    result = []
    result.append('{')
    result.append('""text"": ""{}"",'.format(node.label))
    result.append(
        '""state"": {{ ""opened"": true, ""selected"": {} }},'.format(
            'true' if node == selected_node else 'false'
        )
    )
    result.append(
        '""data"": {{ ""href"": ""{}"" }},'.format(node.get_absolute_url())
    )

    children = node.get_children().order_by('label',)

    if children:
        result.append('""children"" : [')
        for child in children:
            result.extend(jstree_data(node=child, selected_node=selected_node))

        result.append(']')

    result.append('},')

    return result


def widget_document_cabinets(document, user):
    """"""
    A cabinet widget that displays the cabinets for the given document
    """"""
    AccessControlList = apps.get_model(
        app_label='acls', model_name='AccessControlList'
    )

    cabinets = AccessControlList.objects.filter_by_access(
        permission_cabinet_view, user, queryset=document.document_cabinets().all()
    )

    return format_html_join(
        '\n', '<div class=""cabinet-display"">{}</div>',
        (
            (cabinet.get_full_path(),) for cabinet in cabinets
        )
    )
",CWE-79,54.0,1
"from __future__ import absolute_import, unicode_literals

from django import forms
from django.apps import apps
from django.template.loader import render_to_string
from django.utils.safestring import mark_safe

from .permissions import permission_tag_view


class TagFormWidget(forms.SelectMultiple):
    option_template_name = 'tags/forms/widgets/tag_select_option.html'

    def __init__(self, *args, **kwargs):
        self.queryset = kwargs.pop('queryset')
        return super(TagFormWidget, self).__init__(*args, **kwargs)

    def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):
        result = super(TagFormWidget, self).create_option(
            name=name, value=value, label=label, selected=selected,
            index=index, subindex=subindex, attrs=attrs
        )

        result['attrs']['data-color'] = self.queryset.get(pk=value).color

        return result


def widget_document_tags(document, user):
    """"""
    A tag widget that displays the tags for the given document
    """"""
    AccessControlList = apps.get_model(
        app_label='acls', model_name='AccessControlList'
    )

    result = ['<div class=""tag-container"">']

    tags = AccessControlList.objects.filter_by_access(
        permission_tag_view, user, queryset=document.attached_tags().all()
    )

    for tag in tags:
        result.append(widget_single_tag(tag))

    result.append('</div>')

    return mark_safe(''.join(result))


def widget_single_tag(tag):
    return render_to_string('tags/tag_widget.html', {'tag': tag})
",CWE-79,53.0,1
"# this is a package

__version__ = ""4.6.2""


def get_include():
    """"""
    Returns a list of header include paths (for lxml itself, libxml2
    and libxslt) needed to compile C code against lxml if it was built
    with statically linked libraries.
    """"""
    import os
    lxml_path = __path__[0]
    include_path = os.path.join(lxml_path, 'includes')
    includes = [include_path, lxml_path]

    for name in os.listdir(include_path):
        path = os.path.join(include_path, name)
        if os.path.isdir(path):
            includes.append(path)

    return includes

",CWE-79,24.0,1
"import unittest
from lxml.tests.common_imports import make_doctest

import lxml.html
from lxml.html.clean import Cleaner, clean_html


class CleanerTest(unittest.TestCase):
    def test_allow_tags(self):
        html = """"""
            <html>
            <head>
            </head>
            <body>
            <p>some text</p>
            <table>
            <tr>
            <td>hello</td><td>world</td>
            </tr>
            <tr>
            <td>hello</td><td>world</td>
            </tr>
            </table>
            <img>
            </body>
            </html>
            """"""

        html_root = lxml.html.document_fromstring(html)
        cleaner = Cleaner(
            remove_unknown_tags = False,
            allow_tags = ['table', 'tr', 'td'])
        result = cleaner.clean_html(html_root)

        self.assertEqual(12-5+1, len(list(result.iter())))

    def test_allow_and_remove(self):
        with self.assertRaises(ValueError):
            Cleaner(allow_tags=['a'], remove_unknown_tags=True)

    def test_remove_unknown_tags(self):
        html = """"""<div><bun>lettuce, tomato, veggie patty</bun></div>""""""
        clean_html = """"""<div>lettuce, tomato, veggie patty</div>""""""
        cleaner = Cleaner(remove_unknown_tags=True)
        result = cleaner.clean_html(html)
        self.assertEqual(
            result,
            clean_html,
            msg=""Unknown tags not removed. Got: %s"" % result,
        )

    def test_safe_attrs_included(self):
        html = """"""<p><span style=""color: #00ffff;"">Cyan</span></p>""""""

        safe_attrs=set(lxml.html.defs.safe_attrs)
        safe_attrs.add('style')

        cleaner = Cleaner(
            safe_attrs_only=True,
            safe_attrs=safe_attrs)
        result = cleaner.clean_html(html)

        self.assertEqual(html, result)

    def test_safe_attrs_excluded(self):
        html = """"""<p><span style=""color: #00ffff;"">Cyan</span></p>""""""
        expected = """"""<p><span>Cyan</span></p>""""""

        safe_attrs=set()

        cleaner = Cleaner(
            safe_attrs_only=True,
            safe_attrs=safe_attrs)
        result = cleaner.clean_html(html)

        self.assertEqual(expected, result)

    def test_clean_invalid_root_tag(self):
        # only testing that cleaning with invalid root tags works at all
        s = lxml.html.fromstring('parent <invalid tag>child</another>')
        self.assertEqual('parent child', clean_html(s).text_content())

        s = lxml.html.fromstring('<invalid tag>child</another>')
        self.assertEqual('child', clean_html(s).text_content())

    def test_clean_with_comments(self):
        html = """"""<p><span style=""color: #00ffff;"">Cy<!-- xx -->an</span><!-- XXX --></p>""""""
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<p><span>Cyan</span></p>',
            lxml.html.tostring(clean_html(s)))
        self.assertEqual(
            '<p><span>Cyan</span></p>',
            clean_html(html))

        cleaner = Cleaner(comments=False)
        result = cleaner.clean_html(s)
        self.assertEqual(
            b'<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',
            lxml.html.tostring(result))
        self.assertEqual(
            '<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',
            cleaner.clean_html(html))

    def test_sneaky_noscript_in_style(self):
        # This gets parsed as <noscript> -> <style>""...</noscript>...""</style>
        # thus passing the </noscript> through into the output.
        html = '<noscript><style><a title=""</noscript><img src=x onerror=alert(1)>"">'
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<noscript><style>/* deleted */</style></noscript>',
            lxml.html.tostring(clean_html(s)))

    def test_sneaky_js_in_math_style(self):
        # This gets parsed as <math> -> <style>""...""</style>
        # thus passing any tag/script/whatever content through into the output.
        html = '<math><style><img src=x onerror=alert(1)></style></math>'
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<math><style>/* deleted */</style></math>',
            lxml.html.tostring(clean_html(s)))

    def test_formaction_attribute_in_button_input(self):
        # The formaction attribute overrides the form's action and should be
        # treated as a malicious link attribute
        html = ('<form id=""test""><input type=""submit"" formaction=""javascript:alert(1)""></form>'
        '<button form=""test"" formaction=""javascript:alert(1)"">X</button>')
        expected = ('<div><form id=""test""><input type=""submit"" formaction=""""></form>'
        '<button form=""test"" formaction="""">X</button></div>')
        cleaner = Cleaner(
            forms=False,
            safe_attrs_only=False,
        )
        self.assertEqual(
            expected,
            cleaner.clean_html(html))


def test_suite():
    suite = unittest.TestSuite()
    suite.addTests([make_doctest('test_clean.txt')])
    suite.addTests([make_doctest('test_clean_embed.txt')])
    suite.addTests(unittest.makeSuite(CleanerTest))
    return suite
",CWE-79,148.0,1
"import unittest
from lxml.tests.common_imports import make_doctest

import lxml.html
from lxml.html.clean import Cleaner, clean_html


class CleanerTest(unittest.TestCase):
    def test_allow_tags(self):
        html = """"""
            <html>
            <head>
            </head>
            <body>
            <p>some text</p>
            <table>
            <tr>
            <td>hello</td><td>world</td>
            </tr>
            <tr>
            <td>hello</td><td>world</td>
            </tr>
            </table>
            <img>
            </body>
            </html>
            """"""

        html_root = lxml.html.document_fromstring(html)
        cleaner = Cleaner(
            remove_unknown_tags = False,
            allow_tags = ['table', 'tr', 'td'])
        result = cleaner.clean_html(html_root)

        self.assertEqual(12-5+1, len(list(result.iter())))

    def test_allow_and_remove(self):
        with self.assertRaises(ValueError):
            Cleaner(allow_tags=['a'], remove_unknown_tags=True)

    def test_remove_unknown_tags(self):
        html = """"""<div><bun>lettuce, tomato, veggie patty</bun></div>""""""
        clean_html = """"""<div>lettuce, tomato, veggie patty</div>""""""
        cleaner = Cleaner(remove_unknown_tags=True)
        result = cleaner.clean_html(html)
        self.assertEqual(
            result,
            clean_html,
            msg=""Unknown tags not removed. Got: %s"" % result,
        )

    def test_safe_attrs_included(self):
        html = """"""<p><span style=""color: #00ffff;"">Cyan</span></p>""""""

        safe_attrs=set(lxml.html.defs.safe_attrs)
        safe_attrs.add('style')

        cleaner = Cleaner(
            safe_attrs_only=True,
            safe_attrs=safe_attrs)
        result = cleaner.clean_html(html)

        self.assertEqual(html, result)

    def test_safe_attrs_excluded(self):
        html = """"""<p><span style=""color: #00ffff;"">Cyan</span></p>""""""
        expected = """"""<p><span>Cyan</span></p>""""""

        safe_attrs=set()

        cleaner = Cleaner(
            safe_attrs_only=True,
            safe_attrs=safe_attrs)
        result = cleaner.clean_html(html)

        self.assertEqual(expected, result)

    def test_clean_invalid_root_tag(self):
        # only testing that cleaning with invalid root tags works at all
        s = lxml.html.fromstring('parent <invalid tag>child</another>')
        self.assertEqual('parent child', clean_html(s).text_content())

        s = lxml.html.fromstring('<invalid tag>child</another>')
        self.assertEqual('child', clean_html(s).text_content())

    def test_clean_with_comments(self):
        html = """"""<p><span style=""color: #00ffff;"">Cy<!-- xx -->an</span><!-- XXX --></p>""""""
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<p><span>Cyan</span></p>',
            lxml.html.tostring(clean_html(s)))
        self.assertEqual(
            '<p><span>Cyan</span></p>',
            clean_html(html))

        cleaner = Cleaner(comments=False)
        result = cleaner.clean_html(s)
        self.assertEqual(
            b'<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',
            lxml.html.tostring(result))
        self.assertEqual(
            '<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',
            cleaner.clean_html(html))

    def test_sneaky_noscript_in_style(self):
        # This gets parsed as <noscript> -> <style>""...</noscript>...""</style>
        # thus passing the </noscript> through into the output.
        html = '<noscript><style><a title=""</noscript><img src=x onerror=alert(1)>"">'
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<noscript><style>/* deleted */</style></noscript>',
            lxml.html.tostring(clean_html(s)))

    def test_sneaky_js_in_math_style(self):
        # This gets parsed as <math> -> <style>""...""</style>
        # thus passing any tag/script/whatever content through into the output.
        html = '<math><style><img src=x onerror=alert(1)></style></math>'
        s = lxml.html.fragment_fromstring(html)

        self.assertEqual(
            b'<math><style>/* deleted */</style></math>',
            lxml.html.tostring(clean_html(s)))

    def test_formaction_attribute_in_button_input(self):
        # The formaction attribute overrides the form's action and should be
        # treated as a malicious link attribute
        html = ('<form id=""test""><input type=""submit"" formaction=""javascript:alert(1)""></form>'
        '<button form=""test"" formaction=""javascript:alert(1)"">X</button>')
        expected = ('<div><form id=""test""><input type=""submit"" formaction=""""></form>'
        '<button form=""test"" formaction="""">X</button></div>')
        cleaner = Cleaner(
            forms=False,
            safe_attrs_only=False,
        )
        self.assertEqual(
            expected,
            cleaner.clean_html(html))


def test_suite():
    suite = unittest.TestSuite()
    suite.addTests([make_doctest('test_clean.txt')])
    suite.addTests([make_doctest('test_clean_embed.txt')])
    suite.addTests(unittest.makeSuite(CleanerTest))
    return suite
",CWE-74,148.0,1
"# this is a package

__version__ = ""4.6.4""


def get_include():
    """"""
    Returns a list of header include paths (for lxml itself, libxml2
    and libxslt) needed to compile C code against lxml if it was built
    with statically linked libraries.
    """"""
    import os
    lxml_path = __path__[0]
    include_path = os.path.join(lxml_path, 'includes')
    includes = [include_path, lxml_path]

    for name in os.listdir(include_path):
        path = os.path.join(include_path, name)
        if os.path.isdir(path):
            includes.append(path)

    return includes

",CWE-79,24.0,1
"# this is a package

__version__ = ""4.6.4""


def get_include():
    """"""
    Returns a list of header include paths (for lxml itself, libxml2
    and libxslt) needed to compile C code against lxml if it was built
    with statically linked libraries.
    """"""
    import os
    lxml_path = __path__[0]
    include_path = os.path.join(lxml_path, 'includes')
    includes = [include_path, lxml_path]

    for name in os.listdir(include_path):
        path = os.path.join(include_path, name)
        if os.path.isdir(path):
            includes.append(path)

    return includes

",CWE-74,24.0,1
,CWE-401,,1
"# -*- coding: utf-8 -*-

##############################################################################
#                        2011 E2OpenPlugins                                  #
#                                                                            #
#  This file is open source software; you can redistribute it and/or modify  #
#     it under the terms of the GNU General Public License version 2 as      #
#               published by the Free Software Foundation.                   #
#                                                                            #
##############################################################################

import os
import re
import glob
from urllib import quote
import json

from twisted.web import static, resource, http

from Components.config import config
from Tools.Directories import fileExists

def new_getRequestHostname(self):
	host = self.getHeader(b'host')
	if host:
		if host[0]=='[':
			return host.split(']',1)[0] + ""]""
		return host.split(':', 1)[0].encode('ascii')
	return self.getHost().host.encode('ascii')

http.Request.getRequestHostname = new_getRequestHostname


class FileController(resource.Resource):
	def render(self, request):
		action = ""download""
		if ""action"" in request.args:
			action = request.args[""action""][0]

		if ""file"" in request.args:
			filename = request.args[""file""][0].decode('utf-8', 'ignore').encode('utf-8')
			filename = re.sub(""^/+"", ""/"", os.path.realpath(filename))

			if not os.path.exists(filename):
				return ""File '%s' not found"" % (filename)

			if action == ""stream"":
				name = ""stream""
				if ""name"" in request.args:
					name = request.args[""name""][0]

				port = config.OpenWebif.port.value
				proto = 'http'
				if request.isSecure():
					port = config.OpenWebif.https_port.value
					proto = 'https'
				ourhost = request.getHeader('host')
				m = re.match('.+\:(\d+)$', ourhost)
				if m is not None:
					port = m.group(1)

				response = ""#EXTM3U\n#EXTVLCOPT--http-reconnect=true\n#EXTINF:-1,%s\n%s://%s:%s/file?action=download&file=%s"" % (name, proto, request.getRequestHostname(), port, quote(filename))
				request.setHeader(""Content-Disposition"", 'attachment;filename=""%s.m3u""' % name)
				request.setHeader(""Content-Type"", ""application/x-mpegurl"")
				return response
			elif action == ""delete"":
				request.setResponseCode(http.OK)
				return ""TODO: DELETE FILE: %s"" % (filename)
			elif action == ""download"":
				request.setHeader(""Content-Disposition"", ""attachment;filename=\""%s\"""" % (filename.split('/')[-1]))
				rfile = static.File(filename, defaultType = ""application/octet-stream"")
				return rfile.render(request)
			else: 
				return ""wrong action parameter""

		if ""dir"" in request.args:
			path = request.args[""dir""][0]
			pattern = '*'
			data = []
			if ""pattern"" in request.args:
				pattern = request.args[""pattern""][0]
			directories = []
			files = []
			if fileExists(path):
				try:
					files = glob.glob(path+'/'+pattern)
				except:
					files = []
				files.sort()
				tmpfiles = files[:]
				for x in tmpfiles:
					if os.path.isdir(x):
						directories.append(x + '/')
						files.remove(x)
				data.append({""result"": True,""dirs"": directories,""files"": files})
			else:
				data.append({""result"": False,""message"": ""path %s not exits"" % (path)})
			request.setHeader(""content-type"", ""application/json; charset=utf-8"")
			return json.dumps(data, indent=2)
",CWE-22,100.0,1
"# Grammar for Python

# NOTE WELL: You should also follow all the steps listed at
# https://devguide.python.org/grammar/

# Start symbols for the grammar:
#       single_input is a single interactive statement;
#       file_input is a module or sequence of commands read from an input file;
#       eval_input is the input for the eval() functions.
# NB: compound_stmt in single_input is followed by extra NEWLINE!
single_input: NEWLINE | simple_stmt | compound_stmt NEWLINE
file_input: (NEWLINE | stmt)* ENDMARKER
eval_input: testlist NEWLINE* ENDMARKER

decorator: '@' dotted_name [ '(' [arglist] ')' ] NEWLINE
decorators: decorator+
decorated: decorators (classdef | funcdef | async_funcdef)

async_funcdef: 'async' funcdef
funcdef: 'def' NAME parameters ['->' test] ':' suite

parameters: '(' [typedargslist] ')'
typedargslist: (tfpdef ['=' test] (',' tfpdef ['=' test])* [',' [
        '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]
      | '**' tfpdef [',']]]
  | '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]
  | '**' tfpdef [','])
tfpdef: NAME [':' test]
varargslist: (vfpdef ['=' test] (',' vfpdef ['=' test])* [',' [
        '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]
      | '**' vfpdef [',']]]
  | '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]
  | '**' vfpdef [',']
)
vfpdef: NAME

stmt: simple_stmt | compound_stmt
simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE
small_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |
             import_stmt | global_stmt | nonlocal_stmt | assert_stmt)
expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |
                     ('=' (yield_expr|testlist_star_expr))*)
annassign: ':' test ['=' (yield_expr|testlist)]
testlist_star_expr: (test|star_expr) (',' (test|star_expr))* [',']
augassign: ('+=' | '-=' | '*=' | '@=' | '/=' | '%=' | '&=' | '|=' | '^=' |
            '<<=' | '>>=' | '**=' | '//=')
# For normal and annotated assignments, additional restrictions enforced by the interpreter
del_stmt: 'del' exprlist
pass_stmt: 'pass'
flow_stmt: break_stmt | continue_stmt | return_stmt | raise_stmt | yield_stmt
break_stmt: 'break'
continue_stmt: 'continue'
return_stmt: 'return' [testlist_star_expr]
yield_stmt: yield_expr
raise_stmt: 'raise' [test ['from' test]]
import_stmt: import_name | import_from
import_name: 'import' dotted_as_names
# note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS
import_from: ('from' (('.' | '...')* dotted_name | ('.' | '...')+)
              'import' ('*' | '(' import_as_names ')' | import_as_names))
import_as_name: NAME ['as' NAME]
dotted_as_name: dotted_name ['as' NAME]
import_as_names: import_as_name (',' import_as_name)* [',']
dotted_as_names: dotted_as_name (',' dotted_as_name)*
dotted_name: NAME ('.' NAME)*
global_stmt: 'global' NAME (',' NAME)*
nonlocal_stmt: 'nonlocal' NAME (',' NAME)*
assert_stmt: 'assert' test [',' test]

compound_stmt: if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | decorated | async_stmt
async_stmt: 'async' (funcdef | with_stmt | for_stmt)
if_stmt: 'if' namedexpr_test ':' suite ('elif' namedexpr_test ':' suite)* ['else' ':' suite]
while_stmt: 'while' test ':' suite ['else' ':' suite]
for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite]
try_stmt: ('try' ':' suite
           ((except_clause ':' suite)+
            ['else' ':' suite]
            ['finally' ':' suite] |
           'finally' ':' suite))
with_stmt: 'with' with_item (',' with_item)*  ':' suite
with_item: test ['as' expr]
# NB compile.c makes sure that the default except clause is last
except_clause: 'except' [test ['as' NAME]]
suite: simple_stmt | NEWLINE INDENT stmt+ DEDENT

namedexpr_test: test [':=' test]
test: or_test ['if' or_test 'else' test] | lambdef
test_nocond: or_test | lambdef_nocond
lambdef: 'lambda' [varargslist] ':' test
lambdef_nocond: 'lambda' [varargslist] ':' test_nocond
or_test: and_test ('or' and_test)*
and_test: not_test ('and' not_test)*
not_test: 'not' not_test | comparison
comparison: expr (comp_op expr)*
# <> isn't actually a valid comparison operator in Python. It's here for the
# sake of a __future__ import described in PEP 401 (which really works :-)
comp_op: '<'|'>'|'=='|'>='|'<='|'<>'|'!='|'in'|'not' 'in'|'is'|'is' 'not'
star_expr: '*' expr
expr: xor_expr ('|' xor_expr)*
xor_expr: and_expr ('^' and_expr)*
and_expr: shift_expr ('&' shift_expr)*
shift_expr: arith_expr (('<<'|'>>') arith_expr)*
arith_expr: term (('+'|'-') term)*
term: factor (('*'|'@'|'/'|'%'|'//') factor)*
factor: ('+'|'-'|'~') factor | power
power: atom_expr ['**' factor]
atom_expr: ['await'] atom trailer*
atom: ('(' [yield_expr|testlist_comp] ')' |
       '[' [testlist_comp] ']' |
       '{' [dictorsetmaker] '}' |
       NAME | NUMBER | STRING+ | '...' | 'None' | 'True' | 'False')
testlist_comp: (namedexpr_test|star_expr) ( comp_for | (',' (namedexpr_test|star_expr))* [','] )
trailer: '(' [arglist] ')' | '[' subscriptlist ']' | '.' NAME
subscriptlist: subscript (',' subscript)* [',']
subscript: test | [test] ':' [test] [sliceop]
sliceop: ':' [test]
exprlist: (expr|star_expr) (',' (expr|star_expr))* [',']
testlist: test (',' test)* [',']
dictorsetmaker: ( ((test ':' test | '**' expr)
                   (comp_for | (',' (test ':' test | '**' expr))* [','])) |
                  ((test | star_expr)
                   (comp_for | (',' (test | star_expr))* [','])) )

classdef: 'class' NAME ['(' [arglist] ')'] ':' suite

arglist: argument (',' argument)*  [',']

# The reason that keywords are test nodes instead of NAME is that using NAME
# results in an ambiguity. ast.c makes sure it's a NAME.
# ""test '=' test"" is really ""keyword '=' test"", but we have no such token.
# These need to be in a single rule to avoid grammar that is ambiguous
# to our LL(1) parser. Even though 'test' includes '*expr' in star_expr,
# we explicitly match '*' here, too, to give it proper precedence.
# Illegal combinations and orderings are blocked in ast.c:
# multiple (test comp_for) arguments are blocked; keyword unpackings
# that precede iterable unpackings are blocked; etc.
argument: ( test [comp_for] |
            test ':=' test |
            test '=' test |
            '**' test |
            '*' test )

comp_iter: comp_for | comp_if
sync_comp_for: 'for' exprlist 'in' or_test [comp_iter]
comp_for: ['async'] sync_comp_for
comp_if: 'if' test_nocond [comp_iter]

# not used in grammar, but may appear in ""node"" passed from Parser to Compiler
encoding_decl: NAME

yield_expr: 'yield' [yield_arg]
yield_arg: 'from' test | testlist_star_expr
",CWE-125,153.0,1
"""""""Non-terminal symbols of Python grammar (from ""graminit.h"").""""""

#  This file is automatically generated; please don't muck it up!
#
#  To update the symbols in this file, 'cd' to the top directory of
#  the python source tree after building the interpreter and run:
#
#    python3 Tools/scripts/generate_symbol_py.py Include/graminit.h Lib/symbol.py
#
# or just
#
#    make regen-symbol

#--start constants--
single_input = 256
file_input = 257
eval_input = 258
decorator = 259
decorators = 260
decorated = 261
async_funcdef = 262
funcdef = 263
parameters = 264
typedargslist = 265
tfpdef = 266
varargslist = 267
vfpdef = 268
stmt = 269
simple_stmt = 270
small_stmt = 271
expr_stmt = 272
annassign = 273
testlist_star_expr = 274
augassign = 275
del_stmt = 276
pass_stmt = 277
flow_stmt = 278
break_stmt = 279
continue_stmt = 280
return_stmt = 281
yield_stmt = 282
raise_stmt = 283
import_stmt = 284
import_name = 285
import_from = 286
import_as_name = 287
dotted_as_name = 288
import_as_names = 289
dotted_as_names = 290
dotted_name = 291
global_stmt = 292
nonlocal_stmt = 293
assert_stmt = 294
compound_stmt = 295
async_stmt = 296
if_stmt = 297
while_stmt = 298
for_stmt = 299
try_stmt = 300
with_stmt = 301
with_item = 302
except_clause = 303
suite = 304
namedexpr_test = 305
test = 306
test_nocond = 307
lambdef = 308
lambdef_nocond = 309
or_test = 310
and_test = 311
not_test = 312
comparison = 313
comp_op = 314
star_expr = 315
expr = 316
xor_expr = 317
and_expr = 318
shift_expr = 319
arith_expr = 320
term = 321
factor = 322
power = 323
atom_expr = 324
atom = 325
testlist_comp = 326
trailer = 327
subscriptlist = 328
subscript = 329
sliceop = 330
exprlist = 331
testlist = 332
dictorsetmaker = 333
classdef = 334
arglist = 335
argument = 336
comp_iter = 337
sync_comp_for = 338
comp_for = 339
comp_if = 340
encoding_decl = 341
yield_expr = 342
yield_arg = 343
#--end constants--

sym_name = {}
for _name, _value in list(globals().items()):
    if type(_value) is type(0):
        sym_name[_value] = _name
del _name, _value
",CWE-125,110.0,1
"""""""Tests for the asdl parser in Parser/asdl.py""""""

import importlib.machinery
import os
from os.path import dirname
import sys
import sysconfig
import unittest


# This test is only relevant for from-source builds of Python.
if not sysconfig.is_python_build():
    raise unittest.SkipTest('test irrelevant for an installed Python')

src_base = dirname(dirname(dirname(__file__)))
parser_dir = os.path.join(src_base, 'Parser')


class TestAsdlParser(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        # Loads the asdl module dynamically, since it's not in a real importable
        # package.
        # Parses Python.asdl into an ast.Module and run the check on it.
        # There's no need to do this for each test method, hence setUpClass.
        sys.path.insert(0, parser_dir)
        loader = importlib.machinery.SourceFileLoader(
                'asdl', os.path.join(parser_dir, 'asdl.py'))
        cls.asdl = loader.load_module()
        cls.mod = cls.asdl.parse(os.path.join(parser_dir, 'Python.asdl'))
        cls.assertTrue(cls.asdl.check(cls.mod), 'Module validation failed')

    @classmethod
    def tearDownClass(cls):
        del sys.path[0]

    def setUp(self):
        # alias stuff from the class, for convenience
        self.asdl = TestAsdlParser.asdl
        self.mod = TestAsdlParser.mod
        self.types = self.mod.types

    def test_module(self):
        self.assertEqual(self.mod.name, 'Python')
        self.assertIn('stmt', self.types)
        self.assertIn('expr', self.types)
        self.assertIn('mod', self.types)

    def test_definitions(self):
        defs = self.mod.dfns
        self.assertIsInstance(defs[0], self.asdl.Type)
        self.assertIsInstance(defs[0].value, self.asdl.Sum)

        self.assertIsInstance(self.types['withitem'], self.asdl.Product)
        self.assertIsInstance(self.types['alias'], self.asdl.Product)

    def test_product(self):
        alias = self.types['alias']
        self.assertEqual(
            str(alias),
            'Product([Field(identifier, name), Field(identifier, asname, opt=True)])')

    def test_attributes(self):
        stmt = self.types['stmt']
        self.assertEqual(len(stmt.attributes), 4)
        self.assertEqual(str(stmt.attributes[0]), 'Field(int, lineno)')
        self.assertEqual(str(stmt.attributes[1]), 'Field(int, col_offset)')
        self.assertEqual(str(stmt.attributes[2]), 'Field(int, end_lineno, opt=True)')
        self.assertEqual(str(stmt.attributes[3]), 'Field(int, end_col_offset, opt=True)')

    def test_constructor_fields(self):
        ehandler = self.types['excepthandler']
        self.assertEqual(len(ehandler.types), 1)
        self.assertEqual(len(ehandler.attributes), 4)

        cons = ehandler.types[0]
        self.assertIsInstance(cons, self.asdl.Constructor)
        self.assertEqual(len(cons.fields), 3)

        f0 = cons.fields[0]
        self.assertEqual(f0.type, 'expr')
        self.assertEqual(f0.name, 'type')
        self.assertTrue(f0.opt)

        f1 = cons.fields[1]
        self.assertEqual(f1.type, 'identifier')
        self.assertEqual(f1.name, 'name')
        self.assertTrue(f1.opt)

        f2 = cons.fields[2]
        self.assertEqual(f2.type, 'stmt')
        self.assertEqual(f2.name, 'body')
        self.assertFalse(f2.opt)
        self.assertTrue(f2.seq)

    def test_visitor(self):
        class CustomVisitor(self.asdl.VisitorBase):
            def __init__(self):
                super().__init__()
                self.names_with_seq = []

            def visitModule(self, mod):
                for dfn in mod.dfns:
                    self.visit(dfn)

            def visitType(self, type):
                self.visit(type.value)

            def visitSum(self, sum):
                for t in sum.types:
                    self.visit(t)

            def visitConstructor(self, cons):
                for f in cons.fields:
                    if f.seq:
                        self.names_with_seq.append(cons.name)

        v = CustomVisitor()
        v.visit(self.types['mod'])
        self.assertEqual(v.names_with_seq, ['Module', 'Interactive', 'Suite'])


if __name__ == '__main__':
    unittest.main()
",CWE-125,125.0,1
"""""""Token constants.""""""
# Auto-generated by Tools/scripts/generate_token.py

__all__ = ['tok_name', 'ISTERMINAL', 'ISNONTERMINAL', 'ISEOF']

ENDMARKER = 0
NAME = 1
NUMBER = 2
STRING = 3
NEWLINE = 4
INDENT = 5
DEDENT = 6
LPAR = 7
RPAR = 8
LSQB = 9
RSQB = 10
COLON = 11
COMMA = 12
SEMI = 13
PLUS = 14
MINUS = 15
STAR = 16
SLASH = 17
VBAR = 18
AMPER = 19
LESS = 20
GREATER = 21
EQUAL = 22
DOT = 23
PERCENT = 24
LBRACE = 25
RBRACE = 26
EQEQUAL = 27
NOTEQUAL = 28
LESSEQUAL = 29
GREATEREQUAL = 30
TILDE = 31
CIRCUMFLEX = 32
LEFTSHIFT = 33
RIGHTSHIFT = 34
DOUBLESTAR = 35
PLUSEQUAL = 36
MINEQUAL = 37
STAREQUAL = 38
SLASHEQUAL = 39
PERCENTEQUAL = 40
AMPEREQUAL = 41
VBAREQUAL = 42
CIRCUMFLEXEQUAL = 43
LEFTSHIFTEQUAL = 44
RIGHTSHIFTEQUAL = 45
DOUBLESTAREQUAL = 46
DOUBLESLASH = 47
DOUBLESLASHEQUAL = 48
AT = 49
ATEQUAL = 50
RARROW = 51
ELLIPSIS = 52
COLONEQUAL = 53
OP = 54
# These aren't used by the C tokenizer but are needed for tokenize.py
ERRORTOKEN = 55
COMMENT = 56
NL = 57
ENCODING = 58
N_TOKENS = 59
# Special definitions for cooperation with parser
NT_OFFSET = 256

tok_name = {value: name
            for name, value in globals().items()
            if isinstance(value, int) and not name.startswith('_')}
__all__.extend(tok_name.values())

EXACT_TOKEN_TYPES = {
    '!=': NOTEQUAL,
    '%': PERCENT,
    '%=': PERCENTEQUAL,
    '&': AMPER,
    '&=': AMPEREQUAL,
    '(': LPAR,
    ')': RPAR,
    '*': STAR,
    '**': DOUBLESTAR,
    '**=': DOUBLESTAREQUAL,
    '*=': STAREQUAL,
    '+': PLUS,
    '+=': PLUSEQUAL,
    ',': COMMA,
    '-': MINUS,
    '-=': MINEQUAL,
    '->': RARROW,
    '.': DOT,
    '...': ELLIPSIS,
    '/': SLASH,
    '//': DOUBLESLASH,
    '//=': DOUBLESLASHEQUAL,
    '/=': SLASHEQUAL,
    ':': COLON,
    ':=': COLONEQUAL,
    ';': SEMI,
    '<': LESS,
    '<<': LEFTSHIFT,
    '<<=': LEFTSHIFTEQUAL,
    '<=': LESSEQUAL,
    '=': EQUAL,
    '==': EQEQUAL,
    '>': GREATER,
    '>=': GREATEREQUAL,
    '>>': RIGHTSHIFT,
    '>>=': RIGHTSHIFTEQUAL,
    '@': AT,
    '@=': ATEQUAL,
    '[': LSQB,
    ']': RSQB,
    '^': CIRCUMFLEX,
    '^=': CIRCUMFLEXEQUAL,
    '{': LBRACE,
    '|': VBAR,
    '|=': VBAREQUAL,
    '}': RBRACE,
    '~': TILDE,
}

def ISTERMINAL(x):
    return x < NT_OFFSET

def ISNONTERMINAL(x):
    return x >= NT_OFFSET

def ISEOF(x):
    return x == ENDMARKER
",CWE-125,133.0,1
,CWE-20,,1
"# Copyright 2019 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Raw ops tests.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.eager import context
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import ops
from tensorflow.python.framework import test_util
from tensorflow.python.ops import gen_math_ops
from tensorflow.python.platform import test


@test_util.run_all_in_graph_and_eager_modes
class RawOpsTest(test.TestCase):

  def testSimple(self):
    x = constant_op.constant(1)
    self.assertEqual([2], self.evaluate(gen_math_ops.Add(x=x, y=x)))

  def testRequiresKwargs(self):
    with self.assertRaisesRegex(TypeError, ""only takes keyword args""):
      gen_math_ops.Add(1., 1.)

  def testRequiresKwargs_providesSuggestion(self):
    msg = ""possible keys: \\['x', 'y', 'name'\\]""
    with self.assertRaisesRegex(TypeError, msg):
      gen_math_ops.Add(1., y=2.)

  def testName(self):
    x = constant_op.constant(1)
    op = gen_math_ops.Add(x=x, y=x, name=""double"")
    if not context.executing_eagerly():
      # `Tensor.name` is not available in eager.
      self.assertEqual(op.name, ""double:0"")

  def testDoc(self):
    self.assertEqual(gen_math_ops.add.__doc__, gen_math_ops.Add.__doc__)

  def testDefaults(self):
    x = constant_op.constant([[True]])
    self.assertAllClose(
        gen_math_ops.Any(input=x, axis=0),
        gen_math_ops.Any(input=x, axis=0, keep_dims=False))


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-787,65.0,1
"# Copyright 2019 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Raw ops tests.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized

from tensorflow.python.eager import context
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import errors
from tensorflow.python.framework import ops
from tensorflow.python.framework import test_util
from tensorflow.python.ops import gen_math_ops
from tensorflow.python.ops import gen_string_ops
from tensorflow.python.platform import test


@test_util.run_all_in_graph_and_eager_modes
@test_util.disable_tfrt
class RawOpsTest(test.TestCase, parameterized.TestCase):

  def testSimple(self):
    x = constant_op.constant(1)
    self.assertEqual([2], self.evaluate(gen_math_ops.Add(x=x, y=x)))

  def testRequiresKwargs(self):
    with self.assertRaisesRegex(TypeError, ""only takes keyword args""):
      gen_math_ops.Add(1., 1.)

  def testRequiresKwargs_providesSuggestion(self):
    msg = ""possible keys: \\['x', 'y', 'name'\\]""
    with self.assertRaisesRegex(TypeError, msg):
      gen_math_ops.Add(1., y=2.)

  def testName(self):
    x = constant_op.constant(1)
    op = gen_math_ops.Add(x=x, y=x, name=""double"")
    if not context.executing_eagerly():
      # `Tensor.name` is not available in eager.
      self.assertEqual(op.name, ""double:0"")

  def testDoc(self):
    self.assertEqual(gen_math_ops.add.__doc__, gen_math_ops.Add.__doc__)

  def testDefaults(self):
    x = constant_op.constant([[True]])
    self.assertAllClose(
        gen_math_ops.Any(input=x, axis=0),
        gen_math_ops.Any(input=x, axis=0, keep_dims=False))

  @parameterized.parameters([[0, 8]], [[-1, 6]])
  def testStringNGramsBadDataSplits(self, splits):
    data = [""aa"", ""bb"", ""cc"", ""dd"", ""ee"", ""ff""]
    with self.assertRaisesRegex(errors.InvalidArgumentError,
                                ""Invalid split value""):
      self.evaluate(
          gen_string_ops.string_n_grams(
              data=data,
              data_splits=splits,
              separator="""",
              ngram_widths=[2],
              left_pad="""",
              right_pad="""",
              pad_width=0,
              preserve_short_sequences=False))


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-476,86.0,1
"# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for DLPack functions.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np

from tensorflow.python.dlpack import dlpack
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.platform import test
from tensorflow.python.ops import array_ops

int_dtypes = [
    np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32,
    np.uint64
]
float_dtypes = [np.float16, np.float32, np.float64]
complex_dtypes = [np.complex64, np.complex128]
dlpack_dtypes = int_dtypes + float_dtypes + [dtypes.bfloat16]

testcase_shapes = [(), (1,), (2, 3), (2, 0), (0, 7), (4, 1, 2)]


def FormatShapeAndDtype(shape, dtype):
  return ""_{}[{}]"".format(str(dtype), "","".join(map(str, shape)))


def GetNamedTestParameters():
  result = []
  for dtype in dlpack_dtypes:
    for shape in testcase_shapes:
      result.append({
          ""testcase_name"": FormatShapeAndDtype(shape, dtype),
          ""dtype"": dtype,
          ""shape"": shape
      })
  return result


class DLPackTest(parameterized.TestCase, test.TestCase):

  @parameterized.named_parameters(GetNamedTestParameters())
  def testRoundTrip(self, dtype, shape):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, shape)
    # copy to gpu if available
    tf_tensor = array_ops.identity(constant_op.constant(np_array, dtype=dtype))
    tf_tensor_device = tf_tensor.device
    tf_tensor_dtype = tf_tensor.dtype
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    tf_tensor2 = dlpack.from_dlpack(dlcapsule)
    self.assertAllClose(np_array, tf_tensor2)
    if tf_tensor_dtype == dtypes.int32:
      # int32 tensor is always on cpu for now
      self.assertEqual(tf_tensor2.device,
                       ""/job:localhost/replica:0/task:0/device:CPU:0"")
    else:
      self.assertEqual(tf_tensor_device, tf_tensor2.device)

  def testTensorsCanBeConsumedOnceOnly(self):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, (2, 3, 4))
    tf_tensor = constant_op.constant(np_array, dtype=np.float32)
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    _ = dlpack.from_dlpack(dlcapsule)

    def ConsumeDLPackTensor():
      dlpack.from_dlpack(dlcapsule)  # Should can be consumed only once

    self.assertRaisesRegex(Exception,
                           "".*a DLPack tensor may be consumed at most once.*"",
                           ConsumeDLPackTensor)

  def testUnsupportedTypeToDLPack(self):

    def UnsupportedQint16():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.qint16)
      _ = dlpack.to_dlpack(tf_tensor)

    def UnsupportedComplex64():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.complex64)
      _ = dlpack.to_dlpack(tf_tensor)

    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedQint16)
    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedComplex64)


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-252,112.0,1
"# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for DLPack functions.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np

from tensorflow.python.dlpack import dlpack
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.platform import test
from tensorflow.python.ops import array_ops

int_dtypes = [
    np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32,
    np.uint64
]
float_dtypes = [np.float16, np.float32, np.float64]
complex_dtypes = [np.complex64, np.complex128]
dlpack_dtypes = int_dtypes + float_dtypes + [dtypes.bfloat16]

testcase_shapes = [(), (1,), (2, 3), (2, 0), (0, 7), (4, 1, 2)]


def FormatShapeAndDtype(shape, dtype):
  return ""_{}[{}]"".format(str(dtype), "","".join(map(str, shape)))


def GetNamedTestParameters():
  result = []
  for dtype in dlpack_dtypes:
    for shape in testcase_shapes:
      result.append({
          ""testcase_name"": FormatShapeAndDtype(shape, dtype),
          ""dtype"": dtype,
          ""shape"": shape
      })
  return result


class DLPackTest(parameterized.TestCase, test.TestCase):

  @parameterized.named_parameters(GetNamedTestParameters())
  def testRoundTrip(self, dtype, shape):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, shape)
    # copy to gpu if available
    tf_tensor = array_ops.identity(constant_op.constant(np_array, dtype=dtype))
    tf_tensor_device = tf_tensor.device
    tf_tensor_dtype = tf_tensor.dtype
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    tf_tensor2 = dlpack.from_dlpack(dlcapsule)
    self.assertAllClose(np_array, tf_tensor2)
    if tf_tensor_dtype == dtypes.int32:
      # int32 tensor is always on cpu for now
      self.assertEqual(tf_tensor2.device,
                       ""/job:localhost/replica:0/task:0/device:CPU:0"")
    else:
      self.assertEqual(tf_tensor_device, tf_tensor2.device)

  def testTensorsCanBeConsumedOnceOnly(self):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, (2, 3, 4))
    tf_tensor = constant_op.constant(np_array, dtype=np.float32)
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    _ = dlpack.from_dlpack(dlcapsule)

    def ConsumeDLPackTensor():
      dlpack.from_dlpack(dlcapsule)  # Should can be consumed only once

    self.assertRaisesRegex(Exception,
                           "".*a DLPack tensor may be consumed at most once.*"",
                           ConsumeDLPackTensor)

  def testUnsupportedTypeToDLPack(self):

    def UnsupportedQint16():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.qint16)
      _ = dlpack.to_dlpack(tf_tensor)

    def UnsupportedComplex64():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.complex64)
      _ = dlpack.to_dlpack(tf_tensor)

    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedQint16)
    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedComplex64)


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-20,112.0,1
"# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for DLPack functions.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np

from tensorflow.python.dlpack import dlpack
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.platform import test
from tensorflow.python.ops import array_ops

int_dtypes = [
    np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32,
    np.uint64
]
float_dtypes = [np.float16, np.float32, np.float64]
complex_dtypes = [np.complex64, np.complex128]
dlpack_dtypes = int_dtypes + float_dtypes + [dtypes.bfloat16]

testcase_shapes = [(), (1,), (2, 3), (2, 0), (0, 7), (4, 1, 2)]


def FormatShapeAndDtype(shape, dtype):
  return ""_{}[{}]"".format(str(dtype), "","".join(map(str, shape)))


def GetNamedTestParameters():
  result = []
  for dtype in dlpack_dtypes:
    for shape in testcase_shapes:
      result.append({
          ""testcase_name"": FormatShapeAndDtype(shape, dtype),
          ""dtype"": dtype,
          ""shape"": shape
      })
  return result


class DLPackTest(parameterized.TestCase, test.TestCase):

  @parameterized.named_parameters(GetNamedTestParameters())
  def testRoundTrip(self, dtype, shape):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, shape)
    # copy to gpu if available
    tf_tensor = array_ops.identity(constant_op.constant(np_array, dtype=dtype))
    tf_tensor_device = tf_tensor.device
    tf_tensor_dtype = tf_tensor.dtype
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    tf_tensor2 = dlpack.from_dlpack(dlcapsule)
    self.assertAllClose(np_array, tf_tensor2)
    if tf_tensor_dtype == dtypes.int32:
      # int32 tensor is always on cpu for now
      self.assertEqual(tf_tensor2.device,
                       ""/job:localhost/replica:0/task:0/device:CPU:0"")
    else:
      self.assertEqual(tf_tensor_device, tf_tensor2.device)

  def testTensorsCanBeConsumedOnceOnly(self):
    np.random.seed(42)
    np_array = np.random.randint(0, 10, (2, 3, 4))
    tf_tensor = constant_op.constant(np_array, dtype=np.float32)
    dlcapsule = dlpack.to_dlpack(tf_tensor)
    del tf_tensor  # should still work
    _ = dlpack.from_dlpack(dlcapsule)

    def ConsumeDLPackTensor():
      dlpack.from_dlpack(dlcapsule)  # Should can be consumed only once

    self.assertRaisesRegex(Exception,
                           "".*a DLPack tensor may be consumed at most once.*"",
                           ConsumeDLPackTensor)

  def testUnsupportedTypeToDLPack(self):

    def UnsupportedQint16():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.qint16)
      _ = dlpack.to_dlpack(tf_tensor)

    def UnsupportedComplex64():
      tf_tensor = constant_op.constant([[1, 4], [5, 2]], dtype=dtypes.complex64)
      _ = dlpack.to_dlpack(tf_tensor)

    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedQint16)
    self.assertRaisesRegex(Exception, "".* is not supported by dlpack"",
                           UnsupportedComplex64)


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-908,112.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for SoftmaxCrossEntropyWithLogits op.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import itertools
import sys

import numpy as np

from tensorflow.python.client import session
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework import test_util
from tensorflow.python.kernel_tests import xent_op_test_base
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import gen_nn_ops
from tensorflow.python.ops import nn_ops
from tensorflow.python.platform import test


class XentOpTest(xent_op_test_base.XentOpTestBase):

  @test_util.run_deprecated_v1
  def testRankTooLarge(self):
    for dtype in np.float16, np.float32:
      np_features = np.array([[[1., 1., 1., 1.]], [[1., 2., 3.,
                                                    4.]]]).astype(dtype)
      np_labels = np.array([[[0., 0., 0., 1.]], [[0., .5, .5,
                                                  0.]]]).astype(dtype)
      self.assertRaisesRegex(ValueError, ""rank 2, but is rank 3"",
                             gen_nn_ops.softmax_cross_entropy_with_logits,
                             np_features, np_labels)

  def testFeaturesBroadcast(self):
    np_f = np.array([[1., 2., 3., 4.],
                     [1., 2., 3., 4.]]).astype(np.float32)
    np_l = np.array([[0., 0., 0., 1.],
                     [0., .5, .5, 0.]]).astype(np.float32)
    np_loss, np_gradient = self._npXent(labels=np_l, logits=np_f)
    tf_f = constant_op.constant(
        np.array([[1., 2., 3., 4.]]).astype(np.float32))
    tf_l = constant_op.constant(
        np.array([[0., 0., 0., 1.], [0., .5, .5, 0.]]).astype(np.float32))
    tf_loss, tf_gradient = gen_nn_ops.softmax_cross_entropy_with_logits(
        tf_f, tf_l)
    self.assertAllCloseAccordingToType(np_loss, tf_loss)
    self.assertAllCloseAccordingToType(np_gradient, tf_gradient)

  @test_util.run_deprecated_v1
  def testNotMatrix(self):
    with self.cached_session():
      with self.assertRaises(ValueError):
        gen_nn_ops.softmax_cross_entropy_with_logits([0., 1., 2., 3.],
                                                     [0., 1., 0., 1.])


class XentBenchmark(test.Benchmark):

  def benchmarkZeroDimension(self):
    for (m, n, p, use_gpu) in itertools.product(
        [128],
        [10, 100, 1000, 10000, 100000],
        [0.001, 0.01, 0.5, 0.99, 1.0],
        [False]):
      k = int(p * n)
      if k == 0:
        continue
      name = ""zero_dimension_m_%d_n_%d_k_%g_use_gpu_%s"" % (m, n, k, use_gpu)
      device = ""/%s:0"" % (""gpu"" if use_gpu else ""cpu"")
      with ops.Graph().as_default():
        with ops.device(device):
          labels = array_ops.zeros([0, 2, 4], dtype=dtypes.float32)
          logits = array_ops.zeros([0, 2, 4], dtype=dtypes.float32)
          op = nn_ops.softmax_cross_entropy_with_logits(
              labels=labels, logits=logits)
        with session.Session() as sess:
          r = self.run_op_benchmark(sess, op, min_iters=100, name=name)
          gb_processed_input = m * n / 1.0e9
          throughput = gb_processed_input / r[""wall_time""]
          print(""Benchmark: %s \t wall_time: %0.03g s \t ""
                ""Throughput: %0.03g GB/s"" % (name, r[""wall_time""], throughput))
          sys.stdout.flush()

  def benchmarkSingleClass(self):
    for (m, n, p, use_gpu) in itertools.product(
        [128],
        [10, 100, 1000, 10000, 100000],
        [0.001, 0.01, 0.5, 0.99, 1.0],
        [False]):
      k = int(p * n)
      if k == 0:
        continue
      name = ""single_class_m_%d_n_%d_k_%g_use_gpu_%s"" % (m, n, k, use_gpu)
      device = ""/%s:0"" % (""gpu"" if use_gpu else ""cpu"")
      with ops.Graph().as_default():
        with ops.device(device):
          labels = constant_op.constant([[1.], [-1.], [0.]],
                                        dtype=dtypes.float32)
          logits = constant_op.constant([[-1.], [0.], [1.]],
                                        dtype=dtypes.float32)
          op = nn_ops.softmax_cross_entropy_with_logits(
              labels=labels, logits=logits)
        with session.Session() as sess:
          r = self.run_op_benchmark(sess, op, min_iters=100, name=name)
          gb_processed_input = m * n / 1.0e9
          throughput = gb_processed_input / r[""wall_time""]
          print(""Benchmark: %s \t wall_time: %0.03g s \t ""
                ""Throughput: %0.03g GB/s"" % (name, r[""wall_time""], throughput))
          sys.stdout.flush()


if __name__ == ""__main__"":
  test.main()
",CWE-354,131.0,1
"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
# pylint: disable=protected-access
""""""Functions that save the model's config into different formats.""""""

from tensorflow.python.keras.saving.saved_model import json_utils
from tensorflow.python.util.tf_export import keras_export

# pylint: disable=g-import-not-at-top
try:
  import yaml
except ImportError:
  yaml = None
# pylint: enable=g-import-not-at-top


@keras_export('keras.models.model_from_config')
def model_from_config(config, custom_objects=None):
  """"""Instantiates a Keras model from its config.
 
  Usage:
  ```
  # for a Functional API model
  tf.keras.Model().from_config(model.get_config())

  # for a Sequential model
  tf.keras.Sequential().from_config(model.get_config())
  ```

  Args:
      config: Configuration dictionary.
      custom_objects: Optional dictionary mapping names
          (strings) to custom classes or functions to be
          considered during deserialization.

  Returns:
      A Keras model instance (uncompiled).

  Raises:
      TypeError: if `config` is not a dictionary.
  """"""
  if isinstance(config, list):
    raise TypeError('`model_from_config` expects a dictionary, not a list. '
                    'Maybe you meant to use '
                    '`Sequential.from_config(config)`?')
  from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
  return deserialize(config, custom_objects=custom_objects)


@keras_export('keras.models.model_from_yaml')
def model_from_yaml(yaml_string, custom_objects=None):
  """"""Parses a yaml model configuration file and returns a model instance.

  Usage:

  >>> model = tf.keras.Sequential([
  ...     tf.keras.layers.Dense(5, input_shape=(3,)),
  ...     tf.keras.layers.Softmax()])
  >>> try:
  ...   import yaml
  ...   config = model.to_yaml()
  ...   loaded_model = tf.keras.models.model_from_yaml(config)
  ... except ImportError:
  ...   pass

  Args:
      yaml_string: YAML string or open file encoding a model configuration.
      custom_objects: Optional dictionary mapping names
          (strings) to custom classes or functions to be
          considered during deserialization.

  Returns:
      A Keras model instance (uncompiled).

  Raises:
      ImportError: if yaml module is not found.
  """"""
  if yaml is None:
    raise ImportError('Requires yaml module installed (`pip install pyyaml`).')
  # The method unsafe_load only exists in PyYAML 5.x+, so which branch of the
  # try block is covered by tests depends on the installed version of PyYAML.
  try:
    # PyYAML 5.x+
    config = yaml.unsafe_load(yaml_string)
  except AttributeError:
    config = yaml.load(yaml_string)
  from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
  return deserialize(config, custom_objects=custom_objects)


@keras_export('keras.models.model_from_json')
def model_from_json(json_string, custom_objects=None):
  """"""Parses a JSON model configuration string and returns a model instance.

  Usage:

  >>> model = tf.keras.Sequential([
  ...     tf.keras.layers.Dense(5, input_shape=(3,)),
  ...     tf.keras.layers.Softmax()])
  >>> config = model.to_json()
  >>> loaded_model = tf.keras.models.model_from_json(config)

  Args:
      json_string: JSON string encoding a model configuration.
      custom_objects: Optional dictionary mapping names
          (strings) to custom classes or functions to be
          considered during deserialization.

  Returns:
      A Keras model instance (uncompiled).
  """"""
  config = json_utils.decode(json_string)
  from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
  return deserialize(config, custom_objects=custom_objects)
",CWE-502,127.0,1
"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for `tf.data.Dataset.from_sparse_tensor_slices()`.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np

from tensorflow.python.data.kernel_tests import checkpoint_test_base
from tensorflow.python.data.kernel_tests import test_base
from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.framework import combinations
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import errors
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.ops import array_ops
from tensorflow.python.platform import test


class FromSparseTensorSlicesTest(test_base.DatasetTestBase,
                                 parameterized.TestCase):

  @combinations.generate(
      combinations.times(
          combinations.combine(tf_api_version=1, mode=[""graph""]),
          combinations.combine(slices=[[
              [1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []
          ], [[1., 2.], [], [1., 2.], [1.], [1., 2.], [], [1., 2.]]])))
  def testFromSparseTensorSlices(self, slices):
    """"""Test a dataset based on slices of a `tf.sparse.SparseTensor`.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer
    get_next = sparse_tensor.SparseTensor(*iterator.get_next())

    with self.cached_session() as sess:
      # Test with sparse tensor in the appropriate order.
      # pylint: disable=g-complex-comprehension
      indices = np.array(
          [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))])
      values = np.array([val for s in slices for val in s])
      # pylint: enable=g-complex-comprehension
      dense_shape = np.array([len(slices), max(len(s) for s in slices) + 1])
      sparse_feed = sparse_tensor.SparseTensorValue(indices, values,
                                                    dense_shape)
      sess.run(init_op, feed_dict={st: sparse_feed})
      for i, s in enumerate(slices):
        results = sess.run(get_next)
        self.assertAllEqual(s, results.values)
        expected_indices = np.array(
            [[j] for j in range(len(slices[i]))]).reshape([-1, 1])
        self.assertAllEqual(expected_indices, results.indices)
        self.assertAllEqual(dense_shape[1:], results.dense_shape)
      with self.assertRaises(errors.OutOfRangeError):
        sess.run(get_next)

  @combinations.generate(
      combinations.times(
          combinations.combine(tf_api_version=1, mode=[""graph""]),
          combinations.combine(slices=[[
              [1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []
          ], [[1., 2.], [], [1., 2.], [1.], [1., 2.], [], [1., 2.]]])))
  def testFromSparseTensorSlicesInReverse(self, slices):
    """"""Test a dataset based on slices of a `tf.sparse.SparseTensor` in reverse order.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer

    with self.cached_session() as sess:
      # pylint: disable=g-complex-comprehension
      indices = np.array(
          [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))])
      values = np.array([val for s in slices for val in s])
      # pylint: enable=g-complex-comprehension
      dense_shape = np.array([len(slices), max(len(s) for s in slices) + 1])
      # Test with sparse tensor in the reverse order, which is not
      # currently supported.
      reverse_order_indices = indices[::-1, :]
      reverse_order_values = values[::-1]
      sparse_feed = sparse_tensor.SparseTensorValue(
          reverse_order_indices, reverse_order_values, dense_shape)
      with self.assertRaises(errors.UnimplementedError):
        sess.run(init_op, feed_dict={st: sparse_feed})

  @combinations.generate(combinations.combine(tf_api_version=1, mode=[""graph""]))
  def testEmptySparseTensorSlices(self):
    """"""Test a dataset based on slices of an empty `tf.sparse.SparseTensor`.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer
    get_next = sparse_tensor.SparseTensor(*iterator.get_next())

    with self.cached_session() as sess:
      # Test with an empty sparse tensor.
      empty_indices = np.empty((0, 4), dtype=np.int64)
      empty_values = np.empty((0,), dtype=np.float64)
      empty_dense_shape = [0, 4, 37, 9]
      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices, empty_values,
                                                    empty_dense_shape)
      sess.run(init_op, feed_dict={st: sparse_feed})
      with self.assertRaises(errors.OutOfRangeError):
        sess.run(get_next)

  @combinations.generate(combinations.combine(tf_api_version=2, mode=[""eager""]))
  def testFromSparseTensorSlicesError(self):
    with self.assertRaises(AttributeError):
      dataset_ops.Dataset.from_sparse_tensor_slices(None)


class FromSparseTensorSlicesCheckpointTest(
    checkpoint_test_base.CheckpointTestBase, parameterized.TestCase):

  def _build_sparse_tensor_slice_dataset(self, slices):
    # pylint: disable=g-complex-comprehension
    indices = np.array(
        [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))],
        dtype=np.int64)
    values = np.array([val for s in slices for val in s], dtype=np.float64)
    # pylint: enable=g-complex-comprehension
    dense_shape = np.array(
        [len(slices), max(len(s) for s in slices) + 1], dtype=np.int64)
    sparse_components = sparse_tensor.SparseTensor(indices, values, dense_shape)
    return dataset_ops.Dataset.from_sparse_tensor_slices(sparse_components)

  @combinations.generate(
      combinations.times(test_base.v1_only_combinations(),
                         checkpoint_test_base.default_test_combinations()))
  def test(self, verify_fn):
    slices = [[1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []]

    verify_fn(
        self,
        lambda: self._build_sparse_tensor_slice_dataset(slices),
        num_outputs=9,
        sparse_tensors=True)


if __name__ == ""__main__"":
  test.main()
",CWE-476,157.0,1
"# Copyright 2019 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Raw ops tests.""""""

from absl.testing import parameterized

from tensorflow.python.eager import context
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import errors
from tensorflow.python.framework import ops
from tensorflow.python.framework import test_util
from tensorflow.python.ops import gen_data_flow_ops
from tensorflow.python.ops import gen_math_ops
from tensorflow.python.ops import gen_string_ops
from tensorflow.python.platform import test


@test_util.run_all_in_graph_and_eager_modes
@test_util.disable_tfrt
class RawOpsTest(test.TestCase, parameterized.TestCase):

  def testSimple(self):
    x = constant_op.constant(1)
    self.assertEqual([2], self.evaluate(gen_math_ops.Add(x=x, y=x)))

  def testRequiresKwargs(self):
    with self.assertRaisesRegex(TypeError, ""only takes keyword args""):
      gen_math_ops.Add(1., 1.)

  def testRequiresKwargs_providesSuggestion(self):
    msg = ""possible keys: \\['x', 'y', 'name'\\]""
    with self.assertRaisesRegex(TypeError, msg):
      gen_math_ops.Add(1., y=2.)

  def testName(self):
    x = constant_op.constant(1)
    op = gen_math_ops.Add(x=x, y=x, name=""double"")
    if not context.executing_eagerly():
      # `Tensor.name` is not available in eager.
      self.assertEqual(op.name, ""double:0"")

  def testDoc(self):
    self.assertEqual(gen_math_ops.add.__doc__, gen_math_ops.Add.__doc__)

  def testDefaults(self):
    x = constant_op.constant([[True]])
    self.assertAllClose(
        gen_math_ops.Any(input=x, axis=0),
        gen_math_ops.Any(input=x, axis=0, keep_dims=False))

  @parameterized.parameters([[0, 8]], [[-1, 6]])
  def testStringNGramsBadDataSplits(self, splits):
    data = [""aa"", ""bb"", ""cc"", ""dd"", ""ee"", ""ff""]
    with self.assertRaisesRegex(errors.InvalidArgumentError,
                                ""Invalid split value""):
      self.evaluate(
          gen_string_ops.string_n_grams(
              data=data,
              data_splits=splits,
              separator="""",
              ngram_widths=[2],
              left_pad="""",
              right_pad="""",
              pad_width=0,
              preserve_short_sequences=False))

  def testGetSessionHandle(self):
    if context.executing_eagerly():
      with self.assertRaisesRegex(
          errors.FailedPreconditionError,
          ""GetSessionHandle called on null session state""):
        gen_data_flow_ops.GetSessionHandle(value=[1])


if __name__ == ""__main__"":
  ops.enable_eager_execution()
  test.main()
",CWE-190,90.0,1
"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for `tf.data.Dataset.from_sparse_tensor_slices()`.""""""
from absl.testing import parameterized
import numpy as np

from tensorflow.python.data.kernel_tests import checkpoint_test_base
from tensorflow.python.data.kernel_tests import test_base
from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.framework import combinations
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import errors
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.ops import array_ops
from tensorflow.python.platform import test


class FromSparseTensorSlicesTest(test_base.DatasetTestBase,
                                 parameterized.TestCase):

  @combinations.generate(
      combinations.times(
          combinations.combine(tf_api_version=1, mode=[""graph""]),
          combinations.combine(slices=[[
              [1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []
          ], [[1., 2.], [], [1., 2.], [1.], [1., 2.], [], [1., 2.]]])))
  def testFromSparseTensorSlices(self, slices):
    """"""Test a dataset based on slices of a `tf.sparse.SparseTensor`.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer
    get_next = sparse_tensor.SparseTensor(*iterator.get_next())

    with self.cached_session() as sess:
      # Test with sparse tensor in the appropriate order.
      # pylint: disable=g-complex-comprehension
      indices = np.array(
          [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))])
      values = np.array([val for s in slices for val in s])
      # pylint: enable=g-complex-comprehension
      dense_shape = np.array([len(slices), max(len(s) for s in slices) + 1])
      sparse_feed = sparse_tensor.SparseTensorValue(indices, values,
                                                    dense_shape)
      sess.run(init_op, feed_dict={st: sparse_feed})
      for i, s in enumerate(slices):
        results = sess.run(get_next)
        self.assertAllEqual(s, results.values)
        expected_indices = np.array(
            [[j] for j in range(len(slices[i]))]).reshape([-1, 1])
        self.assertAllEqual(expected_indices, results.indices)
        self.assertAllEqual(dense_shape[1:], results.dense_shape)
      with self.assertRaises(errors.OutOfRangeError):
        sess.run(get_next)

  @combinations.generate(
      combinations.times(
          combinations.combine(tf_api_version=1, mode=[""graph""]),
          combinations.combine(slices=[[
              [1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []
          ], [[1., 2.], [], [1., 2.], [1.], [1., 2.], [], [1., 2.]]])))
  def testFromSparseTensorSlicesInReverse(self, slices):
    """"""Test a dataset based on slices of a `tf.sparse.SparseTensor` in reverse order.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer

    with self.cached_session() as sess:
      # pylint: disable=g-complex-comprehension
      indices = np.array(
          [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))])
      values = np.array([val for s in slices for val in s])
      # pylint: enable=g-complex-comprehension
      dense_shape = np.array([len(slices), max(len(s) for s in slices) + 1])
      # Test with sparse tensor in the reverse order, which is not
      # currently supported.
      reverse_order_indices = indices[::-1, :]
      reverse_order_values = values[::-1]
      sparse_feed = sparse_tensor.SparseTensorValue(
          reverse_order_indices, reverse_order_values, dense_shape)
      with self.assertRaises(errors.UnimplementedError):
        sess.run(init_op, feed_dict={st: sparse_feed})

  @combinations.generate(combinations.combine(tf_api_version=1, mode=[""graph""]))
  def testEmptySparseTensorSlices(self):
    """"""Test a dataset based on slices of an empty `tf.sparse.SparseTensor`.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer
    get_next = sparse_tensor.SparseTensor(*iterator.get_next())

    with self.cached_session() as sess:
      # Test with an empty sparse tensor.
      empty_indices = np.empty((0, 4), dtype=np.int64)
      empty_values = np.empty((0,), dtype=np.float64)
      empty_dense_shape = [0, 4, 37, 9]
      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices, empty_values,
                                                    empty_dense_shape)
      sess.run(init_op, feed_dict={st: sparse_feed})
      with self.assertRaises(errors.OutOfRangeError):
        sess.run(get_next)

  @combinations.generate(combinations.combine(tf_api_version=1, mode=[""graph""]))
  def testEmptySparseTensorSlicesInvalid(self):
    """"""Test a dataset based on invalid `tf.sparse.SparseTensor`.""""""
    st = array_ops.sparse_placeholder(dtypes.float64)
    iterator = dataset_ops.make_initializable_iterator(
        dataset_ops.Dataset.from_sparse_tensor_slices(st))
    init_op = iterator.initializer

    with self.cached_session() as sess:
      # Test with an empty sparse tensor but with non empty values.
      empty_indices = np.empty((0, 4), dtype=np.int64)
      non_empty_values = [1, 2, 3, 4]
      empty_dense_shape = [0, 4, 37, 9]
      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices,
                                                    non_empty_values,
                                                    empty_dense_shape)
      # Here, we expect the test to fail when running the feed.
      with self.assertRaises(errors.InvalidArgumentError):
        sess.run(init_op, feed_dict={st: sparse_feed})

  @combinations.generate(combinations.combine(tf_api_version=2, mode=[""eager""]))
  def testFromSparseTensorSlicesError(self):
    with self.assertRaises(AttributeError):
      dataset_ops.Dataset.from_sparse_tensor_slices(None)


class FromSparseTensorSlicesCheckpointTest(
    checkpoint_test_base.CheckpointTestBase, parameterized.TestCase):

  def _build_sparse_tensor_slice_dataset(self, slices):
    # pylint: disable=g-complex-comprehension
    indices = np.array(
        [[i, j] for i in range(len(slices)) for j in range(len(slices[i]))],
        dtype=np.int64)
    values = np.array([val for s in slices for val in s], dtype=np.float64)
    # pylint: enable=g-complex-comprehension
    dense_shape = np.array(
        [len(slices), max(len(s) for s in slices) + 1], dtype=np.int64)
    sparse_components = sparse_tensor.SparseTensor(indices, values, dense_shape)
    return dataset_ops.Dataset.from_sparse_tensor_slices(sparse_components)

  @combinations.generate(
      combinations.times(test_base.v1_only_combinations(),
                         checkpoint_test_base.default_test_combinations()))
  def test(self, verify_fn):
    slices = [[1., 2., 3.], [1.], [1.], [1., 2.], [], [1., 2.], [], [], []]

    verify_fn(
        self,
        lambda: self._build_sparse_tensor_slice_dataset(slices),
        num_outputs=9,
        sparse_tensors=True)


if __name__ == ""__main__"":
  test.main()
",CWE-476,173.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for convolution related functionality in tensorflow.ops.nn.""""""

import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import gradient_checker
from tensorflow.python.ops import nn_ops
import tensorflow.python.ops.nn_grad  # pylint: disable=unused-import
from tensorflow.python.platform import test


class Conv3DBackpropFilterV2GradTest(test.TestCase):

  @test_util.run_deprecated_v1
  def testGradient(self):
    with self.cached_session():
      for padding in [""SAME"", ""VALID""]:
        for stride in [1, 2]:
          np.random.seed(1)
          in_shape = [2, 4, 3, 3, 2]
          in_val = constant_op.constant(
              2 * np.random.random_sample(in_shape) - 1, dtype=dtypes.float32)
          filter_shape = [3, 3, 3, 2, 3]
          strides = [1, stride, stride, stride, 1]
          # Make a convolution op with the current settings, just to easily get
          # the shape of the output.
          conv_out = nn_ops.conv3d(in_val,
                                   array_ops.zeros(filter_shape), strides,
                                   padding)
          out_backprop_shape = conv_out.get_shape().as_list()
          out_backprop_val = constant_op.constant(
              2 * np.random.random_sample(out_backprop_shape) - 1,
              dtype=dtypes.float32)
          output = nn_ops.conv3d_backprop_filter_v2(in_val, filter_shape,
                                                    out_backprop_val, strides,
                                                    padding)
          err = gradient_checker.compute_gradient_error(
              [in_val, out_backprop_val], [in_shape, out_backprop_shape],
              output, filter_shape)
          print(""conv3d_backprop_filter gradient err = %g "" % err)
          err_tolerance = 1e-3
          self.assertLess(err, err_tolerance)


if __name__ == ""__main__"":
  test.main()
",CWE-1284,64.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for local response normalization.""""""

import copy

import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import gradient_checker
from tensorflow.python.ops import gradients_impl
from tensorflow.python.ops import nn
import tensorflow.python.ops.nn_grad  # pylint: disable=unused-import
from tensorflow.python.platform import test


class LRNOpTest(test.TestCase):

  def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0,
           beta=0.5):
    """"""Compute expected result.""""""
    output = copy.deepcopy(input_image)
    batch_size = input_image.shape[0]
    rows = input_image.shape[1]
    cols = input_image.shape[2]
    depth = input_image.shape[3]
    for b in range(batch_size):
      for r in range(rows):
        for c in range(cols):
          for d in range(depth):
            begin = max(0, d - lrn_depth_radius)
            end = min(depth, d + lrn_depth_radius + 1)
            patch = input_image[b, r, c, begin:end]
            output[b, r, c, d] /= (
                np.power(bias + alpha * np.sum(patch * patch), beta))
    return output

  def _RunAndVerify(self, dtype):
    with self.cached_session():
      # random shape
      shape = np.random.randint(1, 16, size=4)
      # Make depth at least 2 to make it meaningful
      shape[3] += 1
      p = array_ops.placeholder(dtype, shape=shape)
      # random depth_radius, bias, alpha, beta. cuDNN requires depth_radius to
      # be in [1, 7].
      lrn_depth_radius = np.random.randint(1, min(8, shape[3]))

      bias = 1.0 + np.random.rand()
      alpha = 2.0 * np.random.rand()
      # cuDNN requires beta >= 0.01.
      beta = 0.01 + 2.0 * np.random.rand()
      lrn_t = nn.local_response_normalization(
          p,
          name=""lrn"",
          depth_radius=lrn_depth_radius,
          bias=bias,
          alpha=alpha,
          beta=beta)
      params = {p: np.random.rand(*shape).astype(""f"")}
      result = lrn_t.eval(feed_dict=params)
    expected = self._LRN(
        params[p],
        lrn_depth_radius=lrn_depth_radius,
        bias=bias,
        alpha=alpha,
        beta=beta)
    err = np.amax(np.abs(result - expected))
    print(""LRN error for bias "", bias, ""alpha "", alpha, "" beta "", beta, "" is "",
          err)
    if dtype == dtypes.float32:
      self.assertTrue(err < 1e-4)
    else:
      self.assertTrue(err < 1e-2)
    self.assertShapeEqual(expected, lrn_t)

  @test_util.run_deprecated_v1
  def testCompute(self):
    for _ in range(2):
      self._RunAndVerify(dtypes.float32)
      # Enable when LRN supports tf.float16 on GPU.
      if not test.is_gpu_available():
        self._RunAndVerify(dtypes.float16)

  @test_util.run_deprecated_v1
  def testGradientsZeroInput(self):
    with self.session():
      shape = [4, 4, 4, 4]
      p = array_ops.placeholder(dtypes.float32, shape=shape)
      inp_array = np.zeros(shape).astype(""f"")
      lrn_op = nn.local_response_normalization(p, 2, 1.0, 0.0, 1.0, name=""lrn"")
      grad = gradients_impl.gradients([lrn_op], [p])[0]
      params = {p: inp_array}
      r = grad.eval(feed_dict=params)
    expected = np.ones(shape).astype(""f"")
    self.assertAllClose(r, expected)
    self.assertShapeEqual(expected, grad)

  def _RunAndVerifyGradients(self, dtype):
    with self.cached_session():
      # random shape
      shape = np.random.randint(1, 5, size=4)
      # Make depth at least 2 to make it meaningful
      shape[3] += 1
      # random depth_radius, bias, alpha, beta. cuDNN requires depth_radius to
      # be in [1, 7].
      lrn_depth_radius = np.random.randint(1, min(8, shape[3]))
      bias = 1.0 + np.random.rand()
      alpha = 1.0 * np.random.rand()
      # cuDNN requires beta >= 0.01.
      beta = 0.01 + 1.0 * np.random.rand()
      if dtype == dtypes.float32:
        inp_array = np.random.rand(*shape).astype(np.float32)
      else:
        inp_array = np.random.rand(*shape).astype(np.float16)

      inp = constant_op.constant(
          list(inp_array.ravel(order=""C"")), shape=shape, dtype=dtype)
      lrn_op = nn.local_response_normalization(
          inp,
          name=""lrn"",
          depth_radius=lrn_depth_radius,
          bias=bias,
          alpha=alpha,
          beta=beta)
      err = gradient_checker.compute_gradient_error(inp, shape, lrn_op, shape)
    print(""LRN Gradient error for bias "", bias, ""alpha "", alpha, "" beta "", beta,
          "" is "", err)
    if dtype == dtypes.float32:
      self.assertLess(err, 1e-4)
    else:
      self.assertLess(err, 1.0)

  @test_util.run_deprecated_v1
  def testGradients(self):
    for _ in range(2):
      self._RunAndVerifyGradients(dtypes.float32)
      # Enable when LRN supports tf.float16 on GPU.
      if not test.is_gpu_available():
        self._RunAndVerifyGradients(dtypes.float16)


if __name__ == ""__main__"":
  test.main()
",CWE-617,160.0,1
"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for ragged_range op.""""""

from tensorflow.python.framework import errors
from tensorflow.python.framework import test_util
from tensorflow.python.ops.ragged import ragged_math_ops
from tensorflow.python.platform import googletest


@test_util.run_all_in_graph_and_eager_modes
class RaggedRangeOpTest(test_util.TensorFlowTestCase):

  def testDocStringExamples(self):
    """"""Examples from ragged_range.__doc__.""""""
    rt1 = ragged_math_ops.range([3, 5, 2])
    self.assertAllEqual(rt1, [[0, 1, 2], [0, 1, 2, 3, 4], [0, 1]])

    rt2 = ragged_math_ops.range([0, 5, 8], [3, 3, 12])
    self.assertAllEqual(rt2, [[0, 1, 2], [], [8, 9, 10, 11]])

    rt3 = ragged_math_ops.range([0, 5, 8], [3, 3, 12], 2)
    self.assertAllEqual(rt3, [[0, 2], [], [8, 10]])

  def testBasicRanges(self):
    # Specify limits only.
    self.assertAllEqual(
        ragged_math_ops.range([0, 3, 5]),
        [list(range(0)), list(range(3)),
         list(range(5))])

    # Specify starts and limits.
    self.assertAllEqual(
        ragged_math_ops.range([0, 3, 5], [2, 3, 10]),
        [list(range(0, 2)),
         list(range(3, 3)),
         list(range(5, 10))])

    # Specify starts, limits, and deltas.
    self.assertAllEqual(
        ragged_math_ops.range([0, 3, 5], [4, 4, 15], [2, 3, 4]),
        [list(range(0, 4, 2)),
         list(range(3, 4, 3)),
         list(range(5, 15, 4))])

  def testFloatRanges(self):
    expected = [[0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6], [3.0],
                [5.0, 7.2, 9.4, 11.6, 13.8]]
    actual = ragged_math_ops.range([0.0, 3.0, 5.0], [3.9, 4.0, 15.0],
                                   [0.4, 1.5, 2.2])
    self.assertAllClose(actual, expected)

  def testNegativeDeltas(self):
    self.assertAllEqual(
        ragged_math_ops.range([0, 3, 5], limits=0, deltas=-1),
        [list(range(0, 0, -1)),
         list(range(3, 0, -1)),
         list(range(5, 0, -1))])

    self.assertAllEqual(
        ragged_math_ops.range([0, -3, 5], limits=0, deltas=[-1, 1, -2]),
        [list(range(0, 0, -1)),
         list(range(-3, 0, 1)),
         list(range(5, 0, -2))])

  def testBroadcast(self):
    # Specify starts and limits, broadcast deltas.
    self.assertAllEqual(
        ragged_math_ops.range([0, 3, 5], [4, 4, 15], 3),
        [list(range(0, 4, 3)),
         list(range(3, 4, 3)),
         list(range(5, 15, 3))])

    # Broadcast all arguments.
    self.assertAllEqual(
        ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])

  def testEmptyRanges(self):
    rt1 = ragged_math_ops.range([0, 5, 3], [0, 3, 5])
    rt2 = ragged_math_ops.range([0, 5, 5], [0, 3, 5], -1)
    self.assertAllEqual(rt1, [[], [], [3, 4]])
    self.assertAllEqual(rt2, [[], [5, 4], []])

  def testShapeFnErrors(self):
    self.assertRaises((ValueError, errors.InvalidArgumentError),
                      ragged_math_ops.range, [[0]], 5)
    self.assertRaises((ValueError, errors.InvalidArgumentError),
                      ragged_math_ops.range, 0, [[5]])
    self.assertRaises((ValueError, errors.InvalidArgumentError),
                      ragged_math_ops.range, 0, 5, [[0]])
    self.assertRaises((ValueError, errors.InvalidArgumentError),
                      ragged_math_ops.range, [0], [1, 2])

  def testKernelErrors(self):
    with self.assertRaisesRegex(errors.InvalidArgumentError,
                                r'Requires delta != 0'):
      self.evaluate(ragged_math_ops.range(0, 0, 0))

  def testShape(self):
    self.assertAllEqual(
        ragged_math_ops.range(0, 0, 1).shape.as_list(), [1, None])
    self.assertAllEqual(
        ragged_math_ops.range([1, 2, 3]).shape.as_list(), [3, None])
    self.assertAllEqual(
        ragged_math_ops.range([1, 2, 3], [4, 5, 6]).shape.as_list(), [3, None])


if __name__ == '__main__':
  googletest.main()
",CWE-190,122.0,1
,CWE-617,,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for draw_bounding_box_op.""""""

import numpy as np

from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import image_ops
from tensorflow.python.ops import image_ops_impl
from tensorflow.python.ops import math_ops
from tensorflow.python.platform import test


class DrawBoundingBoxOpTest(test.TestCase):

  def _fillBorder(self, image, color):
    """"""Fill the border of the image.

    Args:
      image: Numpy array of shape [height, width, depth].
      color: Numpy color of shape [depth] and either contents RGB/RGBA.

    Returns:
      image of original shape with border filled with ""color"".

    Raises:
      ValueError: Depths of image and color don""t match.
    """"""
    height, width, depth = image.shape
    if depth != color.shape[0]:
      raise ValueError(""Image (%d) and color (%d) depths must match."" %
                       (depth, color.shape[0]))
    image[0:height, 0, 0:depth] = color
    image[0:height, width - 1, 0:depth] = color
    image[0, 0:width, 0:depth] = color
    image[height - 1, 0:width, 0:depth] = color
    return image

  def _testDrawBoundingBoxColorCycling(self, img, colors=None):
    """"""Tests if cycling works appropriately.

    Args:
      img: 3-D numpy image on which to draw.
    """"""
    color_table = colors
    if colors is None:
      # THIS TABLE MUST MATCH draw_bounding_box_op.cc
      color_table = np.asarray([[1, 1, 0, 1], [0, 0, 1, 1], [1, 0, 0, 1],
                                [0, 1, 0, 1], [0.5, 0, 0.5,
                                               1], [0.5, 0.5, 0, 1],
                                [0.5, 0, 0, 1], [0, 0, 0.5, 1], [0, 1, 1, 1],
                                [1, 0, 1, 1]])
    assert len(img.shape) == 3
    depth = img.shape[2]
    assert depth <= color_table.shape[1]
    assert depth == 1 or depth == 3 or depth == 4
    ## Set red channel to 1 if image is GRY.
    if depth == 1:
      color_table[:, 0] = 1
    num_colors = color_table.shape[0]
    for num_boxes in range(1, num_colors + 2):
      # Generate draw_bounding_box_op drawn image
      image = np.copy(img)
      color = color_table[(num_boxes - 1) % num_colors, 0:depth]
      test_drawn_image = self._fillBorder(image, color)
      bboxes = np.asarray([0, 0, 1, 1])
      bboxes = np.vstack([bboxes for _ in range(num_boxes)])
      bboxes = math_ops.cast(bboxes, dtypes.float32)
      bboxes = array_ops.expand_dims(bboxes, 0)
      image = ops.convert_to_tensor(image)
      image = image_ops_impl.convert_image_dtype(image, dtypes.float32)
      image = array_ops.expand_dims(image, 0)
      image = image_ops.draw_bounding_boxes(image, bboxes, colors=colors)
      with self.cached_session(use_gpu=False) as sess:
        op_drawn_image = np.squeeze(sess.run(image), 0)
        self.assertAllEqual(test_drawn_image, op_drawn_image)

  def testDrawBoundingBoxRGBColorCycling(self):
    """"""Test if RGB color cycling works correctly.""""""
    image = np.zeros([10, 10, 3], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxRGBAColorCycling(self):
    """"""Test if RGBA color cycling works correctly.""""""
    image = np.zeros([10, 10, 4], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxGRY(self):
    """"""Test if drawing bounding box on a GRY image works.""""""
    image = np.zeros([4, 4, 1], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxRGBColorCyclingWithColors(self):
    """"""Test if RGB color cycling works correctly with provided colors.""""""
    image = np.zeros([10, 10, 3], ""float32"")
    colors = np.asarray([[1, 1, 0, 1], [0, 0, 1, 1], [0.5, 0, 0.5, 1],
                         [0.5, 0.5, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]])
    self._testDrawBoundingBoxColorCycling(image, colors=colors)

  def testDrawBoundingBoxRGBAColorCyclingWithColors(self):
    """"""Test if RGBA color cycling works correctly with provided colors.""""""
    image = np.zeros([10, 10, 4], ""float32"")
    colors = np.asarray([[0.5, 0, 0.5, 1], [0.5, 0.5, 0, 1], [0.5, 0, 0, 1],
                         [0, 0, 0.5, 1]])
    self._testDrawBoundingBoxColorCycling(image, colors=colors)


if __name__ == ""__main__"":
  test.main()
",CWE-617,124.0,1
"# Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for tensorflow.ops.random_ops.random_poisson.""""""
import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework import test_util
from tensorflow.python.kernel_tests.random import util
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import random_ops
from tensorflow.python.platform import test
from tensorflow.python.platform import tf_logging

# All supported dtypes for random_poisson().
_SUPPORTED_DTYPES = (dtypes.float16, dtypes.float32, dtypes.float64,
                     dtypes.int32, dtypes.int64)


class RandomPoissonTest(test.TestCase):
  """"""This is a large test due to the moments computation taking some time.""""""

  def _Sampler(self, num, lam, dtype, use_gpu, seed=None):

    def func():
      with self.session(use_gpu=use_gpu, graph=ops.Graph()) as sess:
        rng = random_ops.random_poisson(lam, [num], dtype=dtype, seed=seed)
        ret = np.empty([10, num])
        for i in range(10):
          ret[i, :] = self.evaluate(rng)
      return ret

    return func

  def testMoments(self):
    try:
      from scipy import stats  # pylint: disable=g-import-not-at-top
    except ImportError as e:
      tf_logging.warn(""Cannot test moments: %s"", e)
      return

    # The moments test is a z-value test.  This is the largest z-value
    # we want to tolerate. Since the z-test approximates a unit normal
    # distribution, it should almost definitely never exceed 6.
    z_limit = 6.0
    for dt in _SUPPORTED_DTYPES:
      # Test when lam < 10 and when lam >= 10
      for stride in 0, 4, 10:
        for lam in (3., 20):
          max_moment = 5
          sampler = self._Sampler(10000, lam, dt, use_gpu=False, seed=12345)
          z_scores = util.test_moment_matching(
              sampler(),
              max_moment,
              stats.poisson(lam),
              stride=stride,
          )
          self.assertAllLess(z_scores, z_limit)

  # Checks that the CPU and GPU implementation returns the same results,
  # given the same random seed
  @test_util.run_deprecated_v1
  def testCPUGPUMatch(self):
    for dt in _SUPPORTED_DTYPES:
      results = {}
      for use_gpu in [False, True]:
        sampler = self._Sampler(1000, 1.0, dt, use_gpu=use_gpu, seed=12345)
        results[use_gpu] = sampler()
      if dt == dtypes.float16:
        self.assertAllClose(results[False], results[True], rtol=1e-3, atol=1e-3)
      else:
        self.assertAllClose(results[False], results[True], rtol=1e-6, atol=1e-6)

  @test_util.run_deprecated_v1
  def testSeed(self):
    for dt in dtypes.float16, dtypes.float32, dtypes.float64:
      sx = self._Sampler(1000, 1.0, dt, use_gpu=True, seed=345)
      sy = self._Sampler(1000, 1.0, dt, use_gpu=True, seed=345)
      self.assertAllEqual(sx(), sy())

  @test_util.run_deprecated_v1
  def testNoCSE(self):
    """"""CSE = constant subexpression eliminator.

    SetIsStateful() should prevent two identical random ops from getting
    merged.
    """"""
    for dtype in dtypes.float16, dtypes.float32, dtypes.float64:
      with self.cached_session():
        rnd1 = random_ops.random_poisson(2.0, [24], dtype=dtype)
        rnd2 = random_ops.random_poisson(2.0, [24], dtype=dtype)
        diff = rnd2 - rnd1
        # Since these are all positive integers, the norm will
        # be at least 1 if they are different.
        self.assertGreaterEqual(np.linalg.norm(diff.eval()), 1)

  def testZeroShape(self):
    with self.cached_session():
      rnd = random_ops.random_poisson([], [], seed=12345)
      self.assertEqual([0], rnd.get_shape().as_list())
      self.assertAllClose(np.array([], dtype=np.float32), self.evaluate(rnd))

  @test_util.run_deprecated_v1
  def testShape(self):
    # Fully known shape
    rnd = random_ops.random_poisson(2.0, [150], seed=12345)
    self.assertEqual([150], rnd.get_shape().as_list())
    rnd = random_ops.random_poisson(
        lam=array_ops.ones([1, 2, 3]),
        shape=[150],
        seed=12345)
    self.assertEqual([150, 1, 2, 3], rnd.get_shape().as_list())
    rnd = random_ops.random_poisson(
        lam=array_ops.ones([1, 2, 3]),
        shape=[20, 30],
        seed=12345)
    self.assertEqual([20, 30, 1, 2, 3], rnd.get_shape().as_list())
    rnd = random_ops.random_poisson(
        lam=array_ops.placeholder(dtypes.float32, shape=(2,)),
        shape=[12],
        seed=12345)
    self.assertEqual([12, 2], rnd.get_shape().as_list())
    # Partially known shape.
    rnd = random_ops.random_poisson(
        lam=array_ops.ones([7, 3]),
        shape=array_ops.placeholder(dtypes.int32, shape=(1,)),
        seed=12345)
    self.assertEqual([None, 7, 3], rnd.get_shape().as_list())
    rnd = random_ops.random_poisson(
        lam=array_ops.ones([9, 6]),
        shape=array_ops.placeholder(dtypes.int32, shape=(3,)),
        seed=12345)
    self.assertEqual([None, None, None, 9, 6], rnd.get_shape().as_list())
    # Unknown shape.
    rnd = random_ops.random_poisson(
        lam=array_ops.placeholder(dtypes.float32),
        shape=array_ops.placeholder(dtypes.int32),
        seed=12345)
    self.assertIs(None, rnd.get_shape().ndims)
    rnd = random_ops.random_poisson(
        lam=array_ops.placeholder(dtypes.float32),
        shape=[50],
        seed=12345)
    self.assertIs(None, rnd.get_shape().ndims)

  @test_util.run_deprecated_v1
  def testDTypeCombinationsV2(self):
    """"""Tests random_poisson_v2() for all supported dtype combinations.""""""
    with self.cached_session():
      for lam_dt in _SUPPORTED_DTYPES:
        for out_dt in _SUPPORTED_DTYPES:
          random_ops.random_poisson(
              constant_op.constant([1], dtype=lam_dt), [10],
              dtype=out_dt).eval()

  @test_util.run_deprecated_v1
  def testInfRate(self):
    sample = random_ops.random_poisson(shape=[2], lam=np.inf)
    self.assertAllEqual([np.inf, np.inf], self.evaluate(sample))


if __name__ == ""__main__"":
  test.main()
",CWE-617,177.0,1
"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for composite_tensor_ops.""""""

from absl.testing import parameterized

from tensorflow.python.eager import backprop
from tensorflow.python.eager import context
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import errors
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.framework import test_util
from tensorflow.python.ops import composite_tensor_ops
from tensorflow.python.ops import gradients_impl
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import parsing_ops
from tensorflow.python.ops import sparse_ops
from tensorflow.python.ops.ragged import ragged_factory_ops
from tensorflow.python.ops.ragged import ragged_tensor
from tensorflow.python.platform import googletest
from tensorflow.python.util import nest


@test_util.run_all_in_graph_and_eager_modes
class ExtensionTypeTest(test_util.TensorFlowTestCase, parameterized.TestCase):

  @parameterized.named_parameters([
      ('Ragged', lambda: ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])),
      ('Sparse', lambda: sparse_ops.from_dense([[0, 0, 3, 0], [1, 2, 0, 0]])),
  ])
  def testEncodeAndDecode(self, value_factory):
    value = value_factory()

    encoded = composite_tensor_ops.composite_tensor_to_variants(value)
    self.assertEqual(encoded.dtype, dtypes.variant)
    self.assertEqual(encoded.shape.rank, 0)

    decoded = composite_tensor_ops.composite_tensor_from_variant(
        encoded, value._type_spec)
    self.assertTrue(value._type_spec.is_compatible_with(decoded._type_spec))
    value_components = nest.flatten(value, expand_composites=True)
    decoded_components = nest.flatten(decoded, expand_composites=True)
    self.assertLen(value_components, len(decoded_components))
    for v, d in zip(value_components, decoded_components):
      self.assertAllEqual(v, d)

  @parameterized.named_parameters([
      ('WrongType', lambda: ragged_factory_ops.constant([[1]]),
       sparse_tensor.SparseTensorSpec([None, None], dtypes.int32),
       r'Expected a SPARSE_TENSOR_SPEC \(based on `type_spec`\), but `encoded` '
       'contains a RAGGED_TENSOR_SPEC'),
      ('WrongNumComponents', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None, None], dtypes.int32),
       'Encoded value has 2 tensor components; expected 3 components'),
      ('WrongDType', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None], dtypes.float32),
       'Tensor component 0 had dtype DT_INT32; expected dtype DT_FLOAT'),
  ])
  def testDecodingErrors(self, value, spec, message):
    encoded = composite_tensor_ops.composite_tensor_to_variants(value())
    with self.assertRaisesRegex(errors.InvalidArgumentError, message):
      self.evaluate(
          composite_tensor_ops.composite_tensor_from_variant(encoded, spec))

  @parameterized.named_parameters([
      ('IncompatibleSpec', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None, None], dtypes.int32),
       r'`type_spec` .* is not compatible with `value` .*'),
  ])
  def testEncodingErrors(self, value, spec, message):
    with self.assertRaisesRegex(ValueError, message):
      composite_tensor_ops.composite_tensor_to_variants(value(), spec)

  def testRoundTripThroughTensorProto(self):
    value = ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])
    encoded = composite_tensor_ops.composite_tensor_to_variants(value)
    proto = parsing_ops.SerializeTensor(tensor=encoded)
    parsed = parsing_ops.ParseTensor(serialized=proto, out_type=dtypes.variant)
    decoded = composite_tensor_ops.composite_tensor_from_variant(
        parsed, value._type_spec)
    self.assertAllEqual(value, decoded)

  def testGradient(self):

    def func(x):
      x2 = composite_tensor_ops.composite_tensor_to_variants(x * 2)
      x3 = composite_tensor_ops.composite_tensor_from_variant(x2, x._type_spec)
      return x3.with_values(x3.values * math_ops.range(6.0))

    x = ragged_factory_ops.constant([[1.0, 2.0, 3.0], [4.0], [5.0, 6.0]])
    if context.executing_eagerly():
      with backprop.GradientTape() as t:
        t.watch(x.values)
        y = func(x)
        g = t.gradient(y.values, x.values)
    else:
      y = func(x)
      g = gradients_impl.gradients(ys=y.values, xs=x.values)[0]
    self.assertAllClose(g, [0.0, 2.0, 4.0, 6.0, 8.0, 10.0])


if __name__ == '__main__':
  googletest.main()
",CWE-476,116.0,1
"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for composite_tensor_ops.""""""

from absl.testing import parameterized

from tensorflow.python.eager import backprop
from tensorflow.python.eager import context
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import errors
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.framework import test_util
from tensorflow.python.ops import composite_tensor_ops
from tensorflow.python.ops import gen_composite_tensor_ops
from tensorflow.python.ops import gradients_impl
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import parsing_ops
from tensorflow.python.ops import sparse_ops
from tensorflow.python.ops.ragged import ragged_factory_ops
from tensorflow.python.ops.ragged import ragged_tensor
from tensorflow.python.platform import googletest
from tensorflow.python.util import nest


@test_util.run_all_in_graph_and_eager_modes
class ExtensionTypeTest(test_util.TensorFlowTestCase, parameterized.TestCase):

  @parameterized.named_parameters([
      ('Ragged', lambda: ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])),
      ('Sparse', lambda: sparse_ops.from_dense([[0, 0, 3, 0], [1, 2, 0, 0]])),
  ])
  def testEncodeAndDecode(self, value_factory):
    value = value_factory()

    encoded = composite_tensor_ops.composite_tensor_to_variants(value)
    self.assertEqual(encoded.dtype, dtypes.variant)
    self.assertEqual(encoded.shape.rank, 0)

    decoded = composite_tensor_ops.composite_tensor_from_variant(
        encoded, value._type_spec)
    self.assertTrue(value._type_spec.is_compatible_with(decoded._type_spec))
    value_components = nest.flatten(value, expand_composites=True)
    decoded_components = nest.flatten(decoded, expand_composites=True)
    self.assertLen(value_components, len(decoded_components))
    for v, d in zip(value_components, decoded_components):
      self.assertAllEqual(v, d)

  @parameterized.named_parameters([
      ('WrongType', lambda: ragged_factory_ops.constant([[1]]),
       sparse_tensor.SparseTensorSpec([None, None], dtypes.int32),
       r'Expected a SPARSE_TENSOR_SPEC \(based on `type_spec`\), but `encoded` '
       'contains a RAGGED_TENSOR_SPEC'),
      ('WrongNumComponents', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None, None], dtypes.int32),
       'Encoded value has 2 tensor components; expected 3 components'),
      ('WrongDType', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None], dtypes.float32),
       'Tensor component 0 had dtype DT_INT32; expected dtype DT_FLOAT'),
  ])
  def testDecodingErrors(self, value, spec, message):
    encoded = composite_tensor_ops.composite_tensor_to_variants(value())
    with self.assertRaisesRegex(errors.InvalidArgumentError, message):
      self.evaluate(
          composite_tensor_ops.composite_tensor_from_variant(encoded, spec))

  @parameterized.named_parameters([
      ('IncompatibleSpec', lambda: ragged_factory_ops.constant([[1]]),
       ragged_tensor.RaggedTensorSpec([None, None, None], dtypes.int32),
       r'`type_spec` .* is not compatible with `value` .*'),
  ])
  def testEncodingErrors(self, value, spec, message):
    with self.assertRaisesRegex(ValueError, message):
      composite_tensor_ops.composite_tensor_to_variants(value(), spec)

  def testDecodingEmptyNonScalarTensorError(self):
    if not context.executing_eagerly():
      # Creating a variant tensor of an empty list is not allowed in eager mode.
      return

    with self.assertRaisesRegex(errors.InvalidArgumentError,
                                'must not be an empty variant tensor'):
      gen_composite_tensor_ops.CompositeTensorVariantToComponents(
          encoded=constant_op.constant([], dtype=dtypes.variant),
          metadata='',
          Tcomponents=[dtypes.int32])

  def testRoundTripThroughTensorProto(self):
    value = ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])
    encoded = composite_tensor_ops.composite_tensor_to_variants(value)
    proto = parsing_ops.SerializeTensor(tensor=encoded)
    parsed = parsing_ops.ParseTensor(serialized=proto, out_type=dtypes.variant)
    decoded = composite_tensor_ops.composite_tensor_from_variant(
        parsed, value._type_spec)
    self.assertAllEqual(value, decoded)

  def testGradient(self):

    def func(x):
      x2 = composite_tensor_ops.composite_tensor_to_variants(x * 2)
      x3 = composite_tensor_ops.composite_tensor_from_variant(x2, x._type_spec)
      return x3.with_values(x3.values * math_ops.range(6.0))

    x = ragged_factory_ops.constant([[1.0, 2.0, 3.0], [4.0], [5.0, 6.0]])
    if context.executing_eagerly():
      with backprop.GradientTape() as t:
        t.watch(x.values)
        y = func(x)
        g = t.gradient(y.values, x.values)
    else:
      y = func(x)
      g = gradients_impl.gradients(ys=y.values, xs=x.values)[0]
    self.assertAllClose(g, [0.0, 2.0, 4.0, 6.0, 8.0, 10.0])


if __name__ == '__main__':
  googletest.main()
",CWE-476,130.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Functional tests for ExtractImagePatches op.""""""

import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.ops import array_ops
from tensorflow.python.platform import test


class ExtractImagePatches(test.TestCase):
  """"""Functional tests for ExtractImagePatches op.""""""

  def _VerifyValues(self, image, ksizes, strides, rates, padding, patches):
    """"""Tests input-output pairs for the ExtractImagePatches op.

    Args:
      image: Input tensor with shape: [batch, in_rows, in_cols, depth].
      ksizes: Patch size specified as: [ksize_rows, ksize_cols].
      strides: Output strides, specified as [stride_rows, stride_cols].
      rates: Atrous rates, specified as [rate_rows, rate_cols].
      padding: Padding type.
      patches: Expected output.
    """"""
    ksizes = [1] + ksizes + [1]
    strides = [1] + strides + [1]
    rates = [1] + rates + [1]

    out_tensor = array_ops.extract_image_patches(
        constant_op.constant(image),
        ksizes=ksizes,
        strides=strides,
        rates=rates,
        padding=padding,
        name=""im2col"")
    self.assertAllClose(patches, self.evaluate(out_tensor))

  def testKsize1x1Stride1x1Rate1x1(self):
    """"""Verifies that for 1x1 kernel the output equals the input.""""""
    # [2, 3, 4, 5]
    image = np.reshape(range(120), [2, 3, 4, 5])
    # [2, 3, 4, 5]
    patches = np.reshape(range(120), [2, 3, 4, 5])
    for padding in [""VALID"", ""SAME""]:
      self._VerifyValues(
          image,
          ksizes=[1, 1],
          strides=[1, 1],
          rates=[1, 1],
          padding=padding,
          patches=patches)

  def testKsize1x1Stride2x3Rate1x1(self):
    """"""Test for 1x1 kernel and strides.""""""
    # [2, 4, 5, 3]
    image = np.reshape(range(120), [2, 4, 5, 3])
    # [2, 2, 2, 3]
    patches = image[:, ::2, ::3, :]
    for padding in [""VALID"", ""SAME""]:
      self._VerifyValues(
          image,
          ksizes=[1, 1],
          strides=[2, 3],
          rates=[1, 1],
          padding=padding,
          patches=patches)

  def testKsize2x2Stride1x1Rate1x1Valid(self):
    """"""Test for 2x2 kernel with VALID padding.""""""
    # [1, 2, 2, 1]
    image = [[[[1], [2]], [[3], [4]]]]
    # [1, 1, 1, 4]
    patches = [[[[1, 2, 3, 4]]]]
    self._VerifyValues(
        image,
        ksizes=[2, 2],
        strides=[1, 1],
        rates=[1, 1],
        padding=""VALID"",
        patches=patches)

  def testKsize2x2Stride1x1Rate1x1Same(self):
    """"""Test for 2x2 kernel with SAME padding.""""""
    # [1, 2, 2, 1]
    image = [[[[1], [2]], [[3], [4]]]]
    # [1, 2, 2, 4]
    patches = [[[[1, 2, 3, 4], [2, 0, 4, 0]], [[3, 4, 0, 0], [4, 0, 0, 0]]]]
    self._VerifyValues(
        image,
        ksizes=[2, 2],
        strides=[1, 1],
        rates=[1, 1],
        padding=""SAME"",
        patches=patches)

  def testKsize2x2Stride1x1Rate2x2Valid(self):
    """"""Test for 2x2 kernel with 2x2 dilation.""""""
    # [1, 2, 2, 1]
    image = np.arange(16).reshape(1, 4, 4, 1).astype(np.float32)
    # [1, 2, 2, 4]
    patches = [[[[0, 2, 8, 10], [1, 3, 9, 11]],
                [[4, 6, 12, 14], [5, 7, 13, 15]]]]
    self._VerifyValues(
        image,
        ksizes=[2, 2],
        strides=[1, 1],
        rates=[2, 2],
        padding=""VALID"",
        patches=patches)

  def testComplexDataTypes(self):
    """"""Test for complex data types""""""
    for dtype in [np.complex64, np.complex128]:
      image = (
          np.reshape(range(120), [2, 3, 4, 5]).astype(dtype) +
          np.reshape(range(120, 240), [2, 3, 4, 5]).astype(dtype) * 1j)
      patches = (
          np.reshape(range(120), [2, 3, 4, 5]).astype(dtype) +
          np.reshape(range(120, 240), [2, 3, 4, 5]).astype(dtype) * 1j)
      for padding in [""VALID"", ""SAME""]:
        self._VerifyValues(
            image,
            ksizes=[1, 1],
            strides=[1, 1],
            rates=[1, 1],
            padding=padding,
            patches=patches)


if __name__ == ""__main__"":
  test.main()
",CWE-476,145.0,1
"# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for script operations.""""""

from tensorflow.python.eager import def_function
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util
from tensorflow.python.ops import resource_variable_ops
from tensorflow.python.ops import script_ops
from tensorflow.python.ops.script_ops import numpy_function
from tensorflow.python.platform import test


class NumpyFunctionTest(test.TestCase):

  @test_util.run_in_graph_and_eager_modes
  def test_numpy_arguments(self):

    def plus(a, b):
      return a + b

    actual_result = script_ops.numpy_function(plus, [1, 2], dtypes.int32)
    expect_result = constant_op.constant(3, dtypes.int32)
    self.assertAllEqual(actual_result, expect_result)

  def test_stateless(self):
    call_count = 0

    def plus(a, b):
      nonlocal call_count
      call_count += 1
      return a + b

    @def_function.function
    def numpy_func_stateless(a, b):
      return numpy_function(plus, [a, b], dtypes.int32, stateful=False)

    @def_function.function
    def func_stateless(a, b):
      sum1 = numpy_func_stateless(a, b)
      sum2 = numpy_func_stateless(a, b)
      return sum1 + sum2

    self.evaluate(func_stateless(
        constant_op.constant(1),
        constant_op.constant(2),
    ))

    self.assertIn(call_count, (1, 2))  # as stateless, func may be deduplicated

  def test_stateful(self):
    call_count = 0

    def plus(a, b):
      nonlocal call_count
      call_count += 1
      return a + b

    @def_function.function
    def numpy_func_stateful(a, b):
      return numpy_function(plus, [a, b], dtypes.int32, stateful=True)

    @def_function.function
    def func_stateful(a, b):
      sum1 = numpy_func_stateful(a, b)
      sum2 = numpy_func_stateful(a, b)
      return sum1 + sum2

    self.evaluate(func_stateful(
        constant_op.constant(1),
        constant_op.constant(2),
    ))

    self.assertEqual(call_count,
                     2)  # as stateful, func is guaranteed to execute twice


class PyFunctionTest(test.TestCase):

  @test_util.run_in_graph_and_eager_modes
  def test_variable_arguments(self):

    def plus(a, b):
      return a + b

    v1 = resource_variable_ops.ResourceVariable(1)
    self.evaluate(v1.initializer)

    actual_result = script_ops.eager_py_func(plus, [v1, 2], dtypes.int32)
    expect_result = constant_op.constant(3, dtypes.int32)
    self.assertAllEqual(actual_result, expect_result)


if __name__ == ""__main__"":
  test.main()
",CWE-20,109.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for CandidateSamplerOp.""""""

import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import candidate_sampling_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.platform import test


class RangeSamplerOpsTest(test.TestCase):

  BATCH_SIZE = 3
  NUM_TRUE = 2
  RANGE = 5
  NUM_SAMPLED = RANGE

  TRUE_LABELS = [[1, 2], [0, 4], [3, 3]]

  @test_util.run_deprecated_v1
  def testTrueCandidates(self):
    with self.cached_session() as sess:
      indices = constant_op.constant([0, 0, 1, 1, 2, 2])
      true_candidates_vec = constant_op.constant([1, 2, 0, 4, 3, 3])
      true_candidates_matrix = array_ops.reshape(
          true_candidates_vec, [self.BATCH_SIZE, self.NUM_TRUE])
      indices_val, true_candidates_val = sess.run(
          [indices, true_candidates_matrix])

    self.assertAllEqual(indices_val, [0, 0, 1, 1, 2, 2])
    self.assertAllEqual(true_candidates_val, self.TRUE_LABELS)

  def testSampledCandidates(self):
    with self.cached_session():
      true_classes = constant_op.constant(
          [[1, 2], [0, 4], [3, 3]], dtype=dtypes.int64)
      sampled_candidates, _, _ = candidate_sampling_ops.all_candidate_sampler(
          true_classes, self.NUM_TRUE, self.NUM_SAMPLED, True)
      result = self.evaluate(sampled_candidates)

    expected_ids = [0, 1, 2, 3, 4]
    self.assertAllEqual(result, expected_ids)
    self.assertEqual(sampled_candidates.get_shape(), [self.NUM_SAMPLED])

  def testTrueLogExpectedCount(self):
    with self.cached_session():
      true_classes = constant_op.constant(
          [[1, 2], [0, 4], [3, 3]], dtype=dtypes.int64)
      _, true_expected_count, _ = candidate_sampling_ops.all_candidate_sampler(
          true_classes, self.NUM_TRUE, self.NUM_SAMPLED, True)
      true_log_expected_count = math_ops.log(true_expected_count)
      result = self.evaluate(true_log_expected_count)

    self.assertAllEqual(result, [[0.0] * self.NUM_TRUE] * self.BATCH_SIZE)
    self.assertEqual(true_expected_count.get_shape(),
                     [self.BATCH_SIZE, self.NUM_TRUE])
    self.assertEqual(true_log_expected_count.get_shape(),
                     [self.BATCH_SIZE, self.NUM_TRUE])

  def testSampledLogExpectedCount(self):
    with self.cached_session():
      true_classes = constant_op.constant(
          [[1, 2], [0, 4], [3, 3]], dtype=dtypes.int64)
      _, _, sampled_expected_count = candidate_sampling_ops.all_candidate_sampler(  # pylint: disable=line-too-long
          true_classes, self.NUM_TRUE, self.NUM_SAMPLED, True)
      sampled_log_expected_count = math_ops.log(sampled_expected_count)
      result = self.evaluate(sampled_log_expected_count)

    self.assertAllEqual(result, [0.0] * self.NUM_SAMPLED)
    self.assertEqual(sampled_expected_count.get_shape(), [self.NUM_SAMPLED])
    self.assertEqual(sampled_log_expected_count.get_shape(), [self.NUM_SAMPLED])

  def testAccidentalHits(self):
    with self.cached_session() as sess:
      true_classes = constant_op.constant(
          [[1, 2], [0, 4], [3, 3]], dtype=dtypes.int64)
      sampled_candidates, _, _ = candidate_sampling_ops.all_candidate_sampler(
          true_classes, self.NUM_TRUE, self.NUM_SAMPLED, True)
      accidental_hits = candidate_sampling_ops.compute_accidental_hits(
          true_classes, sampled_candidates, self.NUM_TRUE)
      indices, ids, weights = self.evaluate(accidental_hits)

    self.assertEqual(1, accidental_hits[0].get_shape().ndims)
    self.assertEqual(1, accidental_hits[1].get_shape().ndims)
    self.assertEqual(1, accidental_hits[2].get_shape().ndims)
    for index, id_, weight in zip(indices, ids, weights):
      self.assertTrue(id_ in self.TRUE_LABELS[index])
      self.assertLess(weight, -1.0e37)

  @test_util.run_deprecated_v1
  def testSeed(self):

    def draw(seed):
      with self.cached_session():
        true_classes = constant_op.constant(
            [[1, 2], [0, 4], [3, 3]], dtype=dtypes.int64)
        sampled, _, _ = candidate_sampling_ops.log_uniform_candidate_sampler(
            true_classes, self.NUM_TRUE, self.NUM_SAMPLED, True, 5, seed=seed)
        return self.evaluate(sampled)

    # Non-zero seed. Repeatable.
    for seed in [1, 12, 123, 1234]:
      self.assertAllEqual(draw(seed), draw(seed))
    # Seed=0 means random seeds.
    num_same = 0
    for _ in range(10):
      if np.allclose(draw(None), draw(None)):
        num_same += 1
    # Accounts for the fact that the same random seed may be picked
    # twice very rarely.
    self.assertLessEqual(num_same, 2)


if __name__ == ""__main__"":
  test.main()
",CWE-125,133.0,1
"# Tests of TensorFlow image kernels written using the Python API.

load(""//tensorflow:tensorflow.default.bzl"", ""cuda_py_test"", ""tf_py_test"")

package(licenses = [""notice""])

tf_py_test(
    name = ""attention_ops_test"",
    size = ""small"",
    srcs = [""attention_ops_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:image_ops"",
        ""//third_party/py/numpy"",
    ],
)

tf_py_test(
    name = ""decode_bmp_op_test"",
    size = ""small"",
    srcs = [""decode_bmp_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:image_ops"",
        ""//tensorflow/python:nn_grad"",
    ],
)

tf_py_test(
    name = ""decode_compressed_op_test"",
    size = ""small"",
    srcs = [""decode_compressed_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:parsing_ops"",
        ""//third_party/py/numpy"",
    ],
)

tf_py_test(
    name = ""decode_image_op_test"",
    size = ""small"",
    srcs = [""decode_image_op_test.py""],
    data = [""//tensorflow/core:image_testdata""],
    deps = [
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:errors"",
        ""//tensorflow/python:image_ops"",
        ""//tensorflow/python:io_ops"",
        ""//tensorflow/python:nn_grad"",
        ""//third_party/py/numpy"",
    ],
)

tf_py_test(
    name = ""decode_jpeg_op_test"",
    srcs = [""decode_jpeg_op_test.py""],
    data = [""//tensorflow/core:image_testdata""],
    deps = [
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:image_ops"",
        ""//tensorflow/python:platform"",
    ],
)

tf_py_test(
    name = ""decode_png_op_test"",
    size = ""small"",
    srcs = [""decode_png_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:image_ops"",
        ""//tensorflow/python:nn_grad"",
    ],
)

tf_py_test(
    name = ""decode_raw_op_test"",
    size = ""small"",
    srcs = [""decode_raw_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:parsing_ops"",
        ""//third_party/py/numpy"",
    ],
)

tf_py_test(
    name = ""draw_bounding_box_op_test"",
    size = ""small"",
    srcs = [""draw_bounding_box_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//tensorflow/python:image_ops"",
        ""//tensorflow/python:math_ops"",
        ""//third_party/py/numpy"",
    ],
)

# TODO(gpapan): Revisit the gradient of extract_image_patches_op to resolve
# http://b/31080670.
cuda_py_test(
    name = ""extract_image_patches_grad_test"",
    size = ""medium"",
    srcs = [""extract_image_patches_grad_test.py""],
    shard_count = 15,
    tags = [
        ""no_oss"",  # b/241024908
        ""no_rocm"",
        ""nomac"",  # b/181799478
        ""notap"",  # b/31080670
    ],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//third_party/py/numpy"",
    ],
)

cuda_py_test(
    name = ""extract_image_patches_op_test"",
    size = ""small"",
    srcs = [""extract_image_patches_op_test.py""],
    # TODO(b/144432983): S32 convolutions should not be auto-clustered.
    xla_enable_strict_auto_jit = False,
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//third_party/py/numpy"",
    ],
)

cuda_py_test(
    name = ""extract_volume_patches_grad_test"",
    size = ""medium"",
    srcs = [""extract_volume_patches_grad_test.py""],
    shard_count = 50,
    tags = [
        ""no_gpu"",  # b/171837334
        ""no_oss"",  # Test times out on oss-nightly cpu builds
        ""no_pip"",
        ""nomac"",  # b/139946976
        ""notap"",  # b/31080670
    ],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//third_party/py/numpy"",
    ],
)

cuda_py_test(
    name = ""extract_volume_patches_op_test"",
    size = ""small"",
    srcs = [""extract_volume_patches_op_test.py""],
    deps = [
        ""//tensorflow/python:array_ops"",
        ""//tensorflow/python:client_testlib"",
        ""//tensorflow/python:framework_for_generated_wrappers"",
        ""//third_party/py/numpy"",
    ],
)
",CWE-20,181.0,1
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for draw_bounding_box_op.""""""

import numpy as np

from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import image_ops
from tensorflow.python.ops import image_ops_impl
from tensorflow.python.ops import math_ops
from tensorflow.python.platform import test


class DrawBoundingBoxOpTest(test.TestCase):

  def _fillBorder(self, image, color):
    """"""Fill the border of the image.

    Args:
      image: Numpy array of shape [height, width, depth].
      color: Numpy color of shape [depth] and either contents RGB/RGBA.

    Returns:
      image of original shape with border filled with ""color"".

    Raises:
      ValueError: Depths of image and color don""t match.
    """"""
    height, width, depth = image.shape
    if depth != color.shape[0]:
      raise ValueError(""Image (%d) and color (%d) depths must match."" %
                       (depth, color.shape[0]))
    image[0:height, 0, 0:depth] = color
    image[0:height, width - 1, 0:depth] = color
    image[0, 0:width, 0:depth] = color
    image[height - 1, 0:width, 0:depth] = color
    return image

  def _testDrawBoundingBoxColorCycling(self,
                                       img,
                                       dtype=dtypes.float32,
                                       colors=None):
    """"""Tests if cycling works appropriately.

    Args:
      img: 3-D numpy image on which to draw.
      dtype: image dtype (float, half).
      colors: color table.
    """"""
    color_table = colors
    if colors is None:
      # THIS TABLE MUST MATCH draw_bounding_box_op.cc
      color_table = np.asarray([[1, 1, 0, 1], [0, 0, 1, 1], [1, 0, 0, 1],
                                [0, 1, 0, 1], [0.5, 0, 0.5,
                                               1], [0.5, 0.5, 0, 1],
                                [0.5, 0, 0, 1], [0, 0, 0.5, 1], [0, 1, 1, 1],
                                [1, 0, 1, 1]])
    assert len(img.shape) == 3
    depth = img.shape[2]
    assert depth <= color_table.shape[1]
    assert depth == 1 or depth == 3 or depth == 4
    ## Set red channel to 1 if image is GRY.
    if depth == 1:
      color_table[:, 0] = 1
    num_colors = color_table.shape[0]
    for num_boxes in range(1, num_colors + 2):
      # Generate draw_bounding_box_op drawn image
      image = np.copy(img)
      color = color_table[(num_boxes - 1) % num_colors, 0:depth]
      test_drawn_image = self._fillBorder(image, color)
      bboxes = np.asarray([0, 0, 1, 1])
      bboxes = np.vstack([bboxes for _ in range(num_boxes)])
      bboxes = math_ops.cast(bboxes, dtypes.float32)
      bboxes = array_ops.expand_dims(bboxes, 0)
      image = ops.convert_to_tensor(image)
      image = image_ops_impl.convert_image_dtype(image, dtype)
      image = array_ops.expand_dims(image, 0)
      image = image_ops.draw_bounding_boxes(image, bboxes, colors=colors)
      with self.cached_session(use_gpu=False) as sess:
        op_drawn_image = np.squeeze(sess.run(image), 0)
        self.assertAllEqual(test_drawn_image, op_drawn_image)

  def testDrawBoundingBoxRGBColorCycling(self):
    """"""Test if RGB color cycling works correctly.""""""
    image = np.zeros([10, 10, 3], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxRGBAColorCycling(self):
    """"""Test if RGBA color cycling works correctly.""""""
    image = np.zeros([10, 10, 4], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxGRY(self):
    """"""Test if drawing bounding box on a GRY image works.""""""
    image = np.zeros([4, 4, 1], ""float32"")
    self._testDrawBoundingBoxColorCycling(image)

  def testDrawBoundingBoxRGBColorCyclingWithColors(self):
    """"""Test if RGB color cycling works correctly with provided colors.""""""
    image = np.zeros([10, 10, 3], ""float32"")
    colors = np.asarray([[1, 1, 0, 1], [0, 0, 1, 1], [0.5, 0, 0.5, 1],
                         [0.5, 0.5, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]])
    self._testDrawBoundingBoxColorCycling(image, colors=colors)

  def testDrawBoundingBoxRGBAColorCyclingWithColors(self):
    """"""Test if RGBA color cycling works correctly with provided colors.""""""
    image = np.zeros([10, 10, 4], ""float32"")
    colors = np.asarray([[0.5, 0, 0.5, 1], [0.5, 0.5, 0, 1], [0.5, 0, 0, 1],
                         [0, 0, 0.5, 1]])
    self._testDrawBoundingBoxColorCycling(image, colors=colors)

  def testDrawBoundingBoxHalf(self):
    """"""Test if RGBA color cycling works correctly with provided colors.""""""
    image = np.zeros([10, 10, 4], ""float32"")
    colors = np.asarray([[0.5, 0, 0.5, 1], [0.5, 0.5, 0, 1], [0.5, 0, 0, 1],
                         [0, 0, 0.5, 1]])
    self._testDrawBoundingBoxColorCycling(
        image, dtype=dtypes.half, colors=colors)


if __name__ == ""__main__"":
  test.main()
",CWE-20,137.0,1
"# Copyright 2023 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Fault tolerance tests for tf.data service snapshots.""""""
import os
import tempfile

from absl.testing import parameterized

from tensorflow.python.data.experimental.kernel_tests.service import test_base as data_service_test_base
from tensorflow.python.data.experimental.ops import distributed_save_op
from tensorflow.python.data.kernel_tests import test_base
from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.framework import combinations
from tensorflow.python.platform import test


def write_file(path):
  os.makedirs(os.path.dirname(path), exist_ok=True)
  with open(path, ""w"") as _:
    pass


class SnapshotFtTest(data_service_test_base.TestBase, parameterized.TestCase):

  def setUp(self):
    super().setUp()
    self._path = os.path.join(
        tempfile.mkdtemp(dir=self.get_temp_dir()),
        ""snapshot_ft_test"",
    )

  # This ""manual"" setup function is needed due to some bad interaction between
  # `setUp` and `combinations` that causes the dataset to be out-of-scope.
  def setup(self):
    ds = dataset_ops.Dataset.range(10)
    cluster = data_service_test_base.TestCluster(num_workers=1)
    distributed_save_op.distributed_save(
        ds, self._path, cluster.dispatcher_address()
    )
    return cluster, ds

  def splits_dir(self, stream_idx=0):
    return os.path.join(
        self._path,
        ""streams"",
        f""stream_{stream_idx}"",
        ""splits"",
    )

  def source_dir(self, stream_idx=0, source_idx=0):
    return os.path.join(
        self.splits_dir(stream_idx),
        f""source_{source_idx}"",
    )

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoverySucceeds(self):
    cluster, _ = self.setup()
    cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryBlocksOverwrite(self):
    cluster, ds = self.setup()
    cluster.restart_dispatcher()
    with self.assertRaisesOpError(""is already started or completed""):
      distributed_save_op.distributed_save(
          ds, self._path, cluster.dispatcher_address()
      )

  @combinations.generate(
      combinations.times(
          test_base.eager_only_combinations(),
          combinations.combine(
              bad_stream_dir_name=[""stream_"", ""stream_x"", ""stream_-1""]
          ),
      )
  )
  def testSnapshotRecoveryFailsWithBadStreamName(self, bad_stream_dir_name):
    cluster, _ = self.setup()
    os.makedirs(os.path.join(self._path, ""streams"", bad_stream_dir_name))
    with self.assertRaisesRegex(ValueError, ""can't parse""):
      cluster.restart_dispatcher()

  @combinations.generate(
      combinations.times(
          test_base.eager_only_combinations(),
          combinations.combine(
              bad_source_dir_name=[""source_"", ""source_x"", ""source_-1""]
          ),
      )
  )
  def testSnapshotRecoveryFailsWithBadSourceName(self, bad_source_dir_name):
    cluster, _ = self.setup()
    os.makedirs(os.path.join(self.splits_dir(), bad_source_dir_name))
    with self.assertRaisesRegex(ValueError, ""can't parse""):
      cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryFailsWithOutOfBoundsSourceName(self):
    cluster, _ = self.setup()
    os.makedirs(os.path.join(self.splits_dir(), ""source_1""))
    with self.assertRaisesRegex(ValueError, ""found conflict""):
      cluster.restart_dispatcher()

  @combinations.generate(
      combinations.times(
          test_base.eager_only_combinations(),
          combinations.combine(
              bad_split_filename=[
                  ""split_"",
                  ""split_x_0"",
                  ""split_-1_0"",
                  ""split_0_x"",
                  ""split_0_-1"",
              ]
          ),
      )
  )
  def testSnapshotRecoveryFailsWithBadSplitNames(self, bad_split_filename):
    cluster, _ = self.setup()
    write_file(os.path.join(self.source_dir(), bad_split_filename))
    with self.assertRaisesRegex(ValueError, ""can't parse""):
      cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryFailsWithOutOfOrderSplitName(self):
    cluster, _ = self.setup()
    write_file(os.path.join(self.source_dir(), ""split_1_0""))
    with self.assertRaisesRegex(ValueError, ""found conflict""):
      cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryFailsWithOutOfBoundsSplitName(self):
    cluster, _ = self.setup()
    write_file(os.path.join(self.source_dir(), ""split_1_1""))
    with self.assertRaisesRegex(ValueError, ""found conflict""):
      cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryFailsWithMissingGlobalIndexInSplitNames(self):
    cluster, _ = self.setup()
    write_file(os.path.join(self.source_dir(), ""split_0_1""))
    with self.assertRaisesRegex(ValueError, ""found missing global""):
      cluster.restart_dispatcher()

  @combinations.generate(test_base.eager_only_combinations())
  def testSnapshotRecoveryFailsWithDuplicateGlobalIndexInSplitName(self):
    cluster, _ = self.setup()
    write_file(os.path.join(self.source_dir(stream_idx=0), ""split_0_1""))
    write_file(os.path.join(self.source_dir(stream_idx=1), ""split_0_1""))
    with self.assertRaisesRegex(ValueError, ""found duplicate global""):
      cluster.restart_dispatcher()


if __name__ == ""__main__"":
  test.main()
",CWE-125,169.0,1
"# To have reproducible builds, these dependencies should be pinned always.
# Prefer pinning to the same version as in setup.py for now.
# This will change in the future.
absl-py ~= 1.0.0
astunparse ~= 1.6.3
flatbuffers ~= 2.0
google_pasta ~= 0.2
h5py ~= 3.8.0  # Earliest version for Python 3.11
# TODO(b/262592253): Support older versions of NumPy for Python 3.10 and lower
# to support TFX. Remove when Apache Beam upgrades to newer NumPy.
numpy ~= 1.21.4; python_version < '3.11'
numpy ~= 1.23.2; python_version >= '3.11' # Earliest version for Python 3.11
opt_einsum ~= 3.3.0
protobuf ~= 3.19.3  # NOTE: Earliest version for Python 3.10
six ~= 1.16.0
termcolor ~= 2.1.1
typing_extensions ~= 3.10.0.0
wheel ~= 0.36.2
wrapt ~= 1.14.1

# We need to pin the gast dependency exactly
gast == 0.4.0

# Finally, install tensorboard and estimator and keras
# Note that here we want the latest version that matches TF major.minor version
# Note that we must use nightly here as these are used in nightly jobs
# For release jobs, we will pin these on the release branch
keras-nightly ~= 2.12.0.dev
tb-nightly ~= 2.12.0.a
tf-estimator-nightly ~= 2.12.0.dev

# Test dependencies
grpcio ~= 1.49.1 # Earliest version for Python 3.11
portpicker ~= 1.4.0
scipy ~= 1.7.2; python_version < '3.11'
scipy ~= 1.9.2; python_version >= '3.11' # Earliest version for Python 3.11

# This is usually vendored in setuptools but ensure it gets installed in CI anyway
# No bound here, we prefer the one in setuptools
packaging",CWE-125,40.0,1
"""""""Provides the repository macro to import TFRT.""""""

load(""//third_party:repo.bzl"", ""tf_http_archive"", ""tf_mirror_urls"")

def repo():
    """"""Imports TFRT.""""""

    # Attention: tools parse and update these lines.
    TFRT_COMMIT = ""c1248a015d23949afa2471bb21f6f52850aead7d""
    TFRT_SHA256 = ""8cdd8ea905478ac4ffd36ffb39cebe288d3b840d71a02d418bc6a8a760f92af8""

    tf_http_archive(
        name = ""tf_runtime"",
        sha256 = TFRT_SHA256,
        strip_prefix = ""runtime-{commit}"".format(commit = TFRT_COMMIT),
        urls = tf_mirror_urls(""https://github.com/tensorflow/runtime/archive/{commit}.tar.gz"".format(commit = TFRT_COMMIT)),
        # A patch file can be provided for atomic commits to both TF and TFRT.
        # The job that bumps the TFRT_COMMIT also resets patch_file to 'None'.
        patch_file = None,
    )
",CWE-125,21.0,1
"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
""""""Tests for array operations.""""""

from tensorflow.python.eager import backprop
from tensorflow.python.eager import def_function
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import tensor_spec
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import random_ops
from tensorflow.python.platform import test


class ArrayOpTest(test.TestCase):

  def testGatherGradHasPartialStaticShape(self):
    # Create a tensor with an unknown dim 1.
    x = random_ops.random_normal([4, 10, 10])
    x = array_ops.gather(
        x,
        array_ops.reshape(array_ops.where_v2(x[0, :, 0] > 0.5), [-1]),
        axis=1)
    x.shape.assert_is_compatible_with([4, None, 10])

    with backprop.GradientTape() as tape:
      tape.watch(x)
      a = array_ops.gather(array_ops.gather(x, [0, 1]), [0, 1])
    grad_a = tape.gradient(a, x)
    with backprop.GradientTape() as tape:
      tape.watch(x)
      b = array_ops.gather(array_ops.gather(x, [2, 3], axis=2), [0, 1])
    grad_b = tape.gradient(b, x)

    # We make sure that the representation of the shapes are correct; the shape
    # equality check will always eval to false due to the shapes being partial.
    grad_a.shape.assert_is_compatible_with([None, None, 10])
    grad_b.shape.assert_is_compatible_with([4, None, 10])

  def testReshapeShapeInference(self):
    # Create a tensor with an unknown dim 1.
    x = random_ops.random_normal([4, 10, 10])
    x = array_ops.gather(
        x,
        array_ops.reshape(array_ops.where_v2(x[0, :, 0] > 0.5), [-1]),
        axis=1)
    x.shape.assert_is_compatible_with([4, None, 10])
    a = array_ops.reshape(x, array_ops.shape(x))
    a.shape.assert_is_compatible_with([4, None, 10])
    b = array_ops.reshape(x, math_ops.cast(array_ops.shape(x), dtypes.int64))
    b.shape.assert_is_compatible_with([4, None, 10])

    # We do not shape-infer across a tf.cast into anything that's not tf.int32
    # or tf.int64, since they might end up mangling the shape.
    c = array_ops.reshape(
        x,
        math_ops.cast(
            math_ops.cast(array_ops.shape(x), dtypes.float32), dtypes.int32))
    c.shape.assert_is_compatible_with([None, None, None])

  def testEmptyMeshgrid(self):
    self.assertEqual(array_ops.meshgrid(), [])

  def testSlicedPartialShapeInference(self):

    @def_function.function(autograph=False)
    def g(x):
      return array_ops.zeros([array_ops.shape(x)[0]])

    conc = g.get_concrete_function(tensor_spec.TensorSpec([10, None]))
    self.assertAllEqual(conc.output_shapes.as_list(), [10])

  def testIdentityOnSlicedPartialShapeInference(self):

    @def_function.function(autograph=False)
    def g(x):
      return array_ops.zeros([array_ops.identity(array_ops.shape(x)[0])])

    conc = g.get_concrete_function(tensor_spec.TensorSpec([10, None]))
    self.assertAllEqual(conc.output_shapes.as_list(), [10])


if __name__ == ""__main__"":
  test.main()
",CWE-476,97.0,1
,CWE-697,,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

import re
import mistune
import tornado.web


from urllib.parse import unquote, quote

from .models import *
from .markdown import *
from tornado.escape import to_unicode

class BaseHandler(tornado.web.RequestHandler):
    def description(self, text):
        if len(text) <= 200:
            return re.sub('(<.*?>)', '', text).replace('\n', ' ')[:int(len(text)/2-4)] + '...'
        elif len(text) > 200:
            return re.sub('(<.*?>)', '', text).replace('\n', ' ')[:195] + '...'

    def md_to_html(self, text):
        text = to_unicode(text)
        renderer = MyRenderer()
        md = mistune.Markdown(renderer=renderer)
        return md.render(text)

    def urlencode(self, text):
        return quote(text.encode('utf8'))

    def urldecode(self, text):
        return unquote(text.encode('utf8'))

    def get_custom_page(self):
        return get_all_pages()

    def get_current_user(self):
        username = self.get_secure_cookie(""username"")
        if not username:
            return None
        return username

    def get_error_html(self, status_code, **kwargs):
        if status_code == 404:
            self.render(""404.html"",
                title = ""404 Page Not Found"",
                )
        else:
            try:
                exception = ""%s\n\n%s"" % (kwargs[""exception""],
                    traceback.format_exc())
                if self.settings.get(""debug""):
                    self.set_header('Content-Type', 'text/plain')
                    for line in exception:
                        self.write(line)
                else:
                    self.write(""oOps...! I made a mistake... "")
            except Exception:
                return super(BaseHandler, self).get_error_html(status_code,
                    **kwargs)",CWE-79,60.0,1
"import re

from django.utils.html import format_html
from django.utils.safestring import mark_safe

from docutils.core import publish_parts
from markdown import markdown
from mdx_gfm import GithubFlavoredMarkdownExtension


def metadata_fields(metadata_version):
    """"""Return meta-data about the meta-data :)""""""

    if metadata_version not in ('1.0', '1.1', '1.2', '2.1'):
        raise ValueError(""Unknown Metadata-Version: %s"" % metadata_version)

    required = set((
        'Metadata-Version',
        'Name',
        'Summary',
        'Version',
    ))
    fields = set((
        'Author',
        'Author-email',
        'Description',
        'Home-page',
        'Keywords',
        'License',
    ))
    multivalued = set((
        'Platform',
        'Supported-Platform',
    ))
    csv = set((
        'Platform',
        'Keywords',
    ))
    deprecated = set()

    if metadata_version in ('1.0', '1.1'):
        required.update((
            'Author-email',
            'License',
        ))
    if metadata_version in ('1.1', '1.2', '2.1'):
        required.update((
            'Download-URL',
        ))
        multivalued.update((
            'Classifier',
            'Requires',
            'Provides',
            'Obsoletes',
        ))
    if metadata_version in ('1.2', '2.1'):
        required.update((
            'Requires-Python',
        ))
        deprecated.update((
            'Requires',
            'Provides',
            'Obsoletes',
        ))
        fields.update((
            'Maintainer',
            'Maintainer-email',
        ))
        multivalued.update((
            'Obsoletes-Dist',
            'Project-URL',
            'Provides-Dist',
            'Requires-Dist',
            'Requires-External',
        ))
    if metadata_version in ('2.1',):
        fields.update((
            'Description-Content-Type',
        ))
        multivalued.update((
            'Provides-Extra',
        ))
    fields.update(required, deprecated, multivalued)

    return {
        'fields': fields,
        'required': required,
        'multivalued': multivalued,
        'csv': csv,
        'deprecated': deprecated,
    }


def display_sort(metadata):
    """"""Return an ordered list of key-value pairs, of a given metadata dict""""""
    key_order = (
        'Name',
        'Version',
        'Summary',
        'License',
        'Home-page',
        'Project-URL',
        'Download-URL',
        'Description',
        'Description-Content-Type',
        'Author',
        'Author-email',
        'Maintainer',
        'Maintainer-email',
        'Keywords',
        'Classifier',
        'Requires-Python',
        'Requires-External',
        'Requires-Dist',
        'Requires',
        'Provides-Dist',
        'Provides',
        'Provides-Extra',
        'Obsoletes-Dist',
        'Obsoletes',
        'Platform',
        'Supported-Platform',
        'Metadata-Version',
    )
    indices = dict((key, i) for i, key in enumerate(key_order))

    if isinstance(metadata, dict):
        metadata = metadata.items()

    return sorted(metadata, key=lambda row: (indices.get(row[0], 100), row))


def render_description(text, content_type):
    """"""Render Description field to HTML""""""
    if re.match(r'^.+(\n {8}.*)+\n?$', text):
        text = re.sub(r'^ {8}', '', text, flags=re.MULTILINE)

    if content_type == 'text/x-rst':
        html = publish_parts(
            text, writer_name='html',
            settings_overrides={'syntax_highlight': 'short'})['html_body']
    elif content_type == 'text/markdown':
        html = markdown(text, extensions=[GithubFlavoredMarkdownExtension()])
    else:
        html = format_html('<pre>{}</pre>', text)

    return mark_safe(html)
",CWE-79,148.0,1
"import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT


def _create_pg_connection(config):
    if 'server' in config:
        username = '@'.join([config['username'], config['server']])
    else:
        username = config['username']
    return psycopg2.connect(
        database=config['database'],
        user=username,
        host=config['host'],
        port=config['port'],
        password=config['password'],
    )


def check_db_or_user_exists(db_name, db_user, config):
    with _create_pg_connection(config) as con:
        with con.cursor() as cur:
            cur.execute(""SELECT 1 FROM pg_database WHERE datname='{}';"".format(db_name))
            db_exists = cur.fetchone() is not None
            cur.execute(""SELECT 1 FROM pg_roles WHERE rolname='{}';"".format(db_user))
            user = cur.fetchone()
            user_exists = user is not None
            return db_exists or user_exists


def create_postgres_db(connection_dict, config):
    if check_db_or_user_exists(connection_dict[""db_name""], connection_dict[""db_username""], config):
        raise ValueError(""db or user already exists"")
    with _create_pg_connection(config) as con:
        con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with con.cursor() as cur:
            create_role = ""CREATE USER {db_username} WITH PASSWORD '{db_pwd}';"".format(**connection_dict)
            drop_role = ""DROP ROLE {db_username};"".format(**connection_dict)
            grant_role = 'GRANT {db_username} TO ""{postgraas_user}"";'.format(
                db_username=connection_dict['db_username'], postgraas_user=get_normalized_username(config['username'])
            )
            create_database = ""CREATE DATABASE {db_name} OWNER {db_username};"".format(**connection_dict)
            try:
                cur.execute(create_role)
                cur.execute(grant_role)
            except psycopg2.ProgrammingError as e:
                raise ValueError(e.args[0])
            # cleanup role in case database creation fails
            # saidly 'CREATE DATABASE' cannot run inside a transaction block
            try:
                cur.execute(create_database)
            except psycopg2.ProgrammingError as e:
                cur.execute(drop_role)
                raise ValueError(e.args[0])


def get_normalized_username(username):
    return username.split('@')[0]


def delete_database(db_name, config):
    with _create_pg_connection(config) as con:
        con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with con.cursor() as cur:
            try:
                cur.execute('''DROP DATABASE ""{}"";'''.format(db_name))
            except psycopg2.ProgrammingError as e:
                raise ValueError(e.args[0])


def delete_user(username, config):
    with _create_pg_connection(config) as con:
        con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with con.cursor() as cur:
            try:
                cur.execute('''DROP USER ""{}"";'''.format(get_normalized_username(username)))
            except psycopg2.ProgrammingError as e:
                raise ValueError(e.args[0])
",CWE-89,78.0,1
"# This file is protected via CODEOWNERS
from __future__ import annotations

__version__ = ""2.0.6""
",CWE-200,5.0,1
"# Copyright (c) 2013-2017 by Ron Frederick <ronf@timeheart.net>.
# All rights reserved.
#
# This program and the accompanying materials are made available under
# the terms of the Eclipse Public License v1.0 which accompanies this
# distribution and is available at:
#
#     http://www.eclipse.org/legal/epl-v10.html
#
# Contributors:
#     Ron Frederick - initial implementation, API, and documentation

""""""AsyncSSH version information""""""

__author__ = 'Ron Frederick'

__author_email__ = 'ronf@timeheart.net'

__url__ = 'http://asyncssh.timeheart.net'

__version__ = '1.12.0'
",CWE-287,22.0,1
"# -*- coding: utf-8 -*-

""""""
    eve.io.mongo.parser
    ~~~~~~~~~~~~~~~~~~~

    This module implements a Python-to-Mongo syntax parser. Allows the MongoDB
    data-layer to seamlessly respond to a Python-like query.

    :copyright: (c) 2017 by Nicola Iarocci.
    :license: BSD, see LICENSE for more details.
""""""

import ast
import sys
from datetime import datetime   # noqa
from bson import ObjectId       # noqa


def parse(expression):
    """""" Given a python-like conditional statement, returns the equivalent
    mongo-like query expression. Conditional and boolean operators (==, <=, >=,
    !=, >, <) along with a couple function calls (ObjectId(), datetime()) are
    supported.
    """"""
    v = MongoVisitor()
    try:
        v.visit(ast.parse(expression))
    except SyntaxError as e:
        e = ParseError(e)
        e.__traceback__ = sys.exc_info()[2]
        raise e
    return v.mongo_query


class ParseError(ValueError):
    pass


class MongoVisitor(ast.NodeVisitor):
    """""" Implements the python-to-mongo parser. Only Python conditional
    statements are supported, however nested, combined with most common compare
    and boolean operators (And and Or).

    Supported compare operators: ==, >, <, !=, >=, <=
    Supported boolean operators: And, Or
    """"""
    op_mapper = {
        ast.Eq: '',
        ast.Gt: '$gt',
        ast.GtE: '$gte',
        ast.Lt: '$lt',
        ast.LtE: '$lte',
        ast.NotEq: '$ne',
        ast.Or: '$or',
        ast.And: '$and'
    }

    def visit_Module(self, node):
        """""" Module handler, our entry point.
        """"""
        self.mongo_query = {}
        self.ops = []
        self.current_value = None

        # perform the magic.
        self.generic_visit(node)

        # if we didn't obtain a query, it is likely that an unsupported
        # python expression has been passed.
        if self.mongo_query == {}:
            raise ParseError(""Only conditional statements with boolean ""
                             ""(and, or) and comparison operators are ""
                             ""supported."")

    def visit_Expr(self, node):
        """""" Make sure that we are parsing compare or boolean operators
        """"""
        if not (isinstance(node.value, ast.Compare) or
                isinstance(node.value, ast.BoolOp)):
            raise ParseError(""Will only parse conditional statements"")
        self.generic_visit(node)

    def visit_Compare(self, node):
        """""" Compare operator handler.
        """"""
        self.visit(node.left)
        left = self.current_value

        operator = self.op_mapper[node.ops[0].__class__] if node.ops else None

        if node.comparators:
            comparator = node.comparators[0]
            self.visit(comparator)

        if operator != '':
            value = {operator: self.current_value}
        else:
            value = self.current_value

        if self.ops:
            self.ops[-1].append({left: value})
        else:
            self.mongo_query[left] = value

    def visit_BoolOp(self, node):
        """""" Boolean operator handler.
        """"""
        op = self.op_mapper[node.op.__class__]
        self.ops.append([])
        for value in node.values:
            self.visit(value)

        c = self.ops.pop()
        if self.ops:
            self.ops[-1].append({op: c})
        else:
            self.mongo_query[op] = c

    def visit_Call(self, node):
        """""" A couple function calls are supported: bson's ObjectId() and
        datetime().
        """"""
        if isinstance(node.func, ast.Name):
            expr = None
            if node.func.id == 'ObjectId':
                expr = ""('"" + node.args[0].s + ""')""
            elif node.func.id == 'datetime':
                values = []
                for arg in node.args:
                    values.append(str(arg.n))
                expr = ""("" + "", "".join(values) + "")""
            if expr:
                self.current_value = eval(node.func.id + expr)

    def visit_Attribute(self, node):
        """""" Attribute handler ('Contact.Id').
        """"""
        self.visit(node.value)
        self.current_value += ""."" + node.attr

    def visit_Name(self, node):
        """""" Names handler.
        """"""
        self.current_value = node.id

    def visit_Num(self, node):
        """""" Numbers handler.
        """"""
        self.current_value = node.n

    def visit_Str(self, node):
        """""" Strings handler.
        """"""
        self.current_value = node.s
",CWE-94,156.0,1
,CWE-312,,1
"# -*- coding: utf-8 -*-
from datetime import timedelta

from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.backends import ModelBackend
from django.utils import timezone

from nopassword.models import LoginCode


class NoPasswordBackend(ModelBackend):

    def authenticate(self, request, username=None, code=None, **kwargs):
        if username is None:
            username = kwargs.get(get_user_model().USERNAME_FIELD)

        if not username or not code:
            return

        try:
            user = get_user_model()._default_manager.get_by_natural_key(username)

            if not self.user_can_authenticate(user):
                return

            timeout = getattr(settings, 'NOPASSWORD_LOGIN_CODE_TIMEOUT', 900)
            timestamp = timezone.now() - timedelta(seconds=timeout)

            # We don't delete the login code when authenticating,
            # as that is done during validation of the login form
            # and validation should not have any side effects.
            # It is the responsibility of the view/form to delete the token
            # as soon as the login was successfull.
            user.login_code = LoginCode.objects.get(user=user, code=code, timestamp__gt=timestamp)

            return user

        except (get_user_model().DoesNotExist, LoginCode.DoesNotExist):
            return

    def send_login_code(self, code, context, **kwargs):
        raise NotImplementedError
",CWE-312,44.0,1
"# -*- coding: utf-8 -*-
from django import forms
from django.contrib.auth import authenticate, get_backends, get_user_model
from django.contrib.sites.shortcuts import get_current_site
from django.core.exceptions import ImproperlyConfigured
from django.shortcuts import resolve_url
from django.utils.translation import ugettext_lazy as _

from nopassword import models


class LoginForm(forms.Form):
    error_messages = {
        'invalid_username': _(
            ""Please enter a correct %(username)s. ""
            ""Note that it is case-sensitive.""
        ),
        'inactive': _(""This account is inactive.""),
    }

    next = forms.CharField(max_length=200, required=False, widget=forms.HiddenInput)

    def __init__(self, *args, **kwargs):
        super(LoginForm, self).__init__(*args, **kwargs)

        self.username_field = get_user_model()._meta.get_field(get_user_model().USERNAME_FIELD)
        self.fields['username'] = self.username_field.formfield()

    def clean_username(self):
        username = self.cleaned_data['username']

        try:
            user = get_user_model()._default_manager.get_by_natural_key(username)
        except get_user_model().DoesNotExist:
            raise forms.ValidationError(
                self.error_messages['invalid_username'],
                code='invalid_username',
                params={'username': self.username_field.verbose_name},
            )

        if not user.is_active:
            raise forms.ValidationError(
                self.error_messages['inactive'],
                code='inactive',
            )

        self.cleaned_data['user'] = user

        return username

    def save(self, request, login_code_url='login_code', domain_override=None, extra_context=None):
        login_code = models.LoginCode.create_code_for_user(
            user=self.cleaned_data['user'],
            next=self.cleaned_data['next'],
        )

        if not domain_override:
            current_site = get_current_site(request)
            site_name = current_site.name
            domain = current_site.domain
        else:
            site_name = domain = domain_override

        url = '{}://{}{}?code={}'.format(
            'https' if request.is_secure() else 'http',
            domain,
            resolve_url(login_code_url),
            login_code.code,
        )

        context = {
            'domain': domain,
            'site_name': site_name,
            'code': login_code.code,
            'url': url,
        }

        if extra_context:
            context.update(extra_context)

        self.send_login_code(login_code, context)

        return login_code

    def send_login_code(self, login_code, context, **kwargs):
        for backend in get_backends():
            if hasattr(backend, 'send_login_code'):
                backend.send_login_code(login_code, context, **kwargs)
                break
        else:
            raise ImproperlyConfigured(
                'Please add a nopassword authentication backend to settings, '
                'e.g. `nopassword.backends.EmailBackend`'
            )


class LoginCodeForm(forms.Form):
    code = forms.ModelChoiceField(
        label=_('Login code'),
        queryset=models.LoginCode.objects.select_related('user'),
        to_field_name='code',
        widget=forms.TextInput,
        error_messages={
            'invalid_choice': _('Login code is invalid. It might have expired.'),
        },
    )

    error_messages = {
        'invalid_code': _(""Unable to log in with provided login code.""),
    }

    def __init__(self, request=None, *args, **kwargs):
        super(LoginCodeForm, self).__init__(*args, **kwargs)

        self.request = request

    def clean_code(self):
        code = self.cleaned_data['code']
        username = code.user.get_username()
        user = authenticate(self.request, **{
            get_user_model().USERNAME_FIELD: username,
            'code': code.code,
        })

        if not user:
            raise forms.ValidationError(
                self.error_messages['invalid_code'],
                code='invalid_code',
            )

        self.cleaned_data['user'] = user

        return code

    def get_user(self):
        return self.cleaned_data.get('user')

    def save(self):
        self.cleaned_data['code'].delete()
",CWE-312,140.0,1
,CWE-312,,1
"# -*- coding: utf-8 -*-
import hashlib
import os

from django.conf import settings
from django.db import models
from django.utils import timezone
from django.utils.translation import ugettext_lazy as _


class LoginCode(models.Model):
    user = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='login_codes',
                             editable=False, verbose_name=_('user'), on_delete=models.CASCADE)
    code = models.CharField(max_length=20, editable=False, verbose_name=_('code'))
    timestamp = models.DateTimeField(editable=False)
    next = models.TextField(editable=False, blank=True)

    def __str__(self):
        return ""%s - %s"" % (self.user, self.timestamp)

    def save(self, *args, **kwargs):
        self.timestamp = timezone.now()

        if not self.next:
            self.next = '/'

        super(LoginCode, self).save(*args, **kwargs)

    @classmethod
    def create_code_for_user(cls, user, next=None):
        if not user.is_active:
            return None

        code = cls.generate_code()
        login_code = LoginCode(user=user, code=code)
        if next is not None:
            login_code.next = next
        login_code.save()
        return login_code

    @classmethod
    def generate_code(cls):
        hash_algorithm = getattr(settings, 'NOPASSWORD_HASH_ALGORITHM', 'sha256')
        m = getattr(hashlib, hash_algorithm)()
        m.update(getattr(settings, 'SECRET_KEY', None).encode('utf-8'))
        m.update(os.urandom(16))
        if getattr(settings, 'NOPASSWORD_NUMERIC_CODES', False):
            hashed = str(int(m.hexdigest(), 16))
        else:
            hashed = m.hexdigest()
        return hashed
",CWE-312,52.0,1
"# -*- coding: utf-8 -*-
from django.conf import settings
from django.contrib.auth import login as django_login
from django.contrib.auth import logout as django_logout
from django.core.exceptions import ObjectDoesNotExist
from django.utils.decorators import method_decorator
from django.utils.translation import ugettext_lazy as _
from django.views.decorators.debug import sensitive_post_parameters
from rest_framework import status
from rest_framework.authtoken.models import Token
from rest_framework.generics import GenericAPIView
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from nopassword.rest import serializers


class LoginView(GenericAPIView):
    serializer_class = serializers.LoginSerializer
    permission_classes = (AllowAny,)

    def post(self, request, *args, **kwargs):
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        serializer.save()

        return Response(
            {""detail"": _(""Login code has been sent."")},
            status=status.HTTP_200_OK
        )


@method_decorator(sensitive_post_parameters('code'), 'dispatch')
class LoginCodeView(GenericAPIView):
    permission_classes = (AllowAny,)
    serializer_class = serializers.LoginCodeSerializer
    token_serializer_class = serializers.TokenSerializer
    token_model = Token

    def process_login(self):
        django_login(self.request, self.user)

    def login(self):
        self.user = self.serializer.validated_data['user']
        self.token, created = self.token_model.objects.get_or_create(user=self.user)

        if getattr(settings, 'REST_SESSION_LOGIN', True):
            self.process_login()

    def get_response(self):
        token_serializer = self.token_serializer_class(
            instance=self.token,
            context=self.get_serializer_context(),
        )
        data = token_serializer.data
        data['next'] = self.serializer.validated_data['code'].next
        return Response(data, status=status.HTTP_200_OK)

    def post(self, request, *args, **kwargs):
        self.serializer = self.get_serializer(data=request.data)
        self.serializer.is_valid(raise_exception=True)
        self.serializer.save()
        self.login()
        return self.get_response()


class LogoutView(APIView):
    permission_classes = (AllowAny,)

    def post(self, request, *args, **kwargs):
        return self.logout(request)

    def logout(self, request):
        try:
            request.user.auth_token.delete()
        except (AttributeError, ObjectDoesNotExist):
            pass

        django_logout(request)

        return Response(
            {""detail"": _(""Successfully logged out."")},
            status=status.HTTP_200_OK,
        )
",CWE-312,86.0,1
"from django.db import models

try:
    from django.contrib.auth.models import AbstractUser
except ImportError:
    from django.db.models import Model as AbstractUser


class CustomUser(AbstractUser):
    extra_field = models.CharField(max_length=2)
    new_username_field = models.CharField('userid', unique=True, max_length=20)

    USERNAME_FIELD = 'new_username_field'

    def save(self, *args, **kwargs):
        self.new_username_field = self.username
        super(CustomUser, self).save(*args, **kwargs)


class PhoneNumberUser(CustomUser):
    phone_number = models.CharField(max_length=11, default=""+15555555"")


class NoUsernameUser(models.Model):
    """"""User model without a ""username"" field for authentication
    backend testing
    """"""
    pass
",CWE-312,29.0,1
"# -*- coding: utf8 -*-

import django

DEBUG = False

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': ':memory:',
    }
}

AUTH_USER_MODEL = 'tests.CustomUser'

NOPASSWORD_LOGIN_CODE_TIMEOUT = 900

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',

    'rest_framework',
    'rest_framework.authtoken',

    'nopassword',
    'tests',
]
AUTHENTICATION_BACKENDS = (
    'nopassword.backends.EmailBackend',
    'django.contrib.auth.backends.ModelBackend'
)

TIME_ZONE = 'America/Chicago'
LANGUAGE_CODE = 'en-us'
STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
)

SECRET_KEY = 'supersecret'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.contrib.auth.context_processors.auth',
            ],
        },
    },
]

MIDDLEWARE = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
)

if django.VERSION < (1, 10):
    MIDDLEWARE_CLASSES = MIDDLEWARE

ROOT_URLCONF = 'tests.urls'

EMAIL_BACKEND = 'django.core.mail.backends.dummy.EmailBackend'

REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework.authentication.SessionAuthentication',
        'rest_framework.authentication.TokenAuthentication',
    ),
}
",CWE-312,78.0,1
"# -*- coding: utf8 -*-
import time
from datetime import datetime

from django.contrib.auth import authenticate, get_user_model
from django.test import TestCase
from django.test.utils import override_settings

from nopassword.models import LoginCode


class TestLoginCodes(TestCase):

    def setUp(self):
        self.user = get_user_model().objects.create(username='test_user')
        self.inactive_user = get_user_model().objects.create(username='inactive', is_active=False)
        self.code = LoginCode.create_code_for_user(self.user)

    def test_login_backend(self):
        self.assertEqual(len(self.code.code), 64)
        self.assertIsNotNone(authenticate(username=self.user.username, code=self.code.code))
        self.assertIsNone(LoginCode.create_code_for_user(self.inactive_user))

    @override_settings(NOPASSWORD_NUMERIC_CODES=True)
    def test_numeric_code(self):
        code = LoginCode.create_code_for_user(self.user)
        self.assertGreater(len(code.code), 64)
        self.assertTrue(code.code.isdigit())

    def test_next_value(self):
        code = LoginCode.create_code_for_user(self.user, next='/secrets/')
        self.assertEqual(code.next, '/secrets/')

    @override_settings(NOPASSWORD_LOGIN_CODE_TIMEOUT=1)
    def test_code_timeout(self):
        timeout_code = LoginCode.create_code_for_user(self.user)
        time.sleep(3)
        self.assertIsNone(authenticate(username=self.user.username, code=timeout_code.code))

    def test_str(self):
        code = LoginCode(user=self.user, code='foo', timestamp=datetime(2018, 7, 1))
        self.assertEqual(str(code), 'test_user - 2018-07-01 00:00:00')
",CWE-312,43.0,1
"# -*- coding: utf8 -*-
from django.contrib.auth import get_user_model
from django.core import mail
from django.test import TestCase
from rest_framework.authtoken.models import Token

from nopassword.models import LoginCode


class TestRestViews(TestCase):

    def setUp(self):
        self.user = get_user_model().objects.create(username='user', email='foo@bar.com')

    def test_request_login_code(self):
        response = self.client.post('/accounts-rest/login/', {
            'username': self.user.username,
            'next': '/private/',
        })

        self.assertEqual(response.status_code, 200)

        login_code = LoginCode.objects.filter(user=self.user).first()

        self.assertIsNotNone(login_code)
        self.assertEqual(login_code.next, '/private/')
        self.assertEqual(len(mail.outbox), 1)
        self.assertIn(
            'http://testserver/accounts/login/code/?code={}'.format(login_code.code),
            mail.outbox[0].body,
        )

    def test_request_login_code_missing_username(self):
        response = self.client.post('/accounts-rest/login/')

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'username': ['This field is required.'],
        })

    def test_request_login_code_unknown_user(self):
        response = self.client.post('/accounts-rest/login/', {
            'username': 'unknown',
        })

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'username': ['Please enter a correct userid. Note that it is case-sensitive.'],
        })

    def test_request_login_code_inactive_user(self):
        self.user.is_active = False
        self.user.save()

        response = self.client.post('/accounts-rest/login/', {
            'username': self.user.username,
        })

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'username': ['This account is inactive.'],
        })

    def test_login(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar', next='/private/')

        response = self.client.post('/accounts-rest/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 200)
        self.assertFalse(LoginCode.objects.filter(pk=login_code.pk).exists())

        token = Token.objects.filter(user=self.user).first()

        self.assertIsNotNone(token)
        self.assertEqual(response.data, {
            'key': token.key,
            'next': '/private/',
        })

    def test_login_missing_code(self):
        response = self.client.post('/accounts-rest/login/code/')

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'code': ['This field is required.'],
        })

    def test_login_unknown_code(self):
        response = self.client.post('/accounts-rest/login/code/', {
            'code': 'unknown',
        })

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'code': ['Login code is invalid. It might have expired.'],
        })

    def test_login_inactive_user(self):
        self.user.is_active = False
        self.user.save()

        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        response = self.client.post('/accounts-rest/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.json(), {
            'code': ['Unable to log in with provided login code.'],
        })

    def test_logout(self):
        token = Token.objects.create(user=self.user, key='foobar')

        response = self.client.post(
            '/accounts-rest/logout/',
            HTTP_AUTHORIZATION='Token {}'.format(token.key),
        )

        self.assertEqual(response.status_code, 200)
        self.assertFalse(Token.objects.filter(user=self.user).exists())

    def test_logout_unknown_token(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        self.client.login(username=self.user.username, code=login_code.code)

        response = self.client.post(
            '/accounts-rest/logout/',
            HTTP_AUTHORIZATION='Token unknown',
        )

        self.assertEqual(response.status_code, 200)
",CWE-312,137.0,1
"# -*- coding: utf8 -*-
from django.contrib.auth import get_user_model
from django.core import mail
from django.test import TestCase, override_settings

from nopassword.models import LoginCode


class TestViews(TestCase):

    def setUp(self):
        self.user = get_user_model().objects.create(username='user', email='foo@bar.com')

    def test_request_login_code(self):
        response = self.client.post('/accounts/login/', {
            'username': self.user.username,
            'next': '/private/',
        })

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response['Location'], '/accounts/login/code/')

        login_code = LoginCode.objects.filter(user=self.user).first()

        self.assertIsNotNone(login_code)
        self.assertEqual(login_code.next, '/private/')
        self.assertEqual(len(mail.outbox), 1)
        self.assertIn(
            'http://testserver/accounts/login/code/?code={}'.format(login_code.code),
            mail.outbox[0].body,
        )

    def test_request_login_code_missing_username(self):
        response = self.client.post('/accounts/login/')

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'username': ['This field is required.'],
        })

    def test_request_login_code_unknown_user(self):
        response = self.client.post('/accounts/login/', {
            'username': 'unknown',
        })

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'username': ['Please enter a correct userid. Note that it is case-sensitive.'],
        })

    def test_request_login_code_inactive_user(self):
        self.user.is_active = False
        self.user.save()

        response = self.client.post('/accounts/login/', {
            'username': self.user.username,
        })

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'username': ['This account is inactive.'],
        })

    def test_login_post(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar', next='/private/')

        response = self.client.post('/accounts/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response['Location'], '/private/')
        self.assertEqual(response.wsgi_request.user, self.user)
        self.assertFalse(LoginCode.objects.filter(pk=login_code.pk).exists())

    def test_login_get(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        response = self.client.get('/accounts/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].cleaned_data['code'], login_code)
        self.assertTrue(response.wsgi_request.user.is_anonymous)
        self.assertTrue(LoginCode.objects.filter(pk=login_code.pk).exists())

    @override_settings(NOPASSWORD_LOGIN_ON_GET=True)
    def test_login_get_non_idempotent(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar', next='/private/')

        response = self.client.get('/accounts/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response['Location'], '/private/')
        self.assertEqual(response.wsgi_request.user, self.user)
        self.assertFalse(LoginCode.objects.filter(pk=login_code.pk).exists())

    def test_login_missing_code_post(self):
        response = self.client.post('/accounts/login/code/')

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'code': ['This field is required.'],
        })

    def test_login_missing_code_get(self):
        response = self.client.get('/accounts/login/code/')

        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.context['form'].is_bound)

    def test_login_unknown_code(self):
        response = self.client.post('/accounts/login/code/', {
            'code': 'unknown',
        })

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'code': ['Login code is invalid. It might have expired.'],
        })

    def test_login_inactive_user(self):
        self.user.is_active = False
        self.user.save()

        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        response = self.client.post('/accounts/login/code/', {
            'code': login_code.code,
        })

        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context['form'].errors, {
            'code': ['Unable to log in with provided login code.'],
        })

    def test_logout_post(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        self.client.login(username=self.user.username, code=login_code.code)

        response = self.client.post('/accounts/logout/?next=/accounts/login/')

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response['Location'], '/accounts/login/')
        self.assertTrue(response.wsgi_request.user.is_anonymous)

    def test_logout_get(self):
        login_code = LoginCode.objects.create(user=self.user, code='foobar')

        self.client.login(username=self.user.username, code=login_code.code)

        response = self.client.post('/accounts/logout/?next=/accounts/login/')

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response['Location'], '/accounts/login/')
        self.assertTrue(response.wsgi_request.user.is_anonymous)
",CWE-312,161.0,1
"# -*- coding: utf8 -*-
from django.conf.urls import include, url

urlpatterns = [
    url(r'^accounts/', include('nopassword.urls')),
    url(r'^accounts-rest/', include('nopassword.rest.urls')),
]
",CWE-312,8.0,1
"[tox]
envlist =
    flake8,
    isort,
    py2-{django1_11},
    py3-{django1_11,django2_0,django2_1},
    coverage
skipsdist = True

[testenv]
basepython =
    py3: python3
    py2: python2
setenv =
    PYTHONPATH = {toxinidir}:{toxinidir}
commands =
    coverage run -p --source=nopassword runtests.py
deps =
    -r{toxinidir}/requirements.txt
    django1_11: Django>=1.11,<1.12
    django2_0: Django>=2.0,<2.1
    django2_1: Django>=2.1,<2.2

[testenv:flake8]
basepython = python3
deps = flake8
commands = flake8

[testenv:isort]
basepython = python3
deps = isort
commands = isort -c -rc nopassword tests

[testenv:coverage]
basepython = python3
deps = coverage
commands = 
    coverage combine
    coverage report 
    coverage xml
",CWE-312,41.0,1
"# -*- coding: utf-8 -*-

# Copyright 2014-2015 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import socket
import random
import smtplib
import email.utils
import string
import twisted.python.log
import cgi
import urllib

import email.utils

from sydent.util import time_msec

logger = logging.getLogger(__name__)


def sendEmail(sydent, templateName, mailTo, substitutions):
        mailFrom = sydent.cfg.get('email', 'email.from')
        mailTemplateFile = sydent.cfg.get('email', templateName)

        myHostname = sydent.cfg.get('email', 'email.hostname')
        if myHostname == '':
            myHostname = socket.getfqdn()
        midRandom = """".join([random.choice(string.ascii_letters) for _ in range(16)])
        messageid = ""<%d%s@%s>"" % (time_msec(), midRandom, myHostname)

        allSubstitutions = {}
        allSubstitutions.update(substitutions)
        allSubstitutions.update({
            'messageid': messageid,
            'date': email.utils.formatdate(localtime=False),
            'to': mailTo,
            'from': mailFrom,
        })

        for k,v in allSubstitutions.items():
            allSubstitutions[k] = v.decode('utf8')
            allSubstitutions[k+""_forhtml""] = cgi.escape(v.decode('utf8'))
            allSubstitutions[k+""_forurl""] = urllib.quote(v)

        mailString = open(mailTemplateFile).read() % allSubstitutions
        rawFrom = email.utils.parseaddr(mailFrom)[1]
        rawTo = email.utils.parseaddr(mailTo)[1]
        if rawFrom == '' or rawTo == '':
            logger.info(""Couldn't parse from / to address %s / %s"", mailFrom, mailTo)
            raise EmailAddressException()
        mailServer = sydent.cfg.get('email', 'email.smtphost')
        mailPort = sydent.cfg.get('email', 'email.smtpport')
        mailUsername = sydent.cfg.get('email', 'email.smtpusername')
        mailPassword = sydent.cfg.get('email', 'email.smtppassword')
        mailTLSMode = sydent.cfg.get('email', 'email.tlsmode')
        logger.info(""Sending mail to %s with mail server: %s"" % (mailTo, mailServer,))
        try:
            if mailTLSMode == 'SSL' or mailTLSMode == 'TLS':
                smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname)
            elif mailTLSMode == 'STARTTLS':
                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)
                smtp.starttls()
            else:
                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)
            if mailUsername != '':
                smtp.login(mailUsername, mailPassword)
            smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))
            smtp.quit()
        except Exception as origException:
            twisted.python.log.err()
            ese = EmailSendException()
            ese.cause = origException
            raise ese


class EmailAddressException(Exception):
    pass


class EmailSendException(Exception):
    pass
",CWE-20,95.0,1
"# -*- coding: utf-8 -*-

# Copyright 2014 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

import twisted.internet.ssl

logger = logging.getLogger(__name__)

class SslComponents:
    def __init__(self, sydent):
        self.sydent = sydent

        self.myPrivateCertificate = self.makeMyCertificate()
        self.trustRoot = self.makeTrustRoot()

    def makeMyCertificate(self):
        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')
        if privKeyAndCertFilename == '':
            logger.warn(""No HTTPS private key / cert found: not starting replication server ""
                        ""or doing replication pushes"")
            return None

        try:
            fp = open(privKeyAndCertFilename)
        except IOError:
            logger.warn(""Unable to read private key / cert file from %s: not starting the replication HTTPS server ""
                        ""or doing replication pushes."",
                        privKeyAndCertFilename)
            return None

        authData = fp.read()
        fp.close()
        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)

    def makeTrustRoot(self):
        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not
        # practical to get the client cert signed by a real root CA but should never be used on a production server.
        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')
        if len(caCertFilename) > 0:
            try:
                fp = open(caCertFilename)
                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())
                fp.close()
            except:
                logger.warn(""Failed to open CA cert file %s"", caCertFilename)
                raise
            logger.warn(""Using custom CA cert file: %s"", caCertFilename)
            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])
        else:
            return twisted.internet.ssl.OpenSSLDefaultPaths()
",CWE-770,65.0,1
"# -*- coding: utf-8 -*-

# Copyright 2016 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

import json
import logging
from io import BytesIO

from twisted.internet import defer
from twisted.web.client import FileBodyProducer, Agent, readBody
from twisted.web.http_headers import Headers
from sydent.http.matrixfederationagent import MatrixFederationAgent

from sydent.http.federation_tls_options import ClientTLSOptionsFactory

logger = logging.getLogger(__name__)


class HTTPClient(object):
    """"""A base HTTP class that contains methods for making GET and POST HTTP
    requests.
    """"""
    @defer.inlineCallbacks
    def get_json(self, uri):
        """"""Make a GET request to an endpoint returning JSON and parse result

        :param uri: The URI to make a GET request to.
        :type uri: unicode

        :return: A deferred containing JSON parsed into a Python object.
        :rtype: twisted.internet.defer.Deferred[dict[any, any]]
        """"""
        logger.debug(""HTTP GET %s"", uri)

        response = yield self.agent.request(
            b""GET"",
            uri.encode(""utf8""),
        )
        body = yield readBody(response)
        try:
            # json.loads doesn't allow bytes in Python 3.5
            json_body = json.loads(body.decode(""UTF-8""))
        except Exception as e:
            logger.exception(""Error parsing JSON from %s"", uri)
            raise
        defer.returnValue(json_body)

    @defer.inlineCallbacks
    def post_json_get_nothing(self, uri, post_json, opts):
        """"""Make a POST request to an endpoint returning JSON and parse result

        :param uri: The URI to make a POST request to.
        :type uri: unicode

        :param post_json: A Python object that will be converted to a JSON
            string and POSTed to the given URI.
        :type post_json: dict[any, any]

        :param opts: A dictionary of request options. Currently only opts.headers
            is supported.
        :type opts: dict[str,any]

        :return: a response from the remote server.
        :rtype: twisted.internet.defer.Deferred[twisted.web.iweb.IResponse]
        """"""
        json_bytes = json.dumps(post_json).encode(""utf8"")

        headers = opts.get('headers', Headers({
            b""Content-Type"": [b""application/json""],
        }))

        logger.debug(""HTTP POST %s -> %s"", json_bytes, uri)

        response = yield self.agent.request(
            b""POST"",
            uri.encode(""utf8""),
            headers,
            bodyProducer=FileBodyProducer(BytesIO(json_bytes))
        )

        # Ensure the body object is read otherwise we'll leak HTTP connections
        # as per
        # https://twistedmatrix.com/documents/current/web/howto/client.html
        yield readBody(response)

        defer.returnValue(response)

class SimpleHttpClient(HTTPClient):
    """"""A simple, no-frills HTTP client based on the class of the same name
    from Synapse.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        # The default endpoint factory in Twisted 14.0.0 (which we require) uses the
        # BrowserLikePolicyForHTTPS context factory which will do regular cert validation
        # 'like a browser'
        self.agent = Agent(
            self.sydent.reactor,
            connectTimeout=15,
        )

class FederationHttpClient(HTTPClient):
    """"""HTTP client for federation requests to homeservers. Uses a
    MatrixFederationAgent.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        self.agent = MatrixFederationAgent(
            self.sydent.reactor,
            ClientTLSOptionsFactory(sydent.cfg),
        )
",CWE-770,125.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource
from twisted.internet import defer

import logging
import json
from six.moves import urllib

from sydent.http.servlets import get_args, jsonwrap, deferjsonwrap, send_cors
from sydent.http.httpclient import FederationHttpClient
from sydent.users.tokens import issueToken


logger = logging.getLogger(__name__)


class RegisterServlet(Resource):
    isLeaf = True

    def __init__(self, syd):
        self.sydent = syd
        self.client = FederationHttpClient(self.sydent)

    @deferjsonwrap
    @defer.inlineCallbacks
    def render_POST(self, request):
        """"""
        Register with the Identity Server
        """"""
        send_cors(request)

        args = get_args(request, ('matrix_server_name', 'access_token'))

        result = yield self.client.get_json(
            ""matrix://%s/_matrix/federation/v1/openid/userinfo?access_token=%s"" % (
                args['matrix_server_name'], urllib.parse.quote(args['access_token']),
            ),
        )
        if 'sub' not in result:
            raise Exception(""Invalid response from homeserver"")

        user_id = result['sub']
        tok = yield issueToken(self.sydent, user_id)

        # XXX: `token` is correct for the spec, but we released with `access_token`
        # for a substantial amount of time. Serve both to make spec-compliant clients
        # happy.
        defer.returnValue({
            ""access_token"": tok,
            ""token"": tok,
        })

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-770,72.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource
from twisted.internet import defer

import logging
import json
from six.moves import urllib

from sydent.http.servlets import get_args, jsonwrap, deferjsonwrap, send_cors
from sydent.http.httpclient import FederationHttpClient
from sydent.users.tokens import issueToken


logger = logging.getLogger(__name__)


class RegisterServlet(Resource):
    isLeaf = True

    def __init__(self, syd):
        self.sydent = syd
        self.client = FederationHttpClient(self.sydent)

    @deferjsonwrap
    @defer.inlineCallbacks
    def render_POST(self, request):
        """"""
        Register with the Identity Server
        """"""
        send_cors(request)

        args = get_args(request, ('matrix_server_name', 'access_token'))

        result = yield self.client.get_json(
            ""matrix://%s/_matrix/federation/v1/openid/userinfo?access_token=%s"" % (
                args['matrix_server_name'], urllib.parse.quote(args['access_token']),
            ),
            1024 * 5,
        )
        if 'sub' not in result:
            raise Exception(""Invalid response from homeserver"")

        user_id = result['sub']
        tok = yield issueToken(self.sydent, user_id)

        # XXX: `token` is correct for the spec, but we released with `access_token`
        # for a substantial amount of time. Serve both to make spec-compliant clients
        # happy.
        defer.returnValue({
            ""access_token"": tok,
            ""token"": tok,
        })

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-20,73.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource
from twisted.internet import defer

import logging
import json
from six.moves import urllib

from sydent.http.servlets import get_args, jsonwrap, deferjsonwrap, send_cors
from sydent.http.httpclient import FederationHttpClient
from sydent.users.tokens import issueToken


logger = logging.getLogger(__name__)


class RegisterServlet(Resource):
    isLeaf = True

    def __init__(self, syd):
        self.sydent = syd
        self.client = FederationHttpClient(self.sydent)

    @deferjsonwrap
    @defer.inlineCallbacks
    def render_POST(self, request):
        """"""
        Register with the Identity Server
        """"""
        send_cors(request)

        args = get_args(request, ('matrix_server_name', 'access_token'))

        result = yield self.client.get_json(
            ""matrix://%s/_matrix/federation/v1/openid/userinfo?access_token=%s"" % (
                args['matrix_server_name'], urllib.parse.quote(args['access_token']),
            ),
            1024 * 5,
        )
        if 'sub' not in result:
            raise Exception(""Invalid response from homeserver"")

        user_id = result['sub']
        tok = yield issueToken(self.sydent, user_id)

        # XXX: `token` is correct for the spec, but we released with `access_token`
        # for a substantial amount of time. Serve both to make spec-compliant clients
        # happy.
        defer.returnValue({
            ""access_token"": tok,
            ""token"": tok,
        })

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-918,73.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import re

# https://matrix.org/docs/spec/client_server/r0.6.0#post-matrix-client-r0-register-email-requesttoken
client_secret_regex = re.compile(r""^[0-9a-zA-Z\.\=\_\-]+$"")


def is_valid_client_secret(client_secret):
    """"""Validate that a given string matches the client_secret regex defined by the spec

    :param client_secret: The client_secret to validate
    :type client_secret: unicode

    :return: Whether the client_secret is valid
    :rtype: bool
    """"""
    return client_secret_regex.match(client_secret) is not None
",CWE-20,31.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import re

# https://matrix.org/docs/spec/client_server/r0.6.0#post-matrix-client-r0-register-email-requesttoken
client_secret_regex = re.compile(r""^[0-9a-zA-Z\.\=\_\-]+$"")


def is_valid_client_secret(client_secret):
    """"""Validate that a given string matches the client_secret regex defined by the spec

    :param client_secret: The client_secret to validate
    :type client_secret: unicode

    :return: Whether the client_secret is valid
    :rtype: bool
    """"""
    return client_secret_regex.match(client_secret) is not None
",CWE-918,31.0,1
"# -*- coding: utf-8 -*-

# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from twisted.trial import unittest

from sydent.http.auth import tokenFromRequest
from tests.utils import make_request, make_sydent


class AuthTestCase(unittest.TestCase):
    """"""Tests Sydent's auth code""""""

    def setUp(self):
        # Create a new sydent
        self.sydent = make_sydent()
        self.test_token = ""testingtoken""

        # Inject a fake OpenID token into the database
        cur = self.sydent.db.cursor()
        cur.execute(
            ""INSERT INTO accounts (user_id, created_ts, consent_version)""
            ""VALUES (?, ?, ?)"",
            (""@bob:localhost"", 101010101, ""asd"")
        )
        cur.execute(
            ""INSERT INTO tokens (user_id, token)""
            ""VALUES (?, ?)"",
            (""@bob:localhost"", self.test_token)
        )

        self.sydent.db.commit()

    def test_can_read_token_from_headers(self):
        """"""Tests that Sydent correct extracts an auth token from request headers""""""
        self.sydent.run()

        request, _ = make_request(
            self.sydent.reactor, ""GET"", ""/_matrix/identity/v2/hash_details""
        )
        request.requestHeaders.addRawHeader(
            b""Authorization"", b""Bearer "" + self.test_token.encode(""ascii"")
        )

        token = tokenFromRequest(request)

        self.assertEqual(token, self.test_token)

    def test_can_read_token_from_query_parameters(self):
        """"""Tests that Sydent correct extracts an auth token from query parameters""""""
        self.sydent.run()

        request, _ = make_request(
            self.sydent.reactor, ""GET"",
            ""/_matrix/identity/v2/hash_details?access_token="" + self.test_token
        )

        token = tokenFromRequest(request)

        self.assertEqual(token, self.test_token)
",CWE-20,73.0,1
"# -*- coding: utf-8 -*-

# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from twisted.trial import unittest

from sydent.http.auth import tokenFromRequest
from tests.utils import make_request, make_sydent


class AuthTestCase(unittest.TestCase):
    """"""Tests Sydent's auth code""""""

    def setUp(self):
        # Create a new sydent
        self.sydent = make_sydent()
        self.test_token = ""testingtoken""

        # Inject a fake OpenID token into the database
        cur = self.sydent.db.cursor()
        cur.execute(
            ""INSERT INTO accounts (user_id, created_ts, consent_version)""
            ""VALUES (?, ?, ?)"",
            (""@bob:localhost"", 101010101, ""asd"")
        )
        cur.execute(
            ""INSERT INTO tokens (user_id, token)""
            ""VALUES (?, ?)"",
            (""@bob:localhost"", self.test_token)
        )

        self.sydent.db.commit()

    def test_can_read_token_from_headers(self):
        """"""Tests that Sydent correct extracts an auth token from request headers""""""
        self.sydent.run()

        request, _ = make_request(
            self.sydent.reactor, ""GET"", ""/_matrix/identity/v2/hash_details""
        )
        request.requestHeaders.addRawHeader(
            b""Authorization"", b""Bearer "" + self.test_token.encode(""ascii"")
        )

        token = tokenFromRequest(request)

        self.assertEqual(token, self.test_token)

    def test_can_read_token_from_query_parameters(self):
        """"""Tests that Sydent correct extracts an auth token from query parameters""""""
        self.sydent.run()

        request, _ = make_request(
            self.sydent.reactor, ""GET"",
            ""/_matrix/identity/v2/hash_details?access_token="" + self.test_token
        )

        token = tokenFromRequest(request)

        self.assertEqual(token, self.test_token)
",CWE-918,73.0,1
,CWE-20,,1
,CWE-918,,1
,CWE-20,,1
,CWE-918,,1
"# -*- coding: utf-8 -*-

# Copyright 2014 OpenMarket Ltd
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

import json
import logging

from sydent.hs_federation.verifier import NoAuthenticationError
from signedjson.sign import SignatureVerifyException

from sydent.http.servlets import dict_to_json_bytes
from sydent.db.valsession import ThreePidValSessionStore
from sydent.util.stringutils import is_valid_client_secret
from sydent.validators import (
    IncorrectClientSecretException,
    InvalidSessionIdException,
    SessionNotValidatedException,
)

from twisted.web.resource import Resource
from twisted.web import server
from twisted.internet import defer

logger = logging.getLogger(__name__)


class ThreePidUnbindServlet(Resource):
    def __init__(self, sydent):
        self.sydent = sydent

    def render_POST(self, request):
        self._async_render_POST(request)
        return server.NOT_DONE_YET

    @defer.inlineCallbacks
    def _async_render_POST(self, request):
        try:
            try:
                # json.loads doesn't allow bytes in Python 3.5
                body = json.loads(request.content.read().decode(""UTF-8""))
            except ValueError:
                request.setResponseCode(400)
                request.write(dict_to_json_bytes({'errcode': 'M_BAD_JSON', 'error': 'Malformed JSON'}))
                request.finish()
                return

            missing = [k for k in (""threepid"", ""mxid"") if k not in body]
            if len(missing) > 0:
                request.setResponseCode(400)
                msg = ""Missing parameters: ""+("","".join(missing))
                request.write(dict_to_json_bytes({'errcode': 'M_MISSING_PARAMS', 'error': msg}))
                request.finish()
                return

            threepid = body['threepid']
            mxid = body['mxid']

            if 'medium' not in threepid or 'address' not in threepid:
                request.setResponseCode(400)
                request.write(dict_to_json_bytes({'errcode': 'M_MISSING_PARAMS', 'error': 'Threepid lacks medium / address'}))
                request.finish()
                return

            # We now check for authentication in two different ways, depending
            # on the contents of the request. If the user has supplied ""sid""
            # (the Session ID returned by Sydent during the original binding)
            # and ""client_secret"" fields, they are trying to prove that they
            # were the original author of the bind. We then check that what
            # they supply matches and if it does, allow the unbind.
            # 
            # However if these fields are not supplied, we instead check
            # whether the request originated from a homeserver, and if so the
            # same homeserver that originally created the bind. We do this by
            # checking the signature of the request. If it all matches up, we
            # allow the unbind.
            #
            # Only one method of authentication is required.
            if 'sid' in body and 'client_secret' in body:
                sid = body['sid']
                client_secret = body['client_secret']

                if not is_valid_client_secret(client_secret):
                    request.setResponseCode(400)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_INVALID_PARAM',
                        'error': 'Invalid client_secret provided'
                    }))
                    request.finish()
                    return

                valSessionStore = ThreePidValSessionStore(self.sydent)

                try:
                    s = valSessionStore.getValidatedSession(sid, client_secret)
                except (IncorrectClientSecretException, InvalidSessionIdException):
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_NO_VALID_SESSION',
                        'error': ""No valid session was found matching that sid and client secret""
                    }))
                    request.finish()
                    return
                except SessionNotValidatedException:
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_SESSION_NOT_VALIDATED',
                        'error': ""This validation session has not yet been completed""
                    }))
                    return
                
                if s.medium != threepid['medium'] or s.address != threepid['address']:
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_FORBIDDEN',
                        'error': 'Provided session information does not match medium/address combo',
                    }))
                    request.finish()
                    return
            else:
                try:
                    origin_server_name = yield self.sydent.sig_verifier.authenticate_request(request, body)
                except SignatureVerifyException as ex:
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': str(ex)}))
                    request.finish()
                    return
                except NoAuthenticationError as ex:
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': str(ex)}))
                    request.finish()
                    return
                except:
                    logger.exception(""Exception whilst authenticating unbind request"")
                    request.setResponseCode(500)
                    request.write(dict_to_json_bytes({'errcode': 'M_UNKNOWN', 'error': 'Internal Server Error'}))
                    request.finish()
                    return

                if not mxid.endswith(':' + origin_server_name):
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': 'Origin server name does not match mxid'}))
                    request.finish()
                    return

            self.sydent.threepidBinder.removeBinding(threepid, mxid)

            request.write(dict_to_json_bytes({}))
            request.finish()
        except Exception as ex:
            logger.exception(""Exception whilst handling unbind"")
            request.setResponseCode(500)
            request.write(dict_to_json_bytes({'errcode': 'M_UNKNOWN', 'error': str(ex)}))
            request.finish()
",CWE-20,168.0,1
"# -*- coding: utf-8 -*-

# Copyright 2014 OpenMarket Ltd
# Copyright 2018 New Vector Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

import json
import logging

from sydent.hs_federation.verifier import NoAuthenticationError
from signedjson.sign import SignatureVerifyException

from sydent.http.servlets import dict_to_json_bytes
from sydent.db.valsession import ThreePidValSessionStore
from sydent.util.stringutils import is_valid_client_secret
from sydent.validators import (
    IncorrectClientSecretException,
    InvalidSessionIdException,
    SessionNotValidatedException,
)

from twisted.web.resource import Resource
from twisted.web import server
from twisted.internet import defer

logger = logging.getLogger(__name__)


class ThreePidUnbindServlet(Resource):
    def __init__(self, sydent):
        self.sydent = sydent

    def render_POST(self, request):
        self._async_render_POST(request)
        return server.NOT_DONE_YET

    @defer.inlineCallbacks
    def _async_render_POST(self, request):
        try:
            try:
                # json.loads doesn't allow bytes in Python 3.5
                body = json.loads(request.content.read().decode(""UTF-8""))
            except ValueError:
                request.setResponseCode(400)
                request.write(dict_to_json_bytes({'errcode': 'M_BAD_JSON', 'error': 'Malformed JSON'}))
                request.finish()
                return

            missing = [k for k in (""threepid"", ""mxid"") if k not in body]
            if len(missing) > 0:
                request.setResponseCode(400)
                msg = ""Missing parameters: ""+("","".join(missing))
                request.write(dict_to_json_bytes({'errcode': 'M_MISSING_PARAMS', 'error': msg}))
                request.finish()
                return

            threepid = body['threepid']
            mxid = body['mxid']

            if 'medium' not in threepid or 'address' not in threepid:
                request.setResponseCode(400)
                request.write(dict_to_json_bytes({'errcode': 'M_MISSING_PARAMS', 'error': 'Threepid lacks medium / address'}))
                request.finish()
                return

            # We now check for authentication in two different ways, depending
            # on the contents of the request. If the user has supplied ""sid""
            # (the Session ID returned by Sydent during the original binding)
            # and ""client_secret"" fields, they are trying to prove that they
            # were the original author of the bind. We then check that what
            # they supply matches and if it does, allow the unbind.
            # 
            # However if these fields are not supplied, we instead check
            # whether the request originated from a homeserver, and if so the
            # same homeserver that originally created the bind. We do this by
            # checking the signature of the request. If it all matches up, we
            # allow the unbind.
            #
            # Only one method of authentication is required.
            if 'sid' in body and 'client_secret' in body:
                sid = body['sid']
                client_secret = body['client_secret']

                if not is_valid_client_secret(client_secret):
                    request.setResponseCode(400)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_INVALID_PARAM',
                        'error': 'Invalid client_secret provided'
                    }))
                    request.finish()
                    return

                valSessionStore = ThreePidValSessionStore(self.sydent)

                try:
                    s = valSessionStore.getValidatedSession(sid, client_secret)
                except (IncorrectClientSecretException, InvalidSessionIdException):
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_NO_VALID_SESSION',
                        'error': ""No valid session was found matching that sid and client secret""
                    }))
                    request.finish()
                    return
                except SessionNotValidatedException:
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_SESSION_NOT_VALIDATED',
                        'error': ""This validation session has not yet been completed""
                    }))
                    return
                
                if s.medium != threepid['medium'] or s.address != threepid['address']:
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({
                        'errcode': 'M_FORBIDDEN',
                        'error': 'Provided session information does not match medium/address combo',
                    }))
                    request.finish()
                    return
            else:
                try:
                    origin_server_name = yield self.sydent.sig_verifier.authenticate_request(request, body)
                except SignatureVerifyException as ex:
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': str(ex)}))
                    request.finish()
                    return
                except NoAuthenticationError as ex:
                    request.setResponseCode(401)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': str(ex)}))
                    request.finish()
                    return
                except:
                    logger.exception(""Exception whilst authenticating unbind request"")
                    request.setResponseCode(500)
                    request.write(dict_to_json_bytes({'errcode': 'M_UNKNOWN', 'error': 'Internal Server Error'}))
                    request.finish()
                    return

                if not mxid.endswith(':' + origin_server_name):
                    request.setResponseCode(403)
                    request.write(dict_to_json_bytes({'errcode': 'M_FORBIDDEN', 'error': 'Origin server name does not match mxid'}))
                    request.finish()
                    return

            self.sydent.threepidBinder.removeBinding(threepid, mxid)

            request.write(dict_to_json_bytes({}))
            request.finish()
        except Exception as ex:
            logger.exception(""Exception whilst handling unbind"")
            request.setResponseCode(500)
            request.write(dict_to_json_bytes({'errcode': 'M_UNKNOWN', 'error': str(ex)}))
            request.finish()
",CWE-918,168.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource
from twisted.internet import defer

import logging
import json
from six.moves import urllib

from sydent.http.servlets import get_args, jsonwrap, deferjsonwrap, send_cors
from sydent.http.httpclient import FederationHttpClient
from sydent.users.tokens import issueToken
from sydent.util.stringutils import is_valid_hostname

logger = logging.getLogger(__name__)


class RegisterServlet(Resource):
    isLeaf = True

    def __init__(self, syd):
        self.sydent = syd
        self.client = FederationHttpClient(self.sydent)

    @deferjsonwrap
    @defer.inlineCallbacks
    def render_POST(self, request):
        """"""
        Register with the Identity Server
        """"""
        send_cors(request)

        args = get_args(request, ('matrix_server_name', 'access_token'))

        matrix_server = args['matrix_server_name'].lower()

        if not is_valid_hostname(matrix_server):
            request.setResponseCode(400)
            return {
                'errcode': 'M_INVALID_PARAM',
                'error': 'matrix_server_name must be a valid hostname'
            }

        result = yield self.client.get_json(
            ""matrix://%s/_matrix/federation/v1/openid/userinfo?access_token=%s""
            % (
                matrix_server,
                urllib.parse.quote(args['access_token']),
            ),
            1024 * 5,
        )

        if 'sub' not in result:
            raise Exception(""Invalid response from homeserver"")

        user_id = result['sub']

        if not isinstance(user_id, str):
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned a malformed reply'
            }

        user_id_components = user_id.split(':', 1)

        # Ensure there's a localpart and domain in the returned user ID.
        if len(user_id_components) != 2:
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned an invalid MXID'
            }

        user_id_server = user_id_components[1]

        if not is_valid_hostname(user_id_server):
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned an invalid MXID'
            }

        if user_id_server != matrix_server:
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned a MXID belonging to another homeserver'
            }

        tok = yield issueToken(self.sydent, user_id)

        # XXX: `token` is correct for the spec, but we released with `access_token`
        # for a substantial amount of time. Serve both to make spec-compliant clients
        # happy.
        defer.returnValue({
            ""access_token"": tok,
            ""token"": tok,
        })

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-20,119.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource
from twisted.internet import defer

import logging
import json
from six.moves import urllib

from sydent.http.servlets import get_args, jsonwrap, deferjsonwrap, send_cors
from sydent.http.httpclient import FederationHttpClient
from sydent.users.tokens import issueToken
from sydent.util.stringutils import is_valid_hostname

logger = logging.getLogger(__name__)


class RegisterServlet(Resource):
    isLeaf = True

    def __init__(self, syd):
        self.sydent = syd
        self.client = FederationHttpClient(self.sydent)

    @deferjsonwrap
    @defer.inlineCallbacks
    def render_POST(self, request):
        """"""
        Register with the Identity Server
        """"""
        send_cors(request)

        args = get_args(request, ('matrix_server_name', 'access_token'))

        matrix_server = args['matrix_server_name'].lower()

        if not is_valid_hostname(matrix_server):
            request.setResponseCode(400)
            return {
                'errcode': 'M_INVALID_PARAM',
                'error': 'matrix_server_name must be a valid hostname'
            }

        result = yield self.client.get_json(
            ""matrix://%s/_matrix/federation/v1/openid/userinfo?access_token=%s""
            % (
                matrix_server,
                urllib.parse.quote(args['access_token']),
            ),
            1024 * 5,
        )

        if 'sub' not in result:
            raise Exception(""Invalid response from homeserver"")

        user_id = result['sub']

        if not isinstance(user_id, str):
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned a malformed reply'
            }

        user_id_components = user_id.split(':', 1)

        # Ensure there's a localpart and domain in the returned user ID.
        if len(user_id_components) != 2:
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned an invalid MXID'
            }

        user_id_server = user_id_components[1]

        if not is_valid_hostname(user_id_server):
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned an invalid MXID'
            }

        if user_id_server != matrix_server:
            request.setResponseCode(500)
            return {
                'errcode': 'M_UNKNOWN',
                'error': 'The Matrix homeserver returned a MXID belonging to another homeserver'
            }

        tok = yield issueToken(self.sydent, user_id)

        # XXX: `token` is correct for the spec, but we released with `access_token`
        # for a substantial amount of time. Serve both to make spec-compliant clients
        # happy.
        defer.returnValue({
            ""access_token"": tok,
            ""token"": tok,
        })

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-918,119.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import re

# https://matrix.org/docs/spec/client_server/r0.6.0#post-matrix-client-r0-register-email-requesttoken
client_secret_regex = re.compile(r""^[0-9a-zA-Z\.\=\_\-]+$"")

# hostname/domain name + optional port
# https://regex101.com/r/OyN1lg/2
hostname_regex = re.compile(
    r""^(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)(?:\.[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)*$"",
    flags=re.IGNORECASE)


def is_valid_client_secret(client_secret):
    """"""Validate that a given string matches the client_secret regex defined by the spec

    :param client_secret: The client_secret to validate
    :type client_secret: str

    :return: Whether the client_secret is valid
    :rtype: bool
    """"""
    return client_secret_regex.match(client_secret) is not None


def is_valid_hostname(string: str) -> bool:
    """"""Validate that a given string is a valid hostname or domain name, with an
    optional port number.

    For domain names, this only validates that the form is right (for
    instance, it doesn't check that the TLD is valid). If a port is
    specified, it has to be a valid port number.

    :param string: The string to validate
    :type string: str

    :return: Whether the input is a valid hostname
    :rtype: bool
    """"""

    host_parts = string.split("":"", 1)

    if len(host_parts) == 1:
        return hostname_regex.match(string) is not None
    else:
        host, port = host_parts
        valid_hostname = hostname_regex.match(host) is not None

        try:
            port_num = int(port)
            valid_port = (
                port == str(port_num)  # exclude things like '08090' or ' 8090'
                and 1 <= port_num < 65536)
        except ValueError:
            valid_port = False

        return valid_hostname and valid_port
",CWE-20,71.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import re

# https://matrix.org/docs/spec/client_server/r0.6.0#post-matrix-client-r0-register-email-requesttoken
client_secret_regex = re.compile(r""^[0-9a-zA-Z\.\=\_\-]+$"")

# hostname/domain name + optional port
# https://regex101.com/r/OyN1lg/2
hostname_regex = re.compile(
    r""^(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)(?:\.[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)*$"",
    flags=re.IGNORECASE)


def is_valid_client_secret(client_secret):
    """"""Validate that a given string matches the client_secret regex defined by the spec

    :param client_secret: The client_secret to validate
    :type client_secret: str

    :return: Whether the client_secret is valid
    :rtype: bool
    """"""
    return client_secret_regex.match(client_secret) is not None


def is_valid_hostname(string: str) -> bool:
    """"""Validate that a given string is a valid hostname or domain name, with an
    optional port number.

    For domain names, this only validates that the form is right (for
    instance, it doesn't check that the TLD is valid). If a port is
    specified, it has to be a valid port number.

    :param string: The string to validate
    :type string: str

    :return: Whether the input is a valid hostname
    :rtype: bool
    """"""

    host_parts = string.split("":"", 1)

    if len(host_parts) == 1:
        return hostname_regex.match(string) is not None
    else:
        host, port = host_parts
        valid_hostname = hostname_regex.match(host) is not None

        try:
            port_num = int(port)
            valid_port = (
                port == str(port_num)  # exclude things like '08090' or ' 8090'
                and 1 <= port_num < 65536)
        except ValueError:
            valid_port = False

        return valid_hostname and valid_port
",CWE-918,71.0,1
"# -*- coding: utf-8 -*-

# Copyright 2021 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from twisted.trial import unittest

from tests.utils import make_request, make_sydent


class RegisterTestCase(unittest.TestCase):
    """"""Tests Sydent's register servlet""""""
    def setUp(self):
        # Create a new sydent
        self.sydent = make_sydent()

    def test_sydent_rejects_invalid_hostname(self):
        """"""Tests that the /register endpoint rejects an invalid hostname passed as matrix_server_name""""""
        self.sydent.run()

        bad_hostname = ""example.com#""

        request, channel = make_request(
            self.sydent.reactor,
            ""POST"",
            ""/_matrix/identity/v2/account/register"",
            content={
                ""matrix_server_name"": bad_hostname,
                ""access_token"": ""foo""
            })

        request.render(self.sydent.servlets.registerServlet)

        self.assertEqual(channel.code, 400)
",CWE-20,46.0,1
"# -*- coding: utf-8 -*-

# Copyright 2021 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from twisted.trial import unittest

from tests.utils import make_request, make_sydent


class RegisterTestCase(unittest.TestCase):
    """"""Tests Sydent's register servlet""""""
    def setUp(self):
        # Create a new sydent
        self.sydent = make_sydent()

    def test_sydent_rejects_invalid_hostname(self):
        """"""Tests that the /register endpoint rejects an invalid hostname passed as matrix_server_name""""""
        self.sydent.run()

        bad_hostname = ""example.com#""

        request, channel = make_request(
            self.sydent.reactor,
            ""POST"",
            ""/_matrix/identity/v2/account/register"",
            content={
                ""matrix_server_name"": bad_hostname,
                ""access_token"": ""foo""
            })

        request.render(self.sydent.servlets.registerServlet)

        self.assertEqual(channel.code, 400)
",CWE-918,46.0,1
"from twisted.trial import unittest
from sydent.util.stringutils import is_valid_hostname


class UtilTests(unittest.TestCase):
    """"""Tests Sydent utility functions.""""""
    def test_is_valid_hostname(self):
        """"""Tests that the is_valid_hostname function accepts only valid
        hostnames (or domain names), with optional port number.
        """"""

        self.assertTrue(is_valid_hostname(""example.com""))
        self.assertTrue(is_valid_hostname(""EXAMPLE.COM""))
        self.assertTrue(is_valid_hostname(""ExAmPlE.CoM""))
        self.assertTrue(is_valid_hostname(""example.com:4242""))
        self.assertTrue(is_valid_hostname(""localhost""))
        self.assertTrue(is_valid_hostname(""localhost:9000""))
        self.assertTrue(is_valid_hostname(""a.b:1234""))

        self.assertFalse(is_valid_hostname(""example.com:65536""))
        self.assertFalse(is_valid_hostname(""example.com:0""))
        self.assertFalse(is_valid_hostname(""example.com:a""))
        self.assertFalse(is_valid_hostname(""example.com:04242""))
        self.assertFalse(is_valid_hostname(""example.com: 4242""))
        self.assertFalse(is_valid_hostname(""example.com/example.com""))
        self.assertFalse(is_valid_hostname(""example.com#example.com""))
",CWE-20,27.0,1
"from twisted.trial import unittest
from sydent.util.stringutils import is_valid_hostname


class UtilTests(unittest.TestCase):
    """"""Tests Sydent utility functions.""""""
    def test_is_valid_hostname(self):
        """"""Tests that the is_valid_hostname function accepts only valid
        hostnames (or domain names), with optional port number.
        """"""

        self.assertTrue(is_valid_hostname(""example.com""))
        self.assertTrue(is_valid_hostname(""EXAMPLE.COM""))
        self.assertTrue(is_valid_hostname(""ExAmPlE.CoM""))
        self.assertTrue(is_valid_hostname(""example.com:4242""))
        self.assertTrue(is_valid_hostname(""localhost""))
        self.assertTrue(is_valid_hostname(""localhost:9000""))
        self.assertTrue(is_valid_hostname(""a.b:1234""))

        self.assertFalse(is_valid_hostname(""example.com:65536""))
        self.assertFalse(is_valid_hostname(""example.com:0""))
        self.assertFalse(is_valid_hostname(""example.com:a""))
        self.assertFalse(is_valid_hostname(""example.com:04242""))
        self.assertFalse(is_valid_hostname(""example.com: 4242""))
        self.assertFalse(is_valid_hostname(""example.com/example.com""))
        self.assertFalse(is_valid_hostname(""example.com#example.com""))
",CWE-918,27.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
import shutil
import time
from subprocess import Popen

CFG_TEMPLATE = """"""
[http]
clientapi.http.bind_address = localhost
clientapi.http.port = {port}
client_http_base = http://localhost:{port}
federation.verifycerts = False

[db]
db.file = :memory:

[general]
server.name = test.local
terms.path = {terms_path}
templates.path = {testsubject_path}/res
brand.default = is-test

[email]
email.tlsmode = 0
email.invite.subject = %(sender_display_name)s has invited you to chat
email.smtphost = localhost
email.from = Sydent Validation <noreply@localhost>
email.smtpport = 9925
email.subject = Your Validation Token
""""""

class MatrixIsTestLauncher(object):
    def __init__(self, with_terms):
        self.with_terms = with_terms

    def launch(self):
        sydent_path = os.path.abspath(os.path.join(
            os.path.dirname(__file__), '..',
        ))
        testsubject_path = os.path.join(
            sydent_path, 'matrix_is_test',
        )
        terms_path = os.path.join(testsubject_path, 'terms.yaml') if self.with_terms else ''
        port = 8099 if self.with_terms else 8098

        self.tmpdir = tempfile.mkdtemp(prefix='sydenttest')

        with open(os.path.join(self.tmpdir, 'sydent.conf'), 'w') as cfgfp:
            cfgfp.write(CFG_TEMPLATE.format(
                testsubject_path=testsubject_path,
                terms_path=terms_path,
                port=port,
            ))

        newEnv = os.environ.copy()
        newEnv.update({
            'PYTHONPATH': sydent_path,
        })

        stderr_fp = open(os.path.join(testsubject_path, 'sydent.stderr'), 'w')

        pybin = os.getenv('SYDENT_PYTHON', 'python')

        self.process = Popen(
            args=[pybin, '-m', 'sydent.sydent'],
            cwd=self.tmpdir,
            env=newEnv,
            stderr=stderr_fp,
        )
        # XXX: wait for startup in a sensible way
        time.sleep(2)

        self._baseUrl = 'http://localhost:%d' % (port,)

    def tearDown(self):
        print(""Stopping sydent..."")
        self.process.terminate()
        shutil.rmtree(self.tmpdir)

    def get_base_url(self):
        return self._baseUrl
",CWE-20,98.0,1
"# -*- coding: utf-8 -*-

# Copyright 2019 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
import shutil
import time
from subprocess import Popen

CFG_TEMPLATE = """"""
[http]
clientapi.http.bind_address = localhost
clientapi.http.port = {port}
client_http_base = http://localhost:{port}
federation.verifycerts = False

[db]
db.file = :memory:

[general]
server.name = test.local
terms.path = {terms_path}
templates.path = {testsubject_path}/res
brand.default = is-test

[email]
email.tlsmode = 0
email.invite.subject = %(sender_display_name)s has invited you to chat
email.smtphost = localhost
email.from = Sydent Validation <noreply@localhost>
email.smtpport = 9925
email.subject = Your Validation Token
""""""

class MatrixIsTestLauncher(object):
    def __init__(self, with_terms):
        self.with_terms = with_terms

    def launch(self):
        sydent_path = os.path.abspath(os.path.join(
            os.path.dirname(__file__), '..',
        ))
        testsubject_path = os.path.join(
            sydent_path, 'matrix_is_test',
        )
        terms_path = os.path.join(testsubject_path, 'terms.yaml') if self.with_terms else ''
        port = 8099 if self.with_terms else 8098

        self.tmpdir = tempfile.mkdtemp(prefix='sydenttest')

        with open(os.path.join(self.tmpdir, 'sydent.conf'), 'w') as cfgfp:
            cfgfp.write(CFG_TEMPLATE.format(
                testsubject_path=testsubject_path,
                terms_path=terms_path,
                port=port,
            ))

        newEnv = os.environ.copy()
        newEnv.update({
            'PYTHONPATH': sydent_path,
        })

        stderr_fp = open(os.path.join(testsubject_path, 'sydent.stderr'), 'w')

        pybin = os.getenv('SYDENT_PYTHON', 'python')

        self.process = Popen(
            args=[pybin, '-m', 'sydent.sydent'],
            cwd=self.tmpdir,
            env=newEnv,
            stderr=stderr_fp,
        )
        # XXX: wait for startup in a sensible way
        time.sleep(2)

        self._baseUrl = 'http://localhost:%d' % (port,)

    def tearDown(self):
        print(""Stopping sydent..."")
        self.process.terminate()
        shutil.rmtree(self.tmpdir)

    def get_base_url(self):
        return self._baseUrl
",CWE-918,98.0,1
,CWE-20,,1
,CWE-918,,1
"# -*- coding: utf-8 -*-

# Copyright 2016 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

import json
import logging
from io import BytesIO

from twisted.internet import defer
from twisted.web.client import FileBodyProducer, Agent, readBody
from twisted.web.http_headers import Headers
from sydent.http.matrixfederationagent import MatrixFederationAgent

from sydent.http.federation_tls_options import ClientTLSOptionsFactory
from sydent.http.httpcommon import BodyExceededMaxSize, read_body_with_max_size

logger = logging.getLogger(__name__)


class HTTPClient(object):
    """"""A base HTTP class that contains methods for making GET and POST HTTP
    requests.
    """"""
    @defer.inlineCallbacks
    def get_json(self, uri, max_size = None):
        """"""Make a GET request to an endpoint returning JSON and parse result

        :param uri: The URI to make a GET request to.
        :type uri: unicode

        :param max_size: The maximum size (in bytes) to allow as a response.
        :type max_size: int

        :return: A deferred containing JSON parsed into a Python object.
        :rtype: twisted.internet.defer.Deferred[dict[any, any]]
        """"""
        logger.debug(""HTTP GET %s"", uri)

        response = yield self.agent.request(
            b""GET"",
            uri.encode(""utf8""),
        )
        body = yield read_body_with_max_size(response, max_size)
        try:
            # json.loads doesn't allow bytes in Python 3.5
            json_body = json.loads(body.decode(""UTF-8""))
        except Exception as e:
            logger.exception(""Error parsing JSON from %s"", uri)
            raise
        defer.returnValue(json_body)

    @defer.inlineCallbacks
    def post_json_get_nothing(self, uri, post_json, opts):
        """"""Make a POST request to an endpoint returning JSON and parse result

        :param uri: The URI to make a POST request to.
        :type uri: unicode

        :param post_json: A Python object that will be converted to a JSON
            string and POSTed to the given URI.
        :type post_json: dict[any, any]

        :param opts: A dictionary of request options. Currently only opts.headers
            is supported.
        :type opts: dict[str,any]

        :return: a response from the remote server.
        :rtype: twisted.internet.defer.Deferred[twisted.web.iweb.IResponse]
        """"""
        json_bytes = json.dumps(post_json).encode(""utf8"")

        headers = opts.get('headers', Headers({
            b""Content-Type"": [b""application/json""],
        }))

        logger.debug(""HTTP POST %s -> %s"", json_bytes, uri)

        response = yield self.agent.request(
            b""POST"",
            uri.encode(""utf8""),
            headers,
            bodyProducer=FileBodyProducer(BytesIO(json_bytes))
        )

        # Ensure the body object is read otherwise we'll leak HTTP connections
        # as per
        # https://twistedmatrix.com/documents/current/web/howto/client.html
        try:
            # TODO Will this cause the server to think the request was a failure?
            yield read_body_with_max_size(response, 0)
        except BodyExceededMaxSize:
            pass

        defer.returnValue(response)

class SimpleHttpClient(HTTPClient):
    """"""A simple, no-frills HTTP client based on the class of the same name
    from Synapse.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        # The default endpoint factory in Twisted 14.0.0 (which we require) uses the
        # BrowserLikePolicyForHTTPS context factory which will do regular cert validation
        # 'like a browser'
        self.agent = Agent(
            self.sydent.reactor,
            connectTimeout=15,
        )

class FederationHttpClient(HTTPClient):
    """"""HTTP client for federation requests to homeservers. Uses a
    MatrixFederationAgent.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        self.agent = MatrixFederationAgent(
            self.sydent.reactor,
            ClientTLSOptionsFactory(sydent.cfg),
        )
",CWE-20,133.0,1
"# -*- coding: utf-8 -*-

# Copyright 2016 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

import json
import logging
from io import BytesIO

from twisted.internet import defer
from twisted.web.client import FileBodyProducer, Agent, readBody
from twisted.web.http_headers import Headers
from sydent.http.matrixfederationagent import MatrixFederationAgent

from sydent.http.federation_tls_options import ClientTLSOptionsFactory
from sydent.http.httpcommon import BodyExceededMaxSize, read_body_with_max_size

logger = logging.getLogger(__name__)


class HTTPClient(object):
    """"""A base HTTP class that contains methods for making GET and POST HTTP
    requests.
    """"""
    @defer.inlineCallbacks
    def get_json(self, uri, max_size = None):
        """"""Make a GET request to an endpoint returning JSON and parse result

        :param uri: The URI to make a GET request to.
        :type uri: unicode

        :param max_size: The maximum size (in bytes) to allow as a response.
        :type max_size: int

        :return: A deferred containing JSON parsed into a Python object.
        :rtype: twisted.internet.defer.Deferred[dict[any, any]]
        """"""
        logger.debug(""HTTP GET %s"", uri)

        response = yield self.agent.request(
            b""GET"",
            uri.encode(""utf8""),
        )
        body = yield read_body_with_max_size(response, max_size)
        try:
            # json.loads doesn't allow bytes in Python 3.5
            json_body = json.loads(body.decode(""UTF-8""))
        except Exception as e:
            logger.exception(""Error parsing JSON from %s"", uri)
            raise
        defer.returnValue(json_body)

    @defer.inlineCallbacks
    def post_json_get_nothing(self, uri, post_json, opts):
        """"""Make a POST request to an endpoint returning JSON and parse result

        :param uri: The URI to make a POST request to.
        :type uri: unicode

        :param post_json: A Python object that will be converted to a JSON
            string and POSTed to the given URI.
        :type post_json: dict[any, any]

        :param opts: A dictionary of request options. Currently only opts.headers
            is supported.
        :type opts: dict[str,any]

        :return: a response from the remote server.
        :rtype: twisted.internet.defer.Deferred[twisted.web.iweb.IResponse]
        """"""
        json_bytes = json.dumps(post_json).encode(""utf8"")

        headers = opts.get('headers', Headers({
            b""Content-Type"": [b""application/json""],
        }))

        logger.debug(""HTTP POST %s -> %s"", json_bytes, uri)

        response = yield self.agent.request(
            b""POST"",
            uri.encode(""utf8""),
            headers,
            bodyProducer=FileBodyProducer(BytesIO(json_bytes))
        )

        # Ensure the body object is read otherwise we'll leak HTTP connections
        # as per
        # https://twistedmatrix.com/documents/current/web/howto/client.html
        try:
            # TODO Will this cause the server to think the request was a failure?
            yield read_body_with_max_size(response, 0)
        except BodyExceededMaxSize:
            pass

        defer.returnValue(response)

class SimpleHttpClient(HTTPClient):
    """"""A simple, no-frills HTTP client based on the class of the same name
    from Synapse.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        # The default endpoint factory in Twisted 14.0.0 (which we require) uses the
        # BrowserLikePolicyForHTTPS context factory which will do regular cert validation
        # 'like a browser'
        self.agent = Agent(
            self.sydent.reactor,
            connectTimeout=15,
        )

class FederationHttpClient(HTTPClient):
    """"""HTTP client for federation requests to homeservers. Uses a
    MatrixFederationAgent.
    """"""
    def __init__(self, sydent):
        self.sydent = sydent
        self.agent = MatrixFederationAgent(
            self.sydent.reactor,
            ClientTLSOptionsFactory(sydent.cfg),
        )
",CWE-918,133.0,1
,CWE-20,,1
,CWE-918,,1
"# -*- coding: utf-8 -*-

# Copyright 2014 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
from io import BytesIO

import twisted.internet.ssl
from twisted.internet import defer, protocol
from twisted.internet.protocol import connectionDone
from twisted.web._newclient import ResponseDone
from twisted.web.http import PotentialDataLoss
from twisted.web.iweb import UNKNOWN_LENGTH

logger = logging.getLogger(__name__)

class SslComponents:
    def __init__(self, sydent):
        self.sydent = sydent

        self.myPrivateCertificate = self.makeMyCertificate()
        self.trustRoot = self.makeTrustRoot()

    def makeMyCertificate(self):
        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')
        if privKeyAndCertFilename == '':
            logger.warn(""No HTTPS private key / cert found: not starting replication server ""
                        ""or doing replication pushes"")
            return None

        try:
            fp = open(privKeyAndCertFilename)
        except IOError:
            logger.warn(""Unable to read private key / cert file from %s: not starting the replication HTTPS server ""
                        ""or doing replication pushes."",
                        privKeyAndCertFilename)
            return None

        authData = fp.read()
        fp.close()
        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)

    def makeTrustRoot(self):
        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not
        # practical to get the client cert signed by a real root CA but should never be used on a production server.
        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')
        if len(caCertFilename) > 0:
            try:
                fp = open(caCertFilename)
                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())
                fp.close()
            except:
                logger.warn(""Failed to open CA cert file %s"", caCertFilename)
                raise
            logger.warn(""Using custom CA cert file: %s"", caCertFilename)
            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])
        else:
            return twisted.internet.ssl.OpenSSLDefaultPaths()



class BodyExceededMaxSize(Exception):
    """"""The maximum allowed size of the HTTP body was exceeded.""""""


class _DiscardBodyWithMaxSizeProtocol(protocol.Protocol):
    """"""A protocol which immediately errors upon receiving data.""""""

    def __init__(self, deferred):
        self.deferred = deferred

    def _maybe_fail(self):
        """"""
        Report a max size exceed error and disconnect the first time this is called.
        """"""
        if not self.deferred.called:
            self.deferred.errback(BodyExceededMaxSize())
            # Close the connection (forcefully) since all the data will get
            # discarded anyway.
            self.transport.abortConnection()

    def dataReceived(self, data) -> None:
        self._maybe_fail()

    def connectionLost(self, reason) -> None:
        self._maybe_fail()


class _ReadBodyWithMaxSizeProtocol(protocol.Protocol):
    """"""A protocol which reads body to a stream, erroring if the body exceeds a maximum size.""""""

    def __init__(self, deferred, max_size):
        self.stream = BytesIO()
        self.deferred = deferred
        self.length = 0
        self.max_size = max_size

    def dataReceived(self, data) -> None:
        # If the deferred was called, bail early.
        if self.deferred.called:
            return

        self.stream.write(data)
        self.length += len(data)
        # The first time the maximum size is exceeded, error and cancel the
        # connection. dataReceived might be called again if data was received
        # in the meantime.
        if self.max_size is not None and self.length >= self.max_size:
            self.deferred.errback(BodyExceededMaxSize())
            # Close the connection (forcefully) since all the data will get
            # discarded anyway.
            self.transport.abortConnection()

    def connectionLost(self, reason = connectionDone) -> None:
        # If the maximum size was already exceeded, there's nothing to do.
        if self.deferred.called:
            return

        if reason.check(ResponseDone):
            self.deferred.callback(self.stream.getvalue())
        elif reason.check(PotentialDataLoss):
            # stolen from https://github.com/twisted/treq/pull/49/files
            # http://twistedmatrix.com/trac/ticket/4840
            self.deferred.callback(self.stream.getvalue())
        else:
            self.deferred.errback(reason)


def read_body_with_max_size(response, max_size):
    """"""
    Read a HTTP response body to a file-object. Optionally enforcing a maximum file size.

    If the maximum file size is reached, the returned Deferred will resolve to a
    Failure with a BodyExceededMaxSize exception.

    Args:
        response: The HTTP response to read from.
        max_size: The maximum file size to allow.

    Returns:
        A Deferred which resolves to the read body.
    """"""
    d = defer.Deferred()

    # If the Content-Length header gives a size larger than the maximum allowed
    # size, do not bother downloading the body.
    if max_size is not None and response.length != UNKNOWN_LENGTH:
        if response.length > max_size:
            response.deliverBody(_DiscardBodyWithMaxSizeProtocol(d))
            return d

    response.deliverBody(_ReadBodyWithMaxSizeProtocol(d, max_size))
    return d
",CWE-770,166.0,1
"# -*- coding: utf-8 -*-

# Copyright 2014 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import

from twisted.web.resource import Resource

from sydent.util.stringutils import is_valid_client_secret
from sydent.util.emailutils import EmailAddressException, EmailSendException
from sydent.validators import (
    IncorrectClientSecretException,
    InvalidSessionIdException,
    IncorrectSessionTokenException,
    SessionExpiredException,
)


from sydent.http.servlets import get_args, jsonwrap, send_cors
from sydent.http.auth import authV2


class EmailRequestCodeServlet(Resource):
    isLeaf = True

    def __init__(self, syd, require_auth=False):
        self.sydent = syd
        self.require_auth = require_auth

    @jsonwrap
    def render_POST(self, request):
        send_cors(request)

        if self.require_auth:
            authV2(self.sydent, request)

        args = get_args(request, ('email', 'client_secret', 'send_attempt'))

        email = args['email']
        sendAttempt = args['send_attempt']
        clientSecret = args['client_secret']

        if not is_valid_client_secret(clientSecret):
            request.setResponseCode(400)
            return {
                'errcode': 'M_INVALID_PARAM',
                'error': 'Invalid client_secret provided'
            }

        ipaddress = self.sydent.ip_from_request(request)
        brand = self.sydent.brand_from_request(request)

        nextLink = None
        if 'next_link' in args and not args['next_link'].startswith(""file:///""):
            nextLink = args['next_link']

        try:
            sid = self.sydent.validators.email.requestToken(
                email, clientSecret, sendAttempt, nextLink, ipaddress=ipaddress, brand=brand,
            )
            resp = {'sid': str(sid)}
        except EmailAddressException:
            request.setResponseCode(400)
            resp = {'errcode': 'M_INVALID_EMAIL', 'error': 'Invalid email address'}
        except EmailSendException:
            request.setResponseCode(500)
            resp = {'errcode': 'M_EMAIL_SEND_ERROR', 'error': 'Failed to send email'}

        return resp

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''


class EmailValidateCodeServlet(Resource):
    isLeaf = True

    def __init__(self, syd, require_auth=False):
        self.sydent = syd
        self.require_auth = require_auth

    def render_GET(self, request):
        args = get_args(request, ('nextLink',), required=False)

        resp = None
        try:
            resp = self.do_validate_request(request)
        except:
            pass
        if resp and 'success' in resp and resp['success']:
            msg = ""Verification successful! Please return to your Matrix client to continue.""
            if 'nextLink' in args:
                next_link = args['nextLink']
                if not next_link.startswith(""file:///""):
                    request.setResponseCode(302)
                    request.setHeader(""Location"", next_link)
        else:
            msg = ""Verification failed: you may need to request another verification email""

        brand = self.sydent.brand_from_request(request)
        templateFile = self.sydent.get_branded_template(
            brand,
            ""verify_response_template.html"",
            ('http', 'verify_response_template'),
        )

        request.setHeader(""Content-Type"", ""text/html"")
        res = open(templateFile).read() % {'message': msg}
        return res.encode(""UTF-8"")

    @jsonwrap
    def render_POST(self, request):
        send_cors(request)

        if self.require_auth:
            authV2(self.sydent, request)

        return self.do_validate_request(request)

    def do_validate_request(self, request):
        """"""
        Extracts information about a validation session from the request and
        attempts to validate that session.

        :param request: The request to extract information about the session from.
        :type request: twisted.web.server.Request

        :return: A dict with a ""success"" key which value indicates whether the
            validation succeeded. If the validation failed, this dict also includes
            a ""errcode"" and a ""error"" keys which include information about the failure.
        :rtype: dict[str, bool or str]
        """"""
        args = get_args(request, ('token', 'sid', 'client_secret'))

        sid = args['sid']
        tokenString = args['token']
        clientSecret = args['client_secret']

        if not is_valid_client_secret(clientSecret):
            request.setResponseCode(400)
            return {
                'errcode': 'M_INVALID_PARAM',
                'error': 'Invalid client_secret provided'
            }

        try:
            return self.sydent.validators.email.validateSessionWithToken(sid, clientSecret, tokenString)
        except IncorrectClientSecretException:
            return {'success': False, 'errcode': 'M_INVALID_PARAM',
                    'error': ""Client secret does not match the one given when requesting the token""}
        except SessionExpiredException:
            return {'success': False, 'errcode': 'M_SESSION_EXPIRED',
                    'error': ""This validation session has expired: call requestToken again""}
        except InvalidSessionIdException:
            return {'success': False, 'errcode': 'M_INVALID_PARAM',
                    'error': ""The token doesn't match""}
        except IncorrectSessionTokenException:
            return {'success': False, 'errcode': 'M_NO_VALID_SESSION',
                    'error': ""No session could be found with this sid""}

    def render_OPTIONS(self, request):
        send_cors(request)
        return b''
",CWE-20,176.0,1
"# -*- coding: utf-8 -*-
# Copyright 2020 The Matrix.org Foundation C.I.C.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import re
from typing import Optional, Tuple

from twisted.internet.abstract import isIPAddress, isIPv6Address

# https://matrix.org/docs/spec/client_server/r0.6.0#post-matrix-client-r0-register-email-requesttoken
client_secret_regex = re.compile(r""^[0-9a-zA-Z\.\=\_\-]+$"")

# hostname/domain name
# https://regex101.com/r/OyN1lg/2
hostname_regex = re.compile(
    r""^(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)(?:\.[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)*$"",
    flags=re.IGNORECASE)


def is_valid_client_secret(client_secret):
    """"""Validate that a given string matches the client_secret regex defined by the spec

    :param client_secret: The client_secret to validate
    :type client_secret: str

    :return: Whether the client_secret is valid
    :rtype: bool
    """"""
    return client_secret_regex.match(client_secret) is not None


def is_valid_hostname(string: str) -> bool:
    """"""Validate that a given string is a valid hostname or domain name.

    For domain names, this only validates that the form is right (for
    instance, it doesn't check that the TLD is valid).

    :param string: The string to validate
    :type string: str

    :return: Whether the input is a valid hostname
    :rtype: bool
    """"""

    return hostname_regex.match(string) is not None


def parse_server_name(server_name: str) -> Tuple[str, Optional[int]]:
    """"""Split a server name into host/port parts.

    No validation is done on the host part. The port part is validated to be
    a valid port number.

    Args:
        server_name: server name to parse

    Returns:
        host/port parts.

    Raises:
        ValueError if the server name could not be parsed.
    """"""
    try:
        if server_name[-1] == ""]"":
            # ipv6 literal, hopefully
            return server_name, None

        host_port = server_name.rsplit("":"", 1)
        host = host_port[0]
        port = host_port[1] if host_port[1:] else None

        if port:
            port_num = int(port)

            # exclude things like '08090' or ' 8090'
            if port != str(port_num) or not (1 <= port_num < 65536):
                raise ValueError(""Invalid port"")

        return host, port
    except Exception:
        raise ValueError(""Invalid server name '%s'"" % server_name)


def is_valid_matrix_server_name(string: str) -> bool:
    """"""Validate that the given string is a valid Matrix server name.

    A string is a valid Matrix server name if it is one of the following, plus
    an optional port:

    a. IPv4 address
    b. IPv6 literal (`[IPV6_ADDRESS]`)
    c. A valid hostname

    :param string: The string to validate
    :type string: str

    :return: Whether the input is a valid Matrix server name
    :rtype: bool
    """"""

    try:
        host, port = parse_server_name(string)
    except ValueError:
        return False

    valid_ipv4_addr = isIPAddress(host)
    valid_ipv6_literal = host[0] == ""["" and host[-1] == ""]"" and isIPv6Address(host[1:-1])

    return valid_ipv4_addr or valid_ipv6_literal or is_valid_hostname(host)
",CWE-20,120.0,1
"# Copyright 2014-2015 OpenMarket Ltd
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import email.utils
import logging
import random
import smtplib
import string
import urllib
from html import escape
from typing import TYPE_CHECKING, Dict

import twisted.python.log
from prometheus_client import Counter

from sydent.util import time_msec
from sydent.util.tokenutils import generateAlphanumericTokenOfLength

if TYPE_CHECKING:
    from sydent.sydent import Sydent

logger = logging.getLogger(__name__)

email_counter = Counter(""sydent_emails_sent"", ""Number of emails we attempted to send"")


def sendEmail(
    sydent: ""Sydent"",
    templateFile: str,
    mailTo: str,
    substitutions: Dict[str, str],
    log_send_errors: bool = True,
) -> None:
    """"""
    Sends an email with the given parameters.

    :param sydent: The Sydent instance to use when building the configuration to send the
        email with.
    :param templateFile: The filename of the template to use when building the body of the
        email.
    :param mailTo: The email address to send the email to.
    :param substitutions: The substitutions to use with the template.
    :param log_send_errors: Whether to log errors happening when sending an email.
    """"""
    mailFrom = sydent.config.email.sender
    myHostname = sydent.config.email.host_name

    midRandom = """".join([random.choice(string.ascii_letters) for _ in range(16)])
    messageid = ""<%d%s@%s>"" % (time_msec(), midRandom, myHostname)

    substitutions.update(
        {
            ""messageid"": messageid,
            ""date"": email.utils.formatdate(localtime=False),
            ""to"": mailTo,
            ""from"": mailFrom,
        }
    )

    # use jinja for rendering if jinja templates are present
    if templateFile.endswith("".j2""):
        # We add randomize the multipart boundary to stop user input from
        # conflicting with it.
        substitutions[""multipart_boundary""] = generateAlphanumericTokenOfLength(32)
        template = sydent.config.general.template_environment.get_template(templateFile)
        mailString = template.render(substitutions)
    else:
        allSubstitutions = {}
        for k, v in substitutions.items():
            allSubstitutions[k] = v
            allSubstitutions[k + ""_forhtml""] = escape(v)
            allSubstitutions[k + ""_forurl""] = urllib.parse.quote(v)
        allSubstitutions[""multipart_boundary""] = generateAlphanumericTokenOfLength(32)
        with open(templateFile) as template_file:
            mailString = template_file.read() % allSubstitutions

    try:
        check_valid_email_address(mailTo, allow_description=False)
    except EmailAddressException:
        logger.warning(""Invalid email address %s"", mailTo)
        raise

    mailServer = sydent.config.email.smtp_server
    mailPort = int(sydent.config.email.smtp_port)
    mailUsername = sydent.config.email.smtp_username
    mailPassword = sydent.config.email.smtp_password
    mailTLSMode = sydent.config.email.tls_mode

    logger.info(
        ""Sending mail to %s with mail server: %s""
        % (
            mailTo,
            mailServer,
        )
    )
    try:
        smtp: smtplib.SMTP
        if mailTLSMode == ""SSL"" or mailTLSMode == ""TLS"":
            smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname)
        elif mailTLSMode == ""STARTTLS"":
            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)
            smtp.starttls()
        else:
            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)
        if mailUsername != """":
            smtp.login(mailUsername, mailPassword)

        email_counter.inc()

        # We're using the parsing above to do basic validation, but instead of
        # failing it may munge the address it returns. So we should *not* use
        # that parsed address, as it may not match any validation done
        # elsewhere.
        smtp.sendmail(mailFrom, mailTo, mailString.encode(""utf-8""))
        smtp.quit()
    except Exception as origException:
        if log_send_errors:
            twisted.python.log.err()
        raise EmailSendException() from origException


def check_valid_email_address(address: str, allow_description: bool) -> None:
    """"""Check the given string is a valid email address.

    Email addresses are complicated (see RFCs 5321, 5322 and 6531; plus
    https://www.netmeister.org/blog/email.html). This isn't a comprehensive
    validation; we defer to Python's stdlib.

    :raises EmailAddressException: if not.
    """"""
    parsed_address = email.utils.parseaddr(address)[1]
    if parsed_address == """":
        raise EmailAddressException(f""Couldn't parse email address {address}."")
    if not allow_description and address != parsed_address:
        raise EmailAddressException(
            f""Parsing address ({address} yielded a different address""
            f""({parsed_address})""
        )


class EmailAddressException(Exception):
    pass


class EmailSendException(Exception):
    pass
",CWE-295,158.0,1
"""""""I am a virtual hosts implementation.""""""

# System Imports
import string

# Sibling Imports
import resource
import error

class NameVirtualHost(resource.Resource):
    """"""I am a resource which represents named virtual hosts.
    """"""

    def __init__(self):
        """"""Initialize.
        """"""
        resource.Resource.__init__(self)
        self.hosts = {}
        
    def addHost(self, name, resrc):
        """"""Add a host to this virtual host.
        
        This will take a host named `name', and map it to a resource
        `resrc'.  For example, a setup for our virtual hosts would be::
        
            nvh.addHost('divunal.com', divunalDirectory)
            nvh.addHost('www.divunal.com', divunalDirectory)
            nvh.addHost('twistedmatrix.com', twistedMatrixDirectory)
            nvh.addHost('www.twistedmatrix.com', twistedMatrixDirectory)
        """"""
        self.hosts[name] = resrc

    def _getResourceForRequest(self, request):
        """"""(Internal) Get the appropriate resource for the given host.
        """"""
        host = string.lower(request.getHeader('host'))
        return self.hosts.get(host, error.NoResource())
        
    def render(self, request):
        """"""Implementation of resource.Resource's render method.
        """"""
        resrc = self._getResourceForRequest(request)
        return resrc.render(request)
        
    def getChild(self, path, request):
        """"""Implementation of resource.Resource's getChild method.
        """"""
        resrc = self._getResourceForRequest(request)
        return resrc.getChildWithDefault(path, request)
",CWE-79,50.0,1
"""""""I am a virtual hosts implementation.""""""

# System Imports
import string

# Sibling Imports
import resource
import error

class NameVirtualHost(resource.Resource):
    """"""I am a resource which represents named virtual hosts.
    """"""

    def __init__(self):
        """"""Initialize.
        """"""
        resource.Resource.__init__(self)
        self.hosts = {}
        
    def addHost(self, name, resrc):
        """"""Add a host to this virtual host.
        
        This will take a host named `name', and map it to a resource
        `resrc'.  For example, a setup for our virtual hosts would be::
        
            nvh.addHost('divunal.com', divunalDirectory)
            nvh.addHost('www.divunal.com', divunalDirectory)
            nvh.addHost('twistedmatrix.com', twistedMatrixDirectory)
            nvh.addHost('www.twistedmatrix.com', twistedMatrixDirectory)
        """"""
        self.hosts[name] = resrc

    def _getResourceForRequest(self, request):
        """"""(Internal) Get the appropriate resource for the given host.
        """"""
        host = string.lower(request.getHeader('host'))
        return self.hosts.get(host, error.NoResource())
        
    def render(self, request):
        """"""Implementation of resource.Resource's render method.
        """"""
        resrc = self._getResourceForRequest(request)
        return resrc.render(request)
        
    def getChild(self, path, request):
        """"""Implementation of resource.Resource's getChild method.
        """"""
        resrc = self._getResourceForRequest(request)
        return resrc.getChildWithDefault(path, request)
",CWE-80,50.0,1
,CWE-74,,1
"; ASTPP Database Connection Information
dbhost = 127.0.0.1
dbname = astpp
dbuser = astppuser
dbpass = <PASSSWORD>


; Database type:  ASTPP was designed for a MySQL database initially.  Valid options are:
; MySQL. Pgsql is coming but is not ready yet.
astpp_dbengine = MySQLi

; Do we want the startup of ASTPP debugged?
debug = 0

;Define Baseurl
;Note : Default we are running ASTPP on 8089. So, please do not remove 8089 from url.
base_url=http://localhost:8089/
",CWE-798,18.0,1
"; ASTPP Database Connection Information
dbhost = 127.0.0.1
dbname = astpp
dbuser = astppuser
dbpass = <PASSSWORD>


; Database type:  ASTPP was designed for a MySQL database initially.  Valid options are:
; MySQL. Pgsql is coming but is not ready yet.
astpp_dbengine = MySQLi

; Do we want the startup of ASTPP debugged?
debug = 0

;Define Baseurl
;Note : Default we are running ASTPP on 8089. So, please do not remove 8089 from url.
base_url=http://localhost:8089/
",CWE-327,18.0,1
"
            <p class=""nd_sidebar-title""><em>Port Utilization</em></p>
            <div class=""clearfix"">
              <em class=""muted"">Mark as Free if Down for:</em><br/>
              <select id=""nd_days-select"" name=""age_num"">
                [% FOREACH count IN [1..31] %]
                <option[% ' selected=""selected""' IF vars.sidebar_defaults.report_portutilization.age_num == count %]>[% count %]</option>
                [% END %]
              </select>
              <select id=""nd_age-select"" name=""age_unit"">
                [% FOREACH unit IN [ 'days', 'weeks', 'months', 'years' ] %]
                <option[% ' selected=""selected""' IF vars.sidebar_defaults.report_portutilization.age_unit == unit %]>[% unit %]</option>
                [% END %]
              </select>
            </div>

            <button id=""[% report.tag %]_submit"" type=""submit"" class=""btn btn-info"">
             <i class=""icon-search icon-large pull-left nd_navbar-icon""></i> Run Report</button>

",CWE-79,20.0,1
"import qrcode
import qrcode.image.svg
from django.conf import settings
from django.contrib.auth import REDIRECT_FIELD_NAME
from django.contrib.auth.views import SuccessURLAllowedHostsMixin
from django.http import HttpResponse
from django.shortcuts import resolve_url
from django.urls import reverse
from django.utils.decorators import method_decorator
from django.utils.functional import cached_property
from django.utils.http import is_safe_url
from django.views.decorators.cache import never_cache
from django.views.decorators.debug import sensitive_post_parameters
from django.views.generic import (
    DeleteView, FormView, ListView, UpdateView, View)
from django_otp import login as otp_login
from django_otp.plugins.otp_totp.models import TOTPDevice

from wagtail_2fa import forms, utils
from wagtail_2fa.mixins import OtpRequiredMixin


class LoginView(SuccessURLAllowedHostsMixin, FormView):
    template_name = ""wagtail_2fa/otp_form.html""
    form_class = forms.TokenForm
    redirect_field_name = REDIRECT_FIELD_NAME

    @method_decorator(sensitive_post_parameters())
    @method_decorator(never_cache)
    def dispatch(self, *args, **kwargs):
        return super().dispatch(*args, **kwargs)

    def get_form_kwargs(self):
        kwargs = super().get_form_kwargs()
        kwargs[""user""] = self.request.user
        return kwargs

    def get_context_data(self, *args, **kwargs):
        context = super().get_context_data(*args, **kwargs)
        context[self.redirect_field_name] = self.get_redirect_url()
        return context

    def form_valid(self, form):
        otp_login(self.request, self.request.user.otp_device)
        return super().form_valid(form)

    def get_redirect_url(self):
        """"""Return the user-originating redirect URL if it's safe.""""""
        redirect_to = self.request.POST.get(
            self.redirect_field_name, self.request.GET.get(self.redirect_field_name, """")
        )
        url_is_safe = is_safe_url(
            url=redirect_to,
            allowed_hosts=self.get_success_url_allowed_hosts(),
            require_https=self.request.is_secure(),
        )
        return redirect_to if url_is_safe else """"

    def get_success_url(self):
        url = self.get_redirect_url()
        return url or resolve_url(settings.LOGIN_REDIRECT_URL)


class DeviceListView(OtpRequiredMixin, ListView):
    template_name = ""wagtail_2fa/device_list.html""

    # require OTP if configured
    if_configured = True

    def get_queryset(self):
        return TOTPDevice.objects.devices_for_user(self.kwargs['user_id'], confirmed=True)

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['user_id'] = int(self.kwargs['user_id'])
        return context


class DeviceCreateView(OtpRequiredMixin, FormView):
    form_class = forms.DeviceForm
    template_name = ""wagtail_2fa/device_form.html""

    # require OTP if configured
    if_configured = True

    def get_form_kwargs(self):
        kwargs = super().get_form_kwargs()
        kwargs[""request""] = self.request
        kwargs[""instance""] = self.device
        return kwargs

    def form_valid(self, form):
        form.save()
        utils.delete_unconfirmed_devices(self.request.user)

        if not self.request.user.is_verified():
            otp_login(self.request, form.instance)
        return super().form_valid(form)

    def get_success_url(self):
        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.user.id})

    @cached_property
    def device(self):
        if self.request.method.lower() == ""get"":
            return utils.new_unconfirmed_device(self.request.user)
        else:
            return utils.get_unconfirmed_device(self.request.user)


class DeviceUpdateView(OtpRequiredMixin, UpdateView):
    form_class = forms.DeviceForm
    template_name = ""wagtail_2fa/device_form.html""

    def get_queryset(self):
        return TOTPDevice.objects.devices_for_user(self.request.user, confirmed=True)

    def get_form_kwargs(self):
        kwargs = super().get_form_kwargs()
        kwargs[""request""] = self.request
        return kwargs

    def get_success_url(self):
        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.user.id})


class DeviceDeleteView(OtpRequiredMixin, DeleteView):
    template_name = ""wagtail_2fa/device_confirm_delete.html""

    def get_queryset(self):
        device = TOTPDevice.objects.get(**self.kwargs)
        return TOTPDevice.objects.devices_for_user(device.user, confirmed=True)

    def get_success_url(self):
        return reverse('wagtail_2fa_device_list', kwargs={'user_id': self.request.POST.get('user_id')})


class DeviceQRCodeView(OtpRequiredMixin, View):
    # require OTP if configured
    if_configured = True

    def get(self, request):
        device = utils.get_unconfirmed_device(self.request.user)
        img = qrcode.make(device.config_url, image_factory=qrcode.image.svg.SvgImage)
        response = HttpResponse(content_type=""image/svg+xml"")
        img.save(response)

        return response
",CWE-863,149.0,1
"##############################################################################
#
# Copyright (c) 2001, 2002 Zope Foundation and Contributors.
# All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################
""""""Data Chunk Receiver
""""""

from waitress.utilities import find_double_newline

from waitress.utilities import BadRequest


class FixedStreamReceiver(object):

    # See IStreamConsumer
    completed = False
    error = None

    def __init__(self, cl, buf):
        self.remain = cl
        self.buf = buf

    def __len__(self):
        return self.buf.__len__()

    def received(self, data):
        ""See IStreamConsumer""
        rm = self.remain
        if rm < 1:
            self.completed = True  # Avoid any chance of spinning
            return 0
        datalen = len(data)
        if rm <= datalen:
            self.buf.append(data[:rm])
            self.remain = 0
            self.completed = True
            return rm
        else:
            self.buf.append(data)
            self.remain -= datalen
            return datalen

    def getfile(self):
        return self.buf.getfile()

    def getbuf(self):
        return self.buf


class ChunkedReceiver(object):

    chunk_remainder = 0
    control_line = b""""
    all_chunks_received = False
    trailer = b""""
    completed = False
    error = None

    # max_control_line = 1024
    # max_trailer = 65536

    def __init__(self, buf):
        self.buf = buf

    def __len__(self):
        return self.buf.__len__()

    def received(self, s):
        # Returns the number of bytes consumed.
        if self.completed:
            return 0
        orig_size = len(s)
        while s:
            rm = self.chunk_remainder
            if rm > 0:
                # Receive the remainder of a chunk.
                to_write = s[:rm]
                self.buf.append(to_write)
                written = len(to_write)
                s = s[written:]
                self.chunk_remainder -= written
            elif not self.all_chunks_received:
                # Receive a control line.
                s = self.control_line + s
                pos = s.find(b""\n"")
                if pos < 0:
                    # Control line not finished.
                    self.control_line = s
                    s = """"
                else:
                    # Control line finished.
                    line = s[:pos]
                    s = s[pos + 1 :]
                    self.control_line = b""""
                    line = line.strip()
                    if line:
                        # Begin a new chunk.
                        semi = line.find(b"";"")
                        if semi >= 0:
                            # discard extension info.
                            line = line[:semi]
                        try:
                            sz = int(line.strip(), 16)  # hexadecimal
                        except ValueError:  # garbage in input
                            self.error = BadRequest(""garbage in chunked encoding input"")
                            sz = 0
                        if sz > 0:
                            # Start a new chunk.
                            self.chunk_remainder = sz
                        else:
                            # Finished chunks.
                            self.all_chunks_received = True
                    # else expect a control line.
            else:
                # Receive the trailer.
                trailer = self.trailer + s
                if trailer.startswith(b""\r\n""):
                    # No trailer.
                    self.completed = True
                    return orig_size - (len(trailer) - 2)
                elif trailer.startswith(b""\n""):
                    # No trailer.
                    self.completed = True
                    return orig_size - (len(trailer) - 1)
                pos = find_double_newline(trailer)
                if pos < 0:
                    # Trailer not finished.
                    self.trailer = trailer
                    s = b""""
                else:
                    # Finished the trailer.
                    self.completed = True
                    self.trailer = trailer[:pos]
                    return orig_size - (len(trailer) - pos)
        return orig_size

    def getfile(self):
        return self.buf.getfile()

    def getbuf(self):
        return self.buf
",CWE-444,151.0,1
"##############################################################################
#
# Copyright (c) 2002 Zope Foundation and Contributors.
# All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################

import unittest


class Test_parse_http_date(unittest.TestCase):
    def _callFUT(self, v):
        from waitress.utilities import parse_http_date

        return parse_http_date(v)

    def test_rfc850(self):
        val = ""Tuesday, 08-Feb-94 14:15:29 GMT""
        result = self._callFUT(val)
        self.assertEqual(result, 760716929)

    def test_rfc822(self):
        val = ""Sun, 08 Feb 1994 14:15:29 GMT""
        result = self._callFUT(val)
        self.assertEqual(result, 760716929)

    def test_neither(self):
        val = """"
        result = self._callFUT(val)
        self.assertEqual(result, 0)


class Test_build_http_date(unittest.TestCase):
    def test_rountdrip(self):
        from waitress.utilities import build_http_date, parse_http_date
        from time import time

        t = int(time())
        self.assertEqual(t, parse_http_date(build_http_date(t)))


class Test_unpack_rfc850(unittest.TestCase):
    def _callFUT(self, val):
        from waitress.utilities import unpack_rfc850, rfc850_reg

        return unpack_rfc850(rfc850_reg.match(val.lower()))

    def test_it(self):
        val = ""Tuesday, 08-Feb-94 14:15:29 GMT""
        result = self._callFUT(val)
        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))


class Test_unpack_rfc_822(unittest.TestCase):
    def _callFUT(self, val):
        from waitress.utilities import unpack_rfc822, rfc822_reg

        return unpack_rfc822(rfc822_reg.match(val.lower()))

    def test_it(self):
        val = ""Sun, 08 Feb 1994 14:15:29 GMT""
        result = self._callFUT(val)
        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))


class Test_find_double_newline(unittest.TestCase):
    def _callFUT(self, val):
        from waitress.utilities import find_double_newline

        return find_double_newline(val)

    def test_empty(self):
        self.assertEqual(self._callFUT(b""""), -1)

    def test_one_linefeed(self):
        self.assertEqual(self._callFUT(b""\n""), -1)

    def test_double_linefeed(self):
        self.assertEqual(self._callFUT(b""\n\n""), 2)

    def test_one_crlf(self):
        self.assertEqual(self._callFUT(b""\r\n""), -1)

    def test_double_crfl(self):
        self.assertEqual(self._callFUT(b""\r\n\r\n""), 4)

    def test_mixed(self):
        self.assertEqual(self._callFUT(b""\n\n00\r\n\r\n""), 2)


class TestBadRequest(unittest.TestCase):
    def _makeOne(self):
        from waitress.utilities import BadRequest

        return BadRequest(1)

    def test_it(self):
        inst = self._makeOne()
        self.assertEqual(inst.body, 1)


class Test_undquote(unittest.TestCase):
    def _callFUT(self, value):
        from waitress.utilities import undquote

        return undquote(value)

    def test_empty(self):
        self.assertEqual(self._callFUT(""""), """")

    def test_quoted(self):
        self.assertEqual(self._callFUT('""test""'), ""test"")

    def test_unquoted(self):
        self.assertEqual(self._callFUT(""test""), ""test"")

    def test_quoted_backslash_quote(self):
        self.assertEqual(self._callFUT('""\\""""'), '""')

    def test_quoted_htab(self):
        self.assertEqual(self._callFUT('""\t""'), ""\t"")

    def test_quoted_backslash_htab(self):
        self.assertEqual(self._callFUT('""\\\t""'), ""\t"")

    def test_quoted_backslash_invalid(self):
        self.assertRaises(ValueError, self._callFUT, '""\\""')

    def test_invalid_quoting(self):
        self.assertRaises(ValueError, self._callFUT, '""test')

    def test_invalid_quoting_single_quote(self):
        self.assertRaises(ValueError, self._callFUT, '""')
",CWE-444,141.0,1
,CWE-94,,1
"# Grammar for Python

# Note:  Changing the grammar specified in this file will most likely
#        require corresponding changes in the parser module
#        (../Modules/parsermodule.c).  If you can't make the changes to
#        that module yourself, please co-ordinate the required changes
#        with someone who can; ask around on python-dev for help.  Fred
#        Drake <fdrake@acm.org> will probably be listening there.

# NOTE WELL: You should also follow all the steps listed at
# https://docs.python.org/devguide/grammar.html

# Start symbols for the grammar:
#       single_input is a single interactive statement;
#       file_input is a module or sequence of commands read from an input file;
#       eval_input is the input for the eval() functions.
#       func_type_input is a PEP 484 Python 2 function type comment
# NB: compound_stmt in single_input is followed by extra NEWLINE!
# NB: due to the way TYPE_COMMENT is tokenized it will always be followed by a
#      NEWLINE
single_input: NEWLINE | simple_stmt | compound_stmt NEWLINE
file_input: (NEWLINE | stmt)* ENDMARKER
eval_input: testlist NEWLINE* ENDMARKER

decorator: '@' dotted_name [ '(' [arglist] ')' ] NEWLINE
decorators: decorator+
decorated: decorators (classdef | funcdef | async_funcdef)

async_funcdef: ASYNC funcdef
funcdef: 'def' NAME parameters ['->' test] ':' [TYPE_COMMENT] suite

parameters: '(' [typedargslist] ')'
typedargslist: (tfpdef ['=' test] (',' [TYPE_COMMENT] tfpdef ['=' test])* (TYPE_COMMENT | [',' [TYPE_COMMENT] [
        '*' [tfpdef] (',' [TYPE_COMMENT] tfpdef ['=' test])* (TYPE_COMMENT | [',' [TYPE_COMMENT] ['**' tfpdef [','] [TYPE_COMMENT]]])
      | '**' tfpdef [','] [TYPE_COMMENT]]])
  | '*' [tfpdef] (',' [TYPE_COMMENT] tfpdef ['=' test])* (TYPE_COMMENT | [',' [TYPE_COMMENT] ['**' tfpdef [','] [TYPE_COMMENT]]])
  | '**' tfpdef [','] [TYPE_COMMENT])
tfpdef: NAME [':' test]
varargslist: (vfpdef ['=' test] (',' vfpdef ['=' test])* [',' [
        '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]
      | '**' vfpdef [',']]]
  | '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]
  | '**' vfpdef [',']
)
vfpdef: NAME

stmt: simple_stmt | compound_stmt
simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE
small_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |
             import_stmt | global_stmt | nonlocal_stmt | assert_stmt)
expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |
                     ('=' (yield_expr|testlist_star_expr))* [TYPE_COMMENT])
annassign: ':' test ['=' test]
testlist_star_expr: (test|star_expr) (',' (test|star_expr))* [',']
augassign: ('+=' | '-=' | '*=' | '@=' | '/=' | '%=' | '&=' | '|=' | '^=' |
            '<<=' | '>>=' | '**=' | '//=')
# For normal and annotated assignments, additional restrictions enforced by the interpreter
del_stmt: 'del' exprlist
pass_stmt: 'pass'
flow_stmt: break_stmt | continue_stmt | return_stmt | raise_stmt | yield_stmt
break_stmt: 'break'
continue_stmt: 'continue'
return_stmt: 'return' [testlist]
yield_stmt: yield_expr
raise_stmt: 'raise' [test ['from' test]]
import_stmt: import_name | import_from
import_name: 'import' dotted_as_names
# note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS
import_from: ('from' (('.' | '...')* dotted_name | ('.' | '...')+)
              'import' ('*' | '(' import_as_names ')' | import_as_names))
import_as_name: NAME ['as' NAME]
dotted_as_name: dotted_name ['as' NAME]
import_as_names: import_as_name (',' import_as_name)* [',']
dotted_as_names: dotted_as_name (',' dotted_as_name)*
dotted_name: NAME ('.' NAME)*
global_stmt: 'global' NAME (',' NAME)*
nonlocal_stmt: 'nonlocal' NAME (',' NAME)*
assert_stmt: 'assert' test [',' test]

compound_stmt: if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | decorated | async_stmt
async_stmt: ASYNC (funcdef | with_stmt | for_stmt)
if_stmt: 'if' test ':' suite ('elif' test ':' suite)* ['else' ':' suite]
while_stmt: 'while' test ':' suite ['else' ':' suite]
for_stmt: 'for' exprlist 'in' testlist ':' [TYPE_COMMENT] suite ['else' ':' suite]
try_stmt: ('try' ':' suite
           ((except_clause ':' suite)+
            ['else' ':' suite]
            ['finally' ':' suite] |
           'finally' ':' suite))
with_stmt: 'with' with_item (',' with_item)*  ':' [TYPE_COMMENT] suite
with_item: test ['as' expr]
# NB compile.c makes sure that the default except clause is last
except_clause: 'except' [test ['as' NAME]]
# the TYPE_COMMENT in suites is only parsed for funcdefs, but can't go elsewhere due to ambiguity
suite: simple_stmt | NEWLINE [TYPE_COMMENT NEWLINE] INDENT stmt+ DEDENT

test: or_test ['if' or_test 'else' test] | lambdef
test_nocond: or_test | lambdef_nocond
lambdef: 'lambda' [varargslist] ':' test
lambdef_nocond: 'lambda' [varargslist] ':' test_nocond
or_test: and_test ('or' and_test)*
and_test: not_test ('and' not_test)*
not_test: 'not' not_test | comparison
comparison: expr (comp_op expr)*
# <> isn't actually a valid comparison operator in Python. It's here for the
# sake of a __future__ import described in PEP 401 (which really works :-)
comp_op: '<'|'>'|'=='|'>='|'<='|'<>'|'!='|'in'|'not' 'in'|'is'|'is' 'not'
star_expr: '*' expr
expr: xor_expr ('|' xor_expr)*
xor_expr: and_expr ('^' and_expr)*
and_expr: shift_expr ('&' shift_expr)*
shift_expr: arith_expr (('<<'|'>>') arith_expr)*
arith_expr: term (('+'|'-') term)*
term: factor (('*'|'@'|'/'|'%'|'//') factor)*
factor: ('+'|'-'|'~') factor | power
power: atom_expr ['**' factor]
atom_expr: [AWAIT] atom trailer*
atom: ('(' [yield_expr|testlist_comp] ')' |
       '[' [testlist_comp] ']' |
       '{' [dictorsetmaker] '}' |
       NAME | NUMBER | STRING+ | '...' | 'None' | 'True' | 'False')
testlist_comp: (test|star_expr) ( comp_for | (',' (test|star_expr))* [','] )
trailer: '(' [arglist] ')' | '[' subscriptlist ']' | '.' NAME
subscriptlist: subscript (',' subscript)* [',']
subscript: test | [test] ':' [test] [sliceop]
sliceop: ':' [test]
exprlist: (expr|star_expr) (',' (expr|star_expr))* [',']
testlist: test (',' test)* [',']
dictorsetmaker: ( ((test ':' test | '**' expr)
                   (comp_for | (',' (test ':' test | '**' expr))* [','])) |
                  ((test | star_expr)
                   (comp_for | (',' (test | star_expr))* [','])) )

classdef: 'class' NAME ['(' [arglist] ')'] ':' suite

arglist: argument (',' argument)*  [',']

# The reason that keywords are test nodes instead of NAME is that using NAME
# results in an ambiguity. ast.c makes sure it's a NAME.
# ""test '=' test"" is really ""keyword '=' test"", but we have no such token.
# These need to be in a single rule to avoid grammar that is ambiguous
# to our LL(1) parser. Even though 'test' includes '*expr' in star_expr,
# we explicitly match '*' here, too, to give it proper precedence.
# Illegal combinations and orderings are blocked in ast.c:
# multiple (test comp_for) arguments are blocked; keyword unpackings
# that precede iterable unpackings are blocked; etc.
argument: ( test [comp_for] |
            test '=' test |
            '**' test |
            '*' test )

comp_iter: comp_for | comp_if
comp_for: [ASYNC] 'for' exprlist 'in' or_test [comp_iter]
comp_if: 'if' test_nocond [comp_iter]

# not used in grammar, but may appear in ""node"" passed from Parser to Compiler
encoding_decl: NAME

yield_expr: 'yield' [yield_arg]
yield_arg: 'from' test | testlist

func_type_input: func_type NEWLINE* ENDMARKER
func_type: '(' [typelist] ')' '->' test
# typelist is a modified typedargslist (see above)
typelist: (test (',' test)* [','
       ['*' [test] (',' test)* [',' '**' test] | '**' test]]
     |  '*' [test] (',' test)* [',' '**' test] | '**' test)
",CWE-125,168.0,1
"import ast
import re
import sys
if sys.version_info[0] < 3 or sys.version_info[1] < 3:
    sys.exit('Error: typed_ast only runs on Python 3.3 and above.')

try:
    from setuptools import setup, Extension
except ImportError:
    from distutils.core import setup, Extension

_ast27 = Extension(
    '_ast27',
    include_dirs = ['ast27/Include'],
    sources = [
        'ast27/Parser/acceler.c',
        'ast27/Parser/bitset.c',
        'ast27/Parser/grammar.c',
        'ast27/Parser/grammar1.c',
        'ast27/Parser/node.c',
        'ast27/Parser/parser.c',
        'ast27/Parser/parsetok.c',
        'ast27/Parser/tokenizer.c',
        'ast27/Python/asdl.c',
        'ast27/Python/ast.c',
        'ast27/Python/graminit.c',
        'ast27/Python/mystrtoul.c',
        'ast27/Python/Python-ast.c',
        'ast27/Custom/typed_ast.c',
    ],
    depends = [
        'ast27/Include/asdl.h',
        'ast27/Include/ast.h',
        'ast27/Include/bitset.h',
        'ast27/Include/compile.h',
        'ast27/Include/errcode.h',
        'ast27/Include/graminit.h',
        'ast27/Include/grammar.h',
        'ast27/Include/node.h',
        'ast27/Include/parsetok.h',
        'ast27/Include/Python-ast.h',
        'ast27/Include/token.h',
        'ast27/Parser/parser.h',
        'ast27/Parser/tokenizer.h',
    ])


_ast3 = Extension(
    '_ast3',
    include_dirs = ['ast3/Include'],
    sources = [
        'ast3/Parser/acceler.c',
        'ast3/Parser/bitset.c',
        'ast3/Parser/grammar.c',
        'ast3/Parser/grammar1.c',
        'ast3/Parser/node.c',
        'ast3/Parser/parser.c',
        'ast3/Parser/parsetok.c',
        'ast3/Parser/tokenizer.c',
        'ast3/Python/asdl.c',
        'ast3/Python/ast.c',
        'ast3/Python/graminit.c',
        'ast3/Python/Python-ast.c',
        'ast3/Custom/typed_ast.c',
    ],
    depends = [
        'ast3/Include/asdl.h',
        'ast3/Include/ast.h',
        'ast3/Include/bitset.h',
        'ast3/Include/compile.h',
        'ast3/Include/errcode.h',
        'ast3/Include/graminit.h',
        'ast3/Include/grammar.h',
        'ast3/Include/node.h',
        'ast3/Include/parsetok.h',
        'ast3/Include/Python-ast.h',
        'ast3/Include/token.h',
        'ast3/Parser/parser.h',
        'ast3/Parser/tokenizer.h',
    ])

long_description = """"""
`typed_ast` is a Python 3 package that provides a Python 2.7 and Python 3
parser similar to the standard `ast` library.  Unlike `ast`, the parsers in
`typed_ast` include PEP 484 type comments and are independent of the version of
Python under which they are run.  The `typed_ast` parsers produce the standard
Python AST (plus type comments), and are both fast and correct, as they are
based on the CPython 2.7 and 3.6 parsers.
"""""".strip()

_version_re = re.compile(r'__version__\s+=\s+(?P<version>.*)')

with open('typed_ast/__init__.py', 'r', encoding='utf8') as f:
    version = _version_re.search(f.read()).group('version')
    version = str(ast.literal_eval(version))

setup (name = 'typed-ast',
       version = version,
       description = 'a fork of Python 2 and 3 ast modules with type comment support',
       long_description = long_description,
       author = 'David Fisher',
       author_email = 'ddfisher@dropbox.com',
       url = 'https://github.com/python/typed_ast',
       license='Apache License 2.0',
       platforms = ['POSIX', 'Windows'],
       classifiers = [
           'Development Status :: 5 - Production/Stable',
           'Environment :: Console',
           'Intended Audience :: Developers',
           'Operating System :: POSIX',
           'Operating System :: Microsoft',
           'Programming Language :: Python :: 3.3',
           'Programming Language :: Python :: 3.4',
           'Programming Language :: Python :: 3.5',
           'Programming Language :: Python :: 3.6',
           'Programming Language :: Python :: 3.7',
           'Topic :: Software Development',
       ],
       packages = ['typed_ast'],
       ext_modules = [_ast27, _ast3])
",CWE-125,121.0,1
,CWE-125,,1
,CWE-327,,1
,CWE-916,,1
"""""""\
Front-to-back rapid web development
===================================

TurboGears brings together four major pieces to create an easy to
install, easy to use web mega-framework. It covers everything from
front end (MochiKit JavaScript for the browser, Genshi / Kid / Mako /
Cheetah for templates in Python) to the controllers (CherryPy) to the
back end (SQLAlchemy or SQLObject).

The TurboGears project is focused on providing documentation and
integration with these tools without losing touch with the communities
that already exist around those tools.

TurboGears is easy to use for a wide range of web applications.

The latest development version is available in the `TurboGears
subversion repository`_.

Our `mailing list`_ is lively and helpful, don't hesitate to send your
questions there, we will try to help you find out a solution to your
problem.

.. _mailing list:
    http://groups.google.com/group/turbogears

.. _TurboGears subversion repository:
    http://svn.turbogears.org/trunk#egg=turbogears-dev
""""""

version = ""1.0.11.8""
description = ""Front-to-back, open-source, rapid web development framework""
long_description = __doc__
author = ""Kevin Dangoor""
email = ""dangoor+turbogears@gmail.com""
maintainer = ""TurboGears Release Team""
maintainer_email = ""turbogears@googlegroups.com""
url = ""http://www.turbogears.org/""
download_url = ""http://www.turbogears.org/%s/downloads/%s/index"" % (
    '.'.join(version.split('.', 2)[:2]), version)
dependency_links = [download_url]
copyright = ""Copyright 2005 - 2011 Kevin Dangoor and contributors""
license = ""MIT""
",CWE-436,44.0,1
"#! /usr/bin/python3

# This file is part of Cockpit.
#
# Copyright (C) 2013 Red Hat, Inc.
#
# Cockpit is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# Cockpit is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with Cockpit; If not, see <http://www.gnu.org/licenses/>.

import subprocess

import parent
from testlib import *


@skipDistroPackage()
@nondestructive
class TestEmbed(MachineCase):

    def testBasic(self):
        b = self.browser
        m = self.machine

        self.restore_dir(""/home/admin/.local/share/cockpit"")
        m.execute(""mkdir -p /home/admin/.local/share/cockpit/embed-cockpit"")
        m.upload([""verify/files/embed-cockpit/index.html"",
                  ""verify/files/embed-cockpit/embed.js"",
                  ""verify/files/embed-cockpit/embed.css"",
                  ""verify/files/embed-cockpit/manifest.json""],
                 ""/home/admin/.local/share/cockpit/embed-cockpit/"")

        # replace the shell with our embedded page, this way we can avoid
        # cross-origin errors when executing js in the iframe
        m.write(""/etc/cockpit/cockpit.conf"", """"""
[WebService]
Shell=/embed-cockpit/index.html
"""""")
        m.start_cockpit()
        self.login_and_go()

        b.wait_visible(""#embed-loaded"")
        b.wait_visible(""#embed-address"")
        m.write(""/etc/cockpit/cockpit.conf"", """"""
[WebService]
Shell=/shell/index.html
"""""")
        b.set_val(""#embed-address"", ""http://{0}:{1}"".format(m.web_address, m.web_port))
        b.click(""#embed-full"")
        b.wait_visible(""iframe[name='embed-full'][loaded]"")
        b.switch_to_frame(""embed-full"")
        b.wait_visible(""#system_information_os_text"")

        # Page should show automatically now that other frame logged in
        b.switch_to_top()
        b.click(""#embed-terminal"")
        b.wait_visible(""iframe[name='embed-terminal'][loaded]"")
        b.switch_to_frame(""embed-terminal"")
        b.wait_visible(""#terminal"")

        # Clicking on the link with separate auth, shouldn't log in automatically
        b.switch_to_top()
        b.click(""#embed-auth"")
        b.wait_visible(""iframe[name='embed-auth'][loaded]"")
        b.switch_to_frame(""embed-auth"")
        b.wait_visible(""#login-user-input"")

    @skipBrowser(""Chromium cannot inspect cross-origin frames"", ""chromium"")
    def testCrossOrigin(self):
        b = self.browser
        m = self.machine

        pyhttpd = subprocess.Popen(['python3', '-m', 'http.server', '--bind=localhost',
                                    '--directory=test/verify/files/embed-cockpit', '12346'])

        def clean_pyhttpd():
            pyhttpd.terminate()
            pyhttpd.wait()

        self.addCleanup(clean_pyhttpd)

        # log in normally, to get the auth cookie into the browser and thus maximize possible cross-domain exposure
        self.login_and_go()

        b.open(""http://localhost:12346/index.html"")
        b.set_val(""#embed-address"", ""http://{0}:{1}"".format(m.web_address, m.web_port))
        b.click(""#embed-full"")
        # FIXME (#16122): we should not even get that far, frame loading should already be blocked here
        b.wait_visible(""iframe[name='embed-full'][loaded]"")
        b.switch_to_frame(""embed-full"")

        # second line of defense: existing login cookie does not work (default browser protection)
        b.wait_visible(""#login"")
        b.set_val(""#login-user-input"", ""admin"")
        b.set_val(""#login-password-input"", ""foobar"")
        b.click('#login-button')
        b.expect_load_frame(""embed-full"")

        # third line of defense: login succeeds and creates a PAM session; but loading session UI does not
        # (again, due to default browser protection)
        b.wait_visible(""#login"")


if __name__ == '__main__':
    test_main()
",CWE-1021,115.0,1
"{
  ""name"": ""bower"",
  ""version"": ""1.8.7"",
  ""description"": ""The browser package manager"",
  ""author"": ""Twitter"",
  ""license"": ""MIT"",
  ""repository"": ""bower/bower"",
  ""main"": ""lib"",
  ""bin"": ""bin/bower"",
  ""homepage"": ""http://bower.io"",
  ""engines"": {
    ""node"": "">=0.10.0""
  },
  ""keywords"": [
    ""bower""
  ],
  ""dependencies"": {
    ""abbrev"": ""^1.0.5"",
    ""archy"": ""1.0.0"",
    ""bower-config"": ""^1.4.1"",
    ""bower-endpoint-parser"": ""^0.2.2"",
    ""bower-json"": ""^0.8.1"",
    ""bower-logger"": ""^0.2.2"",
    ""bower-registry-client"": ""^1.0.0"",
    ""cardinal"": ""0.4.4"",
    ""chalk"": ""^1.0.0"",
    ""chmodr"": ""^1.0.2"",
    ""configstore"": ""^2.0.0"",
    ""decompress-zip"": ""^0.2.2"",
    ""destroy"": ""^1.0.3"",
    ""findup-sync"": ""^0.3.0"",
    ""fs-write-stream-atomic"": ""1.0.8"",
    ""fstream"": ""^1.0.3"",
    ""fstream-ignore"": ""^1.0.2"",
    ""github"": ""^0.2.3"",
    ""glob"": ""^4.3.2"",
    ""graceful-fs"": ""^4.1.3"",
    ""handlebars"": ""^4.0.5"",
    ""inquirer"": ""0.10.0"",
    ""is-root"": ""^1.0.0"",
    ""junk"": ""^1.0.0"",
    ""lockfile"": ""^1.0.0"",
    ""lru-cache"": ""^2.5.0"",
    ""md5-hex"": ""^1.0.2"",
    ""mkdirp"": ""0.5.0"",
    ""mout"": ""^0.11.0"",
    ""nopt"": ""^3.0.1"",
    ""opn"": ""^4.0.0"",
    ""p-throttler"": ""0.1.1"",
    ""promptly"": ""0.2.0"",
    ""q"": ""^1.1.2"",
    ""request"": ""2.67.0"",
    ""request-progress"": ""0.3.1"",
    ""requireg"": ""^0.1.5"",
    ""resolve"": ""^1.1.7"",
    ""retry"": ""0.6.1"",
    ""rimraf"": ""^2.2.8"",
    ""semver"": ""^2.3.0"",
    ""semver-utils"": ""^1.1.1"",
    ""shell-quote"": ""^1.4.2"",
    ""stringify-object"": ""^1.0.0"",
    ""tar-fs"": ""^1.4.1"",
    ""tmp"": ""0.0.28"",
    ""update-notifier"": ""^0.6.0"",
    ""user-home"": ""^1.1.0"",
    ""which"": ""^1.0.8""
  },
  ""devDependencies"": {
    ""arr-diff"": ""^2.0.0"",
    ""chai"": ""^3.5.0"",
    ""coveralls"": ""^2.11.9"",
    ""expect.js"": ""^0.3.1"",
    ""grunt"": ""^1.0.1"",
    ""grunt-cli"": ""^1.1.0"",
    ""grunt-contrib-watch"": ""^1.0.0"",
    ""grunt-eslint"": ""^18.1.0"",
    ""grunt-exec"": ""^0.4.7"",
    ""grunt-simple-mocha"": ""^0.4.1"",
    ""husky"": ""^0.14.3"",
    ""in-publish"": ""^2.0.0"",
    ""istanbul"": ""^0.4.3"",
    ""lint-staged"": ""^7.0.0"",
    ""load-grunt-tasks"": ""^3.5.0"",
    ""mocha"": ""^2.5.3"",
    ""multiline"": ""^1.0.2"",
    ""nock"": ""^9.2.3"",
    ""node-uuid"": ""^1.4.7"",
    ""prettier"": ""^1.11.1"",
    ""proxyquire"": ""^1.7.9"",
    ""spawn-sync"": ""1.0.15"",
    ""wrench"": ""^1.5.8""
  },
  ""scripts"": {
    ""test"": ""grunt test"",
    ""ci"": ""grunt travis"",
    ""coveralls"": ""coveralls"",
    ""prepublish"": ""in-publish && echo 'You need to use \""grunt publish\"" to publish bower' && false || not-in-publish"",
    ""format"": ""prettier --write --single-quote --tab-width 4 '**/*.js'"",
    ""precommit"": ""lint-staged""
  },
  ""lint-staged"": {
    ""*.js"": [
      ""prettier --single-quote --tab-width 4"",
      ""git add""
    ]
  },
  ""files"": [
    ""bin"",
    ""lib""
  ]
}
",CWE-22,112.0,1
"from collections import OrderedDict

import django.forms
from django.utils.translation import gettext_lazy as _

from wagtail.admin.forms import WagtailAdminPageForm
from wagtail.contrib.forms.utils import get_field_clean_name


class BaseForm(django.forms.Form):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault('label_suffix', '')

        self.user = kwargs.pop('user', None)
        self.page = kwargs.pop('page', None)

        super().__init__(*args, **kwargs)


class FormBuilder:
    def __init__(self, fields):
        self.fields = fields

    def create_singleline_field(self, field, options):
        # TODO: This is a default value - it may need to be changed
        options['max_length'] = 255
        return django.forms.CharField(**options)

    def create_multiline_field(self, field, options):
        return django.forms.CharField(widget=django.forms.Textarea, **options)

    def create_date_field(self, field, options):
        return django.forms.DateField(**options)

    def create_datetime_field(self, field, options):
        return django.forms.DateTimeField(**options)

    def create_email_field(self, field, options):
        return django.forms.EmailField(**options)

    def create_url_field(self, field, options):
        return django.forms.URLField(**options)

    def create_number_field(self, field, options):
        return django.forms.DecimalField(**options)

    def create_dropdown_field(self, field, options):
        options['choices'] = map(
            lambda x: (x.strip(), x.strip()),
            field.choices.split(',')
        )
        return django.forms.ChoiceField(**options)

    def create_multiselect_field(self, field, options):
        options['choices'] = map(
            lambda x: (x.strip(), x.strip()),
            field.choices.split(',')
        )
        return django.forms.MultipleChoiceField(**options)

    def create_radio_field(self, field, options):
        options['choices'] = map(
            lambda x: (x.strip(), x.strip()),
            field.choices.split(',')
        )
        return django.forms.ChoiceField(widget=django.forms.RadioSelect, **options)

    def create_checkboxes_field(self, field, options):
        options['choices'] = [(x.strip(), x.strip()) for x in field.choices.split(',')]
        options['initial'] = [x.strip() for x in field.default_value.split(',')]
        return django.forms.MultipleChoiceField(
            widget=django.forms.CheckboxSelectMultiple, **options
        )

    def create_checkbox_field(self, field, options):
        return django.forms.BooleanField(**options)

    def create_hidden_field(self, field, options):
        return django.forms.CharField(widget=django.forms.HiddenInput, **options)

    def get_create_field_function(self, type):
        """"""
            Takes string of field type and returns a Django Form Field Instance.
            Assumes form field creation functions are in the format:
            'create_fieldtype_field'
        """"""
        create_field_function = getattr(self, 'create_%s_field' % type, None)
        if create_field_function:
            return create_field_function
        else:
            import inspect
            method_list = [
                f[0] for f in
                inspect.getmembers(self.__class__, inspect.isfunction)
                if f[0].startswith('create_') and f[0].endswith('_field')
            ]
            raise AttributeError(
                ""Could not find function matching format \
                create_<fieldname>_field for type: "" + type,
                ""Must be one of: "" + "", "".join(method_list)
            )

    @property
    def formfields(self):
        formfields = OrderedDict()

        for field in self.fields:
            options = self.get_field_options(field)
            create_field = self.get_create_field_function(field.field_type)
            formfields[field.clean_name] = create_field(field, options)

        return formfields

    def get_field_options(self, field):
        options = {}
        options['label'] = field.label
        options['help_text'] = field.help_text
        options['required'] = field.required
        options['initial'] = field.default_value
        return options

    def get_form_class(self):
        return type(str('WagtailForm'), (BaseForm,), self.formfields)


class SelectDateForm(django.forms.Form):
    date_from = django.forms.DateTimeField(
        required=False,
        widget=django.forms.DateInput(attrs={'placeholder': _('Date from')})
    )
    date_to = django.forms.DateTimeField(
        required=False,
        widget=django.forms.DateInput(attrs={'placeholder': _('Date to')})
    )


class WagtailAdminFormPageForm(WagtailAdminPageForm):

    def clean(self):

        super().clean()

        # Check for dupe form field labels - fixes #585
        if 'form_fields' in self.formsets:
            _forms = self.formsets['form_fields'].forms
            for f in _forms:
                f.is_valid()

            for i, form in enumerate(_forms):
                if 'label' in form.changed_data:
                    label = form.cleaned_data.get('label')
                    clean_name = get_field_clean_name(label)
                    for idx, ff in enumerate(_forms):
                        # Exclude self
                        ff_clean_name = get_field_clean_name(ff.cleaned_data.get('label'))
                        if idx != i and clean_name == ff_clean_name:
                            form.add_error(
                                'label',
                                django.forms.ValidationError(_('There is another field with the label %s, please change one of them.' % label))
                            )
",CWE-79,161.0,1
,CWE-400,,1
,CWE-770,,1
,CWE-89,,1
"from pypika import Parameter, functions
from pypika.enums import SqlTypes
from pypika.terms import Criterion

from tortoise import Model
from tortoise.backends.base.executor import BaseExecutor
from tortoise.fields import BigIntField, Field, IntField, SmallIntField
from tortoise.filters import (
    contains,
    ends_with,
    insensitive_contains,
    insensitive_ends_with,
    insensitive_exact,
    insensitive_starts_with,
    starts_with,
)


def mysql_contains(field: Field, value: str) -> Criterion:
    return functions.Cast(field, SqlTypes.CHAR).like(f""%{value}%"")


def mysql_starts_with(field: Field, value: str) -> Criterion:
    return functions.Cast(field, SqlTypes.CHAR).like(f""{value}%"")


def mysql_ends_with(field: Field, value: str) -> Criterion:
    return functions.Cast(field, SqlTypes.CHAR).like(f""%{value}"")


def mysql_insensitive_exact(field: Field, value: str) -> Criterion:
    return functions.Upper(functions.Cast(field, SqlTypes.CHAR)).eq(functions.Upper(f""{value}""))


def mysql_insensitive_contains(field: Field, value: str) -> Criterion:
    return functions.Upper(functions.Cast(field, SqlTypes.CHAR)).like(functions.Upper(f""%{value}%""))


def mysql_insensitive_starts_with(field: Field, value: str) -> Criterion:
    return functions.Upper(functions.Cast(field, SqlTypes.CHAR)).like(functions.Upper(f""{value}%""))


def mysql_insensitive_ends_with(field: Field, value: str) -> Criterion:
    return functions.Upper(functions.Cast(field, SqlTypes.CHAR)).like(functions.Upper(f""%{value}""))


class MySQLExecutor(BaseExecutor):
    FILTER_FUNC_OVERRIDE = {
        contains: mysql_contains,
        starts_with: mysql_starts_with,
        ends_with: mysql_ends_with,
        insensitive_exact: mysql_insensitive_exact,
        insensitive_contains: mysql_insensitive_contains,
        insensitive_starts_with: mysql_insensitive_starts_with,
        insensitive_ends_with: mysql_insensitive_ends_with,
    }
    EXPLAIN_PREFIX = ""EXPLAIN FORMAT=JSON""

    def parameter(self, pos: int) -> Parameter:
        return Parameter(""%s"")

    async def _process_insert_result(self, instance: Model, results: int) -> None:
        pk_field_object = self.model._meta.pk
        if (
            isinstance(pk_field_object, (SmallIntField, IntField, BigIntField))
            and pk_field_object.generated
        ):
            instance.pk = results

        # MySQL can only generate a single ROWID
        #   so if any other primary key, it won't generate what we want.
",CWE-89,72.0,1
,CWE-400,,1
,CWE-400,,1
"import os
import setuptools
import setuptools.command.test
import sys

pkgdir = {"""": ""python%s"" % sys.version_info[0]}
VERSION = ""0.18.1""


# `python setup.py test` uses existing Python environment, no virtualenv, no pip.
# Use case: Archlinux package. https://github.com/httplib2/httplib2/issues/103
# Otherwise, use `script/test`
class TestCommand(setuptools.command.test.test):
    def run_tests(self):
        # pytest may be not installed yet
        import pytest
        args = ['--forked', '--fulltrace', '--no-cov', 'tests/']
        if self.test_suite:
            args += ['-k', self.test_suite]
        sys.stderr.write('setup.py:test run pytest {}\n'.format(' '.join(args)))
        errno = pytest.main(args)
        sys.exit(errno)


def read_requirements(name):
    project_root = os.path.dirname(os.path.abspath(__file__))
    with open(os.path.join(project_root, name), 'rb') as f:
        # remove whitespace and comments
        g = (line.decode('utf-8').lstrip().split('#', 1)[0].rstrip() for line in f)
        return [l for l in g if l]


setuptools.setup(
    name=""httplib2"",
    version=VERSION,
    author=""Joe Gregorio"",
    author_email=""joe@bitworking.org"",
    url=""https://github.com/httplib2/httplib2"",
    description=""A comprehensive HTTP client library."",
    license=""MIT"",
    long_description=""""""

A comprehensive HTTP client library, ``httplib2`` supports many features left out of other HTTP libraries.

**HTTP and HTTPS**
  HTTPS support is only available if the socket module was compiled with SSL support.


**Keep-Alive**
  Supports HTTP 1.1 Keep-Alive, keeping the socket open and performing multiple requests over the same connection if possible.


**Authentication**
  The following three types of HTTP Authentication are supported. These can be used over both HTTP and HTTPS.

  * Digest
  * Basic
  * WSSE

**Caching**
  The module can optionally operate with a private cache that understands the Cache-Control:
  header and uses both the ETag and Last-Modified cache validators. Both file system
  and memcached based caches are supported.


**All Methods**
  The module can handle any HTTP request method, not just GET and POST.


**Redirects**
  Automatically follows 3XX redirects on GETs.


**Compression**
  Handles both 'deflate' and 'gzip' types of compression.


**Lost update support**
  Automatically adds back ETags into PUT requests to resources we have already cached. This implements Section 3.2 of Detecting the Lost Update Problem Using Unreserved Checkout


**Unit Tested**
  A large and growing set of unit tests.
"""""",
    package_dir=pkgdir,
    packages=[""httplib2""],
    package_data={""httplib2"": [""*.txt""]},
    tests_require=read_requirements(""requirements-test.txt""),
    cmdclass={""test"": TestCommand},
    classifiers=[
        ""Development Status :: 4 - Beta"",
        ""Environment :: Web Environment"",
        ""Intended Audience :: Developers"",
        ""License :: OSI Approved :: MIT License"",
        ""Operating System :: OS Independent"",
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 2"",
        ""Programming Language :: Python :: 2.7"",
        ""Programming Language :: Python :: 3"",
        ""Programming Language :: Python :: 3.4"",
        ""Programming Language :: Python :: 3.5"",
        ""Programming Language :: Python :: 3.6"",
        ""Programming Language :: Python :: 3.7"",
        ""Topic :: Internet :: WWW/HTTP"",
        ""Topic :: Software Development :: Libraries"",
    ],
)
",CWE-400,108.0,1
"# -*- coding: utf-8 -*-
#
# fastecdsa documentation build configuration file, created by
# sphinx-quickstart on Thu Dec 15 20:02:52 2016.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
from datetime import datetime
import os
import sys
from unittest import mock

sys.path.insert(0, os.path.abspath('.'))
sys.path.insert(0, os.path.abspath('../'))

MOCK_MODULES = ['fastecdsa._ecdsa', 'fastecdsa.curvemath']
for mod_name in MOCK_MODULES:
    sys.modules[mod_name] = mock.Mock()


# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#
# needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = ['sphinx.ext.mathjax', 'sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix(es) of source filenames.
# You can specify multiple suffix as a list of string:
#
# source_suffix = ['.rst', '.md']
source_suffix = ['.rst', '.md']

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'fastecdsa'
copyright = '{}, Anton Kueltz'.format(datetime.now().year)
author = 'Anton Kueltz'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '2.1'
# The full version, including alpha/beta/rc tags.
release = '2.1.1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#
# This is also used if you do content translation via gettext catalogs.
# Usually you set ""language"" from the command line for these cases.
language = None

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This patterns also effect to html_static_path and html_extra_path
exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# If true, `todo` and `todoList` produce output, else they produce nothing.
todo_include_todos = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#
# html_theme = 'alabaster'
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#
# html_theme_options = {}

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named ""default.css"" will overwrite the builtin ""default.css"".
html_static_path = ['_static']


# -- Options for HTMLHelp output ------------------------------------------

# Output file base name for HTML help builder.
htmlhelp_basename = 'fastecdsadoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #
    # 'papersize': 'letterpaper',

    # The font size ('10pt', '11pt' or '12pt').
    #
    # 'pointsize': '10pt',

    # Additional stuff for the LaTeX preamble.
    #
    # 'preamble': '',

    # Latex figure (float) alignment
    #
    # 'figure_align': 'htbp',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
    (master_doc, 'fastecdsa.tex', 'fastecdsa Documentation',
     'Anton Kueltz', 'manual'),
]


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    (master_doc, 'fastecdsa', 'fastecdsa Documentation',
     [author], 1)
]


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
    (master_doc, 'fastecdsa', 'fastecdsa Documentation',
     author, 'fastecdsa', 'One line description of project.',
     'Miscellaneous'),
]
",CWE-347,163.0,1
"import logging
import requests
from flask import redirect, url_for, Blueprint, flash, request, session
from flask_oauthlib.client import OAuth

from redash import models, settings
from redash.authentication import (
    create_and_login_user,
    logout_and_redirect_to_index,
    get_next_path,
)
from redash.authentication.org_resolving import current_org

logger = logging.getLogger(""google_oauth"")

oauth = OAuth()
blueprint = Blueprint(""google_oauth"", __name__)


def google_remote_app():
    if ""google"" not in oauth.remote_apps:
        oauth.remote_app(
            ""google"",
            base_url=""https://www.google.com/accounts/"",
            authorize_url=""https://accounts.google.com/o/oauth2/auth?prompt=select_account+consent"",
            request_token_url=None,
            request_token_params={
                ""scope"": ""https://www.googleapis.com/auth/userinfo.email https://www.googleapis.com/auth/userinfo.profile""
            },
            access_token_url=""https://accounts.google.com/o/oauth2/token"",
            access_token_method=""POST"",
            consumer_key=settings.GOOGLE_CLIENT_ID,
            consumer_secret=settings.GOOGLE_CLIENT_SECRET,
        )

    return oauth.google


def get_user_profile(access_token):
    headers = {""Authorization"": ""OAuth {}"".format(access_token)}
    response = requests.get(
        ""https://www.googleapis.com/oauth2/v1/userinfo"", headers=headers
    )

    if response.status_code == 401:
        logger.warning(""Failed getting user profile (response code 401)."")
        return None

    return response.json()


def verify_profile(org, profile):
    if org.is_public:
        return True

    email = profile[""email""]
    domain = email.split(""@"")[-1]

    if domain in org.google_apps_domains:
        return True

    if org.has_user(email) == 1:
        return True

    return False


@blueprint.route(""/<org_slug>/oauth/google"", endpoint=""authorize_org"")
def org_login(org_slug):
    session[""org_slug""] = current_org.slug
    return redirect(url_for("".authorize"", next=request.args.get(""next"", None)))


@blueprint.route(""/oauth/google"", endpoint=""authorize"")
def login():
    callback = url_for("".callback"", _external=True)
    next_path = request.args.get(
        ""next"", url_for(""redash.index"", org_slug=session.get(""org_slug""))
    )
    logger.debug(""Callback url: %s"", callback)
    logger.debug(""Next is: %s"", next_path)
    return google_remote_app().authorize(callback=callback, state=next_path)


@blueprint.route(""/oauth/google_callback"", endpoint=""callback"")
def authorized():
    resp = google_remote_app().authorized_response()
    access_token = resp[""access_token""]

    if access_token is None:
        logger.warning(""Access token missing in call back request."")
        flash(""Validation error. Please retry."")
        return redirect(url_for(""redash.login""))

    profile = get_user_profile(access_token)
    if profile is None:
        flash(""Validation error. Please retry."")
        return redirect(url_for(""redash.login""))

    if ""org_slug"" in session:
        org = models.Organization.get_by_slug(session.pop(""org_slug""))
    else:
        org = current_org

    if not verify_profile(org, profile):
        logger.warning(
            ""User tried to login with unauthorized domain name: %s (org: %s)"",
            profile[""email""],
            org,
        )
        flash(""Your Google Apps account ({}) isn't allowed."".format(profile[""email""]))
        return redirect(url_for(""redash.login"", org_slug=org.slug))

    picture_url = ""%s?sz=40"" % profile[""picture""]
    user = create_and_login_user(org, profile[""name""], profile[""email""], picture_url)
    if user is None:
        return logout_and_redirect_to_index()

    unsafe_next_path = request.args.get(""state"") or url_for(
        ""redash.index"", org_slug=org.slug
    )
    next_path = get_next_path(unsafe_next_path)

    return redirect(next_path)
",CWE-601,125.0,1
"import logging
import yaml
import requests
import io

from redash import settings
from redash.query_runner import *
from redash.utils import json_dumps

logger = logging.getLogger(__name__)

try:
    import pandas as pd
    import numpy as np
    enabled = True
except ImportError:
    enabled = False


class CSV(BaseQueryRunner):
    should_annotate_query = False

    @classmethod
    def name(cls):
        return ""CSV""

    @classmethod
    def enabled(cls):
        return enabled

    @classmethod
    def configuration_schema(cls):
        return {
            'type': 'object',
            'properties': {},
        }

    def __init__(self, configuration):
        super(CSV, self).__init__(configuration)
        self.syntax = ""yaml""

    def test_connection(self):
        pass

    def run_query(self, query, user):
        path = """"
        ua = """"
        args = {}
        try:
            args = yaml.safe_load(query)
            path = args['url']
            args.pop('url', None)
            ua = args['user-agent']
            args.pop('user-agent', None)

            if is_private_address(path) and settings.ENFORCE_PRIVATE_ADDRESS_BLOCK:
                raise Exception(""Can't query private addresses."")
        except:
            pass

        try:
            response = requests.get(url=path, headers={""User-agent"": ua})
            workbook = pd.read_csv(io.BytesIO(response.content),sep="","", **args)

            df = workbook.copy()
            data = {'columns': [], 'rows': []}
            conversions = [
                {'pandas_type': np.integer, 'redash_type': 'integer',},
                {'pandas_type': np.inexact, 'redash_type': 'float',},
                {'pandas_type': np.datetime64, 'redash_type': 'datetime', 'to_redash': lambda x: x.strftime('%Y-%m-%d %H:%M:%S')},
                {'pandas_type': np.bool_, 'redash_type': 'boolean'},
                {'pandas_type': np.object, 'redash_type': 'string'}
            ]
            labels = []
            for dtype, label in zip(df.dtypes, df.columns):
                for conversion in conversions:
                    if issubclass(dtype.type, conversion['pandas_type']):
                        data['columns'].append({'name': label, 'friendly_name': label, 'type': conversion['redash_type']})
                        labels.append(label)
                        func = conversion.get('to_redash')
                        if func:
                            df[label] = df[label].apply(func)
                        break
            data['rows'] = df[labels].replace({np.nan: None}).to_dict(orient='records')

            json_data = json_dumps(data)
            error = None
        except KeyboardInterrupt:
            error = ""Query cancelled by user.""
            json_data = None
        except Exception as e:
            error = ""Error reading {0}. {1}"".format(path, str(e))
            json_data = None

        return json_data, error

    def get_schema(self):
        raise NotSupported()

register(CSV)
",CWE-918,101.0,1
"import logging
import yaml
import requests

from redash import settings
from redash.query_runner import *
from redash.utils import json_dumps

logger = logging.getLogger(__name__)

try:
    import pandas as pd
    import xlrd
    import openpyxl
    import numpy as np
    enabled = True
except ImportError:
    enabled = False

class Excel(BaseQueryRunner):
    should_annotate_query = False

    @classmethod
    def enabled(cls):
        return enabled

    @classmethod
    def configuration_schema(cls):
        return {
            'type': 'object',
            'properties': {},
        }

    def __init__(self, configuration):
        super(Excel, self).__init__(configuration)
        self.syntax = ""yaml""

    def test_connection(self):
        pass

    def run_query(self, query, user):
        path = """"
        ua = """"
        args = {}
        try:
            args = yaml.safe_load(query)
            path = args['url']
            args.pop('url', None)
            ua = args['user-agent']
            args.pop('user-agent', None)

            if is_private_address(path) and settings.ENFORCE_PRIVATE_ADDRESS_BLOCK:
                raise Exception(""Can't query private addresses."")
        except:
            pass

        try:
            response = requests.get(url=path, headers={""User-agent"": ua})
            workbook = pd.read_excel(response.content, **args)

            df = workbook.copy()
            data = {'columns': [], 'rows': []}
            conversions = [
                {'pandas_type': np.integer, 'redash_type': 'integer',},
                {'pandas_type': np.inexact, 'redash_type': 'float',},
                {'pandas_type': np.datetime64, 'redash_type': 'datetime', 'to_redash': lambda x: x.strftime('%Y-%m-%d %H:%M:%S')},
                {'pandas_type': np.bool_, 'redash_type': 'boolean'},
                {'pandas_type': np.object, 'redash_type': 'string'}
            ]
            labels = []
            for dtype, label in zip(df.dtypes, df.columns):
                for conversion in conversions:
                    if issubclass(dtype.type, conversion['pandas_type']):
                        data['columns'].append({'name': label, 'friendly_name': label, 'type': conversion['redash_type']})
                        labels.append(label)
                        func = conversion.get('to_redash')
                        if func:
                            df[label] = df[label].apply(func)
                        break
            data['rows'] = df[labels].replace({np.nan: None}).to_dict(orient='records')

            json_data = json_dumps(data)
            error = None
        except KeyboardInterrupt:
            error = ""Query cancelled by user.""
            json_data = None
        except Exception as e:
            error = ""Error reading {0}. {1}"".format(path, str(e))
            json_data = None

        return json_data, error

    def get_schema(self):
        raise NotSupported()

register(Excel)
",CWE-918,97.0,1
"import requests
from redash import settings


class ConfiguredSession(requests.Session):
    def request(self, *args, **kwargs):
        if not settings.REQUESTS_ALLOW_REDIRECTS:
            kwargs.update({""allow_redirects"": False})
        return super().request(*args, **kwargs)


requests_session = ConfiguredSession()
",CWE-918,13.0,1
"import mock
from unittest import TestCase

from redash.utils.requests_session import requests, ConfiguredSession
from redash.query_runner import BaseHTTPQueryRunner


class RequiresAuthQueryRunner(BaseHTTPQueryRunner):
    requires_authentication = True


class TestBaseHTTPQueryRunner(TestCase):
    def test_requires_authentication_default(self):
        self.assertFalse(BaseHTTPQueryRunner.requires_authentication)
        schema = BaseHTTPQueryRunner.configuration_schema()
        self.assertNotIn(""username"", schema[""required""])
        self.assertNotIn(""password"", schema[""required""])

    def test_requires_authentication_true(self):
        schema = RequiresAuthQueryRunner.configuration_schema()
        self.assertIn(""username"", schema[""required""])
        self.assertIn(""password"", schema[""required""])

    def test_get_auth_with_values(self):
        query_runner = BaseHTTPQueryRunner(
            {""username"": ""username"", ""password"": ""password""}
        )
        self.assertEqual(query_runner.get_auth(), (""username"", ""password""))

    def test_get_auth_empty(self):
        query_runner = BaseHTTPQueryRunner({})
        self.assertIsNone(query_runner.get_auth())

    def test_get_auth_empty_requires_authentication(self):
        query_runner = RequiresAuthQueryRunner({})
        self.assertRaisesRegex(
            ValueError, ""Username and Password required"", query_runner.get_auth
        )

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_success(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 200
        mock_response.text = ""Success""
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        response, error = query_runner.get_response(url)
        mock_get.assert_called_once_with(""get"", url, auth=None)
        self.assertEqual(response.status_code, 200)
        self.assertIsNone(error)

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_success_custom_auth(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 200
        mock_response.text = ""Success""
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        auth = (""username"", ""password"")
        response, error = query_runner.get_response(url, auth=auth)
        mock_get.assert_called_once_with(""get"", url, auth=auth)
        self.assertEqual(response.status_code, 200)
        self.assertIsNone(error)

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_failure(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 301
        mock_response.text = ""Redirect""
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        response, error = query_runner.get_response(url)
        mock_get.assert_called_once_with(""get"", url, auth=None)
        self.assertIn(query_runner.response_error, error)

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_httperror_exception(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 500
        mock_response.text = ""Server Error""
        http_error = requests.HTTPError()
        mock_response.raise_for_status.side_effect = http_error
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        response, error = query_runner.get_response(url)
        mock_get.assert_called_once_with(""get"", url, auth=None)
        self.assertIsNotNone(error)
        self.assertIn(""Failed to execute query"", error)

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_requests_exception(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 500
        mock_response.text = ""Server Error""
        exception_message = ""Some requests exception""
        requests_exception = requests.RequestException(exception_message)
        mock_response.raise_for_status.side_effect = requests_exception
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        response, error = query_runner.get_response(url)
        mock_get.assert_called_once_with(""get"", url, auth=None)
        self.assertIsNotNone(error)
        self.assertEqual(exception_message, error)

    @mock.patch.object(ConfiguredSession, ""request"")
    def test_get_response_generic_exception(self, mock_get):
        mock_response = mock.Mock()
        mock_response.status_code = 500
        mock_response.text = ""Server Error""
        exception_message = ""Some generic exception""
        exception = ValueError(exception_message)
        mock_response.raise_for_status.side_effect = exception
        mock_get.return_value = mock_response

        url = ""https://example.com/""
        query_runner = BaseHTTPQueryRunner({})
        self.assertRaisesRegex(
            ValueError, exception_message, query_runner.get_response, url
        )
",CWE-918,130.0,1
"<?php
#**************************************************************************
#  openSIS is a free student information system for public and non-public 
#  schools from Open Solutions for Education, Inc. web: www.os4ed.com
#
#  openSIS is  web-based, open source, and comes packed with features that 
#  include student demographic info, scheduling, grade book, attendance, 
#  report cards, eligibility, transcripts, parent portal, 
#  student portal and more.   
#
#  Visit the openSIS web site at http://www.opensis.com to learn more.
#  If you have question regarding this system or the license, please send 
#  an email to info@os4ed.com.
#
#  This program is released under the terms of the GNU General Public License as  
#  published by the Free Software Foundation, version 2 of the License. 
#  See license.txt.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#***************************************************************************************
include('../../RedirectModulesInc.php');
$menu['tools']['admin'] = array(
						
                               'tools/LogDetails.php'=>'Access Log',
			       'tools/DeleteLog.php'=>'Delete Log',
                               'tools/Rollover.php'=>'Rollover',
                               'tools/Backup.php'=>'Backup Database',
                               'tools/DataImport.php'=>'Data Import Utility',
                               'tools/GenerateApi.php'=>'API Token',
                                1=>'Reports',  
                               'tools/Reports.php?func=Basic'=>'At a Glance',
                               'tools/Reports.php?func=Ins_r'=>'Institute Reports',
//                               'tools/Reports.php?func=Ins_cf'=>'Institute Custom Field Reports',                                
    );
?>
",CWE-89,43.0,1
"<?php
#**************************************************************************
#  openSIS is a free student information system for public and non-public 
#  schools from Open Solutions for Education, Inc. web: www.os4ed.com
#
#  openSIS is  web-based, open source, and comes packed with features that 
#  include student demographic info, scheduling, grade book, attendance, 
#  report cards, eligibility, transcripts, parent portal, 
#  student portal and more.   
#
#  Visit the openSIS web site at http://www.opensis.com to learn more.
#  If you have question regarding this system or the license, please send 
#  an email to info@os4ed.com.
#
#  This program is released under the terms of the GNU General Public License as  
#  published by the Free Software Foundation, version 2 of the License. 
#  See license.txt.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#***************************************************************************************
include('../../RedirectModulesInc.php');
$menu['tools']['admin'] = array(
						
                               'tools/LogDetails.php'=>'Access Log',
			       'tools/DeleteLog.php'=>'Delete Log',
                               'tools/Rollover.php'=>'Rollover',
                               'tools/Backup.php'=>'Backup Database',
                               'tools/DataImport.php'=>'Data Import Utility',
                               'tools/GenerateApi.php'=>'API Token',
                                1=>'Reports',  
                               'tools/Reports.php?func=Basic'=>'At a Glance',
                               'tools/Reports.php?func=Ins_r'=>'Institute Reports',
//                               'tools/Reports.php?func=Ins_cf'=>'Institute Custom Field Reports',                                
    );
?>
",CWE-22,43.0,1
"# Features

[[feature]]
desc = ""pgJDBC allows Java programs to connect to a PostgreSQL database using standard, database independent Java code.""
path = ""/icons/java-icon.svg""

[[feature]]
desc = ""pgJDBC provides a reasonably complete implementation of the JDBC specification in addition to some PostgreSQL specific extensions.""
path = ""/icons/api-icon.svg""

[[feature]]
desc = ""The current development driver supports eleven server versions and three java environments.""
path = ""/icons/driver-icon.svg""

# Releases Info

[[info]]
date = ""24 August 2022""
url = ""/changelogs/2022-08-24-42.5.0-release/""
version = ""42.5.0""

[[info]]
date = ""17 August 2022""
url = ""/changelogs/2022-08-17-42.4.2-release/""
version = ""42.4.2""

[[info]]
date = ""03 August 2022""
url = ""/changelogs/2022-08-03-42.4.1-release/""
version = ""42.4.1""

[[info]]
date = ""09 JUne 2022""
url = ""/changelogs/2022-06-09-42.4.0-release/""
version = ""42.4.0""
",CWE-668,36.0,1
"#!/usr/bin/python3 -O

# freewvs - a free web vulnerability scanner
#
# https://freewvs.schokokeks.org/
#
# Written by schokokeks.org Hosting, https://schokokeks.org
#
# Contributions by
# Hanno Boeck, https://hboeck.de/
# Fabian Fingerle, https://fabian-fingerle.de/
# Bernd Wurst, https://bwurst.org/
#
# To the extent possible under law, the author(s) have dedicated all copyright
# and related and neighboring rights to this software to the public domain
# worldwide. This software is distributed without any warranty.
#
# You should have received a copy of the CC0 Public Domain Dedication along
# with this software. If not, see
# https://creativecommons.org/publicdomain/zero/1.0/
# Nevertheless, in case you use a significant part of this code, we ask (but
# not require, see the license) that you keep the authors' names in place and
# return your changes to the public. We would be especially happy if you tell
# us what you're going to do with this code.

import os
import glob
import re
import argparse
import sys
import json
import pathlib
from xml.sax.saxutils import escape  # noqa: DUO107


def versioncompare(safe_version, find_version):
    if safe_version == """":
        return True
    safe_version_tup = [int(x) for x in safe_version.split(""."")]
    find_version_tup = [int(x) for x in find_version.split(""."")]
    return find_version_tup < safe_version_tup


def vulnprint(appname, version, safeversion, vuln, vfilename, subdir,
              xml):
    appdir = '/'.join(os.path.abspath(vfilename).split('/')[:-1 - subdir])
    if not xml:
        print(""%(appname)s %(version)s (%(safeversion)s) %(vuln)s ""
              ""%(appdir)s"" % vars())
    else:
        state = 'vulnerable'
        if safeversion == 'ok':
            state = 'ok'
        print('  <app state=""%s"">' % state)
        print('    <appname>%s</appname>' % escape(appname))
        print('    <version>%s</version>' % escape(version))
        print('    <directory>%s</directory>' % escape(appdir))
        if state == 'vulnerable':
            print('    <safeversion>%s</safeversion>' % escape(safeversion))
            print('    <vulninfo>%s</vulninfo>' % escape(vuln))
        print('  </app>')


# Command-line options
parser = argparse.ArgumentParser()
parser.add_argument(""dirs"", nargs=""*"",
                    help=""Directories to scan"")
parser.add_argument(""-a"", ""--all"", action=""store_true"",
                    help=""Show all webapps found, not just vulnerable"")
parser.add_argument(""-x"", ""--xml"", action=""store_true"",
                    help=""Output results as XML"")
parser.add_argument(""-3"", ""--thirdparty"", action=""store_true"",
                    help=""Scan for third-party components like jquery"")
opts = parser.parse_args()

# Warn people with old-style freewvsdb dirs,
# should be removed in a few months
for d in [""/usr/share/freewvs"", ""/usr/local/share/freewvs""]:
    if os.path.isdir(d):
        print(""WARNING: Obsolete freewvs data in %s, removal recommended"" % d,
              file=sys.stderr)

jdir = False
for p in [os.path.dirname(sys.argv[0]) + '/freewvsdb', '/var/lib/freewvs',
          str(pathlib.Path.home()) + ""/.cache/freewvs/""]:
    if os.path.isdir(p):
        jdir = p
        break
if not jdir:
    print(""Can't find freewvs json db"")
    sys.exit(1)

jconfig = []
for cfile in glob.glob(jdir + '/*.json'):
    with open(cfile) as json_file:
        data = json.load(json_file)
        jconfig += data

scanfiles = set()
for app in jconfig:
    for det in app['detection']:
        scanfiles.add(det['file'])


if opts.xml:
    print('<?xml version=""1.0"" ?>')
    print('<freewvs>')

# start the search

for fdir in opts.dirs:
    for root, _, files in os.walk(fdir):
        for filename in scanfiles.intersection(files):
            for item in jconfig:
                if not opts.thirdparty and 'thirdparty' in item:
                    continue
                for det in item['detection']:
                    if filename == det['file']:
                        mfile = os.path.join(root, filename)
                        try:
                            file = open(mfile, errors='replace')
                        except IOError:
                            continue
                        filestr = file.read()
                        file.close()

                        if (('extra_match' in det
                             and det['extra_match'] not in filestr)
                                or ('extra_nomatch' in det
                                    and det['extra_nomatch'] in filestr)):
                            continue

                        if ('path_match' in det
                                and (not root.endswith(det['path_match']))):
                            continue

                        findversion = re.search(re.escape(det['variable'])
                                                + r""[^0-9\n\r]*[.]*""
                                                ""([0-9.]*[0-9])[^0-9.]"",
                                                filestr)
                        if not findversion:
                            continue
                        findversion = findversion.group(1)

                        # Very ugly phpbb workaround
                        if 'add_minor' in det:
                            findversion = findversion.split('.')
                            findversion[-1] = str(int(findversion[-1])
                                                  + int(det['add_minor']))
                            findversion = '.'.join(findversion)

                        if ((not versioncompare(item['safe'], findversion))
                                or ('old_safe' in item
                                    and findversion in
                                    item['old_safe'].split(','))):
                            if opts.all:
                                vulnprint(item['name'], findversion, ""ok"", """",
                                          mfile, det['subdir'], opts.xml)
                            continue

                        safev = item['safe']
                        if 'old_safe' in item:
                            for ver in item['old_safe'].split(','):
                                if versioncompare(ver, findversion):
                                    safev = ver

                        vulnprint(item['name'], findversion, safev,
                                  item['vuln'], mfile, det['subdir'], opts.xml)

if opts.xml:
    print('</freewvs>')
",CWE-674,172.0,1
"#!/usr/bin/python3 -O

# freewvs - a free web vulnerability scanner
#
# https://freewvs.schokokeks.org/
#
# Written by schokokeks.org Hosting, https://schokokeks.org
#
# Contributions by
# Hanno Boeck, https://hboeck.de/
# Fabian Fingerle, https://fabian-fingerle.de/
# Bernd Wurst, https://bwurst.org/
#
# To the extent possible under law, the author(s) have dedicated all copyright
# and related and neighboring rights to this software to the public domain
# worldwide. This software is distributed without any warranty.
#
# You should have received a copy of the CC0 Public Domain Dedication along
# with this software. If not, see
# https://creativecommons.org/publicdomain/zero/1.0/
# Nevertheless, in case you use a significant part of this code, we ask (but
# not require, see the license) that you keep the authors' names in place and
# return your changes to the public. We would be especially happy if you tell
# us what you're going to do with this code.

import os
import glob
import re
import argparse
import sys
import json
import pathlib
from xml.sax.saxutils import escape  # noqa: DUO107


def versioncompare(safe_version, find_version):
    if safe_version == """":
        return True
    safe_version_tup = [int(x) for x in safe_version.split(""."")]
    find_version_tup = [int(x) for x in find_version.split(""."")]
    return find_version_tup < safe_version_tup


def vulnprint(appname, version, safeversion, vuln, vfilename, subdir,
              xml):
    appdir = '/'.join(os.path.abspath(vfilename).split('/')[:-1 - subdir])
    if not xml:
        print(""%(appname)s %(version)s (%(safeversion)s) %(vuln)s ""
              ""%(appdir)s"" % vars())
    else:
        state = 'vulnerable'
        if safeversion == 'ok':
            state = 'ok'
        print('  <app state=""%s"">' % state)
        print('    <appname>%s</appname>' % escape(appname))
        print('    <version>%s</version>' % escape(version))
        print('    <directory>%s</directory>' % escape(appdir))
        if state == 'vulnerable':
            print('    <safeversion>%s</safeversion>' % escape(safeversion))
            print('    <vulninfo>%s</vulninfo>' % escape(vuln))
        print('  </app>')


# Command-line options
parser = argparse.ArgumentParser()
parser.add_argument(""dirs"", nargs=""*"",
                    help=""Directories to scan"")
parser.add_argument(""-a"", ""--all"", action=""store_true"",
                    help=""Show all webapps found, not just vulnerable"")
parser.add_argument(""-x"", ""--xml"", action=""store_true"",
                    help=""Output results as XML"")
parser.add_argument(""-3"", ""--thirdparty"", action=""store_true"",
                    help=""Scan for third-party components like jquery"")
opts = parser.parse_args()

# Warn people with old-style freewvsdb dirs,
# should be removed in a few months
for d in [""/usr/share/freewvs"", ""/usr/local/share/freewvs""]:
    if os.path.isdir(d):
        print(""WARNING: Obsolete freewvs data in %s, removal recommended"" % d,
              file=sys.stderr)

jdir = False
for p in [os.path.dirname(sys.argv[0]) + '/freewvsdb', '/var/lib/freewvs',
          str(pathlib.Path.home()) + ""/.cache/freewvs/""]:
    if os.path.isdir(p):
        jdir = p
        break
if not jdir:
    print(""Can't find freewvs json db"")
    sys.exit(1)

jconfig = []
for cfile in glob.glob(jdir + '/*.json'):
    with open(cfile) as json_file:
        data = json.load(json_file)
        jconfig += data

scanfiles = set()
for app in jconfig:
    for det in app['detection']:
        scanfiles.add(det['file'])


if opts.xml:
    print('<?xml version=""1.0"" ?>')
    print('<freewvs>')

# start the search

for fdir in opts.dirs:
    for root, dirs, files in os.walk(fdir):
        # this protects us against nested directories causing
        # an exception
        if root.count(os.sep) > 500:
            del dirs[:]
        for filename in scanfiles.intersection(files):
            for item in jconfig:
                if not opts.thirdparty and 'thirdparty' in item:
                    continue
                for det in item['detection']:
                    if filename == det['file']:
                        mfile = os.path.join(root, filename)
                        try:
                            file = open(mfile, errors='replace')
                        except OSError:
                            continue
                        filestr = file.read()
                        file.close()

                        if (('extra_match' in det
                             and det['extra_match'] not in filestr)
                                or ('extra_nomatch' in det
                                    and det['extra_nomatch'] in filestr)):
                            continue

                        if ('path_match' in det
                                and (not root.endswith(det['path_match']))):
                            continue

                        findversion = re.search(re.escape(det['variable'])
                                                + r""[^0-9\n\r]*[.]*""
                                                ""([0-9.]*[0-9])[^0-9.]"",
                                                filestr)
                        if not findversion:
                            continue
                        findversion = findversion.group(1)

                        # Very ugly phpbb workaround
                        if 'add_minor' in det:
                            findversion = findversion.split('.')
                            findversion[-1] = str(int(findversion[-1])
                                                  + int(det['add_minor']))
                            findversion = '.'.join(findversion)

                        if ((not versioncompare(item['safe'], findversion))
                                or ('old_safe' in item
                                    and findversion in
                                    item['old_safe'].split(','))):
                            if opts.all:
                                vulnprint(item['name'], findversion, ""ok"", """",
                                          mfile, det['subdir'], opts.xml)
                            continue

                        safev = item['safe']
                        if 'old_safe' in item:
                            for ver in item['old_safe'].split(','):
                                if versioncompare(ver, findversion):
                                    safev = ver

                        vulnprint(item['name'], findversion, safev,
                                  item['vuln'], mfile, det['subdir'], opts.xml)

if opts.xml:
    print('</freewvs>')
",CWE-770,176.0,1
""""""" Regenerate golden-master """"""
import shutil
from pathlib import Path

from typer.testing import CliRunner

from openapi_python_client.cli import app

if __name__ == ""__main__"":
    from .fastapi_app import generate_openapi_json

    generate_openapi_json()
    runner = CliRunner()
    openapi_path = Path(__file__).parent / ""fastapi_app"" / ""openapi.json""
    gm_path = Path(__file__).parent / ""golden-master""
    shutil.rmtree(gm_path, ignore_errors=True)
    output_path = Path.cwd() / ""my-test-api-client""
    shutil.rmtree(output_path, ignore_errors=True)
    config_path = Path(__file__).parent / ""config.yml""

    result = runner.invoke(app, [f""--config={config_path}"", ""generate"", f""--path={openapi_path}""])
    if result.stdout:
        print(result.stdout)
    if result.exception:
        raise result.exception
    output_path.rename(gm_path)
",CWE-22,27.0,1
"import pytest
from jinja2 import Environment, PackageLoader


@pytest.fixture(scope=""session"")
def env() -> Environment:
    from openapi_python_client import utils

    TEMPLATE_FILTERS = {""snakecase"": utils.snake_case, ""spinalcase"": utils.spinal_case}
    env = Environment(loader=PackageLoader(""openapi_python_client""), trim_blocks=True, lstrip_blocks=True)
    env.filters.update(TEMPLATE_FILTERS)
    return env
",CWE-22,13.0,1
"from openapi_python_client import utils


def test_snake_case_uppercase_str():
    assert utils.snake_case(""HTTP"") == ""http""
    assert utils.snake_case(""HTTP RESPONSE"") == ""http_response""


def test_snake_case_from_pascal_with_acronyms():
    assert utils.snake_case(""HTTPResponse"") == ""http_response""
    assert utils.snake_case(""APIClientHTTPResponse"") == ""api_client_http_response""
    assert utils.snake_case(""OAuthClientHTTPResponse"") == ""o_auth_client_http_response""


def test_snake_case_from_pascal():
    assert utils.snake_case(""HttpResponsePascalCase"") == ""http_response_pascal_case""


def test_snake_case_from_camel():
    assert utils.snake_case(""httpResponseLowerCamel"") == ""http_response_lower_camel""


def test_spinal_case():
    assert utils.spinal_case(""keep_alive"") == ""keep-alive""
",CWE-22,25.0,1
""""""" A FastAPI app used to create an OpenAPI document for end-to-end testing """"""
import json
from datetime import date, datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Union

from fastapi import APIRouter, FastAPI, File, Header, Query, UploadFile
from pydantic import BaseModel

app = FastAPI(title=""My Test API"", description=""An API for testing openapi-python-client"",)


@app.get(""/ping"", response_model=bool)
async def ping():
    """""" A quick check to see if the system is running """"""
    return True


test_router = APIRouter()


class AnEnum(Enum):
    """""" For testing Enums in all the ways they can be used """"""

    FIRST_VALUE = ""FIRST_VALUE""
    SECOND_VALUE = ""SECOND_VALUE""


class DifferentEnum(Enum):
    FIRST_VALUE = ""DIFFERENT""
    SECOND_VALUE = ""OTHER""


class OtherModel(BaseModel):
    """""" A different model for calling from TestModel """"""

    a_value: str


class AModel(BaseModel):
    """""" A Model for testing all the ways custom objects can be used """"""

    an_enum_value: AnEnum
    nested_list_of_enums: List[List[DifferentEnum]] = []
    some_dict: Dict[str, str] = {}
    aCamelDateTime: Union[datetime, date]
    a_date: date


@test_router.get(""/"", response_model=List[AModel], operation_id=""getUserList"")
def get_list(an_enum_value: List[AnEnum] = Query(...), some_date: Union[date, datetime] = Query(...)):
    """""" Get a list of things """"""
    return


@test_router.post(""/upload"")
async def upload_file(some_file: UploadFile = File(...), keep_alive: bool = Header(None)):
    """""" Upload a file """"""
    data = await some_file.read()
    return (some_file.filename, some_file.content_type, data)


@test_router.post(""/json_body"")
def json_body(body: AModel):
    """""" Try sending a JSON body """"""
    return


app.include_router(test_router, prefix=""/tests"", tags=[""tests""])


def generate_openapi_json():
    path = Path(__file__).parent / ""openapi.json""
    path.write_text(json.dumps(app.openapi(), indent=4))


if __name__ == ""__main__"":
    generate_openapi_json()
",CWE-94,80.0,1
"from dataclasses import asdict
from datetime import date, datetime
from typing import Any, Dict, List, Optional, Union, cast

import httpx

from ..client import AuthenticatedClient, Client
from ..errors import ApiResponseError
from ..models.a_model import AModel
from ..models.an_enum import AnEnum
from ..models.body_upload_file_tests_upload_post import BodyUploadFileTestsUploadPost
from ..models.http_validation_error import HTTPValidationError


def get_user_list(
    *, client: Client, an_enum_value: List[AnEnum], some_date: Union[date, datetime],
) -> Union[
    List[AModel], HTTPValidationError,
]:

    """""" Get a list of things  """"""
    url = ""{}/tests/"".format(client.base_url)

    headers: Dict[str, Any] = client.get_headers()

    json_an_enum_value = []
    for an_enum_value_item_data in an_enum_value:
        an_enum_value_item = an_enum_value_item_data.value

        json_an_enum_value.append(an_enum_value_item)

    if isinstance(some_date, date):
        json_some_date = some_date.isoformat()

    else:
        json_some_date = some_date.isoformat()

    params: Dict[str, Any] = {
        ""an_enum_value"": json_an_enum_value,
        ""some_date"": json_some_date,
    }

    response = httpx.get(url=url, headers=headers, params=params,)

    if response.status_code == 200:
        return [AModel.from_dict(item) for item in cast(List[Dict[str, Any]], response.json())]
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)


def upload_file_tests_upload_post(
    *, client: Client, multipart_data: BodyUploadFileTestsUploadPost, keep_alive: Optional[bool] = None,
) -> Union[
    None, HTTPValidationError,
]:

    """""" Upload a file  """"""
    url = ""{}/tests/upload"".format(client.base_url)

    headers: Dict[str, Any] = client.get_headers()
    if keep_alive is not None:
        headers[""keep-alive""] = keep_alive

    response = httpx.post(url=url, headers=headers, files=multipart_data.to_dict(),)

    if response.status_code == 200:
        return None
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)


def json_body_tests_json_body_post(
    *, client: Client, json_body: AModel,
) -> Union[
    None, HTTPValidationError,
]:

    """""" Try sending a JSON body  """"""
    url = ""{}/tests/json_body"".format(client.base_url)

    headers: Dict[str, Any] = client.get_headers()

    json_json_body = json_body.to_dict()

    response = httpx.post(url=url, headers=headers, json=json_json_body,)

    if response.status_code == 200:
        return None
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)
",CWE-94,97.0,1
"from dataclasses import asdict
from datetime import date, datetime
from typing import Any, Dict, List, Optional, Union, cast

import httpx

from ..client import AuthenticatedClient, Client
from ..errors import ApiResponseError
from ..models.a_model import AModel
from ..models.an_enum import AnEnum
from ..models.body_upload_file_tests_upload_post import BodyUploadFileTestsUploadPost
from ..models.http_validation_error import HTTPValidationError


async def get_user_list(
    *, client: Client, an_enum_value: List[AnEnum], some_date: Union[date, datetime],
) -> Union[
    List[AModel], HTTPValidationError,
]:

    """""" Get a list of things  """"""
    url = ""{}/tests/"".format(client.base_url,)

    headers: Dict[str, Any] = client.get_headers()

    json_an_enum_value = []
    for an_enum_value_item_data in an_enum_value:
        an_enum_value_item = an_enum_value_item_data.value

        json_an_enum_value.append(an_enum_value_item)

    if isinstance(some_date, date):
        json_some_date = some_date.isoformat()

    else:
        json_some_date = some_date.isoformat()

    params: Dict[str, Any] = {
        ""an_enum_value"": json_an_enum_value,
        ""some_date"": json_some_date,
    }

    async with httpx.AsyncClient() as _client:
        response = await _client.get(url=url, headers=headers, params=params,)

    if response.status_code == 200:
        return [AModel.from_dict(item) for item in cast(List[Dict[str, Any]], response.json())]
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)


async def upload_file_tests_upload_post(
    *, client: Client, multipart_data: BodyUploadFileTestsUploadPost, keep_alive: Optional[bool] = None,
) -> Union[
    None, HTTPValidationError,
]:

    """""" Upload a file  """"""
    url = ""{}/tests/upload"".format(client.base_url,)

    headers: Dict[str, Any] = client.get_headers()
    if keep_alive is not None:
        headers[""keep-alive""] = keep_alive

    async with httpx.AsyncClient() as _client:
        response = await _client.post(url=url, headers=headers, files=multipart_data.to_dict(),)

    if response.status_code == 200:
        return None
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)


async def json_body_tests_json_body_post(
    *, client: Client, json_body: AModel,
) -> Union[
    None, HTTPValidationError,
]:

    """""" Try sending a JSON body  """"""
    url = ""{}/tests/json_body"".format(client.base_url,)

    headers: Dict[str, Any] = client.get_headers()

    json_json_body = json_body.to_dict()

    async with httpx.AsyncClient() as _client:
        response = await _client.post(url=url, headers=headers, json=json_json_body,)

    if response.status_code == 200:
        return None
    if response.status_code == 422:
        return HTTPValidationError.from_dict(cast(Dict[str, Any], response.json()))
    else:
        raise ApiResponseError(response=response)
",CWE-94,100.0,1
"from __future__ import annotations

from dataclasses import dataclass, field
from datetime import date, datetime
from typing import Any, Dict, List, Optional, Union, cast

from .an_enum import AnEnum
from .different_enum import DifferentEnum


@dataclass
class AModel:
    """""" A Model for testing all the ways custom objects can be used  """"""

    an_enum_value: AnEnum
    a_camel_date_time: Union[datetime, date]
    a_date: date
    nested_list_of_enums: Optional[List[List[DifferentEnum]]] = field(
        default_factory=lambda: cast(Optional[List[List[DifferentEnum]]], [])
    )
    some_dict: Optional[Dict[Any, Any]] = field(default_factory=lambda: cast(Optional[Dict[Any, Any]], {}))

    def to_dict(self) -> Dict[str, Any]:
        an_enum_value = self.an_enum_value.value

        if isinstance(self.a_camel_date_time, datetime):
            a_camel_date_time = self.a_camel_date_time.isoformat()

        else:
            a_camel_date_time = self.a_camel_date_time.isoformat()

        a_date = self.a_date.isoformat()

        if self.nested_list_of_enums is None:
            nested_list_of_enums = None
        else:
            nested_list_of_enums = []
            for nested_list_of_enums_item_data in self.nested_list_of_enums:
                nested_list_of_enums_item = []
                for nested_list_of_enums_item_item_data in nested_list_of_enums_item_data:
                    nested_list_of_enums_item_item = nested_list_of_enums_item_item_data.value

                    nested_list_of_enums_item.append(nested_list_of_enums_item_item)

                nested_list_of_enums.append(nested_list_of_enums_item)

        some_dict = self.some_dict

        return {
            ""an_enum_value"": an_enum_value,
            ""aCamelDateTime"": a_camel_date_time,
            ""a_date"": a_date,
            ""nested_list_of_enums"": nested_list_of_enums,
            ""some_dict"": some_dict,
        }

    @staticmethod
    def from_dict(d: Dict[str, Any]) -> AModel:
        an_enum_value = AnEnum(d[""an_enum_value""])

        def _parse_a_camel_date_time(data: Dict[str, Any]) -> Union[datetime, date]:
            a_camel_date_time: Union[datetime, date]
            try:
                a_camel_date_time = datetime.fromisoformat(d[""aCamelDateTime""])

                return a_camel_date_time
            except:
                pass
            a_camel_date_time = date.fromisoformat(d[""aCamelDateTime""])

            return a_camel_date_time

        a_camel_date_time = _parse_a_camel_date_time(d[""aCamelDateTime""])

        a_date = date.fromisoformat(d[""a_date""])

        nested_list_of_enums = []
        for nested_list_of_enums_item_data in d.get(""nested_list_of_enums"") or []:
            nested_list_of_enums_item = []
            for nested_list_of_enums_item_item_data in nested_list_of_enums_item_data:
                nested_list_of_enums_item_item = DifferentEnum(nested_list_of_enums_item_item_data)

                nested_list_of_enums_item.append(nested_list_of_enums_item_item)

            nested_list_of_enums.append(nested_list_of_enums_item)

        some_dict = d.get(""some_dict"")

        return AModel(
            an_enum_value=an_enum_value,
            a_camel_date_time=a_camel_date_time,
            a_date=a_date,
            nested_list_of_enums=nested_list_of_enums,
            some_dict=some_dict,
        )
",CWE-94,96.0,1
"from dataclasses import dataclass
from enum import Enum
from typing import Optional

__all__ = [""GeneratorError"", ""ParseError"", ""PropertyError""]

from pydantic import BaseModel


class ErrorLevel(Enum):
    """""" The level of an error """"""

    WARNING = ""WARNING""  # Client is still generated but missing some pieces
    ERROR = ""ERROR""  # Client could not be generated


@dataclass
class GeneratorError:
    """""" Base data struct containing info on an error that occurred """"""

    detail: Optional[str] = None
    level: ErrorLevel = ErrorLevel.ERROR
    header: str = ""Unable to generate the client""


@dataclass
class ParseError(GeneratorError):
    """""" An error raised when there's a problem parsing an OpenAPI document """"""

    level: ErrorLevel = ErrorLevel.WARNING
    data: Optional[BaseModel] = None
    header: str = ""Unable to parse this part of your OpenAPI document: ""


@dataclass
class PropertyError(ParseError):
    """""" Error raised when there's a problem creating a Property """"""

    header = ""Problem creating a Property: ""
",CWE-94,40.0,1
"import re

import stringcase


def _sanitize(value: str) -> str:
    return re.sub(r""[^\w _-]+"", """", value)


def group_title(value: str) -> str:
    value = re.sub(r""([A-Z]{2,})([A-Z][a-z]|[ -_]|$)"", lambda m: m.group(1).title() + m.group(2), value.strip())
    value = re.sub(r""(^|[ _-])([A-Z])"", lambda m: m.group(1) + m.group(2).lower(), value)
    return value


def snake_case(value: str) -> str:
    return stringcase.snakecase(group_title(_sanitize(value)))


def pascal_case(value: str) -> str:
    return stringcase.pascalcase(_sanitize(value))


def kebab_case(value: str) -> str:
    return stringcase.spinalcase(group_title(_sanitize(value)))
",CWE-94,26.0,1
"from openapi_python_client import utils


def test_snake_case_uppercase_str():
    assert utils.snake_case(""HTTP"") == ""http""
    assert utils.snake_case(""HTTP RESPONSE"") == ""http_response""


def test_snake_case_from_pascal_with_acronyms():
    assert utils.snake_case(""HTTPResponse"") == ""http_response""
    assert utils.snake_case(""APIClientHTTPResponse"") == ""api_client_http_response""
    assert utils.snake_case(""OAuthClientHTTPResponse"") == ""o_auth_client_http_response""


def test_snake_case_from_pascal():
    assert utils.snake_case(""HttpResponsePascalCase"") == ""http_response_pascal_case""


def test_snake_case_from_camel():
    assert utils.snake_case(""httpResponseLowerCamel"") == ""http_response_lower_camel""


def test_kebab_case():
    assert utils.kebab_case(""keep_alive"") == ""keep-alive""
",CWE-94,25.0,1
"# flake8: noqa
import pkgutil

from .filters import *
from .filterset import FilterSet

# We make the `rest_framework` module available without an additional import.
#   If DRF is not installed, no-op.
if pkgutil.find_loader('rest_framework') is not None:
    from . import rest_framework
del pkgutil

__version__ = '2.3.0'


def parse_version(version):
    '''
    '0.1.2.dev1' -> (0, 1, 2, 'dev1')
    '0.1.2' -> (0, 1, 2)
    '''
    v = version.split('.')
    ret = []
    for p in v:
        if p.isdigit():
            ret.append(int(p))
        else:
            ret.append(p)
    return tuple(ret)

VERSION = parse_version(__version__)
",CWE-681,31.0,1
"import os
import sys
from setuptools import setup, find_packages

f = open('README.rst')
readme = f.read()
f.close()

version = '2.3.0'

if sys.argv[-1] == 'publish':
    if os.system(""pip freeze | grep wheel""):
        print(""wheel not installed.\nUse `pip install wheel`.\nExiting."")
        sys.exit()
    if os.system(""pip freeze | grep twine""):
        print(""twine not installed.\nUse `pip install twine`.\nExiting."")
        sys.exit()
    os.system(""python setup.py sdist bdist_wheel"")
    os.system(""twine upload dist/*"")
    print(""You probably want to also tag the version now:"")
    print(""  git tag -a %s -m 'version %s'"" % (version, version))
    print(""  git push --tags"")
    sys.exit()

setup(
    name='django-filter',
    version=version,
    description=('Django-filter is a reusable Django application for allowing'
                 ' users to filter querysets dynamically.'),
    long_description=readme,
    author='Alex Gaynor',
    author_email='alex.gaynor@gmail.com',
    maintainer='Carlton Gibson',
    maintainer_email='carlton.gibson@noumenal.es',
    url='https://github.com/carltongibson/django-filter/tree/master',
    packages=find_packages(exclude=['tests*']),
    include_package_data=True,
    license='BSD',
    classifiers=[
        'Development Status :: 5 - Production/Stable',
        'Environment :: Web Environment',
        'Intended Audience :: Developers',
        'License :: OSI Approved :: BSD License',
        'Operating System :: OS Independent',
        'Framework :: Django',
        'Framework :: Django :: 2.2',
        'Framework :: Django :: 3.0',
        'Framework :: Django :: 3.1',
        'Programming Language :: Python',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.5',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
        'Framework :: Django',
    ],
    zip_safe=False,
    python_requires='>=3.5',
    install_requires=[
        'Django>=2.2',
    ],
)
",CWE-681,64.0,1
"import re
import time

import pyotp
from django.contrib.auth import authenticate, get_user_model, password_validation
from rest_framework import serializers
from rest_framework.authtoken.models import Token
from rest_framework.status import HTTP_401_UNAUTHORIZED, HTTP_400_BAD_REQUEST, HTTP_403_FORBIDDEN

from authentication.providers import LoginProvider, TokenProvider, RegistrationProvider
from authentication.models import InviteCode
from backend.exceptions import FormattedException
from backend.mail import send_email
from backend.signals import login_reject, login, register_reject, register
from config import config
from member.models import TOTPStatus


class BasicAuthRegistrationProvider(RegistrationProvider):
    name = 'basic_auth'

    def register_user(self, username, email, password, invite, **kwargs):
        if config.get('email_regex') and not re.compile(config.get('email_regex')).match(email) or \
                not email.endswith(config.get('email_domain')):
            raise FormattedException(m='invalid_email', status_code=HTTP_400_BAD_REQUEST)
        register_end_time = config.get('register_end_time')
        if not (config.get('enable_registration') and time.time() >= config.get('register_start_time')) \
                and (register_end_time < 0 or register_end_time > time.time()):
            register_reject.send(sender=self.__class__, username=username, email=email)
            raise FormattedException(m='registration_not_open', status_code=HTTP_403_FORBIDDEN)
        user = get_user_model()(
            username=username,
            email=email
        )
        if get_user_model().objects.filter(username=username) or get_user_model().objects.filter(email=email):
            raise FormattedException(m='email_or_username_in_use', status_code=HTTP_403_FORBIDDEN)
        if not get_user_model().objects.all().exists():
            user.is_staff = True
        password_validation.validate_password(password, user)
        user.set_password(password)
        if config.get(""invite_required""):
            if InviteCode.objects.filter(code=invite):
                code = InviteCode.objects.get(code=invite)
                if code:
                    if code.uses >= code.max_uses:
                        raise FormattedException(m=""invite_already_used"", status_code=HTTP_403_FORBIDDEN)
                code.uses += 1
                if code.uses >= code.max_uses:
                    code.fully_used = True
                code.save()
                if code.auto_team:
                    user.team = code.auto_team
            else:
                raise FormattedException(m=""invalid_invite"", status_code=HTTP_403_FORBIDDEN)

        token = user.email_token
        user.save()
        send_email(user.email, 'RACTF - Verify your email', 'verify',
                   url='verify?id={}&secret={}'.format(user.id, token))
        register.send(sender=self.__class__, user=user)
        return user


class BasicAuthLoginProvider(LoginProvider):
    name = 'basic_auth'

    #TODO: These fields don't do anything yet, but they will eventually correlate to the kwargs in login_user
    username = serializers.CharField(max_length=50)
    password = serializers.CharField(max_length=50)
    otp = serializers.CharField(max_length=6)

    def login_user(self, username, password, otp, context, **kwargs):
        user = authenticate(request=context.get('request'),
                            username=username, password=password)
        if not user:
            login_reject.send(sender=self.__class__, username=username, reason='creds')
            raise FormattedException(m='incorrect_username_or_password', d={'reason': 'incorrect_username_or_password'},
                                     status_code=HTTP_401_UNAUTHORIZED)

        if not user.email_verified and not user.is_superuser:
            login_reject.send(sender=self.__class__, username=username, reason='email')
            raise FormattedException(m='email_verification_required', d={'reason': 'email_verification_required'},
                                     status_code=HTTP_401_UNAUTHORIZED)

        if not user.can_login():
            login_reject.send(sender=self.__class__, username=username, reason='closed')
            raise FormattedException(m='login_not_open', d={'reason': 'login_not_open'},
                                     status_code=HTTP_401_UNAUTHORIZED)

        if user.totp_status == TOTPStatus.ENABLED:
            if not otp or otp == '':
                login_reject.send(sender=self.__class__, username=username, reason='no_2fa')
                raise FormattedException(m='2fa_required', d={'reason': '2fa_required'},
                                         status_code=HTTP_401_UNAUTHORIZED)
            totp = pyotp.TOTP(user.totp_secret)
            if not totp.verify(otp, valid_window=1):
                login_reject.send(sender=self.__class__, username=username, reason='incorrect_2fa')
                raise FormattedException(m='incorrect_2fa', d={'reason': 'incorrect_2fa'},
                                         status_code=HTTP_401_UNAUTHORIZED)
        login.send(sender=self.__class__, user=user)
        return user


class BasicAuthTokenProvider(TokenProvider):
    name = 'basic_auth'

    def issue_token(self, user, **kwargs):
        token, created = Token.objects.get_or_create(user=user)
        return token.key
",CWE-287,110.0,1
,CWE-287,,1
"from datetime import timedelta

from django.contrib.auth import get_user_model
from django.db import models
from django.utils import timezone

from team.models import Team


class InviteCode(models.Model):
    code = models.CharField(max_length=64, unique=True)
    uses = models.IntegerField(default=0)
    max_uses = models.IntegerField()
    fully_used = models.BooleanField(default=False)
    auto_team = models.ForeignKey(Team, on_delete=models.CASCADE, null=True)


def one_day():
    return timezone.now() + timedelta(days=1)


class PasswordResetToken(models.Model):
    user = models.ForeignKey(get_user_model(), on_delete=models.CASCADE)
    token = models.CharField(max_length=64)
    issued = models.DateTimeField(default=timezone.now)
    expires = models.DateTimeField(default=one_day)
",CWE-287,27.0,1
"from django.contrib.auth import get_user_model, password_validation
from django.utils import timezone
from rest_framework import serializers
from rest_framework.generics import get_object_or_404
from rest_framework.status import HTTP_403_FORBIDDEN, HTTP_401_UNAUTHORIZED

from authentication.models import InviteCode, PasswordResetToken
from backend.exceptions import FormattedException
from plugins import providers


class LoginSerializer(serializers.Serializer):
    username = serializers.CharField()
    password = serializers.CharField(trim_whitespace=False)
    otp = serializers.CharField(max_length=6, allow_null=True, allow_blank=True)

    def validate(self, data):
        user = providers.get_provider('login').login_user(**data, context=self.context)
        if user is not None:
            data['user'] = user
        return data


class RegistrationSerializer(serializers.Serializer):
    username = serializers.CharField()
    password = serializers.CharField(trim_whitespace=False)
    email = serializers.EmailField()
    invite = serializers.CharField(max_length=64, required=False, default=None)

    def create(self, validated_data):
        return providers.get_provider('registration').register_user(**validated_data, context=self.context)

    def to_representation(self, instance):
        representation = super(RegistrationSerializer, self).to_representation(instance)
        representation.pop('password')
        return representation


class PasswordResetSerializer(serializers.Serializer):
    uid = serializers.IntegerField()
    token = serializers.CharField(max_length=64)
    password = serializers.CharField()

    def validate(self, data):
        uid = data.get('uid')
        token = data.get('token')
        password = data.get('password')
        user = get_object_or_404(get_user_model(), id=uid)
        reset_token = get_object_or_404(PasswordResetToken, token=token, user_id=uid, expires__lt=timezone.now())
        password_validation.validate_password(password, reset_token)
        data['user'] = user
        data['reset_token'] = reset_token
        return data


class EmailVerificationSerializer(serializers.Serializer):
    uid = serializers.IntegerField()
    token = serializers.CharField(max_length=64)

    def validate(self, data):
        uid = int(data.get('uid'))
        token = data.get('token')
        user = get_object_or_404(get_user_model(), id=uid, email_token=token)
        if user.email_verified:
            raise FormattedException(m='email_already_verified', status_code=HTTP_403_FORBIDDEN)
        data['user'] = user
        return data


class EmailSerializer(serializers.Serializer):
    email = serializers.EmailField()

    def validate(self, data):
        user = get_object_or_404(get_user_model(), email=data.get('email'))
        if user.email_verified:
            raise FormattedException(m='email_already_verified', status_code=HTTP_403_FORBIDDEN)
        data['user'] = user
        return data


class ChangePasswordSerializer(serializers.Serializer):
    password = serializers.CharField()

    def validate(self, data):
        user = self.context['request'].user
        password = data.get('password')
        old_password = data.get('old_password')
        if not user.check_password(old_password):
            raise FormattedException(status_code=HTTP_401_UNAUTHORIZED, m='invalid_password')
        password_validation.validate_password(password, user)
        return data


class GenerateInvitesSerializer(serializers.Serializer):
    amount = serializers.IntegerField(max_value=10000)
    max_uses = serializers.IntegerField(required=False, default=1)
    auto_team = serializers.IntegerField(required=False, default=None)


class InviteCodeSerializer(serializers.ModelSerializer):
    class Meta:
        model = InviteCode
        fields = ['id', 'code', 'uses', 'max_uses', 'auto_team']
",CWE-287,104.0,1
"from django.urls import path, include
from rest_framework.routers import DefaultRouter

from authentication import views

router = DefaultRouter()
router.register(r'', views.InviteViewSet, basename='invites')

urlpatterns = [
    path('login/', views.LoginView.as_view(), name='login'),
    path('register/', views.RegistrationView.as_view(), name='register'),
    path('add_2fa/', views.AddTwoFactorView.as_view(), name='add-2fa'),
    path('verify_2fa/', views.VerifyTwoFactorView.as_view(), name='verify-2fa'),
    path('remove_2fa/', views.VerifyTwoFactorView.as_view(), name='remove-2fa'),
    path('logout/', views.LogoutView.as_view(), name='logout'),
    path('request_password_reset/', views.RequestPasswordResetView.as_view(), name='request-password-reset'),
    path('password_reset/', views.DoPasswordResetView.as_view(), name='do-password-reset'),
    path('verify_email/', views.VerifyEmailView.as_view(), name='verify-email'),
    path('resend_email/', views.ResendEmailView.as_view(), name='resend-email'),
    path('change_password/', views.ChangePasswordView.as_view(), name='change-password'),
    path('generate_invites/', views.GenerateInvitesView.as_view(), name='generate-invites'),
    path('invites/', include(router.urls), name='invites')
]
",CWE-287,24.0,1
,CWE-287,,1
"import secrets
import time
from enum import IntEnum

from django.contrib.auth import get_user_model
from django.contrib.auth.models import AbstractUser, UserManager
from django.contrib.postgres.fields import CICharField
from django.db import models
from django.db.models import SET_NULL
from django.utils import timezone
from django.utils.translation import gettext_lazy as _
from rest_framework.authtoken.models import Token

from backend.validators import printable_name
from config import config


class TOTPStatus(IntEnum):
    DISABLED = 0
    VERIFYING = 1
    ENABLED = 2


class Member(AbstractUser):
    username_validator = printable_name

    username = CICharField(
        _(""username""),
        max_length=36,
        unique=True,
        help_text=_(
            ""Required. 36 characters or fewer. Letters, digits and @/./+/-/_ only.""
        ),
        validators=[username_validator],
        error_messages={""unique"": _(""A user with that username already exists.""),},
    )
    email = models.EmailField(_(""email address""), blank=True, unique=True)
    totp_secret = models.CharField(null=True, max_length=16)
    totp_status = models.IntegerField(
        choices=[(status, status.value) for status in TOTPStatus],
        default=TOTPStatus.DISABLED,
    )
    is_visible = models.BooleanField(default=False)
    bio = models.TextField(blank=True, max_length=400)
    discord = models.CharField(blank=True, max_length=36)
    discordid = models.CharField(blank=True, max_length=18)
    twitter = models.CharField(blank=True, max_length=36)
    reddit = models.CharField(blank=True, max_length=36)
    team = models.ForeignKey(
        ""team.Team"", on_delete=SET_NULL, null=True, related_name=""members""
    )
    email_verified = models.BooleanField(default=False)
    email_token = models.CharField(max_length=64, default=secrets.token_hex)
    password_reset_token = models.CharField(max_length=64, default=secrets.token_hex)
    points = models.IntegerField(default=0)
    leaderboard_points = models.IntegerField(default=0)
    last_score = models.DateTimeField(default=timezone.now)

    def __str__(self):
        return self.username

    def can_login(self):
        return (
            self.is_staff
            or config.get(""enable_prelogin"")
            or (config.get(""enable_login"") and config.get(""start_time"") <= time.time())
        )

    def issue_token(self):
        token, created = Token.objects.get_or_create(user=self)
        return token.key

    def is_2fa_enabled(self):
        return self.totp_status == TOTPStatus.ENABLED

    def should_deny_admin(self):
        return self.totp_status != TOTPStatus.ENABLED and config.get(
            ""enable_force_admin_2fa""
        )


class UserIP(models.Model):
    user = models.ForeignKey(get_user_model(), on_delete=SET_NULL, null=True)
    ip = models.CharField(max_length=255)
    seen = models.IntegerField(default=1)
    last_seen = models.DateTimeField(default=timezone.now)
    user_agent = models.CharField(max_length=255)

    @staticmethod
    def hook(request):
        if not request.user.is_authenticated:
            return
        ip = request.headers.get('x-forwarded-for')
        user_agent = request.headers.get('user-agent')
        qs = UserIP.objects.filter(user=request.user, ip=ip)
        if qs.exists():
            user_ip = qs.first()
            user_ip.seen += 1
            user_ip.last_seen = timezone.now()
            user_ip.user_agent = user_agent
            user_ip.save()
        else:
            UserIP(user=request.user, ip=ip, user_agent=user_agent).save()
",CWE-287,104.0,1
"import secrets

from django.contrib.auth import get_user_model
from rest_framework import serializers

from backend.mixins import IncorrectSolvesMixin
from challenge.serializers import SolveSerializer
from member.models import UserIP


class MemberSerializer(IncorrectSolvesMixin, serializers.ModelSerializer):
    solves = SolveSerializer(many=True, read_only=True)
    team_name = serializers.ReadOnlyField(source='team.name')
    incorrect_solves = serializers.SerializerMethodField()

    class Meta:
        model = get_user_model()
        fields = ['id', 'username', 'is_staff', 'bio', 'discord', 'discordid', 'twitter', 'reddit', 'team',
                  'points', 'is_visible', 'is_active', 'solves', 'team_name', 'leaderboard_points', 'date_joined',
                  'incorrect_solves']


class ListMemberSerializer(serializers.ModelSerializer):
    team_name = serializers.ReadOnlyField(source='team.name')

    class Meta:
        model = get_user_model()
        fields = ['id', 'username', 'team', 'team_name']


class AdminMemberSerializer(IncorrectSolvesMixin, serializers.ModelSerializer):
    solves = SolveSerializer(many=True, read_only=True)
    team_name = serializers.ReadOnlyField(source='team.name')
    incorrect_solves = serializers.SerializerMethodField()

    class Meta:
        model = get_user_model()
        fields = ['id', 'username', 'is_staff', 'bio', 'discord', 'discordid', 'twitter', 'reddit', 'team',
                  'points', 'is_visible', 'is_active', 'solves', 'team_name', 'email', 'email_verified',
                  'leaderboard_points', 'date_joined', 'incorrect_solves']


class MinimalMemberSerializer(serializers.ModelSerializer):
    team_name = serializers.ReadOnlyField(source='team.name')

    class Meta:
        model = get_user_model()
        fields = ['id', 'username', 'is_staff', 'bio', 'discord', 'discordid', 'twitter', 'reddit', 'team',
                  'points', 'is_visible', 'is_active', 'team_name', 'leaderboard_points', 'date_joined']


class SelfSerializer(IncorrectSolvesMixin, serializers.ModelSerializer):
    from team.serializers import MinimalTeamSerializer
    solves = SolveSerializer(many=True, read_only=True)
    team = MinimalTeamSerializer(read_only=True)
    team_name = serializers.ReadOnlyField(source='team.name')
    email = serializers.EmailField()
    incorrect_solves = serializers.SerializerMethodField()

    class Meta:
        model = get_user_model()
        fields = ['id', 'username', 'is_staff', 'bio', 'discord', 'discordid', 'twitter', 'reddit', 'team', 'email',
                  'totp_status', 'points', 'solves', 'team_name', 'leaderboard_points', 'date_joined',
                  'incorrect_solves']
        read_only_fields = ['id', 'is_staff', 'team', 'email', 'totp_status', 'points',
                            'leaderboard_points', 'date_joined', 'incorrect_solves']

    def validate_email(self, value):
        self.instance.password_reset_token = secrets.token_hex()
        self.instance.email_token = secrets.token_hex()
        self.instance.save()
        return value


class UserIPSerializer(serializers.ModelSerializer):
    class Meta:
        model = UserIP
        fields = ['user', 'ip', 'seen', 'last_seen', 'user_agent']",CWE-287,78.0,1
"import time
from pydoc import locate

from django.conf import settings

DEFAULT_CONFIG = {
    'config_version': 4,
    'flag_prefix': 'ractf',
    'graph_members': 10,
    'register_end_time': -1,
    'end_time': time.time() + 7 * 24 * 60 * 60,
    'start_time': time.time(),
    'register_start_time': time.time(),
    'team_size': -1,
    'email_regex': '',
    'email_domain': '',
    'login_provider': 'basic_auth',
    'registration_provider': 'basic_auth',
    'token_provider': 'basic_auth',
    'enable_bot_users': True,
    'enable_ctftime': True,
    'enable_flag_submission': True,
    'enable_flag_submission_after_competition': True,
    'enable_force_admin_2fa': False,
    'enable_track_incorrect_submissions': True,
    'enable_login': True,
    'enable_prelogin': True,
    'enable_maintenance_mode': False,
    'enable_registration': True,
    'enable_scoreboard': True,
    'enable_scoring': True,
    'enable_solve_broadcast': True,
    'enable_teams': True,
    'enable_team_join': True,
    'enable_view_challenges_after_competion': True,
    'enable_team_leave': False,
    'invite_required': False,
    'hide_scoreboard_at': -1,
    'setup_wizard_complete': False,
    'sensitive_fields': ['sensitive_fields', 'enable_force_admin_2fa']
}

backend = locate(settings.CONFIG['BACKEND'])()
backend.load(defaults=DEFAULT_CONFIG)


def get(key):
    return backend.get(key)


def set(key, value):
    backend.set(key, value)


def get_all():
    return backend.get_all()


def get_all_non_sensitive():
    sensitive = backend.get('sensitive_fields')
    config = backend.get_all()
    for field in sensitive:
        del config[field]
    return config


def set_bulk(values: dict):
    for key, value in values.items():
        set(key, value)


def add_plugin_config(name, config):
    DEFAULT_CONFIG[name] = config
",CWE-200,74.0,1
"from rest_framework.status import HTTP_400_BAD_REQUEST
from rest_framework.views import APIView

from backend.response import FormattedResponse
from config import config
from backend.permissions import AdminOrAnonymousReadOnly


class ConfigView(APIView):
    throttle_scope = ""config""
    permission_classes = (AdminOrAnonymousReadOnly,)

    def get(self, request, name=None):
        if name is None:
            if request.user.is_staff:
                return FormattedResponse(config.get_all())
            return FormattedResponse(config.get_all_non_sensitive())
        return FormattedResponse(config.get(name))

    def post(self, request, name):
        if ""value"" not in request.data:
            return FormattedResponse(status=HTTP_400_BAD_REQUEST)
        config.set(name, request.data.get(""value""))
        return FormattedResponse()

    def patch(self, request, name):
        if ""value"" not in request.data:
            return FormattedResponse(status=HTTP_400_BAD_REQUEST)
        if config.get(name) is not None and isinstance(config.get(name), list):
            config.set(""name"", config.get(name).append(request.data[""value""]))
            return FormattedResponse()
        config.set(name, request.data.get(""value""))
        return FormattedResponse()
",CWE-200,34.0,1
,CWE-22,,1
"from app import apfell, links, use_ssl
from sanic import response
from jinja2 import Environment, PackageLoader
from sanic_jwt.decorators import scoped, inject_user
from app.routes.routes import respect_pivot
import urllib.parse

env = Environment(loader=PackageLoader('app', 'templates'))


@apfell.route(""/apiui/command_help"")
@inject_user()
@scoped(['auth:user', 'auth:apitoken_user'], False)  # user or user-level api token are ok
async def apiui_command_help(request, user):
    template = env.get_template('apiui_command_help.html')
    if len(request.query_args) != 0:
        data = urllib.parse.unquote(request.query_args[0][1])
        print(data)
    else:
        data = """"
    if use_ssl:
        content = template.render(links=await respect_pivot(links, request), name=user['username'], http=""https"",
                                  ws=""wss"", config=user['ui_config'], view_utc_time=user['view_utc_time'], agent=data)
    else:
        content = template.render(links=await respect_pivot(links, request), name=user['username'], http=""http"",
                                  ws=""ws"", config=user['ui_config'], view_utc_time=user['view_utc_time'], agent=data)
    return response.html(content)

# add links to the routes in this file at the bottom
links['apiui_command_help'] = apfell.url_for('apiui_command_help')
",CWE-79,31.0,1
"# -----------------------------------------------------------------------------
#  Copyright (c) Jupyter Development Team
#
#  Distributed under the terms of the BSD License.  The full license is in
#  the file COPYING, distributed as part of this software.
# -----------------------------------------------------------------------------
import json

from tornado.log import access_log

from .prometheus.log_functions import prometheus_log_method


def log_request(handler):
    """"""log a bit more information about each request than tornado's default

    - move static file get success to debug-level (reduces noise)
    - get proxied IP instead of proxy IP
    - log referer for redirect and failed requests
    - log user-agent for failed requests
    """"""
    status = handler.get_status()
    request = handler.request
    try:
        logger = handler.log
    except AttributeError:
        logger = access_log

    if status < 300 or status == 304:
        # Successes (or 304 FOUND) are debug-level
        log_method = logger.debug
    elif status < 400:
        log_method = logger.info
    elif status < 500:
        log_method = logger.warning
    else:
        log_method = logger.error

    request_time = 1000.0 * handler.request.request_time()
    ns = dict(
        status=status,
        method=request.method,
        ip=request.remote_ip,
        uri=request.uri,
        request_time=request_time,
    )
    msg = ""{status} {method} {uri} ({ip}) {request_time:.2f}ms""
    if status >= 400:
        # log bad referers
        ns[""referer""] = request.headers.get(""Referer"", ""None"")
        msg = msg + "" referer={referer}""
    if status >= 500 and status != 502:
        # log all headers if it caused an error
        log_method(json.dumps(dict(request.headers), indent=2))
    log_method(msg.format(**ns))
    prometheus_log_method(handler)
",CWE-532,57.0,1
"""""""Tests for login redirects""""""
import json
from functools import partial
from urllib.parse import urlencode

import pytest
from tornado.httpclient import HTTPClientError
from tornado.httputil import parse_cookie, url_concat

from jupyter_server.utils import url_path_join


# override default config to ensure a non-empty base url is used
@pytest.fixture
def jp_base_url():
    return ""/a%40b/""


@pytest.fixture
def jp_server_config(jp_base_url):
    return {
        ""ServerApp"": {
            ""base_url"": jp_base_url,
        },
    }


async def _login(
    jp_serverapp,
    http_server_client,
    jp_base_url,
    login_headers,
    next=""/"",
    password=None,
    new_password=None,
):
    # first: request login page with no creds
    login_url = url_path_join(jp_base_url, ""login"")
    first = await http_server_client.fetch(login_url)
    cookie_header = first.headers[""Set-Cookie""]
    cookies = parse_cookie(cookie_header)
    form = {""_xsrf"": cookies.get(""_xsrf"")}
    if password is None:
        password = jp_serverapp.identity_provider.token
    if password:
        form[""password""] = password
    if new_password:
        form[""new_password""] = new_password

    # second, submit login form with credentials
    try:
        resp = await http_server_client.fetch(
            url_concat(login_url, {""next"": next}),
            method=""POST"",
            body=urlencode(form),
            headers={""Cookie"": cookie_header},
            follow_redirects=False,
        )
    except HTTPClientError as e:
        if e.code != 302:
            raise
        assert e.response is not None
        resp = e.response
    else:
        assert resp.code == 302, ""Should have returned a redirect!""
    return resp


@pytest.fixture
def login_headers():
    """"""Extra headers to pass to login

    Fixture so it can be overridden
    """"""
    return {}


@pytest.fixture
def login(jp_serverapp, http_server_client, jp_base_url, login_headers):
    """"""Fixture to return a function to login to a Jupyter server

    by submitting the login page form
    """"""
    yield partial(_login, jp_serverapp, http_server_client, jp_base_url, login_headers)


@pytest.mark.parametrize(
    ""bad_next"",
    (
        r""\\tree"",
        ""//some-host"",
        ""//host{base_url}tree"",
        ""https://google.com"",
        ""/absolute/not/base_url"",
    ),
)
async def test_next_bad(login, jp_base_url, bad_next):
    bad_next = bad_next.format(base_url=jp_base_url)
    resp = await login(bad_next)
    url = resp.headers[""Location""]
    assert url == jp_base_url


@pytest.mark.parametrize(
    ""next_path"",
    (
        ""tree/"",
        ""//{base_url}tree"",
        ""notebooks/notebook.ipynb"",
        ""tree//something"",
    ),
)
async def test_next_ok(login, jp_base_url, next_path):
    next_path = next_path.format(base_url=jp_base_url)
    expected = jp_base_url + next_path
    resp = await login(next=expected)
    actual = resp.headers[""Location""]
    assert actual == expected


async def test_login_cookie(login, jp_serverapp, jp_fetch, login_headers):
    resp = await login()
    assert ""Set-Cookie"" in resp.headers
    cookie = resp.headers[""Set-Cookie""]
    headers = {""Cookie"": cookie}
    headers.update(login_headers)
    id_resp = await jp_fetch(""/api/me"", headers=headers)
    assert id_resp.code == 200
    model = json.loads(id_resp.body.decode(""utf8""))
    assert model[""identity""][""username""]
    with pytest.raises(HTTPClientError) as exc:
        resp = await login(password=""incorrect"")
    assert exc.value.code == 401


@pytest.mark.parametrize(""allow_password_change"", [True, False])
async def test_change_password(login, jp_serverapp, jp_base_url, jp_fetch, allow_password_change):
    new_password = ""super-new-pass""
    jp_serverapp.identity_provider.allow_password_change = allow_password_change
    resp = await login(new_password=new_password)

    # second request
    if allow_password_change:
        resp = await login(password=new_password)
        assert resp.code == 302
    else:
        with pytest.raises(HTTPClientError) as exc_info:
            resp = await login(password=new_password)
        assert exc_info.value.code == 401


async def test_logout(jp_serverapp, login, http_server_client, jp_base_url):
    jp_serverapp.identity_provider.cookie_name = ""test-cookie""
    expected = jp_base_url
    resp = await login(next=jp_base_url)
    cookie_header = resp.headers[""Set-Cookie""]
    cookies = parse_cookie(cookie_header)
    assert cookies.get(""test-cookie"")

    resp = await http_server_client.fetch(jp_base_url + ""logout"", headers={""Cookie"": cookie_header})
    assert resp.code == 200
    cookie_header = resp.headers[""Set-Cookie""]
    cookies = parse_cookie(cookie_header)
    assert not cookies.get(""test-cookie"")
    assert ""Successfully logged out"" in resp.body.decode(""utf8"")


async def test_token_cookie_user_id(jp_serverapp, jp_fetch):
    token = jp_serverapp.identity_provider.token

    # first request with token, sets cookie with user-id
    resp = await jp_fetch(""/"")
    assert resp.code == 200
    set_cookie = resp.headers[""set-cookie""]
    headers = {""Cookie"": set_cookie}

    # subsequent requests with cookie and no token
    # receive same user-id
    resp = await jp_fetch(""/api/me"", headers=headers)
    user_id = json.loads(resp.body.decode(""utf8""))
    resp = await jp_fetch(""/api/me"", headers=headers)
    user_id2 = json.loads(resp.body.decode(""utf8""))
    assert user_id[""identity""] == user_id2[""identity""]

    # new request, just token -> new user_id
    resp = await jp_fetch(""/api/me"")
    user_id3 = json.loads(resp.body.decode(""utf8""))
    assert user_id[""identity""] != user_id3[""identity""]
",CWE-601,189.0,1
"""""""Tornado handlers for kernels.

Preliminary documentation at https://github.com/ipython/ipython/wiki/IPEP-16%3A-Notebook-multi-directory-dashboard-and-URL-mapping#kernels-api
""""""
# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.
import json
from traceback import format_tb

try:
    from jupyter_client.jsonutil import json_default
except ImportError:
    from jupyter_client.jsonutil import date_default as json_default

from jupyter_core.utils import ensure_async
from tornado import web

from jupyter_server.auth.decorator import authorized
from jupyter_server.utils import url_escape, url_path_join

from ...base.handlers import APIHandler
from .websocket import KernelWebsocketHandler

AUTH_RESOURCE = ""kernels""


class KernelsAPIHandler(APIHandler):
    """"""A kernels API handler.""""""

    auth_resource = AUTH_RESOURCE


class MainKernelHandler(KernelsAPIHandler):
    """"""The root kernel handler.""""""

    @web.authenticated
    @authorized
    async def get(self):
        """"""Get the list of running kernels.""""""
        km = self.kernel_manager
        kernels = await ensure_async(km.list_kernels())
        self.finish(json.dumps(kernels, default=json_default))

    @web.authenticated
    @authorized
    async def post(self):
        """"""Start a kernel.""""""
        km = self.kernel_manager
        model = self.get_json_body()
        if model is None:
            model = {""name"": km.default_kernel_name}
        else:
            model.setdefault(""name"", km.default_kernel_name)

        kernel_id = await ensure_async(
            km.start_kernel(  # type:ignore[has-type]
                kernel_name=model[""name""], path=model.get(""path"")
            )
        )
        model = await ensure_async(km.kernel_model(kernel_id))
        location = url_path_join(self.base_url, ""api"", ""kernels"", url_escape(kernel_id))
        self.set_header(""Location"", location)
        self.set_status(201)
        self.finish(json.dumps(model, default=json_default))


class KernelHandler(KernelsAPIHandler):
    """"""A kernel API handler.""""""

    @web.authenticated
    @authorized
    async def get(self, kernel_id):
        """"""Get a kernel model.""""""
        km = self.kernel_manager
        model = await ensure_async(km.kernel_model(kernel_id))
        self.finish(json.dumps(model, default=json_default))

    @web.authenticated
    @authorized
    async def delete(self, kernel_id):
        """"""Remove a kernel.""""""
        km = self.kernel_manager
        await ensure_async(km.shutdown_kernel(kernel_id))
        self.set_status(204)
        self.finish()


class KernelActionHandler(KernelsAPIHandler):
    """"""A kernel action API handler.""""""

    @web.authenticated
    @authorized
    async def post(self, kernel_id, action):
        """"""Interrupt or restart a kernel.""""""
        km = self.kernel_manager
        if action == ""interrupt"":
            await ensure_async(km.interrupt_kernel(kernel_id))  # type:ignore[func-returns-value]
            self.set_status(204)
        if action == ""restart"":
            try:
                await km.restart_kernel(kernel_id)
            except Exception as e:
                message = ""Exception restarting kernel""
                self.log.error(message, exc_info=True)
                traceback = format_tb(e.__traceback__)
                self.write(json.dumps({""message"": message, ""traceback"": traceback}))
                self.set_status(500)
            else:
                model = await ensure_async(km.kernel_model(kernel_id))
                self.write(json.dumps(model, default=json_default))
        self.finish()


# -----------------------------------------------------------------------------
# URL to handler mappings
# -----------------------------------------------------------------------------
_kernel_id_regex = r""(?P<kernel_id>\w+-\w+-\w+-\w+-\w+)""
_kernel_action_regex = r""(?P<action>restart|interrupt)""

default_handlers = [
    (r""/api/kernels"", MainKernelHandler),
    (r""/api/kernels/%s"" % _kernel_id_regex, KernelHandler),
    (
        rf""/api/kernels/{_kernel_id_regex}/{_kernel_action_regex}"",
        KernelActionHandler,
    ),
    (r""/api/kernels/%s/channels"" % _kernel_id_regex, KernelWebsocketHandler),
]
",CWE-209,129.0,1
"from typing import Any, List

import bleach

from .rest_api import ValidationError


allowed_tags_strict = [
    ""a"",
    ""img"",  # links and images
    ""br"",
    ""p"",
    ""span"",
    ""blockquote"",  # text layout
    ""strike"",
    ""del"",
    ""ins"",
    ""strong"",
    ""u"",
    ""em"",
    ""sup"",
    ""sub"",
    ""pre"",  # text formatting
    ""h1"",
    ""h2"",
    ""h3"",
    ""h4"",
    ""h5"",
    ""h6"",  # headings
    ""ol"",
    ""ul"",
    ""li"",  # lists
    ""table"",
    ""caption"",
    ""thead"",
    ""tbody"",
    ""th"",
    ""tr"",
    ""td"",  # tables
    ""div"",
]
allowed_tags_permissive = allowed_tags_strict + [
    ""video"",
]


def allow_all(tag: str, name: str, value: str) -> bool:
    return True


allowed_attributes = allow_all
allowed_styles = [
    ""color"",
    ""background-color"",
    ""height"",
    ""width"",
    ""text-align"",
    ""vertical-align"",
    ""float"",
    ""text-decoration"",
    ""margin"",
    ""padding"",
    ""line-height"",
    ""max-width"",
    ""min-width"",
    ""max-height"",
    ""min-height"",
    ""overflow"",
    ""word-break"",
    ""word-wrap"",
]


def validate_html_strict(html: str) -> str:
    """"""
    This method takes a string and escapes all non-whitelisted html entries.
    Every field of a model that is loaded trusted in the DOM should be validated.
    During copy and paste from Word maybe some tabs are spread over the html. Remove them.
    """"""
    return base_validate_html(html, allowed_tags_strict)


def validate_html_permissive(html: str) -> str:
    """"""
    See validate_html_strict, but allows some more tags, like iframes and videos.
    Do not use on validation for normal users, only for admins!
    """"""
    return base_validate_html(html, allowed_tags_permissive)


def base_validate_html(html: str, allowed_tags: List[str]) -> str:
    """"""
    For internal use only.
    """"""
    html = html.replace(""\t"", """")
    return bleach.clean(
        html, tags=allowed_tags, attributes=allowed_attributes, styles=allowed_styles
    )


def validate_json(json: Any, max_depth: int) -> Any:
    """"""
    Traverses through the JSON structure (dicts and lists) and runs
    validate_html_strict on every found string.

    Give max-depth to protect against stack-overflows. This should be the
    maximum nested depth of the object expected.
    """"""

    if max_depth == 0:
        raise ValidationError({""detail"": ""The JSON is too nested.""})

    if isinstance(json, dict):
        return {key: validate_json(value, max_depth - 1) for key, value in json.items()}
    if isinstance(json, list):
        return [validate_json(item, max_depth - 1) for item in json]
    if isinstance(json, str):
        return validate_html_strict(json)

    return json
",CWE-79,121.0,1
"from cpython cimport Py_INCREF, PyBytes_FromStringAndSize


def write_varint(Py_ssize_t number, buf):
    """"""
    Writes integer of variable length using LEB128.
    """"""
    cdef Py_ssize_t i = 0
    cdef unsigned char towrite
    # Py_ssize_t checks integer on function call and
    # raises OverflowError if integer overflows Py_ssize_t.
    # Long enough for handling Py_ssize_t.
    cdef unsigned char num_buf[32]

    while True:
        towrite = number & 0x7f
        number >>= 7
        if number:
            num_buf[i] = towrite | 0x80
            i += 1
        else:
            num_buf[i] = towrite
            i += 1
            break

    buf.write(PyBytes_FromStringAndSize(<char *>num_buf, i))


def read_varint(f):
    """"""
    Reads integer of variable length using LEB128.
    """"""
    cdef Py_ssize_t shift = 0
    cdef Py_ssize_t result = 0
    cdef unsigned char i

    read_one = f.read_one

    while True:
        i = read_one()
        result |= (i & 0x7f) << shift
        shift += 7
        if i < 0x80:
            break

    return result
",CWE-120,47.0,1
,CWE-120,,1
"from cpython cimport PyMem_Malloc, PyMem_Free, PyBytes_AsString, \
    PyBytes_Check, PyBytes_FromStringAndSize
from libc.string cimport memcpy

from .varint import write_varint


cdef class BufferedWriter(object):
    cdef char* buffer
    cdef Py_ssize_t position, buffer_size

    def __init__(self, Py_ssize_t bufsize):
        self.buffer = <char *> PyMem_Malloc(bufsize)
        if not self.buffer:
            raise MemoryError()

        self.position = 0
        self.buffer_size = bufsize

        super(BufferedWriter, self).__init__()

    def __dealloc__(self):
        PyMem_Free(self.buffer)

    cpdef write_into_stream(self):
        raise NotImplementedError

    cpdef write(self, data):
        cdef Py_ssize_t written = 0
        cdef Py_ssize_t to_write, size
        cdef Py_ssize_t data_len = len(data)
        cdef char* c_data

        c_data = PyBytes_AsString(data)

        while written < data_len:
            size = min(data_len - written, self.buffer_size - self.position)
            memcpy(&self.buffer[self.position], &c_data[written], size)

            if self.position == self.buffer_size:
                self.write_into_stream()

            self.position += size
            written += size

    def flush(self):
        self.write_into_stream()

    def write_strings(self, items, encoding=None):
        cdef int do_encode = encoding is not None

        for value in items:
            if not PyBytes_Check(value):
                if do_encode:
                    value = value.encode(encoding)
                else:
                    raise ValueError('bytes object expected')

            write_varint(len(value), self)
            self.write(value)


cdef class BufferedSocketWriter(BufferedWriter):
    cdef object sock

    def __init__(self, sock, bufsize):
        self.sock = sock
        super(BufferedSocketWriter, self).__init__(bufsize)

    cpdef write_into_stream(self):
        self.sock.sendall(
            PyBytes_FromStringAndSize(self.buffer, self.position)
        )
        self.position = 0


cdef class CompressedBufferedWriter(BufferedWriter):
    cdef object compressor

    def __init__(self, compressor, bufsize):
        self.compressor = compressor
        super(CompressedBufferedWriter, self).__init__(bufsize)

    cpdef write_into_stream(self):
        self.compressor.write(
            PyBytes_FromStringAndSize(self.buffer, self.position)
        )
        self.position = 0

    def flush(self):
        self.write_into_stream()
",CWE-120,92.0,1
,CWE-120,,1
"#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2019 tribe29 GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

import pytest  # type: ignore[import]

import cmk.gui.htmllib as htmllib
from cmk.gui import escaping


def test_htmllib_integration(register_builtin_html):
    assert escaping.escape_attribute("""") == """"
    assert escaping.escape_text("""") == """"


@pytest.mark.parametrize(""inp,out"", [
    (""\"">alert(1)"", ""&quot;&gt;alert(1)""),
    (None, """"),
    (1, ""1""),
    (htmllib.HTML(""\"">alert(1)""), ""\"">alert(1)""),
    (1.1, ""1.1""),
    (""<"", ""&lt;""),
    (""'"", ""&#x27;""),
])
def test_escape_attribute(inp, out):
    assert escaping.escape_attribute(inp) == out


@pytest.mark.parametrize(""inp,out"", [
    (""&quot;&gt;alert(1)"", ""\"">alert(1)""),
    (""&lt;"", ""<""),
])
def test_unescape_attribute(inp, out):
    assert escaping.unescape_attributes(inp) == out


@pytest.mark.parametrize(
    ""inp,out"",
    [
        (""<script>alert(1)</script>"", ""&lt;script&gt;alert(1)&lt;/script&gt;""),
        (""<h1>abc</h1>"", None),
        (""<h2>abc</h2>"", None),
        (""<b>abc</b>"", None),
        (""<tt>abc</tt>"", None),
        (""<i>abc</i>"", None),
        (""<u>abc</u>"", None),
        (""<br>"", None),
        (""<nobr></nobr>"", None),
        (""<pre></pre>"", None),
        (""<sup></sup>"", None),
        (""<p></p>"", None),
        (""<li></li>"", None),
        (""<ul></ul>"", None),
        (""<ol></ol>"", None),
        (""<a href=\""xyz\"">abc</a>"", None),
        (""<a href=\""xyz\"" target=\""123\"">abc</a>"", None),
        (""blah<a href=\""link0\"">aaa</a>blah<a href=\""link1\"" target=\""ttt\"">bbb</a>"", None),
        (""\""I am not a link\"" target=\""still not a link\"""",
         ""&quot;I am not a link&quot; target=&quot;still not a link&quot;""),
        # The next test is perverse: it contains the string `target=` inside of an
        # <a> tag (which must be unescaped) as well as outside (which must not).
        (""<a href=\""aaa\"">bbb</a>\""not a link\"" target=\""really\""<a href=\""ccc\"" target=\""ttt\"">ddd</a>"",
         ""<a href=\""aaa\"">bbb</a>&quot;not a link&quot; target=&quot;really&quot;<a href=\""ccc\"" target=\""ttt\"">ddd</a>""
        ),
        (
            ""<a href=\""xyz\"">abc</a><script>alert(1)</script><a href=\""xyz\"">abc</a>"",
            ""<a href=\""xyz\"">abc</a>&lt;script&gt;alert(1)&lt;/script&gt;<a href=\""xyz\"">abc</a>"",
        ),
        (""&nbsp;"", None),
    ])
def test_escape_text(inp, out):
    if out is None:
        out = inp
    assert escaping.escape_text(inp) == out
",CWE-79,77.0,1
"#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2019 tribe29 GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

import pytest  # type: ignore[import]

import cmk.gui.htmllib as htmllib
from cmk.gui import escaping


def test_htmllib_integration(register_builtin_html):
    assert escaping.escape_attribute("""") == """"
    assert escaping.escape_text("""") == """"


@pytest.mark.parametrize(""inp,out"", [
    (""\"">alert(1)"", ""&quot;&gt;alert(1)""),
    (None, """"),
    (1, ""1""),
    (htmllib.HTML(""\"">alert(1)""), ""\"">alert(1)""),
    (1.1, ""1.1""),
    (""<"", ""&lt;""),
    (""'"", ""&#x27;""),
])
def test_escape_attribute(inp, out):
    assert escaping.escape_attribute(inp) == out


@pytest.mark.parametrize(""inp,out"", [
    (""&quot;&gt;alert(1)"", ""\"">alert(1)""),
    (""&lt;"", ""<""),
])
def test_unescape_attribute(inp, out):
    assert escaping.unescape_attributes(inp) == out


@pytest.mark.parametrize(
    ""inp,out"",
    [
        (""<script>alert(1)</script>"", ""&lt;script&gt;alert(1)&lt;/script&gt;""),
        (""<h1>abc</h1>"", None),
        (""<h2>abc</h2>"", None),
        (""<b>abc</b>"", None),
        (""<tt>abc</tt>"", None),
        (""<i>abc</i>"", None),
        (""<u>abc</u>"", None),
        (""<br>"", None),
        (""<nobr></nobr>"", None),
        (""<pre></pre>"", None),
        (""<sup></sup>"", None),
        (""<p></p>"", None),
        (""<li></li>"", None),
        (""<ul></ul>"", None),
        (""<ol></ol>"", None),
        (""<a href=\""xyz\"">abc</a>"", None),
        (""<a href=\""xyz\"" target=\""123\"">abc</a>"", None),
        # Links with target 1st and href 2nd will not be unescaped
        (""<a target=\""123\"" href=\""xyz\"">abc</a>"",
         ""&lt;a target=&quot;123&quot; href=&quot;xyz&quot;&gt;abc</a>""),
        (""blah<a href=\""link0\"">aaa</a>blah<a href=\""link1\"" target=\""ttt\"">bbb</a>"", None),
        (""\""I am not a link\"" target=\""still not a link\"""",
         ""&quot;I am not a link&quot; target=&quot;still not a link&quot;""),
        # The next test is perverse: it contains the string `target=` inside of an
        # <a> tag (which must be unescaped) as well as outside (which must not).
        (""<a href=\""aaa\"">bbb</a>\""not a link\"" target=\""really\""<a href=\""ccc\"" target=\""ttt\"">ddd</a>"",
         ""<a href=\""aaa\"">bbb</a>&quot;not a link&quot; target=&quot;really&quot;<a href=\""ccc\"" target=\""ttt\"">ddd</a>""
        ),
        (
            ""<a href=\""xyz\"">abc</a><script>alert(1)</script><a href=\""xyz\"">abc</a>"",
            ""<a href=\""xyz\"">abc</a>&lt;script&gt;alert(1)&lt;/script&gt;<a href=\""xyz\"">abc</a>"",
        ),
        (""&nbsp;"", None),
        # At the moment also javascript URLs are accepted. This will be refused in the next step
        (""<a href=\""javascript:alert(1)\"">abc</a>"", None),
    ])
def test_escape_text(inp, out):
    if out is None:
        out = inp
    assert escaping.escape_text(inp) == out
",CWE-79,82.0,1
,CWE-347,,1
"VERSION = (0, 9, '3a3')

__version__ = '.'.join(map(str, VERSION))

version = lambda: __version__
",CWE-78,6.0,1
"#!/usr/bin/env python3
# -*-coding:UTF-8 -*
""""""
The ZMQ_Feed_Q Module
=====================

This module is consuming the Redis-list created by the ZMQ_Feed_Q Module,
And save the paste on disk to allow others modules to work on them.

..todo:: Be able to choose to delete or not the saved paste after processing.
..todo:: Store the empty paste (unprocessed) somewhere in Redis.

..note:: Module ZMQ_Something_Q and ZMQ_Something are closely bound, always put
the same Subscriber name in both of them.

Requirements
------------

*Need running Redis instances.
*Need the ZMQ_Feed_Q Module running to be able to work properly.

""""""
import base64
import os
import time
import uuid
from pubsublogger import publisher

from Helper import Process

import magic

def rreplace(s, old, new, occurrence):
    li = s.rsplit(old, occurrence)
    return new.join(li)


if __name__ == '__main__':
    publisher.port = 6380
    publisher.channel = 'Script'
    processed_paste = 0
    time_1 = time.time()

    config_section = 'Global'

    p = Process(config_section)

    PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(""Directories"", ""pastes""))
    PASTES_FOLDERS = PASTES_FOLDER + '/'

    # LOGGING #
    publisher.info(""Feed Script started to receive & publish."")

    while True:

        message = p.get_from_set()
        # Recovering the streamed message informations.
        if message is not None:
            splitted = message.split()
            if len(splitted) == 2:
                paste, gzip64encoded = splitted
            else:
                # TODO Store the name of the empty paste inside a Redis-list.
                print(""Empty Paste: not processed"")
                publisher.debug(""Empty Paste: {0} not processed"".format(message))
                continue
        else:
            print(""Empty Queues: Waiting..."")
            if int(time.time() - time_1) > 30:
                to_print = 'Global; ; ; ;glob Processed {0} paste(s)'.format(processed_paste)
                print(to_print)
                #publisher.info(to_print)
                time_1 = time.time()
                processed_paste = 0
            time.sleep(1)
            continue

        file_name_paste = paste.split('/')[-1]
        if len(file_name_paste)>255:
            new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))
            paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)

        # Creating the full filepath
        filename = os.path.join(PASTES_FOLDER, paste)

        dirname = os.path.dirname(filename)
        if not os.path.exists(dirname):
            os.makedirs(dirname)

        decoded = base64.standard_b64decode(gzip64encoded)

        with open(filename, 'wb') as f:
            f.write(decoded)
        '''try:
            decoded2 = gunzip_bytes_obj(decoded)
        except:
            decoded2 =''

        type = magic.from_buffer(decoded2, mime=True)

        if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':

            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')
            print(filename)
            print(type)
            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')
        '''

        # remove PASTES_FOLDER from item path (crawled item + submited)
        if PASTES_FOLDERS in paste:
            paste = paste.replace(PASTES_FOLDERS, '', 1)

        p.populate_set_out(paste)
        processed_paste+=1
",CWE-22,115.0,1
"""""""
Command-line interface to CairoSVG.

""""""

import argparse
import os
import sys

from . import SURFACES, VERSION


def main(argv=None, stdout=None, stdin=None):
    """"""Entry-point of the executable.""""""
    # Get command-line options
    parser = argparse.ArgumentParser(
        description='Convert SVG files to other formats')
    parser.add_argument('input', default='-', help='input filename or URL')
    parser.add_argument(
        '-v', '--version', action='version', version=VERSION)
    parser.add_argument(
        '-f', '--format', help='output format',
        choices=sorted([surface.lower() for surface in SURFACES]))
    parser.add_argument(
        '-d', '--dpi', default=96, type=float,
        help='ratio between 1 inch and 1 pixel')
    parser.add_argument(
        '-W', '--width', default=None, type=float,
        help='width of the parent container in pixels')
    parser.add_argument(
        '-H', '--height', default=None, type=float,
        help='height of the parent container in pixels')
    parser.add_argument(
        '-s', '--scale', default=1, type=float, help='output scaling factor')
    parser.add_argument(
        '-b', '--background', metavar='COLOR', help='output background color')
    parser.add_argument(
        '-n', '--negate-colors', action='store_true',
        help='replace every vector color with its complement')
    parser.add_argument(
        '-i', '--invert-images', action='store_true',
        help='replace every raster pixel with its complementary color')
    parser.add_argument(
        '-u', '--unsafe', action='store_true',
        help='resolve XML entities and allow very large files '
             '(WARNING: vulnerable to XXE attacks and various DoS)')
    parser.add_argument(
        '--output-width', default=None, type=float,
        help='desired output width in pixels')
    parser.add_argument(
        '--output-height', default=None, type=float,
        help='desired output height in pixels')

    parser.add_argument('-o', '--output', default='-', help='output filename')

    options = parser.parse_args(argv)
    kwargs = {
        'parent_width': options.width, 'parent_height': options.height,
        'dpi': options.dpi, 'scale': options.scale, 'unsafe': options.unsafe,
        'background_color': options.background,
        'negate_colors': options.negate_colors,
        'invert_images': options.invert_images,
        'output_width': options.output_width,
        'output_height': options.output_height}
    stdin = stdin or sys.stdin
    stdout = stdout or sys.stdout
    kwargs['write_to'] = (
        stdout.buffer if options.output == '-' else options.output)
    if options.input == '-':
        kwargs['file_obj'] = stdin.buffer
    else:
        kwargs['url'] = options.input
    output_format = (
        options.format or
        os.path.splitext(options.output)[1].lstrip('.') or
        'pdf').upper()

    SURFACES[output_format.upper()].convert(**kwargs)


if __name__ == '__main__':  # pragma: no cover
    main()
",CWE-918,83.0,1
"import logging
from aiohttp import web
import os

logger = logging.getLogger(__package__)


def setup_middlewares(app):
    error_middleware = error_pages({404: handle_404,
                                    500: handle_500})
    app.middlewares.append(error_middleware)
    app.middlewares.append(cache_control_middleware)


# Cache-Control middleware
CACHE_MAX_AGE = int(os.getenv(""CACHE_MAX_AGE"", ""30""))
NO_CACHE_ENDPOINTS = ['/v1/', '/v1/__version__', '/v1/__heartbeat__', '/v1/__lbheartbeat__']


async def cache_control_middleware(app, handler):
    async def middleware_handler(request):
        response = await handler(request)
        cache_control_value = ""public; max-age={}"".format(CACHE_MAX_AGE)
        if request.path in NO_CACHE_ENDPOINTS or CACHE_MAX_AGE <= 0:
            cache_control_value = ""no-cache""
        response.headers.setdefault(""Cache-Control"", cache_control_value)
        return response
    return middleware_handler


# Error page middlewares
def error_pages(overrides):
    async def middleware(app, handler):
        async def middleware_handler(request):
            try:
                response = await handler(request)
                override = overrides.get(response.status)
                if override is None:
                    return response
                else:
                    return await override(request, response)
            except web.HTTPException as ex:
                override = overrides.get(ex.status)
                if override is None:
                    return await handle_any(request, ex)
                else:
                    return await override(request, ex)
            except Exception as ex:
                return await handle_500(request, error=ex)
        return middleware_handler
    return middleware


async def handle_any(request, response):
    return web.json_response({
        ""status"": response.status,
        ""message"": response.reason
    }, status=response.status)


async def handle_404(request, response):
    if 'json' not in response.headers['Content-Type']:
        if request.path.endswith('/'):
            return web.HTTPFound(request.path.rstrip('/'))
        return web.json_response({
            ""status"": 404,
            ""message"": ""Page '{}' not found"".format(request.path)
        }, status=404)
    return response


async def handle_500(request, response=None, error=None):
    logger.exception(error)
    return web.json_response({
            ""status"": 503,
            ""message"": ""Service currently unavailable""
        }, status=503)
",CWE-601,78.0,1
"#!/usr/bin/env python3
from apkleaks.colors import clr
from contextlib import closing
from distutils.spawn import find_executable
from pyaxmlparser import APK
from urllib.request import urlopen
from zipfile import ZipFile
import io
import json
import logging.config
import mimetypes
import numpy
import os
import re
import shutil
import sys
import tempfile
import threading

class APKLeaks:
	def __init__(self, args):
		self.file = args.file
		self.prefix = ""apkleaks-""
		self.tempdir = tempfile.mkdtemp(prefix=self.prefix)
		self.main_dir = os.path.dirname(os.path.realpath(__file__))
		self.output = tempfile.mkstemp(suffix="".txt"", prefix=self.prefix)[1] if args.output is None else args.output
		self.pattern = self.main_dir + ""/../config/regexes.json"" if args.pattern is None else args.pattern
		self.jadx = find_executable(""jadx"") if find_executable(""jadx"") is not None else self.main_dir + ""/../jadx/bin/jadx%s"" % ("".bat"" if os.name == ""nt"" else """")
		logging.config.dictConfig({""version"": 1, ""disable_existing_loggers"": True})

	def apk_info(self):
		return APK(self.file)

	def dependencies(self):
		exter = ""https://github.com/skylot/jadx/releases/download/v1.2.0/jadx-1.2.0.zip""
		with closing(urlopen(exter)) as jadx:
			with ZipFile(io.BytesIO(jadx.read())) as zfile:
				zfile.extractall(self.main_dir + ""/../jadx"")
		os.chmod(self.jadx, 33268)

	def write(self, message, color):
		sys.stdout.write(""%s%s%s"" % (color, message, clr.ENDC))

	def writeln(self, message, color):
		self.write(message + ""\n"", color)

	def integrity(self):
		if os.path.exists(self.jadx) is False:
			self.writeln(""Can't find jadx binary."", clr.WARNING)
			valid = {""yes"": True, ""y"": True, ""ye"": True, ""no"": False, ""n"": False}
			while True:
				self.write(""Do you want to download jadx? (Y/n) "", clr.OKBLUE)
				choice = input().lower()
				if choice == """":
					choice = valid[""y""]
					break
				elif choice in valid:
					choice = valid[choice]
					break
				else:
					self.writeln(""\nPlease respond with 'yes' or 'no' (or 'y' or 'n')."", clr.WARNING)
			if choice:
				self.writeln(""** Downloading jadx...\n"", clr.OKBLUE)
				self.dependencies()
			else:
				sys.exit(self.writeln(""Aborted."", clr.FAIL))

		if os.path.isfile(self.file) is True:
			try:
				self.apk = self.apk_info()
			except Exception as e:
				sys.exit(self.writeln(str(e), clr.WARNING))
			else:
				return self.apk
		else:
			sys.exit(self.writeln(""It's not a valid file!"", clr.WARNING))

	def decompile(self):
		self.writeln(""** Decompiling APK..."", clr.OKBLUE)
		with ZipFile(self.file) as zipped:
			try:
				dex = self.tempdir + ""/"" + self.apk.package + "".dex""
				with open(dex, ""wb"") as classes:
					classes.write(zipped.read(""classes.dex""))
			except Exception as e:
				sys.exit(self.writeln(str(e), clr.WARNING))
		dec = ""%s %s -d %s --deobf"" % (self.jadx, dex, self.tempdir)
		os.system(dec)
		return self.tempdir

	def unique(self, list): 
		x = numpy.array(list) 
		return (numpy.unique(x))

	def finder(self, pattern, path):
		matcher = re.compile(pattern)
		found = []
		for path, _, files in os.walk(path):
			for fn in files:
				filepath = os.path.join(path, fn)
				if mimetypes.guess_type(filepath)[0] is None:
					continue
				with open(filepath) as handle:
					for lineno, line in enumerate(handle):
						mo = matcher.search(line)
						if mo:
							found.append(mo.group())
		return self.unique(found)

	def extract(self, name, matches):
		output = open(self.output, ""a+"")
		if matches:
			stdout = (""[%s]"" % (name))
			self.writeln(""\n"" + stdout, clr.OKGREEN)
			output.write(stdout + ""\n"")
			for secret in matches:
				if name == ""LinkFinder"" and re.match(r""^.(L[a-z]|application|audio|fonts|image|layout|multipart|plain|text|video).*\/.+"", secret) is not None:
					continue
				stdout = (""- %s"" % (secret))
				print(stdout)
				output.write(stdout + ""\n"")
			output.write(""\n"")
		output.close()

	def scanning(self):
		self.writeln(""\n** Scanning against '%s'"" % (self.apk.package), clr.OKBLUE)
		with open(self.pattern) as regexes:
			regex = json.load(regexes)
			for name, pattern in regex.items():
				if isinstance(pattern, list):
					for pattern in pattern:
						thread = threading.Thread(target = self.extract, args = (name, self.finder(pattern, self.tempdir)))
						thread.start()
				else:
					thread = threading.Thread(target = self.extract, args = (name, self.finder(pattern, self.tempdir)))
					thread.start()

	def __del__(self):
		print(""%s\n** Results saved into '%s%s%s%s'%s"" % (clr.OKBLUE, clr.ENDC, clr.OKGREEN, self.output, clr.OKBLUE, clr.ENDC))
		try:
			shutil.rmtree(self.tempdir)
		except Exception:
			return
",CWE-78,144.0,1
"#!/usr/bin/env python3
from apkleaks.colors import clr
from contextlib import closing
from distutils.spawn import find_executable
from pyaxmlparser import APK
from urllib.request import urlopen
from zipfile import ZipFile
import io
import json
import logging.config
import mimetypes
import numpy
import os
import re
import shutil
import sys
import tempfile
import threading

class APKLeaks:
	def __init__(self, args):
		self.file = args.file
		self.prefix = ""apkleaks-""
		self.tempdir = tempfile.mkdtemp(prefix=self.prefix)
		self.main_dir = os.path.dirname(os.path.realpath(__file__))
		self.output = tempfile.mkstemp(suffix="".txt"", prefix=self.prefix)[1] if args.output is None else args.output
		self.pattern = self.main_dir + ""/../config/regexes.json"" if args.pattern is None else args.pattern
		self.jadx = find_executable(""jadx"") if find_executable(""jadx"") is not None else self.main_dir + ""/../jadx/bin/jadx%s"" % ("".bat"" if os.name == ""nt"" else """")
		logging.config.dictConfig({""version"": 1, ""disable_existing_loggers"": True})

	def apk_info(self):
		return APK(self.file)

	def dependencies(self):
		exter = ""https://github.com/skylot/jadx/releases/download/v1.2.0/jadx-1.2.0.zip""
		with closing(urlopen(exter)) as jadx:
			with ZipFile(io.BytesIO(jadx.read())) as zfile:
				zfile.extractall(self.main_dir + ""/../jadx"")
		os.chmod(self.jadx, 33268)

	def write(self, message, color):
		sys.stdout.write(""%s%s%s"" % (color, message, clr.ENDC))

	def writeln(self, message, color):
		self.write(message + ""\n"", color)

	def integrity(self):
		if os.path.exists(self.jadx) is False:
			self.writeln(""Can't find jadx binary."", clr.WARNING)
			valid = {""yes"": True, ""y"": True, ""ye"": True, ""no"": False, ""n"": False}
			while True:
				self.write(""Do you want to download jadx? (Y/n) "", clr.OKBLUE)
				choice = input().lower()
				if choice == """":
					choice = valid[""y""]
					break
				elif choice in valid:
					choice = valid[choice]
					break
				else:
					self.writeln(""\nPlease respond with 'yes' or 'no' (or 'y' or 'n')."", clr.WARNING)
			if choice:
				self.writeln(""** Downloading jadx...\n"", clr.OKBLUE)
				self.dependencies()
			else:
				sys.exit(self.writeln(""Aborted."", clr.FAIL))

		if os.path.isfile(self.file) is True:
			try:
				self.apk = self.apk_info()
			except Exception as e:
				sys.exit(self.writeln(str(e), clr.WARNING))
			else:
				return self.apk
		else:
			sys.exit(self.writeln(""It's not a valid file!"", clr.WARNING))

	def decompile(self):
		self.writeln(""** Decompiling APK..."", clr.OKBLUE)
		with ZipFile(self.file) as zipped:
			try:
				dex = self.tempdir + ""/"" + self.apk.package + "".dex""
				with open(dex, ""wb"") as classes:
					classes.write(zipped.read(""classes.dex""))
			except Exception as e:
				sys.exit(self.writeln(str(e), clr.WARNING))
		dec = ""%s %s -d %s --deobf"" % (self.jadx, dex, self.tempdir)
		os.system(dec)
		return self.tempdir

	def unique(self, list): 
		x = numpy.array(list) 
		return (numpy.unique(x))

	def finder(self, pattern, path):
		matcher = re.compile(pattern)
		found = []
		for path, _, files in os.walk(path):
			for fn in files:
				filepath = os.path.join(path, fn)
				if mimetypes.guess_type(filepath)[0] is None:
					continue
				with open(filepath) as handle:
					for lineno, line in enumerate(handle):
						mo = matcher.search(line)
						if mo:
							found.append(mo.group())
		return self.unique(found)

	def extract(self, name, matches):
		output = open(self.output, ""a+"")
		if matches:
			stdout = (""[%s]"" % (name))
			self.writeln(""\n"" + stdout, clr.OKGREEN)
			output.write(stdout + ""\n"")
			for secret in matches:
				if name == ""LinkFinder"" and re.match(r""^.(L[a-z]|application|audio|fonts|image|layout|multipart|plain|text|video).*\/.+"", secret) is not None:
					continue
				stdout = (""- %s"" % (secret))
				print(stdout)
				output.write(stdout + ""\n"")
			output.write(""\n"")
		output.close()

	def scanning(self):
		self.writeln(""\n** Scanning against '%s'"" % (self.apk.package), clr.OKBLUE)
		with open(self.pattern) as regexes:
			regex = json.load(regexes)
			for name, pattern in regex.items():
				if isinstance(pattern, list):
					for pattern in pattern:
						thread = threading.Thread(target = self.extract, args = (name, self.finder(pattern, self.tempdir)))
						thread.start()
				else:
					thread = threading.Thread(target = self.extract, args = (name, self.finder(pattern, self.tempdir)))
					thread.start()

	def __del__(self):
		print(""%s\n** Results saved into '%s%s%s%s'%s"" % (clr.OKBLUE, clr.ENDC, clr.OKGREEN, self.output, clr.OKBLUE, clr.ENDC))
		try:
			shutil.rmtree(self.tempdir)
		except Exception:
			return
",CWE-88,144.0,1
"# -*- coding: utf-8 -*-
#
# This file is part of Glances.
#
# Copyright (C) 2021 Nicolargo <nicolas@nicolargo.com>
#
# Glances is free software; you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Glances is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

""""""Manage on alert actions.""""""

from subprocess import Popen

from glances.logger import logger
from glances.timer import Timer

try:
    import chevron
except ImportError:
    logger.debug(""Chevron library not found (action scripts won't work)"")
    chevron_tag = False
else:
    chevron_tag = True


class GlancesActions(object):

    """"""This class manage action if an alert is reached.""""""

    def __init__(self, args=None):
        """"""Init GlancesActions class.""""""
        # Dict with the criticity status
        # - key: stat_name
        # - value: criticity
        # Goal: avoid to execute the same command twice
        self.status = {}

        # Add a timer to avoid any trigger when Glances is started (issue#732)
        # Action can be triggered after refresh * 2 seconds
        if hasattr(args, 'time'):
            self.start_timer = Timer(args.time * 2)
        else:
            self.start_timer = Timer(3)

    def get(self, stat_name):
        """"""Get the stat_name criticity.""""""
        try:
            return self.status[stat_name]
        except KeyError:
            return None

    def set(self, stat_name, criticity):
        """"""Set the stat_name to criticity.""""""
        self.status[stat_name] = criticity

    def run(self, stat_name, criticity, commands, repeat, mustache_dict=None):
        """"""Run the commands (in background).

        - stats_name: plugin_name (+ header)
        - criticity: criticity of the trigger
        - commands: a list of command line with optional {{mustache}}
        - If True, then repeat the action
        - mustache_dict: Plugin stats (can be use within {{mustache}})

        Return True if the commands have been ran.
        """"""
        if (self.get(stat_name) == criticity and not repeat) or \
           not self.start_timer.finished():
            # Action already executed => Exit
            return False

        logger.debug(""{} action {} for {} ({}) with stats {}"".format(
            ""Repeat"" if repeat else ""Run"",
            commands, stat_name, criticity, mustache_dict))

        # Run all actions in background
        for cmd in commands:
            # Replace {{arg}} by the dict one (Thk to {Mustache})
            if chevron_tag:
                cmd_full = chevron.render(cmd, mustache_dict)
            else:
                cmd_full = cmd
            # Execute the action
            logger.info(""Action triggered for {} ({}): {}"".format(stat_name,
                                                                  criticity,
                                                                  cmd_full))
            logger.debug(""Action will be executed with the following command: \
                subprocess.Popen({}, shell=False)"".format(cmd_full.split(' ')))
            try:
                Popen(cmd_full.split(' '), shell=False)
            except OSError as e:
                logger.error(""Can't execute the action ({})"".format(e))

        self.set(stat_name, criticity)

        return True
",CWE-611,107.0,1
,CWE-611,,1
"#!/usr/bin/env python

import glob
import os
import re
import sys
from io import open

from setuptools import setup, Command


if sys.version_info < (2, 7) or (3, 0) <= sys.version_info < (3, 4):
    print('Glances requires at least Python 2.7 or 3.4 to run.')
    sys.exit(1)

PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3


# Global functions
##################

with open(os.path.join('glances', '__init__.py'), encoding='utf-8') as f:
    version = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"", f.read(), re.M).group(1)

if not version:
    raise RuntimeError('Cannot find Glances version information.')

with open('README.rst', encoding='utf-8') as f:
    long_description = f.read()


def get_data_files():
    data_files = [
        ('share/doc/glances', ['AUTHORS', 'COPYING', 'NEWS.rst', 'README.rst',
                               'CONTRIBUTING.md', 'conf/glances.conf']),
        ('share/man/man1', ['docs/man/glances.1'])
    ]

    return data_files


def get_install_requires():
    requires = ['psutil>=5.3.0', 'future']
    if sys.platform.startswith('win'):
        requires.append('bottle')
        requires.append('requests')

    return requires


def get_install_extras_require():
    extras_require = {
        'action': ['chevron'],
        'browser': ['zeroconf==0.19.1' if PY2 else 'zeroconf>=0.19.1'],
        'cloud': ['requests'],
        'docker': ['docker>=2.0.0'],
        'export': ['bernhard', 'cassandra-driver', 'couchdb', 'elasticsearch',
                   'graphitesender', 'influxdb>=1.0.0', 'kafka-python', 'pika',
                   'paho-mqtt', 'potsdb', 'prometheus_client', 'pyzmq',
                   'statsd'],
        'folders': ['scandir'],  # python_version<""3.5""
        'gpu': ['py3nvml'],
        'graph': ['pygal'],
        'ip': ['netifaces'],
        'raid': ['pymdstat'],
        'smart': ['pySMART.smartx'],
        'snmp': ['pysnmp'],
        'sparklines': ['sparklines'],
        'web': ['bottle', 'requests'],
        'wifi': ['wifi']
    }
    # Add automatically the 'all' target
    extras_require.update({'all': [i[0] for i in extras_require.values()]})

    return extras_require


class tests(Command):
    user_options = []

    def initialize_options(self):
        pass

    def finalize_options(self):
        pass

    def run(self):
        import subprocess
        import sys
        for t in glob.glob('unitest.py'):
            ret = subprocess.call([sys.executable, t]) != 0
            if ret != 0:
                raise SystemExit(ret)
        raise SystemExit(0)


# Setup !

setup(
    name='Glances',
    version=version,
    description=""A cross-platform curses-based monitoring tool"",
    long_description=long_description,
    author='Nicolas Hennion',
    author_email='nicolas@nicolargo.com',
    url='https://github.com/nicolargo/glances',
    license='LGPLv3',
    keywords=""cli curses monitoring system"",
    python_requires="">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"",
    install_requires=get_install_requires(),
    extras_require=get_install_extras_require(),
    packages=['glances'],
    include_package_data=True,
    data_files=get_data_files(),
    cmdclass={'test': tests},
    test_suite=""unitest.py"",
    entry_points={""console_scripts"": [""glances=glances:main""]},
    classifiers=[
        'Development Status :: 5 - Production/Stable',
        'Environment :: Console :: Curses',
        'Environment :: Web Environment',
        'Framework :: Bottle',
        'Intended Audience :: Developers',
        'Intended Audience :: End Users/Desktop',
        'Intended Audience :: System Administrators',
        'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)',
        'Operating System :: OS Independent',
        'Programming Language :: Python :: 2',
        'Programming Language :: Python :: 2.7',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.4',
        'Programming Language :: Python :: 3.5',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
        'Topic :: System :: Monitoring'
    ]
)
",CWE-611,141.0,1
"# pylint: disable=R1732

import io
import os

from ..InputSource import InputSource
from ..messages import *
from .main import scriptPath
from .status import splitStatus


class DataFileRequester:
    def __init__(self, type=None, fallback=None):
        self.type = type
        if self.type not in (""readonly"", ""latest""):
            raise Exception(f""Bad value for DataFileRequester.type, got '{type}'."")
        # fallback is another requester, used if the main one fails.
        self.fallback = fallback

    def fetch(self, *segs, **kwargs):
        str = kwargs.get(""str"", False)
        okayToFail = kwargs.get(""okayToFail"", False)
        fileType = kwargs.get(""type"", self.type)
        location = self._buildPath(segs=segs, fileType=fileType)
        try:
            if str:
                with open(location, encoding=""utf-8"") as fh:
                    return fh.read()
            else:
                return open(location, encoding=""utf-8"")
        except OSError:
            if self.fallback:
                try:
                    return self.fallback.fetch(*segs, str=str, okayToFail=okayToFail)
                except OSError:
                    return self._fail(location, str, okayToFail)
            return self._fail(location, str, okayToFail)

    def walkFiles(self, *segs, **kwargs):
        fileType = kwargs.get(""type"", self.type)
        for _, _, files in os.walk(self._buildPath(segs, fileType=fileType)):
            yield from files

    def _buildPath(self, segs, fileType=None):
        if fileType is None:
            fileType = self.type
        if fileType == ""readonly"":
            return scriptPath(""spec-data"", ""readonly"", *segs)
        else:
            return scriptPath(""spec-data"", *segs)

    def _fail(self, location, str, okayToFail):
        if okayToFail:
            if str:
                return """"
            else:
                return io.StringIO("""")
        raise OSError(f""Couldn't find file '{location}'"")


defaultRequester = DataFileRequester(
    type=""latest"", fallback=DataFileRequester(type=""readonly"")
)


def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True):
    # Looks in three or four locations, in order:
    # the folder the spec source is in, the group's boilerplate folder, the megagroup's boilerplate folder, and the generic boilerplate folder.
    # In each location, it first looks for the file specialized on status, and then for the generic file.
    # Filenames must be of the format NAME.include or NAME-STATUS.include
    if group is None and doc.md.group is not None:
        group = doc.md.group.lower()
    if status is None:
        if doc.md.status is not None:
            status = doc.md.status
        elif doc.md.rawStatus is not None:
            status = doc.md.rawStatus
    megaGroup, status = splitStatus(status)

    searchLocally = doc.md.localBoilerplate[name]

    def boilerplatePath(*segs):
        return scriptPath(""boilerplate"", *segs)

    statusFile = f""{name}-{status}.include""
    genericFile = f""{name}.include""
    sources = []
    if searchLocally:
        sources.append(doc.inputSource.relative(statusFile))  # Can be None.
        sources.append(doc.inputSource.relative(genericFile))
    else:
        for f in (statusFile, genericFile):
            if doc.inputSource.cheaplyExists(f):
                warn(
                    (
                        ""Found {0} next to the specification without a matching\n""
                        + ""Local Boilerplate: {1} yes\n""
                        + ""in the metadata. This include won't be found when building via a URL.""
                    ).format(f, name)
                )
                # We should remove this after giving specs time to react to the warning:
                sources.append(doc.inputSource.relative(f))
    if group:
        sources.append(InputSource(boilerplatePath(group, statusFile)))
        sources.append(InputSource(boilerplatePath(group, genericFile)))
    if megaGroup:
        sources.append(InputSource(boilerplatePath(megaGroup, statusFile)))
        sources.append(InputSource(boilerplatePath(megaGroup, genericFile)))
    sources.append(InputSource(boilerplatePath(statusFile)))
    sources.append(InputSource(boilerplatePath(genericFile)))

    # Watch all the possible sources, not just the one that got used, because if
    # an earlier one appears, we want to rebuild.
    doc.recordDependencies(*sources)

    for source in sources:
        if source is not None:
            try:
                return source.read().content
            except OSError:
                # That input doesn't exist.
                pass
    else:
        if error:
            die(
                ""Couldn't find an appropriate include file for the {0} inclusion, given group='{1}' and status='{2}'."",
                name,
                group,
                status,
            )
        return """"
",CWE-78,132.0,1
"# pylint: disable=R1732

import io
import os

from ..InputSource import InputSource
from ..messages import *
from .main import scriptPath
from .status import splitStatus


class DataFileRequester:
    def __init__(self, type=None, fallback=None):
        self.type = type
        if self.type not in (""readonly"", ""latest""):
            raise Exception(f""Bad value for DataFileRequester.type, got '{type}'."")
        # fallback is another requester, used if the main one fails.
        self.fallback = fallback

    def fetch(self, *segs, **kwargs):
        str = kwargs.get(""str"", False)
        okayToFail = kwargs.get(""okayToFail"", False)
        fileType = kwargs.get(""type"", self.type)
        location = self._buildPath(segs=segs, fileType=fileType)
        try:
            if str:
                with open(location, encoding=""utf-8"") as fh:
                    return fh.read()
            else:
                return open(location, encoding=""utf-8"")
        except OSError:
            if self.fallback:
                try:
                    return self.fallback.fetch(*segs, str=str, okayToFail=okayToFail)
                except OSError:
                    return self._fail(location, str, okayToFail)
            return self._fail(location, str, okayToFail)

    def walkFiles(self, *segs, **kwargs):
        fileType = kwargs.get(""type"", self.type)
        for _, _, files in os.walk(self._buildPath(segs, fileType=fileType)):
            yield from files

    def _buildPath(self, segs, fileType=None):
        if fileType is None:
            fileType = self.type
        if fileType == ""readonly"":
            return scriptPath(""spec-data"", ""readonly"", *segs)
        else:
            return scriptPath(""spec-data"", *segs)

    def _fail(self, location, str, okayToFail):
        if okayToFail:
            if str:
                return """"
            else:
                return io.StringIO("""")
        raise OSError(f""Couldn't find file '{location}'"")


defaultRequester = DataFileRequester(
    type=""latest"", fallback=DataFileRequester(type=""readonly"")
)


def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True):
    # Looks in three or four locations, in order:
    # the folder the spec source is in, the group's boilerplate folder, the megagroup's boilerplate folder, and the generic boilerplate folder.
    # In each location, it first looks for the file specialized on status, and then for the generic file.
    # Filenames must be of the format NAME.include or NAME-STATUS.include
    if group is None and doc.md.group is not None:
        group = doc.md.group.lower()
    if status is None:
        if doc.md.status is not None:
            status = doc.md.status
        elif doc.md.rawStatus is not None:
            status = doc.md.rawStatus
    megaGroup, status = splitStatus(status)

    searchLocally = doc.md.localBoilerplate[name]

    def boilerplatePath(*segs):
        return scriptPath(""boilerplate"", *segs)

    statusFile = f""{name}-{status}.include""
    genericFile = f""{name}.include""
    sources = []
    if searchLocally:
        sources.append(doc.inputSource.relative(statusFile))  # Can be None.
        sources.append(doc.inputSource.relative(genericFile))
    else:
        for f in (statusFile, genericFile):
            if doc.inputSource.cheaplyExists(f):
                warn(
                    (
                        ""Found {0} next to the specification without a matching\n""
                        + ""Local Boilerplate: {1} yes\n""
                        + ""in the metadata. This include won't be found when building via a URL.""
                    ).format(f, name)
                )
                # We should remove this after giving specs time to react to the warning:
                sources.append(doc.inputSource.relative(f))
    if group:
        sources.append(InputSource(boilerplatePath(group, statusFile)))
        sources.append(InputSource(boilerplatePath(group, genericFile)))
    if megaGroup:
        sources.append(InputSource(boilerplatePath(megaGroup, statusFile)))
        sources.append(InputSource(boilerplatePath(megaGroup, genericFile)))
    sources.append(InputSource(boilerplatePath(statusFile)))
    sources.append(InputSource(boilerplatePath(genericFile)))

    # Watch all the possible sources, not just the one that got used, because if
    # an earlier one appears, we want to rebuild.
    doc.recordDependencies(*sources)

    for source in sources:
        if source is not None:
            try:
                return source.read().content
            except OSError:
                # That input doesn't exist.
                pass
    else:
        if error:
            die(
                ""Couldn't find an appropriate include file for the {0} inclusion, given group='{1}' and status='{2}'."",
                name,
                group,
                status,
            )
        return """"
",CWE-22,132.0,1
"from .stringEnum import StringEnum

dryRun = False
errorLevel = [""fatal""]
printMode = ""console""
quiet = True
asciiOnly = False
refStatus = StringEnum(""current"", ""snapshot"")
biblioDisplay = StringEnum(""index"", ""inline"")
specClass = None
testAnnotationURL = ""https://test.csswg.org/harness/annotate.js""


def errorLevelAt(target):
    levels = {
        ""nothing"": 0,
        ""fatal"": 1,
        ""link-error"": 2,
        ""warning"": 3,
        ""everything"": 1000,
    }
    currentLevel = levels[errorLevel[0]]
    targetLevel = levels[target]
    return currentLevel >= targetLevel


def setErrorLevel(level=None):
    if level is None:
        level = ""fatal""
    errorLevel[0] = level
",CWE-78,31.0,1
"from .stringEnum import StringEnum

dryRun = False
errorLevel = [""fatal""]
printMode = ""console""
quiet = True
asciiOnly = False
refStatus = StringEnum(""current"", ""snapshot"")
biblioDisplay = StringEnum(""index"", ""inline"")
specClass = None
testAnnotationURL = ""https://test.csswg.org/harness/annotate.js""


def errorLevelAt(target):
    levels = {
        ""nothing"": 0,
        ""fatal"": 1,
        ""link-error"": 2,
        ""warning"": 3,
        ""everything"": 1000,
    }
    currentLevel = levels[errorLevel[0]]
    targetLevel = levels[target]
    return currentLevel >= targetLevel


def setErrorLevel(level=None):
    if level is None:
        level = ""fatal""
    errorLevel[0] = level
",CWE-22,31.0,1
"from . import config
from .h import *  # noqa: F401
from .messages import *  # noqa: F401


def load(doc):
    code = config.retrieveBoilerplateFile(doc, ""bs-extensions"")
    exec(code, globals())
",CWE-78,9.0,1
"from . import config
from .h import *  # noqa: F401
from .messages import *  # noqa: F401


def load(doc):
    code = config.retrieveBoilerplateFile(doc, ""bs-extensions"")
    exec(code, globals())
",CWE-22,9.0,1
"from subprocess import PIPE, Popen

from ..h import *
from ..messages import *


def processTags(doc):
    for el in findAll(""[data-span-tag]"", doc):
        tag = el.get(""data-span-tag"")
        if tag not in doc.md.inlineTagCommands:
            die(""Unknown inline tag '{0}' found:\n  {1}"", tag, outerHTML(el), el=el)
            continue
        command = doc.md.inlineTagCommands[tag]
        with Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True) as p:
            out, err = p.communicate(innerHTML(el).encode(""utf-8""))
            try:
                out = out.decode(""utf-8"")
            except UnicodeDecodeError as e:
                die(
                    ""When trying to process {0}, got invalid unicode in stdout:\n{1}"",
                    outerHTML(el),
                    e,
                    el=el,
                )
            try:
                err = err.decode(""utf-8"")
            except UnicodeDecodeError as e:
                die(
                    ""When trying to process {0}, got invalid unicode in stderr:\n{1}"",
                    outerHTML(el),
                    e,
                    el=el,
                )
            if p.returncode:
                die(
                    ""When trying to process {0}, got return code {1} and the following stderr:\n{2}"",
                    outerHTML(el),
                    p.returncode,
                    err,
                    el=el,
                )
                continue
            replaceContents(el, parseHTML(out))
",CWE-78,44.0,1
"from subprocess import PIPE, Popen

from ..h import *
from ..messages import *


def processTags(doc):
    for el in findAll(""[data-span-tag]"", doc):
        tag = el.get(""data-span-tag"")
        if tag not in doc.md.inlineTagCommands:
            die(""Unknown inline tag '{0}' found:\n  {1}"", tag, outerHTML(el), el=el)
            continue
        command = doc.md.inlineTagCommands[tag]
        with Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True) as p:
            out, err = p.communicate(innerHTML(el).encode(""utf-8""))
            try:
                out = out.decode(""utf-8"")
            except UnicodeDecodeError as e:
                die(
                    ""When trying to process {0}, got invalid unicode in stdout:\n{1}"",
                    outerHTML(el),
                    e,
                    el=el,
                )
            try:
                err = err.decode(""utf-8"")
            except UnicodeDecodeError as e:
                die(
                    ""When trying to process {0}, got invalid unicode in stderr:\n{1}"",
                    outerHTML(el),
                    e,
                    el=el,
                )
            if p.returncode:
                die(
                    ""When trying to process {0}, got return code {1} and the following stderr:\n{2}"",
                    outerHTML(el),
                    p.returncode,
                    err,
                    el=el,
                )
                continue
            replaceContents(el, parseHTML(out))
",CWE-22,44.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from __future__ import unicode_literals

import six
from django.core.exceptions import ValidationError
from django.http import HttpResponseRedirect, JsonResponse
from django.shortcuts import redirect
from django.utils.translation import ugettext_lazy as _

from shuup.apps.provides import get_provide_objects
from shuup.core.basket import commands
from shuup.core.basket.command_middleware import BaseBasketCommandMiddleware
from shuup.core.signals import get_basket_command_handler
from shuup.utils.django_compat import force_text
from shuup.utils.excs import Problem


class BasketCommandDispatcher(object):
    """"""
    BasketCommandDispatcher handles (usually AJAX) requests that somehow update the basket.
    You should never instantiate BasketCommandDispatcher yourself -- instead use
    `get_basket_command_dispatcher()`.

    All `handle_*` methods are expected to accept `**kwargs`.
    """"""

    commands_module = commands

    def __init__(self, request, basket=None):
        """"""
        :type request: HttpRequest
        """"""
        self.request = request
        self.ajax = self.request.is_ajax()
        # :type self.basket: BaseBasket
        self.basket = basket or request.basket

    def get_command_handler(self, command):
        handler = getattr(self.commands_module, ""handle_%s"" % command.lower(), None)
        if handler and callable(handler):
            return handler

        for receiver, handler in get_basket_command_handler.send(
            BasketCommandDispatcher, command=command, instance=self
        ):
            if handler and callable(handler):
                return handler

    def handle(self, command, kwargs=None):
        """"""
        Dispatch and handle processing of the given command.

        :param command: Name of command to run.
        :type command: unicode
        :param kwargs: Arguments to pass to the command handler. If empty, `request.POST` is used.
        :type kwargs: dict
        :return: response.
        :rtype: HttpResponse
        """"""

        kwargs = kwargs or dict(six.iteritems(self.request.POST))
        try:
            handler = self.get_command_handler(command)
            if not handler or not callable(handler):
                raise Problem(_(""Error! Invalid command `%s`."") % command)
            kwargs.pop(""csrfmiddlewaretoken"", None)  # The CSRF token should never be passed as a kwarg
            kwargs.pop(""command"", None)  # Nor the command
            kwargs.update(request=self.request, basket=self.basket)
            kwargs = self.preprocess_kwargs(command, kwargs)

            response = handler(**kwargs) or {}

        except (Problem, ValidationError) as exc:
            if not self.ajax:
                raise
            msg = exc.message if hasattr(exc, ""message"") else exc
            response = {
                ""error"": force_text(msg, errors=""ignore""),
                ""code"": force_text(getattr(exc, ""code"", None) or """", errors=""ignore""),
            }

        response = self.postprocess_response(command, kwargs, response)

        if self.ajax:
            return JsonResponse(response)

        return_url = response.get(""return"") or kwargs.get(""return"")
        if return_url and return_url.startswith(""/""):
            return HttpResponseRedirect(return_url)
        return redirect(""shuup:basket"")

    def preprocess_kwargs(self, command, kwargs):
        """"""
        Preprocess kwargs before they are passed to the given `command` handler.
        Useful for subclassing. Must return the new `kwargs`, even if it wasn't
        mutated.

        :param command: The name of the command about to be run.
        :param kwargs: dict of arguments.
        :return: dict of arguments.
        """"""

        for basket_command_middleware in get_provide_objects(""basket_command_middleware""):
            if not issubclass(basket_command_middleware, BaseBasketCommandMiddleware):
                continue

            # create a copy
            kwargs = dict(
                basket_command_middleware().preprocess_kwargs(
                    basket=self.basket, request=self.request, command=command, kwargs=kwargs
                )
            )

        return kwargs

    def postprocess_response(self, command, kwargs, response):
        """"""
        Postprocess the response dictionary (not a HTTP response!) before it is
        either turned into JSON or otherwise processed (in the case of non-AJAX requests).

        :param command: The command that was run.
        :param kwargs: The actual kwargs the command was run with.
        :param response: The response the command returned.
        :return: The response to be processed and sent to the client.
        """"""

        for basket_command_middleware in get_provide_objects(""basket_command_middleware""):
            if not issubclass(basket_command_middleware, BaseBasketCommandMiddleware):
                continue

            response = dict(
                basket_command_middleware().postprocess_response(
                    basket=self.basket, request=self.request, command=command, kwargs=kwargs, response=response
                )
            )

        return response
",CWE-79,144.0,1
"# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from __future__ import unicode_literals

from collections import OrderedDict
from django.core.exceptions import ImproperlyConfigured
from django.http.response import Http404

from shuup.front.basket import get_basket
from shuup.utils.django_compat import reverse
from shuup.utils.importing import load


class CheckoutProcess(object):
    horizontal_template = True

    def __init__(self, phase_specs, phase_kwargs, view=None):
        """"""
        Initialize this checkout process.

        :type phase_specs: list[str]
        :type phase_kwargs: dict
        :type view: shuup.front.checkout.BaseCheckoutView|None
        """"""
        self.phase_specs = phase_specs
        self.phase_kwargs = phase_kwargs
        self.view = view
        self.request = self.phase_kwargs.get(""request"")

    @property
    def phases(self):
        """"""
        :rtype: Iterable[CheckoutPhaseViewMixin]
        """"""
        if not getattr(self, ""_phases"", None):
            self._phases = self._load_phases()
        return self._phases

    def instantiate_phase_class(self, phase_class, **extra_kwargs):
        if not phase_class.identifier:  # pragma: no cover
            raise ImproperlyConfigured(""Error! Phase `%r` has no identifier."" % phase_class)
        kwargs = {}
        kwargs.update(self.phase_kwargs)
        kwargs.update(extra_kwargs)
        phase = phase_class(checkout_process=self, horizontal_template=self.horizontal_template, **kwargs)
        return phase

    def _load_phases(self):
        phases = OrderedDict()

        for phase_spec in self.phase_specs:
            phase_class = load(phase_spec)
            phase = self.instantiate_phase_class(phase_class)
            phases[phase_class.identifier] = phase

            # check whether the phase spawns new phases,
            # if so, then let's spawn then and add the phases
            for spawned_phase in phase.spawn_phases(self):
                phases[spawned_phase.identifier] = spawned_phase

        return list(phases.values())

    def get_current_phase(self, requested_phase_identifier):
        found = False
        for phase in self.phases:
            if phase.is_valid():
                phase.process()
            if found or not requested_phase_identifier or requested_phase_identifier == phase.identifier:
                found = True  # We're at or past the requested phase
                if not phase.should_skip():
                    return phase
            if not phase.should_skip() and not phase.is_valid():  # A past phase is not valid, that's the current one
                return phase
        raise Http404(""Error! Phase with identifier `%s` not found."" % requested_phase_identifier)  # pragma: no cover

    def _get_next_phase(self, phases, current_phase, target_phase):
        found = False
        for phase in phases:
            if phase.identifier == current_phase.identifier:
                # Found the current one, so any valid phase from here on out is the next one
                found = True
                continue

            if found and current_phase.identifier != target_phase.identifier:
                return phase

            if found and not phase.should_skip():
                # Yep, that's the one
                return phase

    def get_next_phase(self, current_phase, target_phase):
        return self._get_next_phase(self.phases, current_phase, target_phase)

    def get_previous_phase(self, current_phase, target_phase):
        return self._get_next_phase(reversed(self.phases), current_phase, target_phase)

    def prepare_current_phase(self, phase_identifier):
        current_phase = self.get_current_phase(phase_identifier)
        self.add_phase_attributes(current_phase)
        self.current_phase = current_phase
        return current_phase

    def add_phase_attributes(self, target_phase, current_phase=None):
        """"""
        Add phase instance attributes (previous, next, etc) to the given target phase,
        using the optional `current_phase` as the current phase for previous and next.

        This is exposed as a public API for the benefit of phases that need to do sub-phase
        initialization and dispatching, such as method phases.
        """"""
        current_phase = current_phase or target_phase
        target_phase.previous_phase = self.get_previous_phase(current_phase, target_phase)
        target_phase.next_phase = self.get_next_phase(current_phase, target_phase)
        target_phase.phases = self.phases
        if current_phase in self.phases:
            current_phase_index = self.phases.index(current_phase)
            # Set up attributes that are handy for the phase bar in the templates.
            for i, phase in enumerate(self.phases):
                setattr(phase, ""is_past"", i > current_phase_index)
                setattr(phase, ""is_current"", phase == current_phase)
                setattr(phase, ""is_future"", i < current_phase_index)
                setattr(phase, ""is_previous"", phase == target_phase.previous_phase)
                setattr(phase, ""is_next"", phase == target_phase.next_phase)
        return target_phase

    def reset(self):
        for phase in self.phases:
            phase.reset()

    def complete(self):
        """"""
        To be called from a phase (`self.checkout_process.complete()`) when the checkout process is complete.
        """"""
        self.reset()

    def get_phase_url(self, phase):
        # The self.view is optional for backward compatibility
        if not self.view:
            url_kwargs = {""phase"": phase.identifier}
            return reverse(""shuup:checkout"", kwargs=url_kwargs)
        return self.view.get_phase_url(phase)

    @property
    def basket(self):
        """"""
        The basket used in this checkout process.

        :rtype: shuup.front.basket.objects.BaseBasket
        """"""
        return get_basket(self.request)


class VerticalCheckoutProcess(CheckoutProcess):
    horizontal_template = False
",CWE-79,159.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from __future__ import unicode_literals

from django.conf.urls import url
from django.contrib.auth.decorators import login_required
from django.http.response import HttpResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.i18n import set_language
from itertools import chain

from shuup.apps.provides import get_provide_objects

from .views.basket import BasketView
from .views.category import AllCategoriesView, CategoryView
from .views.checkout import get_checkout_view
from .views.dashboard import DashboardView
from .views.index import IndexView
from .views.misc import (
    force_anonymous_contact,
    force_company_contact,
    force_person_contact,
    stop_impersonating,
    toggle_all_seeing,
)
from .views.order import OrderCompleteView
from .views.payment import ProcessPaymentView
from .views.product import ProductDetailView
from .views.upload import media_upload

# TODO: Check _not_here_yet URLs in this file


def _not_here_yet(request, *args, **kwargs):
    return HttpResponse(""Not here yet: %s (%r, %r)"" % (request.path, args, kwargs), status=410)


# Use a different js catalog function in front urlpatterns to prevent forcing
# the shop language settings in admin js catalog.
def front_javascript_catalog_all(request, domain=""djangojs""):
    from shuup.utils.i18n import javascript_catalog_all

    return javascript_catalog_all(request, domain)


checkout_view = get_checkout_view()


urlpatterns = [
    url(r""^set-language/$"", csrf_exempt(set_language), name=""set-language""),
    url(r""^i18n.js$"", front_javascript_catalog_all, name=""js-catalog""),
    url(r""^checkout/$"", checkout_view, name=""checkout""),
    url(r""^checkout/(?P<phase>.+)/$"", checkout_view, name=""checkout""),
    url(r""^basket/$"", csrf_exempt(BasketView.as_view()), name=""basket""),
    url(r""^dashboard/$"", login_required(DashboardView.as_view()), name=""dashboard""),
    url(r""^toggle-allseeing/$"", login_required(toggle_all_seeing), name=""toggle-all-seeing""),
    url(r""^force-anonymous-contact/$"", login_required(force_anonymous_contact), name=""force-anonymous-contact""),
    url(r""^force-company-contact/$"", login_required(force_company_contact), name=""force-company-contact""),
    url(r""^force-person-contact/$"", login_required(force_person_contact), name=""force-person-contact""),
    url(r""^stop-impersonating/$"", login_required(stop_impersonating), name=""stop-impersonating""),
    url(r""^upload-media/$"", login_required(media_upload), name=""media-upload""),
    url(
        r""^order/payment/(?P<pk>.+?)/(?P<key>.+?)/$"",
        csrf_exempt(ProcessPaymentView.as_view()),
        kwargs={""mode"": ""payment""},
        name=""order_process_payment"",
    ),
    url(
        r""^order/process-payment/(?P<pk>.+?)/(?P<key>.+?)/$"",
        csrf_exempt(ProcessPaymentView.as_view()),
        kwargs={""mode"": ""return""},
        name=""order_process_payment_return"",
    ),
    url(
        r""^order/payment-canceled/(?P<pk>.+?)/(?P<key>.+?)/$"",
        ProcessPaymentView.as_view(),
        kwargs={""mode"": ""cancel""},
        name=""order_payment_canceled"",
    ),
    url(r""^order/complete/(?P<pk>.+?)/(?P<key>.+?)/$"", csrf_exempt(OrderCompleteView.as_view()), name=""order_complete""),
    url(r""^order/verification/(?P<pk>.+?)/(?P<key>.+?)/$"", _not_here_yet, name=""order_requires_verification""),
    url(
        r""^order/get-attachment/(?P<order_pk>\d+)/(?P<key>.+?)/(?P<att_pk>\d+)/"",
        _not_here_yet,
        name=""secure_attachment"",
    ),
    url(r""^p/(?P<pk>\d+)-(?P<slug>.*)/$"", csrf_exempt(ProductDetailView.as_view()), name=""product""),
    url(
        r""^s/(?P<supplier_pk>\d+)-(?P<pk>\d+)-(?P<slug>.*)/$"",
        csrf_exempt(ProductDetailView.as_view()),
        name=""supplier-product"",
    ),
    url(r""^c/$"", csrf_exempt(AllCategoriesView.as_view()), name=""all-categories""),
    url(r""^c/(?P<pk>\d+)-(?P<slug>.*)/$"", csrf_exempt(CategoryView.as_view()), name=""category""),
]

# TODO: Document `front_urls_pre`, `front_urls` and `front_urls_post`.


def _get_extension_urlpatterns(provide_category):
    return chain(*get_provide_objects(provide_category))


app_name = ""shuup""
urlpatterns = list(
    chain(
        *(
            _get_extension_urlpatterns(""front_urls_pre""),
            urlpatterns,
            _get_extension_urlpatterns(""front_urls""),
            [url(r""^$"", IndexView.as_view(), name=""index"")],
            _get_extension_urlpatterns(""front_urls_post""),
        )
    )
)
",CWE-79,121.0,1
"from django.core.exceptions import ValidationError

from shuup.utils.django_compat import force_text

# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.


class Problem(Exception):
    """""" User-visible exception. """"""

    message = property(lambda self: self.args[0] if self.args else None)

    def __init__(self, message, title=None):
        super(Problem, self).__init__(message)
        self.title = title
        self.links = []

    def with_link(self, url, title):
        """"""
        Append a link to this Problem and return itself.

        This API is designed after `Exception.with_traceback()`,
        so you can fluently chain this in a `raise` statement::

            raise Problem(""Oops"").with_link(""..."", ""..."")

        :param url: URL string.
        :type url: str
        :param title: Title text.
        :type title: str
        :return: This same Problem.
        :rtype: shuup.utils.excs.Problem
        """"""
        self.links.append({""url"": url, ""title"": title})
        return self


class ExceptionalResponse(Exception):
    def __init__(self, response):
        self.response = response
        super(ExceptionalResponse, self).__init__(force_text(response))


def extract_messages(obj_list):
    """"""
    Extract ""messages"" from a list of exceptions or other objects.

    For ValidationErrors, `messages` are flattened into the output.
    For Exceptions, `args[0]` is added into the output.
    For other objects, `force_text` is called.

    :param obj_list: List of exceptions etc.
    :type obj_list: Iterable[object]
    :rtype: Iterable[str]
    """"""
    for obj in obj_list:
        if isinstance(obj, ValidationError):
            for msg in obj.messages:
                yield force_text(msg)
            continue
        if isinstance(obj, Exception):
            if len(obj.args):
                yield force_text(obj.args[0])
                continue
        yield force_text(obj)
",CWE-79,71.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from django.conf.urls import url

from shuup.xtheme.views.command import command_dispatch
from shuup.xtheme.views.editor import EditorView
from shuup.xtheme.views.extra import extra_view_dispatch
from shuup.xtheme.views.plugins import (
    get_category_products_highlight,
    get_product_cross_sell_highlight,
    get_product_highlight,
    get_prouduct_selections_highlight,
)

urlpatterns = [
    url(r""^xtheme/editor/$"", EditorView.as_view(), name=""xtheme_editor""),
    url(r""^xtheme/(?P<view>.+)/*$"", extra_view_dispatch, name=""xtheme_extra_view""),
    url(r""^xtheme/$"", command_dispatch, name=""xtheme""),
    url(
        r""^xtheme-prod-hl/(?P<plugin_type>.*)/(?P<cutoff_days>\d+)/(?P<count>\d+)/(?P<cache_timeout>\d+)/$"",
        get_product_highlight,
        name=""xtheme-product-highlight"",
    ),
    url(
        r""""""
            ^xtheme-prod-cross-sell-hl/
            (?P<product_id>.*)/(?P<relation_type>.*)/(?P<use_parents>\d+)/
            (?P<count>\d+)/(?P<cache_timeout>\d+)/$
        """""".strip(),
        get_product_cross_sell_highlight,
        name=""xtheme-product-cross-sells-highlight"",
    ),
    url(
        r""^xtheme-cat-products-hl/(?P<category_id>\d+)/(?P<count>\d+)/(?P<cache_timeout>\d+)/$"",
        get_category_products_highlight,
        name=""xtheme-category-products-highlight"",
    ),
    url(
        r""^xtheme-prod-selections-hl/(?P<product_ids>.*)/(?P<cache_timeout>\d+)/$"",
        get_prouduct_selections_highlight,
        name=""xtheme-product-selections-highlight"",
    ),
]
",CWE-79,49.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from django.http.response import HttpResponseRedirect

from shuup.utils.excs import Problem
from shuup.xtheme.editing import set_edit_mode


def handle_command(request, command):
    """"""
    Internal dispatch function.

    :param request: A request
    :type request: django.http.HttpRequest
    :param command: Command string
    :type command: str
    :return: A response
    :rtype: django.http.HttpResponse
    """"""
    path = request.POST.get(""path"") or request.META.get(""HTTP_REFERER"") or ""/""
    if command == ""edit_on"" or command == ""edit_off"":
        set_edit_mode(request, command.endswith(""_on""))
        return HttpResponseRedirect(path)


def command_dispatch(request):
    """"""
    Xtheme command dispatch view.

    :param request: A request
    :type request: django.http.HttpRequest
    :return: A response
    :rtype: django.http.HttpResponse
    """"""
    command = request.POST.get(""command"")
    if command:
        response = handle_command(request, command)
        if response:
            return response
    raise Problem(""Error! Unknown command: `%r`"" % command)
",CWE-79,46.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
import json
from django.http.response import HttpResponse, HttpResponseRedirect
from django.middleware.csrf import get_token
from django.utils.http import urlencode
from django.utils.translation import ugettext_lazy as _
from django.views.generic import TemplateView

from shuup.utils.excs import Problem
from shuup.xtheme import XTHEME_GLOBAL_VIEW_NAME
from shuup.xtheme._theme import get_theme_by_identifier
from shuup.xtheme.editing import could_edit
from shuup.xtheme.layout import Layout
from shuup.xtheme.layout.utils import get_provided_layouts
from shuup.xtheme.view_config import ViewConfig
from shuup.xtheme.views.forms import LayoutCellFormGroup

# since layouts will most likely break with multiple cells per row, we are
# limiting the amount.
ROW_CELL_LIMIT = 4


class EditorView(TemplateView):
    template_name = ""shuup/xtheme/editor.jinja""
    xtheme_injection = False  # We don't need the editing injection here, so opt-out
    changed = False  # Overridden in `save_layout`

    def _get_default_layout(self):
        try:
            return json.loads(self.request.GET[""default_config""])
        except (ValueError, KeyError):
            return None

    def get_context_data(self, **kwargs):  # doccov: ignore
        ctx = super(EditorView, self).get_context_data(**kwargs)
        ctx[""layout""] = self.layout
        ctx[""csrf_token_str""] = get_token(self.request)
        # ctx[""layout_debug""] = pformat(ctx[""layout""].serialize())
        ctx[""current_cell_coords""] = self.current_cell_coords
        ctx[""current_cell""] = self.current_cell
        ctx[""form""] = self.form
        ctx[""changed""] = self.changed
        ctx[""cell_limit""] = ROW_CELL_LIMIT
        return ctx

    def dispatch(self, request, *args, **kwargs):  # doccov: ignore
        if not could_edit(request):
            raise Problem(_(""No access to editing.""))
        self._populate_vars()
        if self.default_layout:
            self.view_config.save_default_placeholder_layout(self.placeholder_name, self.default_layout)
            # We saved the default layout, so get rid of the humongous GET arg and try again
            get_args = dict(self.request.GET.items())
            get_args.pop(""default_config"", None)
            global_type = get_args.pop(""global_type"", None)
            if global_type:
                get_args[""view""] = XTHEME_GLOBAL_VIEW_NAME
            # We are overriding the view with XTHEME_GLOBAL_VIEW_NAME if this is a global placeholder
            return HttpResponseRedirect(""%s?%s"" % (self.request.path, urlencode(get_args)))
        return super(EditorView, self).dispatch(request, *args, **kwargs)

    def post(self, request, *args, **kwargs):  # doccov: ignore
        command = request.POST.get(""command"")
        if command:
            dispatcher = getattr(self, ""dispatch_%s"" % command, None)
            if not callable(dispatcher):
                raise Problem(_(""Unknown command: `%s`."") % command)
            dispatch_kwargs = dict(request.POST.items())
            rv = dispatcher(**dispatch_kwargs)
            if rv:
                return rv
            self.request.method = ""GET""  # At this point, we won't want to cause form validation
            self.build_form()  # and it's not a bad idea to rebuild the form
            return super(EditorView, self).get(request, *args, **kwargs)

        if request.POST.get(""save"") and self.form and self.form.is_valid():
            self.form.save()
            self.save_layout()

            # after we save the new layout configs, make sure to reload the saved data in forms
            # so the returned get() response contains updated data
            self.build_form()

            if request.POST.get(""publish"") == ""1"":
                return self.dispatch_publish()

        return self.get(request, *args, **kwargs)

    def _populate_vars(self):
        theme = get_theme_by_identifier(self.request.GET[""theme""], self.request.shop)
        if not theme:
            raise Problem(_(""Unable to determine the current theme.""))
        view_name = self.request.GET[""view""]
        global_type = self.request.GET.get(""global_type"", None)
        self.view_config = ViewConfig(
            theme=theme,
            shop=self.request.shop,
            view_name=view_name,
            draft=True,
            global_type=global_type,
        )

        # Let's store the layout data key for save here
        self.layout_data_key = self.request.GET.get(""layout_data_key"", None)

        # Let's use the layout identifier passed by the view to
        # fetch correct layout
        layout_identifier = self.request.GET.get(""layout_identifier"", None)
        layout_cls = Layout
        for provided_layout in get_provided_layouts():
            if provided_layout.identifier == layout_identifier:
                layout_cls = provided_layout

        self.placeholder_name = self.request.GET[""ph""]
        self.default_layout = self._get_default_layout()
        self.layout = self.view_config.get_placeholder_layout(
            layout_cls=layout_cls,
            placeholder_name=self.placeholder_name,
            default_layout=self.default_layout,
            layout_data_key=self.layout_data_key,
        )
        (x, y) = self.current_cell_coords = (
            int(self.request.GET.get(""x"", -1)),
            int(self.request.GET.get(""y"", -1)),
        )
        self.current_cell = self.layout.get_cell(x=x, y=y)
        self.build_form()

    def build_form(self):
        if not self.current_cell:
            self.form = None
            return
        kwargs = {""layout_cell"": self.current_cell, ""theme"": self.view_config.theme, ""request"": self.request}
        if self.request.method == ""POST"":
            kwargs[""data""] = self.request.POST
            kwargs[""files""] = self.request.FILES
        self.form = LayoutCellFormGroup(**kwargs)

    def save_layout(self, layout=None):
        self.view_config.save_placeholder_layout(layout_data_key=self.layout_data_key, layout=(layout or self.layout))
        self.changed = True

    def dispatch_add_cell(self, y, **kwargs):
        y = int(y)
        if len(self.layout.rows[y].cells) >= ROW_CELL_LIMIT:
            raise ValueError(_(""Can't add more than %d cells in one row."") % ROW_CELL_LIMIT)

        if not (0 <= y < len(self.layout.rows)):
            # No need to raise an exception, really.
            # It must have been a honest mistake.
            return
        self.layout.rows[y].add_cell()
        self.save_layout()

    def dispatch_add_row(self, y=None, **kwargs):
        row = self.layout.insert_row(y)
        row.add_cell()  # For convenience, add a cell to the row.
        self.save_layout()

    def dispatch_del_row(self, y, **kwargs):
        self.layout.delete_row(y)
        self.save_layout()

    def dispatch_move_row_to_index(self, from_y, to_y, **kwargs):
        self.layout.move_row_to_index(from_y, to_y)
        self.save_layout()

    def dispatch_move_cell_to_position(self, from_x, from_y, to_x, to_y, **kwargs):
        self.layout.move_cell_to_position(from_x, from_y, to_x, to_y)
        self.save_layout()

    def dispatch_del_cell(self, x, y, **kwargs):
        self.layout.delete_cell(x, y)
        self.save_layout()

    def dispatch_change_plugin(self, plugin="""", **kwargs):
        if self.current_cell:
            if not plugin:
                plugin = None
            self.current_cell.plugin_identifier = plugin
            self.save_layout()

    def dispatch_publish(self, **kwargs):
        self.view_config.publish()
        return HttpResponse(""<html><script>parent.location.reload()</script>%s.</html>"" % _(""Published""))

    def dispatch_revert(self, **kwargs):
        self.view_config.revert()
        return HttpResponse(""<html><script>parent.location.reload()</script>%s.</html>"" % _(""Reverted""))
",CWE-79,196.0,1
"# -*- coding: utf-8 -*-
# This file is part of Shuup.
#
# Copyright (c) 2012-2021, Shuup Commerce Inc. All rights reserved.
#
# This source code is licensed under the OSL-3.0 license found in the
# LICENSE file in the root directory of this source tree.
from django.core.exceptions import ImproperlyConfigured
from django.core.signals import setting_changed
from django.http.response import HttpResponseNotFound

from shuup.xtheme._theme import get_current_theme

_VIEW_CACHE = {}


def clear_view_cache(**kwargs):
    _VIEW_CACHE.clear()


setting_changed.connect(clear_view_cache, dispatch_uid=""shuup.xtheme.views.extra.clear_view_cache"")


def _get_view_by_name(theme, view_name):
    view = theme.get_view(view_name)
    if hasattr(view, ""as_view""):  # Handle CBVs
        view = view.as_view()
    if view and not callable(view):
        raise ImproperlyConfigured(""Error! View `%r` is not callable."" % view)
    return view


def get_view_by_name(theme, view_name):
    if not theme:
        return None
    cache_key = (theme.identifier, view_name)
    if cache_key not in _VIEW_CACHE:
        view = _get_view_by_name(theme, view_name)
        _VIEW_CACHE[cache_key] = view
    else:
        view = _VIEW_CACHE[cache_key]
    return view


def extra_view_dispatch(request, view):
    """"""
    Dispatch to an Xtheme extra view.

    :param request: A request.
    :type request: django.http.HttpRequest
    :param view: View name.
    :type view: str
    :return: A response of some kind.
    :rtype: django.http.HttpResponse
    """"""
    theme = getattr(request, ""theme"", None) or get_current_theme(request.shop)
    view_func = get_view_by_name(theme, view)
    if not view_func:
        msg = ""Error! %s/%s: Not found."" % (getattr(theme, ""identifier"", None), view)
        return HttpResponseNotFound(msg)
    return view_func(request)
",CWE-79,62.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

# custom jinja filters

from __future__ import division, print_function, unicode_literals
import datetime
import mimetypes
from uuid import uuid4

from babel.dates import format_date
from flask import Blueprint, request, url_for
from flask_babel import get_locale
from flask_login import current_user

from . import logger


jinjia = Blueprint('jinjia', __name__)
log = logger.create()


# pagination links in jinja
@jinjia.app_template_filter('url_for_other_page')
def url_for_other_page(page):
    args = request.view_args.copy()
    args['page'] = page
    for get, val in request.args.items():
        args[get] = val
    return url_for(request.endpoint, **args)


# shortentitles to at longest nchar, shorten longer words if necessary
@jinjia.app_template_filter('shortentitle')
def shortentitle_filter(s, nchar=20):
    text = s.split()
    res = """"  # result
    suml = 0  # overall length
    for line in text:
        if suml >= 60:
            res += '...'
            break
        # if word longer than 20 chars truncate line and append '...', otherwise add whole word to result
        # string, and summarize total length to stop at chars given by nchar
        if len(line) > nchar:
            res += line[:(nchar-3)] + '[..] '
            suml += nchar+3
        else:
            res += line + ' '
            suml += len(line) + 1
    return res.strip()


@jinjia.app_template_filter('mimetype')
def mimetype_filter(val):
    return mimetypes.types_map.get('.' + val, 'application/octet-stream')


@jinjia.app_template_filter('formatdate')
def formatdate_filter(val):
    try:
        return format_date(val, format='medium', locale=get_locale())
    except AttributeError as e:
        log.error('Babel error: %s, Current user locale: %s, Current User: %s', e,
                  current_user.locale,
                  current_user.name
                  )
        return val


@jinjia.app_template_filter('formatdateinput')
def format_date_input(val):
    input_date = val.isoformat().split('T', 1)[0]  # Hack to support dates <1900
    return '' if input_date == ""0101-01-01"" else input_date


@jinjia.app_template_filter('strftime')
def timestamptodate(date, fmt=None):
    date = datetime.datetime.fromtimestamp(
        int(date)/1000
    )
    native = date.replace(tzinfo=None)
    if fmt:
        time_format = fmt
    else:
        time_format = '%d %m %Y - %H:%S'
    return native.strftime(time_format)


@jinjia.app_template_filter('yesno')
def yesno(value, yes, no):
    return yes if value else no


@jinjia.app_template_filter('formatfloat')
def formatfloat(value, decimals=1):
    value = 0 if not value else value
    return ('{0:.' + str(decimals) + 'f}').format(value).rstrip('0').rstrip('.')


@jinjia.app_template_filter('formatseriesindex')
def formatseriesindex_filter(series_index):
    if series_index:
        try:
            if int(series_index) - series_index == 0:
                return int(series_index)
            else:
                return series_index
        except ValueError:
            return series_index
    return 0

@jinjia.app_template_filter('uuidfilter')
def uuidfilter(var):
    return uuid4()


",CWE-79,137.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2012-2019  OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

from __future__ import absolute_import, division, print_function, unicode_literals
import sys
import os


# Insert local directories into path
if sys.version_info < (3, 0):
    sys.path.append(os.path.dirname(os.path.abspath(__file__.decode('utf-8'))))
    sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__.decode('utf-8'))), 'vendor'))
else:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'vendor'))


from cps import create_app
from cps import web_server
from cps.opds import opds
from cps.web import web
from cps.jinjia import jinjia
from cps.about import about
from cps.shelf import shelf
from cps.admin import admi
from cps.gdrive import gdrive
from cps.editbooks import editbook
from cps.remotelogin import remotelogin
from cps.search_metadata import meta
from cps.error_handler import init_errorhandler

try:
    from cps.kobo import kobo, get_kobo_activated
    from cps.kobo_auth import kobo_auth
    kobo_available = get_kobo_activated()
except ImportError:
    kobo_available = False

try:
    from cps.oauth_bb import oauth
    oauth_available = True
except ImportError:
    oauth_available = False


def main():
    app = create_app()

    init_errorhandler()

    app.register_blueprint(web)
    app.register_blueprint(opds)
    app.register_blueprint(jinjia)
    app.register_blueprint(about)
    app.register_blueprint(shelf)
    app.register_blueprint(admi)
    app.register_blueprint(remotelogin)
    app.register_blueprint(meta)
    app.register_blueprint(gdrive)
    app.register_blueprint(editbook)
    if kobo_available:
        app.register_blueprint(kobo)
        app.register_blueprint(kobo_auth)
    if oauth_available:
        app.register_blueprint(oauth)
    success = web_server.start()
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
",CWE-352,88.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

from __future__ import division, print_function, unicode_literals
import sys
import os
import mimetypes

from babel import Locale as LC
from babel import negotiate_locale
from babel.core import UnknownLocaleError
from flask import Flask, request, g
from flask_login import LoginManager
from flask_babel import Babel
from flask_principal import Principal

from . import config_sql, logger, cache_buster, cli, ub, db
from .reverseproxy import ReverseProxied
from .server import WebServer

try:
    import lxml
    lxml_present = True
except ImportError:
    lxml_present = False

mimetypes.init()
mimetypes.add_type('application/xhtml+xml', '.xhtml')
mimetypes.add_type('application/epub+zip', '.epub')
mimetypes.add_type('application/fb2+zip', '.fb2')
mimetypes.add_type('application/x-mobipocket-ebook', '.mobi')
mimetypes.add_type('application/x-mobipocket-ebook', '.prc')
mimetypes.add_type('application/vnd.amazon.ebook', '.azw')
mimetypes.add_type('application/x-mobi8-ebook', '.azw3')
mimetypes.add_type('application/x-cbr', '.cbr')
mimetypes.add_type('application/x-cbz', '.cbz')
mimetypes.add_type('application/x-cbt', '.cbt')
mimetypes.add_type('image/vnd.djvu', '.djvu')
mimetypes.add_type('application/mpeg', '.mpeg')
mimetypes.add_type('application/mpeg', '.mp3')
mimetypes.add_type('application/mp4', '.m4a')
mimetypes.add_type('application/mp4', '.m4b')
mimetypes.add_type('application/ogg', '.ogg')
mimetypes.add_type('application/ogg', '.oga')

app = Flask(__name__)
app.config.update(
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE='Lax',
    REMEMBER_COOKIE_SAMESITE='Lax',  # will be available in flask-login 0.5.1 earliest
)


lm = LoginManager()
lm.login_view = 'web.login'
lm.anonymous_user = ub.Anonymous
lm.session_protection = 'strong'

ub.init_db(cli.settingspath)
# pylint: disable=no-member
config = config_sql.load_configuration(ub.session)

web_server = WebServer()

babel = Babel()
_BABEL_TRANSLATIONS = set()

log = logger.create()

from . import services

db.CalibreDB.update_config(config)
db.CalibreDB.setup_db(config.config_calibre_dir, cli.settingspath)


calibre_db = db.CalibreDB()

def create_app():
    if sys.version_info < (3, 0):
        log.info(
            '*** Python2 is EOL since end of 2019, this version of Calibre-Web is no longer supporting Python2, please update your installation to Python3 ***')
        print(
            '*** Python2 is EOL since end of 2019, this version of Calibre-Web is no longer supporting Python2, please update your installation to Python3 ***')
        sys.exit(5)
    if not lxml_present:
        log.info('*** ""lxml"" is needed for calibre-web to run. Please install it using pip: ""pip install lxml"" ***')
        print('*** ""lxml"" is needed for calibre-web to run. Please install it using pip: ""pip install lxml"" ***')
        sys.exit(6)
    app.wsgi_app = ReverseProxied(app.wsgi_app)
    # For python2 convert path to unicode
    if sys.version_info < (3, 0):
        app.static_folder = app.static_folder.decode('utf-8')
        app.root_path = app.root_path.decode('utf-8')
        app.instance_path = app.instance_path.decode('utf-8')

    if os.environ.get('FLASK_DEBUG'):
        cache_buster.init_cache_busting(app)
    log.info('Starting Calibre Web...')

    Principal(app)
    lm.init_app(app)
    app.secret_key = os.getenv('SECRET_KEY', config_sql.get_flask_session_key(ub.session))

    web_server.init_app(app, config)

    babel.init_app(app)
    _BABEL_TRANSLATIONS.update(str(item) for item in babel.list_translations())
    _BABEL_TRANSLATIONS.add('en')

    if services.ldap:
        services.ldap.init_app(app, config)
    if services.goodreads_support:
        services.goodreads_support.connect(config.config_goodreads_api_key,
                                           config.config_goodreads_api_secret,
                                           config.config_use_goodreads)

    return app

@babel.localeselector
def get_locale():
    # if a user is logged in, use the locale from the user settings
    user = getattr(g, 'user', None)
    if user is not None and hasattr(user, ""locale""):
        if user.name != 'Guest':   # if the account is the guest account bypass the config lang settings
            return user.locale

    preferred = list()
    if request.accept_languages:
        for x in request.accept_languages.values():
            try:
                preferred.append(str(LC.parse(x.replace('-', '_'))))
            except (UnknownLocaleError, ValueError) as e:
                log.debug('Could not parse locale ""%s"": %s', x, e)

    return negotiate_locale(preferred or ['en'], _BABEL_TRANSLATIONS)


@babel.timezoneselector
def get_timezone():
    user = getattr(g, 'user', None)
    return user.timezone if user else None


from .updater import Updater
updater_thread = Updater()
updater_thread.start()
",CWE-352,166.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

from __future__ import division, print_function, unicode_literals
import sys
import platform
import sqlite3
from collections import OrderedDict

import babel, pytz, requests, sqlalchemy
import werkzeug, flask, flask_login, flask_principal, jinja2
from flask_babel import gettext as _

from . import db, calibre_db, converter, uploader, server, isoLanguages, constants
from .render_template import render_title_template
try:
    from flask_login import __version__ as flask_loginVersion
except ImportError:
    from flask_login.__about__ import __version__ as flask_loginVersion
try:
    # pylint: disable=unused-import
    import unidecode
    # _() necessary to make babel aware of string for translation
    unidecode_version = _(u'installed')
except ImportError:
    unidecode_version = _(u'not installed')

try:
    from flask_dance import __version__ as flask_danceVersion
except ImportError:
    flask_danceVersion = None

try:
    from greenlet import __version__ as greenlet_Version
except ImportError:
    greenlet_Version = None

try:
    from scholarly import scholarly
    scholarly_version = _(u'installed')
except ImportError:
    scholarly_version = _(u'not installed')

from . import services

about = flask.Blueprint('about', __name__)


_VERSIONS = OrderedDict(
    Platform = '{0[0]} {0[2]} {0[3]} {0[4]} {0[5]}'.format(platform.uname()),
    Python=sys.version,
    Calibre_Web=constants.STABLE_VERSION['version'] + ' - '
                + constants.NIGHTLY_VERSION[0].replace('%','%%') + ' - '
                + constants.NIGHTLY_VERSION[1].replace('%','%%'),
    WebServer=server.VERSION,
    Flask=flask.__version__,
    Flask_Login=flask_loginVersion,
    Flask_Principal=flask_principal.__version__,
    Werkzeug=werkzeug.__version__,
    Babel=babel.__version__,
    Jinja2=jinja2.__version__,
    Requests=requests.__version__,
    SqlAlchemy=sqlalchemy.__version__,
    pySqlite=sqlite3.version,
    SQLite=sqlite3.sqlite_version,
    iso639=isoLanguages.__version__,
    pytz=pytz.__version__,
    Unidecode = unidecode_version,
    Scholarly = scholarly_version,
    Flask_SimpleLDAP =  u'installed' if bool(services.ldap) else None,
    python_LDAP = services.ldapVersion if bool(services.ldapVersion) else None,
    Goodreads = u'installed' if bool(services.goodreads_support) else None,
    jsonschema = services.SyncToken.__version__  if bool(services.SyncToken) else None,
    flask_dance = flask_danceVersion,
    greenlet = greenlet_Version
)
_VERSIONS.update(uploader.get_versions())


def collect_stats():
    _VERSIONS['ebook converter'] = _(converter.get_calibre_version())
    _VERSIONS['unrar'] = _(converter.get_unrar_version())
    _VERSIONS['kepubify'] = _(converter.get_kepubify_version())
    return _VERSIONS

@about.route(""/stats"")
@flask_login.login_required
def stats():
    counter = calibre_db.session.query(db.Books).count()
    authors = calibre_db.session.query(db.Authors).count()
    categorys = calibre_db.session.query(db.Tags).count()
    series = calibre_db.session.query(db.Series).count()
    return render_title_template('stats.html', bookcounter=counter, authorcounter=authors, versions=collect_stats(),
                                 categorycounter=categorys, seriecounter=series, title=_(u""Statistics""), page=""stat"")


",CWE-352,116.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 shavitmichael, OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.


""""""This module is used to control authentication/authorization of Kobo sync requests.
This module also includes research notes into the auth protocol used by Kobo devices.

Log-in:
When first booting a Kobo device the user must sign into a Kobo (or affiliate) account.
Upon successful sign-in, the user is redirected to
    https://auth.kobobooks.com/CrossDomainSignIn?id=<some id>
which serves the following response:
    <script type='text/javascript'>
        location.href='kobo://UserAuthenticated?userId=<redacted>&userKey<redacted>&email=<redacted>&returnUrl=https%3a%2f%2fwww.kobo.com';
    </script>
And triggers the insertion of a userKey into the device's User table.

Together, the device's DeviceId and UserKey act as an *irrevocable* authentication
token to most (if not all) Kobo APIs. In fact, in most cases only the UserKey is
required to authorize the API call.

Changing Kobo password *does not* invalidate user keys! This is apparently a known
issue for a few years now https://www.mobileread.com/forums/showpost.php?p=3476851&postcount=13
(although this poster hypothesised that Kobo could blacklist a DeviceId, many endpoints
will still grant access given the userkey.)

Official Kobo Store Api authorization:
* For most of the endpoints we care about (sync, metadata, tags, etc), the userKey is
passed in the x-kobo-userkey header, and is sufficient to authorize the API call.
* Some endpoints (e.g: AnnotationService) instead make use of Bearer tokens pass through
an authorization header. To get a BearerToken, the device makes a POST request to the
v1/auth/device endpoint with the secret UserKey and the device's DeviceId.
* The book download endpoint passes an auth token as a URL param instead of a header.

Our implementation:
We pretty much ignore all of the above. To authenticate the user, we generate a random
and unique token that they append to the CalibreWeb Url when setting up the api_store
setting on the device.
Thus, every request from the device to the api_store will hit CalibreWeb with the
auth_token in the url (e.g: https://mylibrary.com/<auth_token>/v1/library/sync).
In addition, once authenticated we also set the login cookie on the response that will
be sent back for the duration of the session to authorize subsequent API calls (in
particular calls to non-Kobo specific endpoints such as the CalibreWeb book download).
""""""

from binascii import hexlify
from datetime import datetime
from os import urandom

from flask import g, Blueprint, url_for, abort, request
from flask_login import login_user, current_user, login_required
from flask_babel import gettext as _

from . import logger, config, calibre_db, db, helper, ub, lm
from .render_template import render_title_template

try:
    from functools import wraps
except ImportError:
    pass  # We're not using Python 3


log = logger.create()


def register_url_value_preprocessor(kobo):
    @kobo.url_value_preprocessor
    # pylint: disable=unused-variable
    def pop_auth_token(__, values):
        g.auth_token = values.pop(""auth_token"")


def disable_failed_auth_redirect_for_blueprint(bp):
    lm.blueprint_login_views[bp.name] = None


def get_auth_token():
    if ""auth_token"" in g:
        return g.get(""auth_token"")
    else:
        return None


def requires_kobo_auth(f):
    @wraps(f)
    def inner(*args, **kwargs):
        auth_token = get_auth_token()
        if auth_token is not None:
            user = (
                ub.session.query(ub.User)
                .join(ub.RemoteAuthToken)
                .filter(ub.RemoteAuthToken.auth_token == auth_token).filter(ub.RemoteAuthToken.token_type==1)
                .first()
            )
            if user is not None:
                login_user(user)
                return f(*args, **kwargs)
            log.debug(""Received Kobo request without a recognizable auth token."")
            return abort(401)
    return inner


kobo_auth = Blueprint(""kobo_auth"", __name__, url_prefix=""/kobo_auth"")


@kobo_auth.route(""/generate_auth_token/<int:user_id>"")
@login_required
def generate_auth_token(user_id):
    host_list = request.host.rsplit(':')
    if len(host_list) == 1:
        host = ':'.join(host_list)
    else:
        host = ':'.join(host_list[0:-1])
    if host.startswith('127.') or host.lower() == 'localhost' or host.startswith('[::ffff:7f'):
        warning = _('PLease access calibre-web from non localhost to get valid api_endpoint for kobo device')
        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            warning = warning
        )
    else:
        # Invalidate any prevously generated Kobo Auth token for this user.
        auth_token = ub.session.query(ub.RemoteAuthToken).filter(
            ub.RemoteAuthToken.user_id == user_id
        ).filter(ub.RemoteAuthToken.token_type==1).first()

        if not auth_token:
            auth_token = ub.RemoteAuthToken()
            auth_token.user_id = user_id
            auth_token.expiration = datetime.max
            auth_token.auth_token = (hexlify(urandom(16))).decode(""utf-8"")
            auth_token.token_type = 1

            ub.session.add(auth_token)
            ub.session_commit()

        books = calibre_db.session.query(db.Books).join(db.Data).all()

        for book in books:
            formats = [data.format for data in book.data]
            if not 'KEPUB' in formats and config.config_kepubifypath and 'EPUB' in formats:
                helper.convert_book_format(book.id, config.config_calibre_dir, 'EPUB', 'KEPUB', current_user.name)

        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            kobo_auth_url=url_for(
                ""kobo.TopLevelEndpoint"", auth_token=auth_token.auth_token, _external=True
            ),
            warning = False
        )


@kobo_auth.route(""/deleteauthtoken/<int:user_id>"")
@login_required
def delete_auth_token(user_id):
    # Invalidate any prevously generated Kobo Auth token for this user.
    ub.session.query(ub.RemoteAuthToken).filter(ub.RemoteAuthToken.user_id == user_id)\
        .filter(ub.RemoteAuthToken.token_type==1).delete()

    return ub.session_commit()
",CWE-352,178.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 shavitmichael, OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.


""""""This module is used to control authentication/authorization of Kobo sync requests.
This module also includes research notes into the auth protocol used by Kobo devices.

Log-in:
When first booting a Kobo device the user must sign into a Kobo (or affiliate) account.
Upon successful sign-in, the user is redirected to
    https://auth.kobobooks.com/CrossDomainSignIn?id=<some id>
which serves the following response:
    <script type='text/javascript'>
        location.href='kobo://UserAuthenticated?userId=<redacted>&userKey<redacted>&email=<redacted>&returnUrl=https%3a%2f%2fwww.kobo.com';
    </script>
And triggers the insertion of a userKey into the device's User table.

Together, the device's DeviceId and UserKey act as an *irrevocable* authentication
token to most (if not all) Kobo APIs. In fact, in most cases only the UserKey is
required to authorize the API call.

Changing Kobo password *does not* invalidate user keys! This is apparently a known
issue for a few years now https://www.mobileread.com/forums/showpost.php?p=3476851&postcount=13
(although this poster hypothesised that Kobo could blacklist a DeviceId, many endpoints
will still grant access given the userkey.)

Official Kobo Store Api authorization:
* For most of the endpoints we care about (sync, metadata, tags, etc), the userKey is
passed in the x-kobo-userkey header, and is sufficient to authorize the API call.
* Some endpoints (e.g: AnnotationService) instead make use of Bearer tokens pass through
an authorization header. To get a BearerToken, the device makes a POST request to the
v1/auth/device endpoint with the secret UserKey and the device's DeviceId.
* The book download endpoint passes an auth token as a URL param instead of a header.

Our implementation:
We pretty much ignore all of the above. To authenticate the user, we generate a random
and unique token that they append to the CalibreWeb Url when setting up the api_store
setting on the device.
Thus, every request from the device to the api_store will hit CalibreWeb with the
auth_token in the url (e.g: https://mylibrary.com/<auth_token>/v1/library/sync).
In addition, once authenticated we also set the login cookie on the response that will
be sent back for the duration of the session to authorize subsequent API calls (in
particular calls to non-Kobo specific endpoints such as the CalibreWeb book download).
""""""

from binascii import hexlify
from datetime import datetime
from os import urandom
from functools import wraps

from flask import g, Blueprint, url_for, abort, request
from flask_login import login_user, current_user, login_required
from flask_babel import gettext as _

from . import logger, config, calibre_db, db, helper, ub, lm
from .render_template import render_title_template


log = logger.create()


def register_url_value_preprocessor(kobo):
    @kobo.url_value_preprocessor
    # pylint: disable=unused-variable
    def pop_auth_token(__, values):
        g.auth_token = values.pop(""auth_token"")


def disable_failed_auth_redirect_for_blueprint(bp):
    lm.blueprint_login_views[bp.name] = None


def get_auth_token():
    if ""auth_token"" in g:
        return g.get(""auth_token"")
    else:
        return None


def requires_kobo_auth(f):
    @wraps(f)
    def inner(*args, **kwargs):
        auth_token = get_auth_token()
        if auth_token is not None:
            user = (
                ub.session.query(ub.User)
                .join(ub.RemoteAuthToken)
                .filter(ub.RemoteAuthToken.auth_token == auth_token).filter(ub.RemoteAuthToken.token_type==1)
                .first()
            )
            if user is not None:
                login_user(user)
                return f(*args, **kwargs)
            log.debug(""Received Kobo request without a recognizable auth token."")
            return abort(401)
    return inner


kobo_auth = Blueprint(""kobo_auth"", __name__, url_prefix=""/kobo_auth"")


@kobo_auth.route(""/generate_auth_token/<int:user_id>"")
@login_required
def generate_auth_token(user_id):
    host_list = request.host.rsplit(':')
    if len(host_list) == 1:
        host = ':'.join(host_list)
    else:
        host = ':'.join(host_list[0:-1])
    if host.startswith('127.') or host.lower() == 'localhost' or host.startswith('[::ffff:7f'):
        warning = _('PLease access calibre-web from non localhost to get valid api_endpoint for kobo device')
        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            warning = warning
        )
    else:
        # Invalidate any prevously generated Kobo Auth token for this user.
        auth_token = ub.session.query(ub.RemoteAuthToken).filter(
            ub.RemoteAuthToken.user_id == user_id
        ).filter(ub.RemoteAuthToken.token_type==1).first()

        if not auth_token:
            auth_token = ub.RemoteAuthToken()
            auth_token.user_id = user_id
            auth_token.expiration = datetime.max
            auth_token.auth_token = (hexlify(urandom(16))).decode(""utf-8"")
            auth_token.token_type = 1

            ub.session.add(auth_token)
            ub.session_commit()

        books = calibre_db.session.query(db.Books).join(db.Data).all()

        for book in books:
            formats = [data.format for data in book.data]
            if not 'KEPUB' in formats and config.config_kepubifypath and 'EPUB' in formats:
                helper.convert_book_format(book.id, config.config_calibre_dir, 'EPUB', 'KEPUB', current_user.name)

        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            kobo_auth_url=url_for(
                ""kobo.TopLevelEndpoint"", auth_token=auth_token.auth_token, _external=True
            ),
            warning = False
        )


@kobo_auth.route(""/deleteauthtoken/<int:user_id>"", methods=[""POST""])
@login_required
def delete_auth_token(user_id):
    # Invalidate any prevously generated Kobo Auth token for this user.
    ub.session.query(ub.RemoteAuthToken).filter(ub.RemoteAuthToken.user_id == user_id)\
        .filter(ub.RemoteAuthToken.token_type==1).delete()

    return ub.session_commit()
",CWE-918,174.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 shavitmichael, OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.


""""""This module is used to control authentication/authorization of Kobo sync requests.
This module also includes research notes into the auth protocol used by Kobo devices.

Log-in:
When first booting a Kobo device the user must sign into a Kobo (or affiliate) account.
Upon successful sign-in, the user is redirected to
    https://auth.kobobooks.com/CrossDomainSignIn?id=<some id>
which serves the following response:
    <script type='text/javascript'>
        location.href='kobo://UserAuthenticated?userId=<redacted>&userKey<redacted>&email=<redacted>&returnUrl=https%3a%2f%2fwww.kobo.com';
    </script>
And triggers the insertion of a userKey into the device's User table.

Together, the device's DeviceId and UserKey act as an *irrevocable* authentication
token to most (if not all) Kobo APIs. In fact, in most cases only the UserKey is
required to authorize the API call.

Changing Kobo password *does not* invalidate user keys! This is apparently a known
issue for a few years now https://www.mobileread.com/forums/showpost.php?p=3476851&postcount=13
(although this poster hypothesised that Kobo could blacklist a DeviceId, many endpoints
will still grant access given the userkey.)

Official Kobo Store Api authorization:
* For most of the endpoints we care about (sync, metadata, tags, etc), the userKey is
passed in the x-kobo-userkey header, and is sufficient to authorize the API call.
* Some endpoints (e.g: AnnotationService) instead make use of Bearer tokens pass through
an authorization header. To get a BearerToken, the device makes a POST request to the
v1/auth/device endpoint with the secret UserKey and the device's DeviceId.
* The book download endpoint passes an auth token as a URL param instead of a header.

Our implementation:
We pretty much ignore all of the above. To authenticate the user, we generate a random
and unique token that they append to the CalibreWeb Url when setting up the api_store
setting on the device.
Thus, every request from the device to the api_store will hit CalibreWeb with the
auth_token in the url (e.g: https://mylibrary.com/<auth_token>/v1/library/sync).
In addition, once authenticated we also set the login cookie on the response that will
be sent back for the duration of the session to authorize subsequent API calls (in
particular calls to non-Kobo specific endpoints such as the CalibreWeb book download).
""""""

from binascii import hexlify
from datetime import datetime
from os import urandom
from functools import wraps

from flask import g, Blueprint, url_for, abort, request
from flask_login import login_user, current_user, login_required
from flask_babel import gettext as _

from . import logger, config, calibre_db, db, helper, ub, lm
from .render_template import render_title_template


log = logger.create()


def register_url_value_preprocessor(kobo):
    @kobo.url_value_preprocessor
    # pylint: disable=unused-variable
    def pop_auth_token(__, values):
        g.auth_token = values.pop(""auth_token"")


def disable_failed_auth_redirect_for_blueprint(bp):
    lm.blueprint_login_views[bp.name] = None


def get_auth_token():
    if ""auth_token"" in g:
        return g.get(""auth_token"")
    else:
        return None


def requires_kobo_auth(f):
    @wraps(f)
    def inner(*args, **kwargs):
        auth_token = get_auth_token()
        if auth_token is not None:
            user = (
                ub.session.query(ub.User)
                .join(ub.RemoteAuthToken)
                .filter(ub.RemoteAuthToken.auth_token == auth_token).filter(ub.RemoteAuthToken.token_type==1)
                .first()
            )
            if user is not None:
                login_user(user)
                return f(*args, **kwargs)
            log.debug(""Received Kobo request without a recognizable auth token."")
            return abort(401)
    return inner


kobo_auth = Blueprint(""kobo_auth"", __name__, url_prefix=""/kobo_auth"")


@kobo_auth.route(""/generate_auth_token/<int:user_id>"")
@login_required
def generate_auth_token(user_id):
    host_list = request.host.rsplit(':')
    if len(host_list) == 1:
        host = ':'.join(host_list)
    else:
        host = ':'.join(host_list[0:-1])
    if host.startswith('127.') or host.lower() == 'localhost' or host.startswith('[::ffff:7f'):
        warning = _('PLease access calibre-web from non localhost to get valid api_endpoint for kobo device')
        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            warning = warning
        )
    else:
        # Invalidate any prevously generated Kobo Auth token for this user.
        auth_token = ub.session.query(ub.RemoteAuthToken).filter(
            ub.RemoteAuthToken.user_id == user_id
        ).filter(ub.RemoteAuthToken.token_type==1).first()

        if not auth_token:
            auth_token = ub.RemoteAuthToken()
            auth_token.user_id = user_id
            auth_token.expiration = datetime.max
            auth_token.auth_token = (hexlify(urandom(16))).decode(""utf-8"")
            auth_token.token_type = 1

            ub.session.add(auth_token)
            ub.session_commit()

        books = calibre_db.session.query(db.Books).join(db.Data).all()

        for book in books:
            formats = [data.format for data in book.data]
            if not 'KEPUB' in formats and config.config_kepubifypath and 'EPUB' in formats:
                helper.convert_book_format(book.id, config.config_calibre_dir, 'EPUB', 'KEPUB', current_user.name)

        return render_title_template(
            ""generate_kobo_auth_url.html"",
            title=_(u""Kobo Setup""),
            kobo_auth_url=url_for(
                ""kobo.TopLevelEndpoint"", auth_token=auth_token.auth_token, _external=True
            ),
            warning = False
        )


@kobo_auth.route(""/deleteauthtoken/<int:user_id>"", methods=[""POST""])
@login_required
def delete_auth_token(user_id):
    # Invalidate any prevously generated Kobo Auth token for this user.
    ub.session.query(ub.RemoteAuthToken).filter(ub.RemoteAuthToken.user_id == user_id)\
        .filter(ub.RemoteAuthToken.token_type==1).delete()

    return ub.session_commit()
",CWE-284,174.0,1
"# -*- coding: utf-8 -*-

#   This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#     Copyright (C) 2019 OzzieIsaacs, pwr
#
#   This program is free software: you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation, either version 3 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program. If not, see <http://www.gnu.org/licenses/>.

import sys
import os
from collections import namedtuple
from sqlalchemy import __version__ as sql_version

sqlalchemy_version2 = ([int(x) for x in sql_version.split('.')] >= [2,0,0])

# if installed via pip this variable is set to true (empty file with name .HOMEDIR present)
HOME_CONFIG = os.path.isfile(os.path.join(os.path.dirname(os.path.abspath(__file__)), '.HOMEDIR'))

#In executables updater is not available, so variable is set to False there
UPDATER_AVAILABLE = True

# Base dir is parent of current file, necessary if called from different folder
BASE_DIR            = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)),os.pardir))
STATIC_DIR          = os.path.join(BASE_DIR, 'cps', 'static')
TEMPLATES_DIR       = os.path.join(BASE_DIR, 'cps', 'templates')
TRANSLATIONS_DIR    = os.path.join(BASE_DIR, 'cps', 'translations')

if HOME_CONFIG:
    home_dir = os.path.join(os.path.expanduser(""~""),"".calibre-web"")
    if not os.path.exists(home_dir):
        os.makedirs(home_dir)
    CONFIG_DIR = os.environ.get('CALIBRE_DBPATH', home_dir)
else:
    CONFIG_DIR = os.environ.get('CALIBRE_DBPATH', BASE_DIR)


ROLE_USER               = 0 << 0
ROLE_ADMIN              = 1 << 0
ROLE_DOWNLOAD           = 1 << 1
ROLE_UPLOAD             = 1 << 2
ROLE_EDIT               = 1 << 3
ROLE_PASSWD             = 1 << 4
ROLE_ANONYMOUS          = 1 << 5
ROLE_EDIT_SHELFS        = 1 << 6
ROLE_DELETE_BOOKS       = 1 << 7
ROLE_VIEWER             = 1 << 8

ALL_ROLES = {
                ""admin_role"": ROLE_ADMIN,
                ""download_role"": ROLE_DOWNLOAD,
                ""upload_role"": ROLE_UPLOAD,
                ""edit_role"": ROLE_EDIT,
                ""passwd_role"": ROLE_PASSWD,
                ""edit_shelf_role"": ROLE_EDIT_SHELFS,
                ""delete_role"": ROLE_DELETE_BOOKS,
                ""viewer_role"": ROLE_VIEWER,
            }

DETAIL_RANDOM           = 1 <<  0
SIDEBAR_LANGUAGE        = 1 <<  1
SIDEBAR_SERIES          = 1 <<  2
SIDEBAR_CATEGORY        = 1 <<  3
SIDEBAR_HOT             = 1 <<  4
SIDEBAR_RANDOM          = 1 <<  5
SIDEBAR_AUTHOR          = 1 <<  6
SIDEBAR_BEST_RATED      = 1 <<  7
SIDEBAR_READ_AND_UNREAD = 1 <<  8
SIDEBAR_RECENT          = 1 <<  9
SIDEBAR_SORTED          = 1 << 10
MATURE_CONTENT          = 1 << 11
SIDEBAR_PUBLISHER       = 1 << 12
SIDEBAR_RATING          = 1 << 13
SIDEBAR_FORMAT          = 1 << 14
SIDEBAR_ARCHIVED        = 1 << 15
SIDEBAR_DOWNLOAD        = 1 << 16
SIDEBAR_LIST            = 1 << 17

sidebar_settings = {
                ""detail_random"": DETAIL_RANDOM,
                ""sidebar_language"": SIDEBAR_LANGUAGE,
                ""sidebar_series"": SIDEBAR_SERIES,
                ""sidebar_category"": SIDEBAR_CATEGORY,
                ""sidebar_random"": SIDEBAR_RANDOM,
                ""sidebar_author"": SIDEBAR_AUTHOR,
                ""sidebar_best_rated"": SIDEBAR_BEST_RATED,
                ""sidebar_read_and_unread"": SIDEBAR_READ_AND_UNREAD,
                ""sidebar_recent"": SIDEBAR_RECENT,
                ""sidebar_sorted"": SIDEBAR_SORTED,
                ""sidebar_publisher"": SIDEBAR_PUBLISHER,
                ""sidebar_rating"": SIDEBAR_RATING,
                ""sidebar_format"": SIDEBAR_FORMAT,
                ""sidebar_archived"": SIDEBAR_ARCHIVED,
                ""sidebar_download"": SIDEBAR_DOWNLOAD,
                ""sidebar_list"": SIDEBAR_LIST,
            }


ADMIN_USER_ROLES        = sum(r for r in ALL_ROLES.values()) & ~ROLE_ANONYMOUS
ADMIN_USER_SIDEBAR      = (SIDEBAR_LIST << 1) - 1

UPDATE_STABLE       = 0 << 0
AUTO_UPDATE_STABLE  = 1 << 0
UPDATE_NIGHTLY      = 1 << 1
AUTO_UPDATE_NIGHTLY = 1 << 2

LOGIN_STANDARD      = 0
LOGIN_LDAP          = 1
LOGIN_OAUTH         = 2

LDAP_AUTH_ANONYMOUS      = 0
LDAP_AUTH_UNAUTHENTICATE = 1
LDAP_AUTH_SIMPLE         = 0

DEFAULT_MAIL_SERVER = ""mail.example.org""

DEFAULT_PASSWORD    = ""admin123""  # nosec
DEFAULT_PORT        = 8083
env_CALIBRE_PORT = os.environ.get(""CALIBRE_PORT"", DEFAULT_PORT)
try:
    DEFAULT_PORT = int(env_CALIBRE_PORT)
except ValueError:
    print('Environment variable CALIBRE_PORT has invalid value (%s), faling back to default (8083)' % env_CALIBRE_PORT)
del env_CALIBRE_PORT


EXTENSIONS_AUDIO    = {'mp3', 'mp4', 'ogg', 'opus', 'wav', 'flac', 'm4a', 'm4b'}
EXTENSIONS_CONVERT_FROM  = ['pdf', 'epub', 'mobi', 'azw3', 'docx', 'rtf', 'fb2', 'lit', 'lrf', 'txt', 'htmlz', 'rtf', 'odt','cbz','cbr']
EXTENSIONS_CONVERT_TO  = ['pdf', 'epub', 'mobi', 'azw3', 'docx', 'rtf', 'fb2', 'lit', 'lrf', 'txt', 'htmlz', 'rtf', 'odt']
EXTENSIONS_UPLOAD   = {'txt', 'pdf', 'epub', 'kepub', 'mobi', 'azw', 'azw3', 'cbr', 'cbz', 'cbt', 'djvu', 'prc', 'doc', 'docx',
                       'fb2', 'html', 'rtf', 'lit', 'odt', 'mp3', 'mp4', 'ogg', 'opus', 'wav', 'flac', 'm4a', 'm4b'}


def has_flag(value, bit_flag):
    return bit_flag == (bit_flag & (value or 0))

def selected_roles(dictionary):
    return sum(v for k, v in ALL_ROLES.items() if k in dictionary)


# :rtype: BookMeta
BookMeta = namedtuple('BookMeta', 'file_path, extension, title, author, cover, description, tags, series, '
                                  'series_id, languages, publisher')

STABLE_VERSION = {'version': '0.6.16 Beta'}

NIGHTLY_VERSION = {}
NIGHTLY_VERSION[0] = '$Format:%H$'
NIGHTLY_VERSION[1] = '$Format:%cI$'
# NIGHTLY_VERSION[0] = 'bb7d2c6273ae4560e83950d36d64533343623a57'
# NIGHTLY_VERSION[1] = '2018-09-09T10:13:08+02:00'


# clean-up the module namespace
del sys, os, namedtuple
",CWE-863,165.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2012-2019  OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.
try:
    from gevent import monkey
    monkey.patch_all()
except ImportError:
    pass

import sys
import os


# Insert local directories into path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'vendor'))


from cps import create_app
from cps import web_server
from cps.opds import opds
from cps.web import web
from cps.jinjia import jinjia
from cps.about import about
from cps.shelf import shelf
from cps.admin import admi
from cps.gdrive import gdrive
from cps.editbooks import editbook
from cps.remotelogin import remotelogin
from cps.search_metadata import meta
from cps.error_handler import init_errorhandler

try:
    from cps.kobo import kobo, get_kobo_activated
    from cps.kobo_auth import kobo_auth
    kobo_available = get_kobo_activated()
except (ImportError, AttributeError):   # Catch also error for not installed flask-WTF (missing csrf decorator)
    kobo_available = False

try:
    from cps.oauth_bb import oauth
    oauth_available = True
except ImportError:
    oauth_available = False


def main():
    app = create_app()

    init_errorhandler()

    app.register_blueprint(web)
    app.register_blueprint(opds)
    app.register_blueprint(jinjia)
    app.register_blueprint(about)
    app.register_blueprint(shelf)
    app.register_blueprint(admi)
    app.register_blueprint(remotelogin)
    app.register_blueprint(meta)
    app.register_blueprint(gdrive)
    app.register_blueprint(editbook)
    if kobo_available:
        app.register_blueprint(kobo)
        app.register_blueprint(kobo_auth)
    if oauth_available:
        app.register_blueprint(oauth)
    success = web_server.start()
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
",CWE-918,88.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.
__package__ = ""cps""

import sys
import os
import mimetypes

from babel import Locale as LC
from babel import negotiate_locale
from babel.core import UnknownLocaleError
from flask import Flask, request, g
from .MyLoginManager import MyLoginManager
from flask_babel import Babel
from flask_principal import Principal

from . import config_sql, logger, cache_buster, cli, ub, db
from .reverseproxy import ReverseProxied
from .server import WebServer
from .dep_check import dependency_check

try:
    import lxml
    lxml_present = True
except ImportError:
    lxml_present = False

try:
    from flask_wtf.csrf import CSRFProtect
    wtf_present = True
except ImportError:
    wtf_present = False

mimetypes.init()
mimetypes.add_type('application/xhtml+xml', '.xhtml')
mimetypes.add_type('application/epub+zip', '.epub')
mimetypes.add_type('application/fb2+zip', '.fb2')
mimetypes.add_type('application/x-mobipocket-ebook', '.mobi')
mimetypes.add_type('application/x-mobipocket-ebook', '.prc')
mimetypes.add_type('application/vnd.amazon.ebook', '.azw')
mimetypes.add_type('application/x-mobi8-ebook', '.azw3')
mimetypes.add_type('application/x-cbr', '.cbr')
mimetypes.add_type('application/x-cbz', '.cbz')
mimetypes.add_type('application/x-cbt', '.cbt')
mimetypes.add_type('image/vnd.djvu', '.djvu')
mimetypes.add_type('application/mpeg', '.mpeg')
mimetypes.add_type('application/mpeg', '.mp3')
mimetypes.add_type('application/mp4', '.m4a')
mimetypes.add_type('application/mp4', '.m4b')
mimetypes.add_type('application/ogg', '.ogg')
mimetypes.add_type('application/ogg', '.oga')
mimetypes.add_type('text/css', '.css')
mimetypes.add_type('text/javascript; charset=UTF-8', '.js')

app = Flask(__name__)
app.config.update(
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE='Lax',
    REMEMBER_COOKIE_SAMESITE='Lax',  # will be available in flask-login 0.5.1 earliest
    WTF_CSRF_SSL_STRICT=False
)


lm = MyLoginManager()
lm.login_view = 'web.login'
lm.anonymous_user = ub.Anonymous
lm.session_protection = 'strong'

if wtf_present:
    csrf = CSRFProtect()
    csrf.init_app(app)
else:
    csrf = None

ub.init_db(cli.settingspath)
# pylint: disable=no-member
config = config_sql.load_configuration(ub.session)

web_server = WebServer()

babel = Babel()
_BABEL_TRANSLATIONS = set()

log = logger.create()


from . import services

db.CalibreDB.update_config(config)
db.CalibreDB.setup_db(config.config_calibre_dir, cli.settingspath)


calibre_db = db.CalibreDB()

def create_app():
    if sys.version_info < (3, 0):
        log.info(
            '*** Python2 is EOL since end of 2019, this version of Calibre-Web is no longer supporting Python2, please update your installation to Python3 ***')
        print(
            '*** Python2 is EOL since end of 2019, this version of Calibre-Web is no longer supporting Python2, please update your installation to Python3 ***')
        web_server.stop(True)
        sys.exit(5)
    if not lxml_present:
        log.info('*** ""lxml"" is needed for calibre-web to run. Please install it using pip: ""pip install lxml"" ***')
        print('*** ""lxml"" is needed for calibre-web to run. Please install it using pip: ""pip install lxml"" ***')
        web_server.stop(True)
        sys.exit(6)
    if not wtf_present:
        log.info('*** ""flask-WTF"" is needed for calibre-web to run. Please install it using pip: ""pip install flask-WTF"" ***')
        print('*** ""flask-WTF"" is needed for calibre-web to run. Please install it using pip: ""pip install flask-WTF"" ***')
        web_server.stop(True)
        sys.exit(7)
    for res in dependency_check() + dependency_check(True):
        log.info('*** ""{}"" version does not fit the requirements. Should: {}, Found: {}, please consider installing required version ***'
            .format(res['name'],
                 res['target'],
                 res['found']))
    app.wsgi_app = ReverseProxied(app.wsgi_app)

    if os.environ.get('FLASK_DEBUG'):
        cache_buster.init_cache_busting(app)
    log.info('Starting Calibre Web...')

    Principal(app)
    lm.init_app(app)
    app.secret_key = os.getenv('SECRET_KEY', config_sql.get_flask_session_key(ub.session))

    web_server.init_app(app, config)

    babel.init_app(app)
    _BABEL_TRANSLATIONS.update(str(item) for item in babel.list_translations())
    _BABEL_TRANSLATIONS.add('en')

    if services.ldap:
        services.ldap.init_app(app, config)
    if services.goodreads_support:
        services.goodreads_support.connect(config.config_goodreads_api_key,
                                           config.config_goodreads_api_secret,
                                           config.config_use_goodreads)
    config.store_calibre_uuid(calibre_db, db.Library_Id)
    return app

@babel.localeselector
def get_locale():
    # if a user is logged in, use the locale from the user settings
    user = getattr(g, 'user', None)
    if user is not None and hasattr(user, ""locale""):
        if user.name != 'Guest':   # if the account is the guest account bypass the config lang settings
            return user.locale

    preferred = list()
    if request.accept_languages:
        for x in request.accept_languages.values():
            try:
                preferred.append(str(LC.parse(x.replace('-', '_'))))
            except (UnknownLocaleError, ValueError) as e:
                log.debug('Could not parse locale ""%s"": %s', x, e)

    return negotiate_locale(preferred or ['en'], _BABEL_TRANSLATIONS)


@babel.timezoneselector
def get_timezone():
    user = getattr(g, 'user', None)
    return user.timezone if user else None


from .updater import Updater
updater_thread = Updater()

# Perform dry run of updater and exit afterwards
if cli.dry_run:
    updater_thread.dry_run()
    sys.exit(0)
updater_thread.start()
",CWE-918,195.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018 lemmsh, Kennyl, Kyosfonica, matthazinski
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

import os
import zipfile
from lxml import etree

from . import isoLanguages, cover
from .helper import split_authors
from .constants import BookMeta


def _extract_cover(zip_file, cover_file, cover_path, tmp_file_name):
    if cover_file is None:
        return None
    else:
        cf = extension = None
        zip_cover_path = os.path.join(cover_path, cover_file).replace('\\', '/')

        prefix = os.path.splitext(tmp_file_name)[0]
        tmp_cover_name = prefix + '.' + os.path.basename(zip_cover_path)
        ext = os.path.splitext(tmp_cover_name)
        if len(ext) > 1:
            extension = ext[1].lower()
        if extension in cover.COVER_EXTENSIONS:
            cf = zip_file.read(zip_cover_path)
        return cover.cover_processing(tmp_file_name, cf, extension)


def get_epub_info(tmp_file_path, original_file_name, original_file_extension):
    ns = {
        'n': 'urn:oasis:names:tc:opendocument:xmlns:container',
        'pkg': 'http://www.idpf.org/2007/opf',
        'dc': 'http://purl.org/dc/elements/1.1/'
    }

    epub_zip = zipfile.ZipFile(tmp_file_path)

    txt = epub_zip.read('META-INF/container.xml')
    tree = etree.fromstring(txt)
    cfname = tree.xpath('n:rootfiles/n:rootfile/@full-path', namespaces=ns)[0]
    cf = epub_zip.read(cfname)
    tree = etree.fromstring(cf)

    coverpath = os.path.dirname(cfname)

    p = tree.xpath('/pkg:package/pkg:metadata', namespaces=ns)[0]

    epub_metadata = {}

    for s in ['title', 'description', 'creator', 'language', 'subject']:
        tmp = p.xpath('dc:%s/text()' % s, namespaces=ns)
        if len(tmp) > 0:
            if s == 'creator':
                epub_metadata[s] = ' & '.join(split_authors(tmp))
            elif s == 'subject':
                epub_metadata[s] = ', '.join(tmp)
            else:
                epub_metadata[s] = tmp[0]
        else:
            epub_metadata[s] = 'Unknown'

    if epub_metadata['subject'] == 'Unknown':
        epub_metadata['subject'] = ''

    if epub_metadata['description'] == u'Unknown':
        description = tree.xpath(""//*[local-name() = 'description']/text()"")
        if len(description) > 0:
            epub_metadata['description'] = description
        else:
            epub_metadata['description'] = """"

    lang = epub_metadata['language'].split('-', 1)[0].lower()
    epub_metadata['language'] = isoLanguages.get_lang3(lang)

    epub_metadata = parse_epub_series(ns, tree, epub_metadata)

    cover_file = parse_epub_cover(ns, tree, epub_zip, coverpath, tmp_file_path)

    if not epub_metadata['title']:
        title = original_file_name
    else:
        title = epub_metadata['title']

    return BookMeta(
        file_path=tmp_file_path,
        extension=original_file_extension,
        title=title.encode('utf-8').decode('utf-8'),
        author=epub_metadata['creator'].encode('utf-8').decode('utf-8'),
        cover=cover_file,
        description=epub_metadata['description'],
        tags=epub_metadata['subject'].encode('utf-8').decode('utf-8'),
        series=epub_metadata['series'].encode('utf-8').decode('utf-8'),
        series_id=epub_metadata['series_id'].encode('utf-8').decode('utf-8'),
        languages=epub_metadata['language'],
        publisher="""")


def parse_epub_cover(ns, tree, epub_zip, cover_path, tmp_file_path):
    cover_section = tree.xpath(""/pkg:package/pkg:manifest/pkg:item[@id='cover-image']/@href"", namespaces=ns)
    cover_file = None
    if len(cover_section) > 0:
        cover_file = _extract_cover(epub_zip, cover_section[0], cover_path, tmp_file_path)
    else:
        meta_cover = tree.xpath(""/pkg:package/pkg:metadata/pkg:meta[@name='cover']/@content"", namespaces=ns)
        if len(meta_cover) > 0:
            cover_section = tree.xpath(
                ""/pkg:package/pkg:manifest/pkg:item[@id='""+meta_cover[0]+""']/@href"", namespaces=ns)
            if not cover_section:
                cover_section = tree.xpath(
                    ""/pkg:package/pkg:manifest/pkg:item[@properties='"" + meta_cover[0] + ""']/@href"", namespaces=ns)
        else:
            cover_section = tree.xpath(""/pkg:package/pkg:guide/pkg:reference/@href"", namespaces=ns)
        for cs in cover_section:
            filetype = cs.rsplit('.', 1)[-1]
            if filetype == ""xhtml"" or filetype == ""html"":  # if cover is (x)html format
                markup = epub_zip.read(os.path.join(cover_path, cs))
                markup_tree = etree.fromstring(markup)
                # no matter xhtml or html with no namespace
                img_src = markup_tree.xpath(""//*[local-name() = 'img']/@src"")
                # Alternative image source
                if not len(img_src):
                    img_src = markup_tree.xpath(""//attribute::*[contains(local-name(), 'href')]"")
                if len(img_src):
                    # img_src maybe start with ""../"""" so fullpath join then relpath to cwd
                    filename = os.path.relpath(os.path.join(os.path.dirname(os.path.join(cover_path, cover_section[0])),
                                                            img_src[0]))
                    cover_file = _extract_cover(epub_zip, filename, """", tmp_file_path)
            else:
                cover_file = _extract_cover(epub_zip, cs, cover_path, tmp_file_path)
            if cover_file:
                break
    return cover_file


def parse_epub_series(ns, tree, epub_metadata):
    series = tree.xpath(""/pkg:package/pkg:metadata/pkg:meta[@name='calibre:series']/@content"", namespaces=ns)
    if len(series) > 0:
        epub_metadata['series'] = series[0]
    else:
        epub_metadata['series'] = ''

    series_id = tree.xpath(""/pkg:package/pkg:metadata/pkg:meta[@name='calibre:series_index']/@content"", namespaces=ns)
    if len(series_id) > 0:
        epub_metadata['series_id'] = series_id[0]
    else:
        epub_metadata['series_id'] = '1'
    return epub_metadata
",CWE-918,164.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

from math import ceil


# simple pagination for the feed
class Pagination(object):
    def __init__(self, page, per_page, total_count):
        self.page = int(page)
        self.per_page = int(per_page)
        self.total_count = int(total_count)

    @property
    def next_offset(self):
        return int(self.page * self.per_page)

    @property
    def previous_offset(self):
        return int((self.page - 2) * self.per_page)

    @property
    def last_offset(self):
        last = int(self.total_count) - int(self.per_page)
        if last < 0:
            last = 0
        return int(last)

    @property
    def pages(self):
        return int(ceil(self.total_count / float(self.per_page)))

    @property
    def has_prev(self):
        return self.page > 1

    @property
    def has_next(self):
        return self.page < self.pages

    # right_edge: last right_edges count of all pages are shown as number, means, if 10 pages are paginated -> 9,10 shwn
    # left_edge: first left_edges count of all pages are shown as number                                    -> 1,2 shwn
    # left_current: left_current count below current page are shown as number, means if current page 5      -> 3,4 shwn
    # left_current: right_current count above current page are shown as number, means if current page 5     -> 6,7 shwn
    def iter_pages(self, left_edge=2, left_current=2,
                   right_current=4, right_edge=2):
        last = 0
        left_current = self.page - left_current - 1
        right_current = self.page + right_current + 1
        right_edge = self.pages - right_edge
        for num in range(1, (self.pages + 1)):
            if num <= left_edge or (left_current < num < right_current) or num > right_edge:
                if last + 1 != num:
                    yield None
                yield num
                last = num
",CWE-918,76.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2019 OzzieIsaacs, cervinko, jkrehm, bodybybuddha, ok11,
#                            andy29485, idalin, Kyosfonica, wuqi, Kennyl, lemmsh,
#                            falgh1, grunjol, csitko, ytils, xybydy, trasba, vrabe,
#                            ruben-herold, marblepebble, JackED42, SiphonSquirrel,
#                            apetresc, nanu-c, mutschler
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

import json
from datetime import datetime

from flask import Blueprint, request, make_response, abort, url_for, flash, redirect
from flask_login import login_required, current_user, login_user
from flask_babel import gettext as _
from sqlalchemy.sql.expression import true

from . import config, logger, ub
from .render_template import render_title_template

try:
    from functools import wraps
except ImportError:
    pass  # We're not using Python 3

remotelogin = Blueprint('remotelogin', __name__)
log = logger.create()


def remote_login_required(f):
    @wraps(f)
    def inner(*args, **kwargs):
        if config.config_remote_login:
            return f(*args, **kwargs)
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            data = {'status': 'error', 'message': 'Forbidden'}
            response = make_response(json.dumps(data, ensure_ascii=False))
            response.headers[""Content-Type""] = ""application/json; charset=utf-8""
            return response, 403
        abort(403)

    return inner

@remotelogin.route('/remote/login')
@remote_login_required
def remote_login():
    auth_token = ub.RemoteAuthToken()
    ub.session.add(auth_token)
    ub.session_commit()
    verify_url = url_for('remotelogin.verify_token', token=auth_token.auth_token, _external=true)
    log.debug(u""Remot Login request with token: %s"", auth_token.auth_token)
    return render_title_template('remote_login.html', title=_(u""Login""), token=auth_token.auth_token,
                                 verify_url=verify_url, page=""remotelogin"")


@remotelogin.route('/verify/<token>')
@remote_login_required
@login_required
def verify_token(token):
    auth_token = ub.session.query(ub.RemoteAuthToken).filter(ub.RemoteAuthToken.auth_token == token).first()

    # Token not found
    if auth_token is None:
        flash(_(u""Token not found""), category=""error"")
        log.error(u""Remote Login token not found"")
        return redirect(url_for('web.index'))

    # Token expired
    elif datetime.now() > auth_token.expiration:
        ub.session.delete(auth_token)
        ub.session_commit()

        flash(_(u""Token has expired""), category=""error"")
        log.error(u""Remote Login token expired"")
        return redirect(url_for('web.index'))

    # Update token with user information
    auth_token.user_id = current_user.id
    auth_token.verified = True
    ub.session_commit()

    flash(_(u""Success! Please return to your device""), category=""success"")
    log.debug(u""Remote Login token for userid %s verified"", auth_token.user_id)
    return redirect(url_for('web.index'))


@remotelogin.route('/ajax/verify_token', methods=['POST'])
@remote_login_required
def token_verified():
    token = request.form['token']
    auth_token = ub.session.query(ub.RemoteAuthToken).filter(ub.RemoteAuthToken.auth_token == token).first()

    data = {}

    # Token not found
    if auth_token is None:
        data['status'] = 'error'
        data['message'] = _(u""Token not found"")

    # Token expired
    elif datetime.now() > auth_token.expiration:
        ub.session.delete(auth_token)
        ub.session_commit()

        data['status'] = 'error'
        data['message'] = _(u""Token has expired"")

    elif not auth_token.verified:
        data['status'] = 'not_verified'

    else:
        user = ub.session.query(ub.User).filter(ub.User.id == auth_token.user_id).first()
        login_user(user)

        ub.session.delete(auth_token)
        ub.session_commit(""User {} logged in via remotelogin, token deleted"".format(user.name))

        data['status'] = 'success'
        log.debug(u""Remote Login for userid %s succeded"", user.id)
        flash(_(u""you are now logged in as: '%(nickname)s'"", nickname=user.name), category=""success"")

    response = make_response(json.dumps(data, ensure_ascii=False))
    response.headers[""Content-Type""] = ""application/json; charset=utf-8""

    return response
",CWE-918,139.0,1
"# -*- coding: utf-8 -*-

#  This file is part of the Calibre-Web (https://github.com/janeczku/calibre-web)
#    Copyright (C) 2018-2020 OzzieIsaacs
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program. If not, see <http://www.gnu.org/licenses/>.

import base64
import binascii

from sqlalchemy.sql.expression import func
from werkzeug.security import check_password_hash
from flask_login import login_required, login_user

from . import lm, ub, config, constants, services

try:
    from functools import wraps
except ImportError:
    pass  # We're not using Python 3

def login_required_if_no_ano(func):
    @wraps(func)
    def decorated_view(*args, **kwargs):
        if config.config_anonbrowse == 1:
            return func(*args, **kwargs)
        return login_required(func)(*args, **kwargs)

    return decorated_view


def _fetch_user_by_name(username):
    return ub.session.query(ub.User).filter(func.lower(ub.User.name) == username.lower()).first()


@lm.user_loader
def load_user(user_id):
    return ub.session.query(ub.User).filter(ub.User.id == int(user_id)).first()


@lm.request_loader
def load_user_from_request(request):
    if config.config_allow_reverse_proxy_header_login:
        rp_header_name = config.config_reverse_proxy_login_header_name
        if rp_header_name:
            rp_header_username = request.headers.get(rp_header_name)
            if rp_header_username:
                user = _fetch_user_by_name(rp_header_username)
                if user:
                    login_user(user)
                    return user

    auth_header = request.headers.get(""Authorization"")
    if auth_header:
        user = load_user_from_auth_header(auth_header)
        if user:
            return user

    return


def load_user_from_auth_header(header_val):
    if header_val.startswith('Basic '):
        header_val = header_val.replace('Basic ', '', 1)
    basic_username = basic_password = ''  # nosec
    try:
        header_val = base64.b64decode(header_val).decode('utf-8')
        # Users with colon are invalid: rfc7617 page 4
        basic_username = header_val.split(':', 1)[0]
        basic_password = header_val.split(':', 1)[1]
    except (TypeError, UnicodeDecodeError, binascii.Error):
        pass
    user = _fetch_user_by_name(basic_username)
    if user and config.config_login_type == constants.LOGIN_LDAP and services.ldap:
        if services.ldap.bind_user(str(user.password), basic_password):
            return user
    if user and check_password_hash(str(user.password), basic_password):
        return user
    return
",CWE-918,91.0,1
"{
  ""name"": ""apostrophe"",
  ""version"": ""3.3.1"",
  ""description"": ""The Apostrophe Content Management System."",
  ""main"": ""index.js"",
  ""scripts"": {
    ""pretest"": ""npm run lint && npm audit"",
    ""test"": ""nyc --reporter=html mocha -t 10000"",
    ""lint"": ""eslint . && node scripts/lint-i18n""
  },
  ""repository"": {
    ""type"": ""git"",
    ""url"": ""git@github.com:apostrophecms/apostrophe.git""
  },
  ""engines"": {
    ""node"": "">=12.0.0""
  },
  ""keywords"": [
    ""apostrophe"",
    ""apostrophe-cms"",
    ""apostrophecms"",
    ""cms"",
    ""node cms"",
    ""headless cms"",
    ""content management system""
  ],
  ""author"": ""Apostrophe Technologies, Inc."",
  ""license"": ""MIT"",
  ""dependencies"": {
    ""@apostrophecms/vue-color"": ""^2.8.2"",
    ""@babel/core"": ""^7.14.3"",
    ""@babel/preset-env"": ""^7.14.4"",
    ""@tiptap/extension-highlight"": ""^2.0.0-beta.13"",
    ""@tiptap/extension-link"": ""^2.0.0-beta.17"",
    ""@tiptap/extension-text-align"": ""^2.0.0-beta.17"",
    ""@tiptap/extension-text-style"": ""^2.0.0-beta.13"",
    ""@tiptap/extension-underline"": ""^2.0.0-beta.14"",
    ""@tiptap/starter-kit"": ""^2.0.0-beta.75"",
    ""@tiptap/vue-2"": ""^2.0.0-beta.34"",
    ""autoprefixer"": ""^10.2.4"",
    ""babel-loader"": ""^8.2.2"",
    ""bluebird"": ""^3.7.2"",
    ""body-parser"": ""^1.18.2"",
    ""boring"": ""^1.1.1"",
    ""broadband"": ""^1.1.0"",
    ""cheerio"": ""^1.0.0-rc.10"",
    ""chokidar"": ""^3.5.2"",
    ""common-tags"": ""^1.8.0"",
    ""connect-mongo"": ""^3.0.0"",
    ""connect-multiparty"": ""^2.1.1"",
    ""cookie-parser"": ""^1.4.5"",
    ""core-js"": ""~3.14.0"",
    ""cors"": ""^2.8.5"",
    ""credential"": ""^2.0.0"",
    ""css-loader"": ""^5.2.4"",
    ""cuid"": ""^1.3.8"",
    ""dayjs"": ""^1.9.8"",
    ""debounce-async"": ""0.0.2"",
    ""deep-get-set"": ""^1.1.1"",
    ""eslint-plugin-promise"": ""^5.1.0"",
    ""express"": ""^4.16.4"",
    ""express-bearer-token"": ""^2.4.0"",
    ""express-session"": ""^1.17.1"",
    ""form-data"": ""^4.0.0"",
    ""fs-extra"": ""^7.0.1"",
    ""glob"": ""^5.0.15"",
    ""he"": ""^0.5.0"",
    ""html-to-text"": ""^5.1.1"",
    ""i18next"": ""^20.3.2"",
    ""i18next-http-middleware"": ""^3.1.4"",
    ""import-fresh"": ""^3.3.0"",
    ""is-wsl"": ""^2.2.0"",
    ""klona"": ""^2.0.4"",
    ""launder"": ""^1.4.0"",
    ""lodash"": ""^4.17.20"",
    ""mini-css-extract-plugin"": ""^1.6.0"",
    ""minimatch"": ""^3.0.4"",
    ""mkdirp"": ""^0.5.5"",
    ""mongodb"": ""^3.6.6"",
    ""node-fetch"": ""^2.6.1"",
    ""nodemailer"": ""^6.6.1"",
    ""nunjucks"": ""^3.2.1"",
    ""oembetter"": ""^1.0.1"",
    ""passport"": ""^0.3.2"",
    ""passport-local"": ""^1.0.0"",
    ""path-to-regexp"": ""^1.8.0"",
    ""performance-now"": ""^2.1.0"",
    ""postcss-loader"": ""^5.0.0"",
    ""prompts"": ""^2.4.1"",
    ""qs"": ""^6.10.1"",
    ""regenerator-runtime"": ""^0.13.7"",
    ""regexp-quote"": ""0.0.0"",
    ""resolve"": ""^1.19.0"",
    ""resolve-from"": ""^5.0.0"",
    ""sanitize-html"": ""^2.0.0"",
    ""sass"": ""^1.34.1"",
    ""sass-loader"": ""^10.1.1"",
    ""server-destroy"": ""^1.0.1"",
    ""sluggo"": ""^0.3.0"",
    ""stylelint"": ""^13.13.0"",
    ""stylelint-config-standard"": ""^20.0.0"",
    ""stylelint-declaration-strict-value"": ""^1.7.12"",
    ""stylelint-order"": ""^4.1.0"",
    ""stylelint-webpack-plugin"": ""^2.1.1"",
    ""tinycolor2"": ""^1.4.2"",
    ""tough-cookie"": ""^4.0.0"",
    ""underscore.string"": ""^3.3.4"",
    ""uploadfs"": ""^1.17.1"",
    ""v-tooltip"": ""^2.0.3"",
    ""vue"": ""^2.6.14"",
    ""vue-click-outside-element"": ""^1.0.13"",
    ""vue-loader"": ""^15.9.6"",
    ""vue-material-design-icons"": ""^4.9.0"",
    ""vue-style-loader"": ""^4.1.2"",
    ""vue-template-compiler"": ""^2.6.14"",
    ""vuedraggable"": ""^2.24.3"",
    ""webpack"": ""~5.44.0"",
    ""webpack-merge"": ""^5.7.3"",
    ""xregexp"": ""^2.0.0""
  },
  ""devDependencies"": {
    ""babel-eslint"": ""^10.1.0"",
    ""eslint"": ""^7.25.0"",
    ""eslint-config-apostrophe"": ""^3.4.0"",
    ""eslint-loader"": ""^4.0.2"",
    ""eslint-plugin-node"": ""^11.1.0"",
    ""eslint-plugin-vue"": ""^7.9.0"",
    ""mocha"": ""^7.1.2"",
    ""nyc"": ""^15.1.0"",
    ""replace-in-file"": ""^6.1.0"",
    ""vue-eslint-parser"": ""^7.1.1"",
    ""webpack-bundle-analyzer"": ""^3.9.0""
  },
  ""browserslist"": [
    ""ie >= 10""
  ]
}
",CWE-79,138.0,1
"# -*- coding: utf-8 -*-
""""""
    pygments.lexers.varnish
    ~~~~~~~~~~~~~~~~~~~~~~~

    Lexers for Varnish configuration

    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.
    :license: BSD, see LICENSE for details.
""""""

from pygments.lexer import RegexLexer, include, bygroups, using, this, \
    inherit, words
from pygments.token import Text, Comment, Operator, Keyword, Name, String, \
    Number, Punctuation, Literal

__all__ = ['VCLLexer', 'VCLSnippetLexer']


class VCLLexer(RegexLexer):
    """"""
    For Varnish Configuration Language (VCL).

    .. versionadded:: 2.2
    """"""
    name = 'VCL'
    aliases = ['vcl']
    filenames = ['*.vcl']
    mimetypes = ['text/x-vclsrc']

    def analyse_text(text):
        # If the very first line is 'vcl 4.0;' it's pretty much guaranteed
        # that this is VCL
        if text.startswith('vcl 4.0;'):
            return 1.0
        # Skip over comments and blank lines
        # This is accurate enough that returning 0.9 is reasonable.
        # Almost no VCL files start without some comments.
        elif '\nvcl 4.0;' in text[:1000]:
            return 0.9

    tokens = {
        'probe': [
            include('whitespace'),
            include('comments'),
            (r'(\.\w+)(\s*=\s*)([^;]*)(;)',
             bygroups(Name.Attribute, Operator, using(this), Punctuation)),
            (r'\}', Punctuation, '#pop'),
        ],
        'acl': [
            include('whitespace'),
            include('comments'),
            (r'[!/]+', Operator),
            (r';', Punctuation),
            (r'\d+', Number),
            (r'\}', Punctuation, '#pop'),
        ],
        'backend': [
            include('whitespace'),
            (r'(\.probe)(\s*=\s*)(\w+)(;)',
             bygroups(Name.Attribute, Operator, Name.Variable.Global, Punctuation)),
            (r'(\.probe)(\s*=\s*)(\{)',
             bygroups(Name.Attribute, Operator, Punctuation), 'probe'),
            (r'(\.\w+\b)(\s*=\s*)([^;]*)(\s*;)',
             bygroups(Name.Attribute, Operator, using(this), Punctuation)),
            (r'\{', Punctuation, '#push'),
            (r'\}', Punctuation, '#pop'),
        ],
        'statements': [
            (r'(\d\.)?\d+[sdwhmy]', Literal.Date),
            (r'(\d\.)?\d+ms', Literal.Date),
            (r'(vcl_pass|vcl_hash|vcl_hit|vcl_init|vcl_backend_fetch|vcl_pipe|'
             r'vcl_backend_response|vcl_synth|vcl_deliver|vcl_backend_error|'
             r'vcl_fini|vcl_recv|vcl_purge|vcl_miss)\b', Name.Function),
            (r'(pipe|retry|hash|synth|deliver|purge|abandon|lookup|pass|fail|ok|'
             r'miss|fetch|restart)\b', Name.Constant),
            (r'(beresp|obj|resp|req|req_top|bereq)\.http\.[a-zA-Z_-]+\b', Name.Variable),
            (words((
                'obj.status', 'req.hash_always_miss', 'beresp.backend', 'req.esi_level',
                'req.can_gzip', 'beresp.ttl', 'obj.uncacheable', 'req.ttl', 'obj.hits',
                'client.identity', 'req.hash_ignore_busy', 'obj.reason', 'req.xid',
                'req_top.proto', 'beresp.age', 'obj.proto', 'obj.age', 'local.ip',
                'beresp.uncacheable', 'req.method', 'beresp.backend.ip', 'now',
                'obj.grace', 'req.restarts', 'beresp.keep', 'req.proto', 'resp.proto',
                'bereq.xid', 'bereq.between_bytes_timeout', 'req.esi',
                'bereq.first_byte_timeout', 'bereq.method', 'bereq.connect_timeout',
                'beresp.do_gzip',  'resp.status', 'beresp.do_gunzip',
                'beresp.storage_hint', 'resp.is_streaming', 'beresp.do_stream',
                'req_top.method', 'bereq.backend', 'beresp.backend.name', 'beresp.status',
                'req.url', 'obj.keep', 'obj.ttl', 'beresp.reason', 'bereq.retries',
                'resp.reason', 'bereq.url', 'beresp.do_esi', 'beresp.proto', 'client.ip',
                'bereq.proto', 'server.hostname', 'remote.ip', 'req.backend_hint',
                'server.identity', 'req_top.url', 'beresp.grace', 'beresp.was_304',
                'server.ip', 'bereq.uncacheable'), suffix=r'\b'),
             Name.Variable),
            (r'[!%&+*\-,/<.}{>=|~]+', Operator),
            (r'[();]', Punctuation),

            (r'[,]+', Punctuation),
            (words(('hash_data', 'regsub', 'regsuball', 'if', 'else',
                    'elsif', 'elif', 'synth', 'synthetic', 'ban',
                    'return', 'set', 'unset', 'import', 'include', 'new',
                    'rollback', 'call'), suffix=r'\b'),
             Keyword),
            (r'storage\.\w+\.\w+\b', Name.Variable),
            (words(('true', 'false')), Name.Builtin),
            (r'\d+\b', Number),
            (r'(backend)(\s+\w+)(\s*\{)',
             bygroups(Keyword, Name.Variable.Global, Punctuation), 'backend'),
            (r'(probe\s)(\s*\w+\s)(\{)',
             bygroups(Keyword, Name.Variable.Global, Punctuation), 'probe'),
            (r'(acl\s)(\s*\w+\s)(\{)',
             bygroups(Keyword, Name.Variable.Global, Punctuation), 'acl'),
            (r'(vcl )(4.0)(;)$',
             bygroups(Keyword.Reserved, Name.Constant, Punctuation)),
            (r'(sub\s+)([a-zA-Z]\w*)(\s*\{)',
                bygroups(Keyword, Name.Function, Punctuation)),
            (r'([a-zA-Z_]\w*)'
             r'(\.)'
             r'([a-zA-Z_]\w*)'
             r'(\s*\(.*\))',
             bygroups(Name.Function, Punctuation, Name.Function, using(this))),
            (r'[a-zA-Z_]\w*', Name),
        ],
        'comment': [
            (r'[^*/]+', Comment.Multiline),
            (r'/\*', Comment.Multiline, '#push'),
            (r'\*/', Comment.Multiline, '#pop'),
            (r'[*/]', Comment.Multiline),
        ],
        'comments': [
            (r'#.*$', Comment),
            (r'/\*', Comment.Multiline, 'comment'),
            (r'//.*$', Comment),
        ],
        'string': [
            (r'""', String, '#pop'),
            (r'[^""\n]+', String),  # all other characters
        ],
        'multistring': [
            (r'[^""}]', String),
            (r'""\}', String, '#pop'),
            (r'[""}]', String),
        ],
        'whitespace': [
            (r'L?""', String, 'string'),
            (r'\{""', String, 'multistring'),
            (r'\n', Text),
            (r'\s+', Text),
            (r'\\\n', Text),  # line continuation
        ],
        'root': [
            include('whitespace'),
            include('comments'),
            include('statements'),
            (r'\s+', Text),
        ],
    }


class VCLSnippetLexer(VCLLexer):
    """"""
    For Varnish Configuration Language snippets.

    .. versionadded:: 2.2
    """"""
    name = 'VCLSnippets'
    aliases = ['vclsnippets', 'vclsnippet']
    mimetypes = ['text/x-vclsnippet']
    filenames = []

    def analyse_text(text):
        # override method inherited from VCLLexer
        return 0

    tokens = {
        'snippetspre': [
            (r'\.\.\.+', Comment),
            (r'(bereq|req|req_top|resp|beresp|obj|client|server|local|remote|'
             r'storage)($|\.\*)', Name.Variable),
        ],
        'snippetspost': [
            (r'(backend)\b', Keyword.Reserved),
        ],
        'root': [
            include('snippetspre'),
            inherit,
            include('snippetspost'),
        ],
    }
",CWE-1333,191.0,1
,CWE-22,,1
,CWE-22,,1
,CWE-79,,1
,CWE-22,,1
,CWE-79,,1
,CWE-22,,1
,CWE-79,,1
,CWE-22,,1
,CWE-79,,1
,CWE-22,,1
,CWE-89,,1
,CWE-89,,1
,CWE-611,,1
"from redbot.core import commands
from .core import TicketsCore

BaseCog = getattr(commands, ""Cog"", object)

class Tickets(BaseCog):
    def __init__(self, bot):
        self.bot = bot
        self.core = TicketsCore(bot)

    @commands.group(name='ticket')
    async def ticket(self, context):
        '''
        Tickets!
        '''

    @ticket.command(name='new')
    async def ticket_new(self, context):
        '''
        Create a new ticket
        '''
        if context.invoked_subcommand is None:
            message = await self.core.create_ticket(context)
            if message:
                await context.send(message)

    @ticket.command(name='update')
    async def ticket_update(self, context, *, status: str):
        '''
        Update the status of a ticket
        '''
        await self.core.update_ticket(context, status)

    @ticket.command(name='close')
    async def ticket_close(self, context):
        '''
        Close a ticket, must be run in the ticket channel you want to close
        '''
        await self.core.close_ticket(context)

    @ticket.group(name='set')
    @commands.has_permissions(administrator=True)
    async def ticket_set(self, context):
        '''
        Settings
        '''

    @ticket_set.command(name='purge')
    async def ticket_set_purge(self, context):
        '''
        Delete all closed tickets
        '''
        message = await self.core.purge_tickets(context)
        await context.send(message)

    @ticket_set.command(name='message')
    @commands.has_permissions(administrator=True)
    async def ticket_set_message(self, context, *, message: str):
        '''
        Set the default message when a new ticket has been created (markdown safe)
        '''
        message = await self.core.set_default_message_ticket_channel(context, message)
        await context.send(message)

    @ticket_set.command(name='setup')
    async def ticket_setup(self, context):
        '''
        Automatic setup, will create two categories for open and closed tickets, and a ticket role for people to be able to manage tickets.
        '''
        message = await self.core.automatic_setup(context)
        await context.send(message)
",CWE-94,72.0,1
,CWE-601,,1
,CWE-601,,1
"import io
import os
import re

from setuptools import find_packages, setup


with io.open(""flask_appbuilder/__init__.py"", ""rt"", encoding=""utf8"") as f:
    version = re.search(r""__version__ = \""(.*?)\"""", f.read()).group(1)


def fpath(name):
    return os.path.join(os.path.dirname(__file__), name)


def read(fname):
    return open(fpath(fname)).read()


def desc():
    return read(""README.rst"")


setup(
    name=""Flask-AppBuilder"",
    version=version,
    url=""https://github.com/dpgaspar/flask-appbuilder/"",
    license=""BSD"",
    author=""Daniel Vaz Gaspar"",
    author_email=""danielvazgaspar@gmail.com"",
    description=(
        ""Simple and rapid application development framework, built on top of Flask.""
        "" includes detailed security, auto CRUD generation for your models,""
        "" google charts and much more.""
    ),
    long_description=desc(),
    long_description_content_type=""text/x-rst"",
    packages=find_packages(),
    package_data={"""": [""LICENSE""]},
    entry_points={
        ""flask.commands"": [""fab=flask_appbuilder.cli:fab""],
        ""console_scripts"": [""fabmanager = flask_appbuilder.console:cli""],
    },
    include_package_data=True,
    zip_safe=False,
    platforms=""any"",
    install_requires=[
        ""apispec[yaml]>=3.3, <4"",
        ""colorama>=0.3.9, <1"",
        ""click>=6.7, <9"",
        ""email_validator>=1.0.5, <2"",
        ""Flask>=0.12, <2"",
        ""Flask-Babel>=1, <2"",
        ""Flask-Login>=0.3, <0.5"",
        ""Flask-OpenID>=1.2.5, <2"",
        # SQLAlchemy 1.4.0 breaks flask-sqlalchemy and sqlalchemy-utils
        ""SQLAlchemy<1.4.0"",
        ""Flask-SQLAlchemy>=2.4, <3"",
        ""Flask-WTF>=0.14.2, <0.15.0"",
        ""Flask-JWT-Extended>=3.18, <4"",
        ""jsonschema>=3.0.1, <4"",
        ""marshmallow>=3, <4"",
        ""marshmallow-enum>=1.5.1, <2"",
        ""marshmallow-sqlalchemy>=0.22.0, <0.24.0"",
        ""python-dateutil>=2.3, <3"",
        ""prison>=0.1.3, <1.0.0"",
        ""PyJWT>=1.7.1, <2.0.0"",
        ""sqlalchemy-utils>=0.32.21, <1"",
    ],
    extras_require={""jmespath"": [""jmespath>=0.9.5""]},
    tests_require=[""nose>=1.0"", ""mockldap>=0.3.0""],
    classifiers=[
        ""Development Status :: 5 - Production/Stable"",
        ""Environment :: Web Environment"",
        ""Intended Audience :: Developers"",
        ""License :: OSI Approved :: BSD License"",
        ""Operating System :: OS Independent"",
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 3.6"",
        ""Programming Language :: Python :: 3.7"",
        ""Topic :: Software Development :: Libraries :: Python Modules"",
    ],
    python_requires=""~=3.6"",
    test_suite=""nose.collector"",
)
",CWE-601,86.0,1
"from flask import request
from flask_jwt_extended import (
    create_access_token,
    create_refresh_token,
    get_jwt_identity,
    jwt_refresh_token_required,
)

from ..api import BaseApi, safe
from ..const import (
    API_SECURITY_ACCESS_TOKEN_KEY,
    API_SECURITY_PASSWORD_KEY,
    API_SECURITY_PROVIDER_DB,
    API_SECURITY_PROVIDER_KEY,
    API_SECURITY_PROVIDER_LDAP,
    API_SECURITY_REFRESH_KEY,
    API_SECURITY_REFRESH_TOKEN_KEY,
    API_SECURITY_USERNAME_KEY,
    API_SECURITY_VERSION,
)
from ..views import expose


class SecurityApi(BaseApi):

    resource_name = ""security""
    version = API_SECURITY_VERSION
    openapi_spec_tag = ""Security""

    def add_apispec_components(self, api_spec):
        super(SecurityApi, self).add_apispec_components(api_spec)
        jwt_scheme = {""type"": ""http"", ""scheme"": ""bearer"", ""bearerFormat"": ""JWT""}
        api_spec.components.security_scheme(""jwt"", jwt_scheme)
        api_spec.components.security_scheme(""jwt_refresh"", jwt_scheme)

    @expose(""/login"", methods=[""POST""])
    @safe
    def login(self):
        """"""Login endpoint for the API returns a JWT and optionally a refresh token
        ---
        post:
          description: >-
            Authenticate and get a JWT access and refresh token
          requestBody:
            required: true
            content:
              application/json:
                schema:
                  type: object
                  properties:
                    username:
                      description: The username for authentication
                      example: admin
                      type: string
                    password:
                      description: The password for authentication
                      example: complex-password
                      type: string
                    provider:
                      description: Choose an authentication provider
                      example: db
                      type: string
                      enum:
                      - db
                      - ldap
                    refresh:
                      description: If true a refresh token is provided also
                      example: true
                      type: boolean
          responses:
            200:
              description: Authentication Successful
              content:
                application/json:
                  schema:
                    type: object
                    properties:
                      access_token:
                        type: string
                      refresh_token:
                        type: string
            400:
              $ref: '#/components/responses/400'
            401:
              $ref: '#/components/responses/401'
            500:
              $ref: '#/components/responses/500'
        """"""
        if not request.is_json:
            return self.response_400(message=""Request payload is not JSON"")
        username = request.json.get(API_SECURITY_USERNAME_KEY, None)
        password = request.json.get(API_SECURITY_PASSWORD_KEY, None)
        provider = request.json.get(API_SECURITY_PROVIDER_KEY, None)
        refresh = request.json.get(API_SECURITY_REFRESH_KEY, False)
        if not username or not password or not provider:
            return self.response_400(message=""Missing required parameter"")
        # AUTH
        if provider == API_SECURITY_PROVIDER_DB:
            user = self.appbuilder.sm.auth_user_db(username, password)
        elif provider == API_SECURITY_PROVIDER_LDAP:
            user = self.appbuilder.sm.auth_user_ldap(username, password)
        else:
            return self.response_400(
                message=""Provider {} not supported"".format(provider)
            )
        if not user:
            return self.response_401()

        # Identity can be any data that is json serializable
        resp = dict()
        resp[API_SECURITY_ACCESS_TOKEN_KEY] = create_access_token(
            identity=user.id, fresh=True
        )
        if refresh:
            resp[API_SECURITY_REFRESH_TOKEN_KEY] = create_refresh_token(
                identity=user.id
            )
        return self.response(200, **resp)

    @expose(""/refresh"", methods=[""POST""])
    @jwt_refresh_token_required
    @safe
    def refresh(self):
        """"""
            Security endpoint for the refresh token, so we can obtain a new
            token without forcing the user to login again
        ---
        post:
          description: >-
            Use the refresh token to get a new JWT access token
          responses:
            200:
              description: Refresh Successful
              content:
                application/json:
                  schema:
                    type: object
                    properties:
                      access_token:
                        description: A new refreshed access token
                        type: string
            401:
              $ref: '#/components/responses/401'
            500:
              $ref: '#/components/responses/500'
          security:
            - jwt_refresh: []
        """"""
        resp = {
            API_SECURITY_ACCESS_TOKEN_KEY: create_access_token(
                identity=get_jwt_identity(), fresh=False
            )
        }
        return self.response(200, **resp)
",CWE-287,155.0,1
,CWE-287,,1
"import os

from flask import has_request_context, request, session
from flask_babel import Babel

from .views import LocaleView
from ..basemanager import BaseManager


class BabelManager(BaseManager):

    babel = None
    locale_view = None

    def __init__(self, appbuilder):
        super(BabelManager, self).__init__(appbuilder)
        app = appbuilder.get_app
        app.config.setdefault(""BABEL_DEFAULT_LOCALE"", ""en"")
        if not app.config.get(""LANGUAGES""):
            app.config[""LANGUAGES""] = {""en"": {""flag"": ""us"", ""name"": ""English""}}
        appbuilder_parent_dir = os.path.join(
            os.path.dirname(os.path.abspath(__file__)), os.pardir
        )
        appbuilder_translations_path = os.path.join(
            appbuilder_parent_dir, ""translations""
        )
        if ""BABEL_TRANSLATION_DIRECTORIES"" in app.config:
            current_translation_directories = app.config.get(
                ""BABEL_TRANSLATION_DIRECTORIES""
            )
            translations_path = (
                appbuilder_translations_path + "";"" + current_translation_directories
            )
        else:
            translations_path = appbuilder_translations_path + "";translations""
        app.config[""BABEL_TRANSLATION_DIRECTORIES""] = translations_path
        self.babel = Babel(app)
        self.babel.locale_selector_func = self.get_locale

    def register_views(self):
        self.locale_view = LocaleView()
        self.appbuilder.add_view_no_menu(self.locale_view)

    @property
    def babel_default_locale(self):
        return self.appbuilder.get_app.config[""BABEL_DEFAULT_LOCALE""]

    @property
    def languages(self):
        return self.appbuilder.get_app.config[""LANGUAGES""]

    def get_locale(self):
        if has_request_context():
            # locale selector for API searches for request args
            for arg, value in request.args.items():
                if arg == ""_l_"":
                    if value in self.languages:
                        return value
                    else:
                        return self.babel_default_locale
            locale = session.get(""locale"")
            if locale:
                return locale
            session[""locale""] = self.babel_default_locale
            return session[""locale""]
",CWE-209,66.0,1
"## ---------------------------------------------------------------------------
## See the NOTICE file distributed with this work for additional
## information regarding copyright ownership.
##
## This is free software; you can redistribute it and/or modify it
## under the terms of the GNU Lesser General Public License as
## published by the Free Software Foundation; either version 2.1 of
## the License, or (at your option) any later version.
##
## This software is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
## Lesser General Public License for more details.
##
## You should have received a copy of the GNU Lesser General Public
## License along with this software; if not, write to the Free
## Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
## 02110-1301 USA, or see the FSF site: http://www.fsf.org.
## ---------------------------------------------------------------------------

#**
 This page starts the password reset procedure. It works according to the next algorithm:
 1. Display a form requesting the username
 2. When receiving the username via form submission, generate a random verification string which is stored (as a hash) inside a ResetPasswordRequestClass object attached to the user's profile page. If no such object exists, it is created, but an existing object will be reused, meaning that at most one password reset request can be active at a moment.
 3. Send an email to the address configured in the user's profile, containing a link to the second step of the password reset procedure.

 URL parameters:

 u = user account sent in the form
 *###
##
##

#template(""register_macros.vm"")
#macro(resetPasswordBoxStart $panelClass)
#if (""$!panelClass"" == """")
  #set ($panelClass = ""default"")
#end
<div class=""centered panel panel-$panelClass xwikimessage panel-body"">
  <div class=""panel-heading"">
    <div class=""panel-title"">$services.localization.render('xe.admin.passwordReset.title')</div>
  </div>
  <div class=""panel-body"">
#end
#macro(displayResetPasswordException)
    #set ($causeException = $exception.cause)
    #if ($causeException.class == 'class org.xwiki.security.authentication.api.ResetPasswordException'
        && $causeException.cause == $causeException)
      <div class=""xwikirenderingerror"">
          $escapetool.xml($causeException.message)
      </div>
    #else
        #displayException($escapetool.xml($causeException.message))
    #end
#end

#set ($userName = ""$!request.get('u')"")
#set ($validationString = ""$!request.get('v')"")
## First step, display the form requesting the username
#if (($userName == '' && $validationString == ''))
#resetPasswordBoxStart(""default"")
$services.localization.render('xe.admin.passwordReset.instructions')

<form method=""post"" action=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"" class=""xformInline"" id=""resetPasswordForm"">
    <div>
        <input type=""hidden"" name=""form_token"" value=""$!{services.csrf.getToken()}"" />
        <label for=""u"">$services.localization.render('xe.admin.passwordReset.username.label')</label>
        <input type=""text"" id=""u"" name=""u""/>
        <span class=""buttonwrapper"">
            <input type=""submit"" value=""$services.localization.render('xe.admin.passwordReset.submit')"" class=""button""/>
        </span>
    </div>
</form>
#elseif ($userName != '' && $validationString == '')
    #if (!$services.csrf.isTokenValid($request.form_token))
        #resetPasswordBoxStart(""danger"")
        $services.localization.render('xe.admin.passwordReset.error.csrf')
    #else
        #try()
            #set ($email = $services.security.authentication.requestResetPassword($userName))
        #end
        #if (""$!exception"" != '')
            #resetPasswordBoxStart(""warning"")
            #displayResetPasswordException()
        #else
            #resetPasswordBoxStart(""default"")
            $services.localization.render('xe.admin.passwordReset.emailSent', [""$email""])
        #end
    #end
  <div>
      <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.error.retry')</a> |
      <a href=""$xwiki.getURL('XWiki.ForgotUsername')"">$services.localization.render('xe.admin.passwordReset.error.recoverUsername')</a> |
      <a href=""$xwiki.getURL('XWiki.XWikiLogin', 'login')"">$services.localization.render('xe.admin.passwordReset.login')</a>
  </div>
#else
    ##
    ##
    #**
     * Displays the password reset form.
     * @param message An optional message to display, for example if the sent password is empty.
     * @param u The user account (full document name), which needs to be preserved.
     * @param v The validation string, which will be checked again upon receiving the form.
     *###
    #macro(displayForm $message $validationString)
        #if ($message != '')
            #resetPasswordBoxStart('warning')
            $message
        #else
            #resetPasswordBoxStart('default')
        #end
        ## Load the configuration from a seperate document.
        #loadConfig('XWiki.RegistrationConfig')
        #set ($passwordFields = [])
        #definePasswordFields($passwordFields, 'p', 'p2', $passwordOptions)

        <form action=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"" method=""post"" id=""resetPasswordStep2Form"" class=""xform third"">
            <div class=""hidden"">
                <input type=""hidden"" name=""form_token"" value=""$!{services.csrf.getToken()}"" />
                <input type=""hidden"" name=""u"" value=""$!escapetool.xml($userName)""/>
                <input type=""hidden"" name=""v"" value=""$!escapetool.xml($validationString)""/>
            </div>
            ## A null $request is passed as parameter, since we won't display inserted passwords after a request with error.
            #generateHtml($passwordFields, $NULL)
            <div class=""buttons"">
                <span class=""buttonwrapper""><input type=""submit"" value=""$services.localization.render('xe.admin.passwordReset.step2.submit')"" class=""button""/></span>
            </div>
        </form>
    #end
    #set ($password = ""$!request.p"")
    #set ($password2 = ""$!request.p2"")
    #if (!$request.getParameterMap().containsKey('p'))
        #try()
            #set ($newValidationString = $services.security.authentication.checkVerificationCode($userName, $validationString))
        #end
        #if (""$!exception"" != '')
            #resetPasswordBoxStart(""danger"")
            #displayResetPasswordException()
            <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.step2.backToStep1')</a>
        #else
            #displayForm('' $newValidationString)
        #end
    #elseif (!$services.csrf.isTokenValid($request.form_token))
        #resetPasswordBoxStart(""danger"")
        $request.form_token
        $services.localization.render('xe.admin.passwordReset.error.csrf')
    #else
        #validateFields($passwordFields, $request)
        #if (!$allFieldsValid)
            #displayForm($stringtool.join($allFieldsErrors, ""<br/>"") $validationString)
        #else
            #try()
                #set($discard = $services.security.authentication.resetPassword($userName, $validationString, $password))
            #end
            #if (""$!exception"" != '')
                #resetPasswordBoxStart(""danger"")
                #displayResetPasswordException()
                <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.step2.backToStep1')</a>
            #else
                #resetPasswordBoxStart(""success"")
                $services.localization.render('xe.admin.passwordReset.step2.success')
              <a href=""$xwiki.getURL('XWiki.XWikiLogin', 'login')"">$services.localization.render('xe.admin.passwordReset.step2.login')</a>
            #end
        #end
    #end
    #set ($newValidationString = '')
    #set ($validationString = '')
    #set ($password = '')
    #set ($password2 = '')
#end
#xwikimessageboxend()",CWE-200,170.0,1
"## ---------------------------------------------------------------------------
## See the NOTICE file distributed with this work for additional
## information regarding copyright ownership.
##
## This is free software; you can redistribute it and/or modify it
## under the terms of the GNU Lesser General Public License as
## published by the Free Software Foundation; either version 2.1 of
## the License, or (at your option) any later version.
##
## This software is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
## Lesser General Public License for more details.
##
## You should have received a copy of the GNU Lesser General Public
## License along with this software; if not, write to the Free
## Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
## 02110-1301 USA, or see the FSF site: http://www.fsf.org.
## ---------------------------------------------------------------------------

#**
 This page starts the password reset procedure. It works according to the next algorithm:
 1. Display a form requesting the username
 2. When receiving the username via form submission, generate a random verification string which is stored (as a hash) inside a ResetPasswordRequestClass object attached to the user's profile page. If no such object exists, it is created, but an existing object will be reused, meaning that at most one password reset request can be active at a moment.
 3. Send an email to the address configured in the user's profile, containing a link to the second step of the password reset procedure.

 URL parameters:

 u = user account sent in the form
 *###
##
##

#template(""register_macros.vm"")
#macro(resetPasswordBoxStart $panelClass)
#if (""$!panelClass"" == """")
  #set ($panelClass = ""default"")
#end
<div class=""centered panel panel-$panelClass xwikimessage panel-body"">
  <div class=""panel-heading"">
    <div class=""panel-title"">$services.localization.render('xe.admin.passwordReset.title')</div>
  </div>
  <div class=""panel-body"">
#end
#macro(displayResetPasswordException)
    #set ($causeException = $exception.cause)
    #if ($causeException.class == 'class org.xwiki.security.authentication.api.ResetPasswordException'
        && $causeException.cause == $causeException)
      <div class=""xwikirenderingerror"">
          $escapetool.xml($causeException.message)
      </div>
    #else
        #displayException($escapetool.xml($causeException.message))
    #end
#end

#set ($userName = ""$!request.get('u')"")
#set ($validationString = ""$!request.get('v')"")
## First step, display the form requesting the username
#if (($userName == '' && $validationString == ''))
#resetPasswordBoxStart(""default"")
$services.localization.render('xe.admin.passwordReset.instructions')

<form method=""post"" action=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"" class=""xformInline"" id=""resetPasswordForm"">
    <div>
        <input type=""hidden"" name=""form_token"" value=""$!{services.csrf.getToken()}"" />
        <label for=""u"">$services.localization.render('xe.admin.passwordReset.username.label')</label>
        <input type=""text"" id=""u"" name=""u""/>
        <span class=""buttonwrapper"">
            <input type=""submit"" value=""$services.localization.render('xe.admin.passwordReset.submit')"" class=""button""/>
        </span>
    </div>
</form>
#elseif ($userName != '' && $validationString == '')
    #if (!$services.csrf.isTokenValid($request.form_token))
        #resetPasswordBoxStart(""danger"")
        $services.localization.render('xe.admin.passwordReset.error.csrf')
    #else
        #try()
            #set ($email = $services.security.authentication.requestResetPassword($userName))
        #end
        #if (""$!exception"" != '')
            #resetPasswordBoxStart(""warning"")
            #displayResetPasswordException()
        #else
            #resetPasswordBoxStart(""default"")
            $services.localization.render('xe.admin.passwordReset.emailSent', [""$services.mail.general.obfuscate($email)""])
        #end
    #end
  <div>
      <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.error.retry')</a> |
      <a href=""$xwiki.getURL('XWiki.ForgotUsername')"">$services.localization.render('xe.admin.passwordReset.error.recoverUsername')</a> |
      <a href=""$xwiki.getURL('XWiki.XWikiLogin', 'login')"">$services.localization.render('xe.admin.passwordReset.login')</a>
  </div>
#else
    ##
    ##
    #**
     * Displays the password reset form.
     * @param message An optional message to display, for example if the sent password is empty.
     * @param u The user account (full document name), which needs to be preserved.
     * @param v The validation string, which will be checked again upon receiving the form.
     *###
    #macro(displayForm $message $validationString)
        #if ($message != '')
            #resetPasswordBoxStart('warning')
            $message
        #else
            #resetPasswordBoxStart('default')
        #end
        ## Load the configuration from a seperate document.
        #loadConfig('XWiki.RegistrationConfig')
        #set ($passwordFields = [])
        #definePasswordFields($passwordFields, 'p', 'p2', $passwordOptions)

        <form action=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"" method=""post"" id=""resetPasswordStep2Form"" class=""xform third"">
            <div class=""hidden"">
                <input type=""hidden"" name=""form_token"" value=""$!{services.csrf.getToken()}"" />
                <input type=""hidden"" name=""u"" value=""$!escapetool.xml($userName)""/>
                <input type=""hidden"" name=""v"" value=""$!escapetool.xml($validationString)""/>
            </div>
            ## A null $request is passed as parameter, since we won't display inserted passwords after a request with error.
            #generateHtml($passwordFields, $NULL)
            <div class=""buttons"">
                <span class=""buttonwrapper""><input type=""submit"" value=""$services.localization.render('xe.admin.passwordReset.step2.submit')"" class=""button""/></span>
            </div>
        </form>
    #end
    #set ($password = ""$!request.p"")
    #set ($password2 = ""$!request.p2"")
    #if (!$request.getParameterMap().containsKey('p'))
        #try()
            #set ($newValidationString = $services.security.authentication.checkVerificationCode($userName, $validationString))
        #end
        #if (""$!exception"" != '')
            #resetPasswordBoxStart(""danger"")
            #displayResetPasswordException()
            <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.step2.backToStep1')</a>
        #else
            #displayForm('' $newValidationString)
        #end
    #elseif (!$services.csrf.isTokenValid($request.form_token))
        #resetPasswordBoxStart(""danger"")
        $request.form_token
        $services.localization.render('xe.admin.passwordReset.error.csrf')
    #else
        #validateFields($passwordFields, $request)
        #if (!$allFieldsValid)
            #displayForm($stringtool.join($allFieldsErrors, ""<br/>"") $validationString)
        #else
            #try()
                #set($discard = $services.security.authentication.resetPassword($userName, $validationString, $password))
            #end
            #if (""$!exception"" != '')
                #resetPasswordBoxStart(""danger"")
                #displayResetPasswordException()
                <a href=""$services.security.authentication.getAuthenticationURL('reset', $NULL)"">$services.localization.render('xe.admin.passwordReset.step2.backToStep1')</a>
            #else
                #resetPasswordBoxStart(""success"")
                $services.localization.render('xe.admin.passwordReset.step2.success')
              <a href=""$xwiki.getURL('XWiki.XWikiLogin', 'login')"">$services.localization.render('xe.admin.passwordReset.step2.login')</a>
            #end
        #end
    #end
    #set ($newValidationString = '')
    #set ($validationString = '')
    #set ($password = '')
    #set ($password2 = '')
#end
#xwikimessageboxend()",CWE-640,170.0,1
"import gzip
import json

import pytest
from fastapi import Request
from fastapi.testclient import TestClient

from docs_src.custom_request_and_route.tutorial001 import app


@app.get(""/check-class"")
async def check_gzip_request(request: Request):
    return {""request_class"": type(request).__name__}


client = TestClient(app)


@pytest.mark.parametrize(""compress"", [True, False])
def test_gzip_request(compress):
    n = 1000
    headers = {}
    body = [1] * n
    data = json.dumps(body).encode()
    if compress:
        data = gzip.compress(data)
        headers[""Content-Encoding""] = ""gzip""
    response = client.post(""/sum"", data=data, headers=headers)
    assert response.json() == {""sum"": n}


def test_request_class():
    response = client.get(""/check-class"")
    assert response.json() == {""request_class"": ""GzipRequest""}
",CWE-352,35.0,1
"[build-system]
requires = [""hatchling >= 1.13.0""]
build-backend = ""hatchling.build""

[project]
name = ""fastapi""
description = ""FastAPI framework, high performance, easy to learn, fast to code, ready for production""
readme = ""README.md""
requires-python = "">=3.8""
license = ""MIT""
authors = [
    { name = ""Sebastin Ramrez"", email = ""tiangolo@gmail.com"" },
]
classifiers = [
    ""Intended Audience :: Information Technology"",
    ""Intended Audience :: System Administrators"",
    ""Operating System :: OS Independent"",
    ""Programming Language :: Python :: 3"",
    ""Programming Language :: Python"",
    ""Topic :: Internet"",
    ""Topic :: Software Development :: Libraries :: Application Frameworks"",
    ""Topic :: Software Development :: Libraries :: Python Modules"",
    ""Topic :: Software Development :: Libraries"",
    ""Topic :: Software Development"",
    ""Typing :: Typed"",
    ""Development Status :: 4 - Beta"",
    ""Environment :: Web Environment"",
    ""Framework :: AsyncIO"",
    ""Framework :: FastAPI"",
    ""Framework :: Pydantic"",
    ""Framework :: Pydantic :: 1"",
    ""Intended Audience :: Developers"",
    ""License :: OSI Approved :: MIT License"",
    ""Programming Language :: Python :: 3 :: Only"",
    ""Programming Language :: Python :: 3.8"",
    ""Programming Language :: Python :: 3.9"",
    ""Programming Language :: Python :: 3.10"",
    ""Programming Language :: Python :: 3.11"",
    ""Programming Language :: Python :: 3.12"",
    ""Topic :: Internet :: WWW/HTTP :: HTTP Servers"",
    ""Topic :: Internet :: WWW/HTTP"",
]
dependencies = [
    ""starlette>=0.35.0,<0.36.0"",
    ""pydantic>=1.7.4,!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0"",
    ""typing-extensions>=4.8.0"",
]
dynamic = [""version""]

[project.urls]
Homepage = ""https://github.com/tiangolo/fastapi""
Documentation = ""https://fastapi.tiangolo.com/""
Repository = ""https://github.com/tiangolo/fastapi""

[project.optional-dependencies]
all = [
    ""httpx >=0.23.0"",
    ""jinja2 >=2.11.2"",
    ""python-multipart >=0.0.5"",
    ""itsdangerous >=1.1.0"",
    ""pyyaml >=5.3.1"",
    ""ujson >=4.0.1,!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0"",
    ""orjson >=3.2.1"",
    ""email_validator >=2.0.0"",
    ""uvicorn[standard] >=0.12.0"",
    ""pydantic-settings >=2.0.0"",
    ""pydantic-extra-types >=2.0.0"",
]

[tool.hatch.version]
path = ""fastapi/__init__.py""

[tool.mypy]
strict = true

[[tool.mypy.overrides]]
module = ""fastapi.concurrency""
warn_unused_ignores = false
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = ""fastapi.tests.*""
ignore_missing_imports = true
check_untyped_defs = true

[[tool.mypy.overrides]]
module = ""docs_src.*""
disallow_incomplete_defs = false
disallow_untyped_defs = false
disallow_untyped_calls = false

[tool.pytest.ini_options]
addopts = [
  ""--strict-config"",
  ""--strict-markers"",
  ""--ignore=docs_src"",
]
xfail_strict = true
junit_family = ""xunit2""
filterwarnings = [
    ""error"",
    # TODO: needed by asyncio in Python 3.9.7 https://bugs.python.org/issue45097, try to remove on 3.9.8
    'ignore:The loop argument is deprecated since Python 3\.8, and scheduled for removal in Python 3\.10:DeprecationWarning:asyncio',
    'ignore:starlette.middleware.wsgi is deprecated and will be removed in a future release\..*:DeprecationWarning:starlette',
    # TODO: remove after upgrading HTTPX to a version newer than 0.23.0
    # Including PR: https://github.com/encode/httpx/pull/2309
    ""ignore:'cgi' is deprecated:DeprecationWarning"",
    # For passlib
    ""ignore:'crypt' is deprecated and slated for removal in Python 3.13:DeprecationWarning"",
    # see https://trio.readthedocs.io/en/stable/history.html#trio-0-22-0-2022-09-28
    ""ignore:You seem to already have a custom.*:RuntimeWarning:trio"",
    ""ignore::trio.TrioDeprecationWarning"",
    # TODO remove pytest-cov
    'ignore::pytest.PytestDeprecationWarning:pytest_cov',
    # TODO: remove after upgrading SQLAlchemy to a version that includes the following changes
    # https://github.com/sqlalchemy/sqlalchemy/commit/59521abcc0676e936b31a523bd968fc157fef0c2
    'ignore:datetime\.datetime\.utcfromtimestamp\(\) is deprecated and scheduled for removal in a future version\..*:DeprecationWarning:sqlalchemy',
    # TODO: remove after upgrading python-jose to a version that explicitly supports Python 3.12
    # also, if it won't receive an update, consider replacing python-jose with some alternative
    # related issues:
    #   - https://github.com/mpdavis/python-jose/issues/332
    #   - https://github.com/mpdavis/python-jose/issues/334
    'ignore:datetime\.datetime\.utcnow\(\) is deprecated and scheduled for removal in a future version\..*:DeprecationWarning:jose',
    # TODO: remove after upgrading Starlette to a version including https://github.com/encode/starlette/pull/2406
    # Probably Starlette 0.36.0
    ""ignore: The 'method' parameter is not used, and it will be removed.:DeprecationWarning:starlette"",
]

[tool.coverage.run]
parallel = true
source = [
    ""docs_src"",
    ""tests"",
    ""fastapi""
]
context = '${CONTEXT}'
omit = [
    ""docs_src/response_model/tutorial003_04.py"",
    ""docs_src/response_model/tutorial003_04_py310.py"",
]

[tool.ruff]
select = [
    ""E"",  # pycodestyle errors
    ""W"",  # pycodestyle warnings
    ""F"",  # pyflakes
    ""I"",  # isort
    ""B"",  # flake8-bugbear
    ""C4"",  # flake8-comprehensions
    ""UP"",  # pyupgrade
]
ignore = [
    ""E501"",  # line too long, handled by black
    ""B008"",  # do not perform function calls in argument defaults
    ""W191"",  # indentation contains tabs
]

[tool.ruff.per-file-ignores]
""__init__.py"" = [""F401""]
""docs_src/dependencies/tutorial007.py"" = [""F821""]
""docs_src/dependencies/tutorial008.py"" = [""F821""]
""docs_src/dependencies/tutorial009.py"" = [""F821""]
""docs_src/dependencies/tutorial010.py"" = [""F821""]
""docs_src/custom_response/tutorial007.py"" = [""B007""]
""docs_src/dataclasses/tutorial003.py"" = [""I001""]
""docs_src/path_operation_advanced_configuration/tutorial007.py"" = [""B904""]
""docs_src/path_operation_advanced_configuration/tutorial007_pv1.py"" = [""B904""]
""docs_src/custom_request_and_route/tutorial002.py"" = [""B904""]
""docs_src/dependencies/tutorial008_an.py"" = [""F821""]
""docs_src/dependencies/tutorial008_an_py39.py"" = [""F821""]
""docs_src/query_params_str_validations/tutorial012_an.py"" = [""B006""]
""docs_src/query_params_str_validations/tutorial012_an_py39.py"" = [""B006""]
""docs_src/query_params_str_validations/tutorial013_an.py"" = [""B006""]
""docs_src/query_params_str_validations/tutorial013_an_py39.py"" = [""B006""]
""docs_src/security/tutorial004.py"" = [""B904""]
""docs_src/security/tutorial004_an.py"" = [""B904""]
""docs_src/security/tutorial004_an_py310.py"" = [""B904""]
""docs_src/security/tutorial004_an_py39.py"" = [""B904""]
""docs_src/security/tutorial004_py310.py"" = [""B904""]
""docs_src/security/tutorial005.py"" = [""B904""]
""docs_src/security/tutorial005_an.py"" = [""B904""]
""docs_src/security/tutorial005_an_py310.py"" = [""B904""]
""docs_src/security/tutorial005_an_py39.py"" = [""B904""]
""docs_src/security/tutorial005_py310.py"" = [""B904""]
""docs_src/security/tutorial005_py39.py"" = [""B904""]
""docs_src/dependencies/tutorial008b.py"" = [""B904""]
""docs_src/dependencies/tutorial008b_an.py"" = [""B904""]
""docs_src/dependencies/tutorial008b_an_py39.py"" = [""B904""]


[tool.ruff.isort]
known-third-party = [""fastapi"", ""pydantic"", ""starlette""]

[tool.ruff.pyupgrade]
# Preserve types, even if a file imports `from __future__ import annotations`.
keep-runtime-typing = true
",CWE-1333,197.0,1
"##############################################################################
#
# Copyright (c) 2002 Zope Foundation and Contributors.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE
#
##############################################################################

# This has to happen early so things get initialized properly
from AccessControl.Implementation import setImplementation
from AccessControl.safe_formatter import safe_format
from AccessControl.SecurityInfo import ACCESS_NONE
from AccessControl.SecurityInfo import ACCESS_PRIVATE
from AccessControl.SecurityInfo import ACCESS_PUBLIC
from AccessControl.SecurityInfo import ClassSecurityInfo
from AccessControl.SecurityInfo import ModuleSecurityInfo
from AccessControl.SecurityInfo import allow_class
from AccessControl.SecurityInfo import allow_module
from AccessControl.SecurityInfo import secureModule
from AccessControl.SecurityManagement import getSecurityManager
from AccessControl.SecurityManagement import setSecurityPolicy
from AccessControl.SimpleObjectPolicies import allow_type
from AccessControl.unauthorized import Unauthorized
from AccessControl.ZopeGuards import full_write_guard
from AccessControl.ZopeGuards import get_safe_globals
from AccessControl.ZopeGuards import safe_builtins


ModuleSecurityInfo('AccessControl').declarePublic('getSecurityManager')  # NOQA

# allow imports of utility_builtins

for name in ('string', 'math', 'random', 'sets'):
    ModuleSecurityInfo(name).setDefaultAccess('allow')

ModuleSecurityInfo('DateTime').declarePublic('DateTime')  # NOQA: D001

# We want to allow all methods on string type except ""format"".
# That one needs special handling to avoid access to attributes.
rules = {m: True for m in dir(str) if not m.startswith('_')}
rules['format'] = safe_format
allow_type(str, rules)

zodbupdate_decode_dict = {
    'AccessControl.users User name': 'utf-8',
    'AccessControl.users User __': 'utf-8',
}
",CWE-200,53.0,1
"import string
from collections.abc import Mapping

import _string

from AccessControl.ZopeGuards import guarded_getattr
from AccessControl.ZopeGuards import guarded_getitem


def formatter_field_name_split(field_name):
    return _string.formatter_field_name_split(field_name)


class _MagicFormatMapping(Mapping):
    """"""Pulled from Jinja2.

    This class implements a dummy wrapper to fix a bug in the Python
    standard library for string formatting.

    See http://bugs.python.org/issue13598 for information about why
    this is necessary.
    """"""

    def __init__(self, args, kwargs):
        self._args = args
        self._kwargs = kwargs
        self._last_index = 0

    def __getitem__(self, key):
        if key == '':
            idx = self._last_index
            self._last_index += 1
            try:
                return self._args[idx]
            except LookupError:
                pass
            key = str(idx)
        return self._kwargs[key]

    def __iter__(self):
        return iter(self._kwargs)

    def __len__(self):
        return len(self._kwargs)


class SafeFormatter(string.Formatter):
    """"""Formatter using guarded access.""""""

    def __init__(self, value):
        self.value = value
        super().__init__()

    def get_field(self, field_name, args, kwargs):
        """"""Get the field value using guarded methods.""""""
        first, rest = formatter_field_name_split(field_name)

        obj = self.get_value(first, args, kwargs)

        # loop through the rest of the field_name, doing
        #  getattr or getitem as needed
        for is_attr, i in rest:
            if is_attr:
                obj = guarded_getattr(obj, i)
            else:
                obj = guarded_getitem(obj, i)

        return obj, first

    def safe_format(self, *args, **kwargs):
        """"""Safe variant of `format` method.""""""
        kwargs = _MagicFormatMapping(args, kwargs)
        return self.vformat(self.value, args, kwargs)


def safe_format(inst, method):
    """"""Use our SafeFormatter that uses guarded_getattr for attribute access.""""""
    return SafeFormatter(inst).safe_format
",CWE-200,79.0,1
"# -*- coding: utf-8 -*-

# Tests splitting functions.

import unittest

from tests.utils import load_file, TestCaseBase

import sqlparse


class SQLSplitTest(TestCaseBase):
    """"""Tests sqlparse.sqlsplit().""""""

    _sql1 = 'select * from foo;'
    _sql2 = 'select * from bar;'

    def test_split_semicolon(self):
        sql2 = 'select * from foo where bar = \'foo;bar\';'
        stmts = sqlparse.parse(''.join([self._sql1, sql2]))
        self.assertEqual(len(stmts), 2)
        self.ndiffAssertEqual(unicode(stmts[0]), self._sql1)
        self.ndiffAssertEqual(unicode(stmts[1]), sql2)

    def test_create_function(self):
        sql = load_file('function.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 1)
        self.ndiffAssertEqual(unicode(stmts[0]), sql)

    def test_create_function_psql(self):
        sql = load_file('function_psql.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 1)
        self.ndiffAssertEqual(unicode(stmts[0]), sql)

    def test_create_function_psql3(self):
        sql = load_file('function_psql3.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 1)
        self.ndiffAssertEqual(unicode(stmts[0]), sql)

    def test_create_function_psql2(self):
        sql = load_file('function_psql2.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 1)
        self.ndiffAssertEqual(unicode(stmts[0]), sql)

    def test_dashcomments(self):
        sql = load_file('dashcomment.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 3)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)

    def test_dashcomments_eol(self):
        stmts = sqlparse.parse('select foo; -- comment\n')
        self.assertEqual(len(stmts), 1)
        stmts = sqlparse.parse('select foo; -- comment\r')
        self.assertEqual(len(stmts), 1)
        stmts = sqlparse.parse('select foo; -- comment\r\n')
        self.assertEqual(len(stmts), 1)
        stmts = sqlparse.parse('select foo; -- comment')
        self.assertEqual(len(stmts), 1)

    def test_begintag(self):
        sql = load_file('begintag.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 3)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)

    def test_begintag_2(self):
        sql = load_file('begintag_2.sql')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 1)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)

    def test_dropif(self):
        sql = 'DROP TABLE IF EXISTS FOO;\n\nSELECT * FROM BAR;'
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 2)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)

    def test_comment_with_umlaut(self):
        sql = (u'select * from foo;\n'
               u'-- Testing an umlaut: \n'
               u'select * from bar;')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 2)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)

    def test_comment_end_of_line(self):
        sql = ('select * from foo; -- foo\n'
               'select * from bar;')
        stmts = sqlparse.parse(sql)
        self.assertEqual(len(stmts), 2)
        self.ndiffAssertEqual(''.join(unicode(q) for q in stmts), sql)
        # make sure the comment belongs to first query
        self.ndiffAssertEqual(unicode(stmts[0]), 'select * from foo; -- foo\n')

    def test_casewhen(self):
        sql = ('SELECT case when val = 1 then 2 else null end as foo;\n'
               'comment on table actor is \'The actor table.\';')
        stmts = sqlparse.split(sql)
        self.assertEqual(len(stmts), 2)

    def test_cursor_declare(self):
        sql = ('DECLARE CURSOR ""foo"" AS SELECT 1;\n'
               'SELECT 2;')
        stmts = sqlparse.split(sql)
        self.assertEqual(len(stmts), 2)

    def test_if_function(self):  # see issue 33
        # don't let IF as a function confuse the splitter
        sql = ('CREATE TEMPORARY TABLE tmp '
               'SELECT IF(a=1, a, b) AS o FROM one; '
               'SELECT t FROM two')
        stmts = sqlparse.split(sql)
        self.assertEqual(len(stmts), 2)

    def test_split_stream(self):
        import types
        from cStringIO import StringIO

        stream = StringIO(""SELECT 1; SELECT 2;"")
        stmts = sqlparse.parsestream(stream)
        self.assertEqual(type(stmts), types.GeneratorType)
        self.assertEqual(len(list(stmts)), 2)

    def test_encoding_parsestream(self):
        from cStringIO import StringIO
        stream = StringIO(""SELECT 1; SELECT 2;"")
        stmts = list(sqlparse.parsestream(stream))
        self.assertEqual(type(stmts[0].tokens[0].value), unicode)


def test_split_simple():
    stmts = sqlparse.split('select * from foo; select * from bar;')
    assert len(stmts) == 2
    assert stmts[0] == 'select * from foo;'
    assert stmts[1] == 'select * from bar;'
",CWE-1333,141.0,1
"#
# Copyright (C) 2009-2020 the sqlparse authors and contributors
# <see AUTHORS file>
#
# This module is part of python-sqlparse and is released under
# the BSD License: https://opensource.org/licenses/BSD-3-Clause

import re

from sqlparse import sql, tokens as T
from sqlparse.utils import split_unquoted_newlines


class StripCommentsFilter:

    @staticmethod
    def _process(tlist):
        def get_next_comment():
            # TODO(andi) Comment types should be unified, see related issue38
            return tlist.token_next_by(i=sql.Comment, t=T.Comment)

        def _get_insert_token(token):
            """"""Returns either a whitespace or the line breaks from token.""""""
            # See issue484 why line breaks should be preserved.
            m = re.search(r'((\r\n|\r|\n)+) *$', token.value)
            if m is not None:
                return sql.Token(T.Whitespace.Newline, m.groups()[0])
            else:
                return sql.Token(T.Whitespace, ' ')

        tidx, token = get_next_comment()
        while token:
            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)
            nidx, next_ = tlist.token_next(tidx, skip_ws=False)
            # Replace by whitespace if prev and next exist and if they're not
            # whitespaces. This doesn't apply if prev or next is a parenthesis.
            if (prev_ is None or next_ is None
                    or prev_.is_whitespace or prev_.match(T.Punctuation, '(')
                    or next_.is_whitespace or next_.match(T.Punctuation, ')')):
                # Insert a whitespace to ensure the following SQL produces
                # a valid SQL (see #425).
                if prev_ is not None and not prev_.match(T.Punctuation, '('):
                    tlist.tokens.insert(tidx, _get_insert_token(token))
                tlist.tokens.remove(token)
            else:
                tlist.tokens[tidx] = _get_insert_token(token)

            tidx, token = get_next_comment()

    def process(self, stmt):
        [self.process(sgroup) for sgroup in stmt.get_sublists()]
        StripCommentsFilter._process(stmt)
        return stmt


class StripWhitespaceFilter:
    def _stripws(self, tlist):
        func_name = '_stripws_{cls}'.format(cls=type(tlist).__name__)
        func = getattr(self, func_name.lower(), self._stripws_default)
        func(tlist)

    @staticmethod
    def _stripws_default(tlist):
        last_was_ws = False
        is_first_char = True
        for token in tlist.tokens:
            if token.is_whitespace:
                token.value = '' if last_was_ws or is_first_char else ' '
            last_was_ws = token.is_whitespace
            is_first_char = False

    def _stripws_identifierlist(self, tlist):
        # Removes newlines before commas, see issue140
        last_nl = None
        for token in list(tlist.tokens):
            if last_nl and token.ttype is T.Punctuation and token.value == ',':
                tlist.tokens.remove(last_nl)
            last_nl = token if token.is_whitespace else None

            # next_ = tlist.token_next(token, skip_ws=False)
            # if (next_ and not next_.is_whitespace and
            #             token.ttype is T.Punctuation and token.value == ','):
            #     tlist.insert_after(token, sql.Token(T.Whitespace, ' '))
        return self._stripws_default(tlist)

    def _stripws_parenthesis(self, tlist):
        while tlist.tokens[1].is_whitespace:
            tlist.tokens.pop(1)
        while tlist.tokens[-2].is_whitespace:
            tlist.tokens.pop(-2)
        self._stripws_default(tlist)

    def process(self, stmt, depth=0):
        [self.process(sgroup, depth + 1) for sgroup in stmt.get_sublists()]
        self._stripws(stmt)
        if depth == 0 and stmt.tokens and stmt.tokens[-1].is_whitespace:
            stmt.tokens.pop(-1)
        return stmt


class SpacesAroundOperatorsFilter:
    @staticmethod
    def _process(tlist):

        ttypes = (T.Operator, T.Comparison)
        tidx, token = tlist.token_next_by(t=ttypes)
        while token:
            nidx, next_ = tlist.token_next(tidx, skip_ws=False)
            if next_ and next_.ttype != T.Whitespace:
                tlist.insert_after(tidx, sql.Token(T.Whitespace, ' '))

            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)
            if prev_ and prev_.ttype != T.Whitespace:
                tlist.insert_before(tidx, sql.Token(T.Whitespace, ' '))
                tidx += 1  # has to shift since token inserted before it

            # assert tlist.token_index(token) == tidx
            tidx, token = tlist.token_next_by(t=ttypes, idx=tidx)

    def process(self, stmt):
        [self.process(sgroup) for sgroup in stmt.get_sublists()]
        SpacesAroundOperatorsFilter._process(stmt)
        return stmt


# ---------------------------
# postprocess

class SerializerUnicode:
    @staticmethod
    def process(stmt):
        lines = split_unquoted_newlines(stmt)
        return '\n'.join(line.rstrip() for line in lines)
",CWE-400,134.0,1
"# Tests splitting functions.

import types
from io import StringIO

import pytest

import sqlparse


def test_split_semicolon():
    sql1 = 'select * from foo;'
    sql2 = ""select * from foo where bar = 'foo;bar';""
    stmts = sqlparse.parse(''.join([sql1, sql2]))
    assert len(stmts) == 2
    assert str(stmts[0]) == sql1
    assert str(stmts[1]) == sql2


def test_split_backslash():
    stmts = sqlparse.parse(r""select '\\'; select '\''; select '\\\'';"")
    assert len(stmts) == 3


@pytest.mark.parametrize('fn', ['function.sql',
                                'function_psql.sql',
                                'function_psql2.sql',
                                'function_psql3.sql',
                                'function_psql4.sql'])
def test_split_create_function(load_file, fn):
    sql = load_file(fn)
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 1
    assert str(stmts[0]) == sql


def test_split_dashcomments(load_file):
    sql = load_file('dashcomment.sql')
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 3
    assert ''.join(str(q) for q in stmts) == sql


@pytest.mark.parametrize('s', ['select foo; -- comment\n',
                               'select foo; -- comment\r',
                               'select foo; -- comment\r\n',
                               'select foo; -- comment'])
def test_split_dashcomments_eol(s):
    stmts = sqlparse.parse(s)
    assert len(stmts) == 1


def test_split_begintag(load_file):
    sql = load_file('begintag.sql')
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 3
    assert ''.join(str(q) for q in stmts) == sql


def test_split_begintag_2(load_file):
    sql = load_file('begintag_2.sql')
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 1
    assert ''.join(str(q) for q in stmts) == sql


def test_split_dropif():
    sql = 'DROP TABLE IF EXISTS FOO;\n\nSELECT * FROM BAR;'
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 2
    assert ''.join(str(q) for q in stmts) == sql


def test_split_comment_with_umlaut():
    sql = ('select * from foo;\n'
           '-- Testing an umlaut: \n'
           'select * from bar;')
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 2
    assert ''.join(str(q) for q in stmts) == sql


def test_split_comment_end_of_line():
    sql = ('select * from foo; -- foo\n'
           'select * from bar;')
    stmts = sqlparse.parse(sql)
    assert len(stmts) == 2
    assert ''.join(str(q) for q in stmts) == sql
    # make sure the comment belongs to first query
    assert str(stmts[0]) == 'select * from foo; -- foo\n'


def test_split_casewhen():
    sql = (""SELECT case when val = 1 then 2 else null end as foo;\n""
           ""comment on table actor is 'The actor table.';"")
    stmts = sqlparse.split(sql)
    assert len(stmts) == 2


def test_split_casewhen_procedure(load_file):
    # see issue580
    stmts = sqlparse.split(load_file('casewhen_procedure.sql'))
    assert len(stmts) == 2


def test_split_cursor_declare():
    sql = ('DECLARE CURSOR ""foo"" AS SELECT 1;\n'
           'SELECT 2;')
    stmts = sqlparse.split(sql)
    assert len(stmts) == 2


def test_split_if_function():  # see issue 33
    # don't let IF as a function confuse the splitter
    sql = ('CREATE TEMPORARY TABLE tmp '
           'SELECT IF(a=1, a, b) AS o FROM one; '
           'SELECT t FROM two')
    stmts = sqlparse.split(sql)
    assert len(stmts) == 2


def test_split_stream():
    stream = StringIO(""SELECT 1; SELECT 2;"")
    stmts = sqlparse.parsestream(stream)
    assert isinstance(stmts, types.GeneratorType)
    assert len(list(stmts)) == 2


def test_split_encoding_parsestream():
    stream = StringIO(""SELECT 1; SELECT 2;"")
    stmts = list(sqlparse.parsestream(stream))
    assert isinstance(stmts[0].tokens[0].value, str)


def test_split_unicode_parsestream():
    stream = StringIO('SELECT ')
    stmts = list(sqlparse.parsestream(stream))
    assert str(stmts[0]) == 'SELECT '


def test_split_simple():
    stmts = sqlparse.split('select * from foo; select * from bar;')
    assert len(stmts) == 2
    assert stmts[0] == 'select * from foo;'
    assert stmts[1] == 'select * from bar;'


def test_split_ignores_empty_newlines():
    stmts = sqlparse.split('select foo;\nselect bar;\n')
    assert len(stmts) == 2
    assert stmts[0] == 'select foo;'
    assert stmts[1] == 'select bar;'


def test_split_quotes_with_new_line():
    stmts = sqlparse.split('select ""foo\nbar""')
    assert len(stmts) == 1
    assert stmts[0] == 'select ""foo\nbar""'

    stmts = sqlparse.split(""select 'foo\n\bar'"")
    assert len(stmts) == 1
    assert stmts[0] == ""select 'foo\n\bar'""


def test_split_mysql_handler_for(load_file):
    # see issue581
    stmts = sqlparse.split(load_file('mysql_handler.sql'))
    assert len(stmts) == 2
",CWE-1333,169.0,1
"""""""
:mod:`websockets.legacy.auth` provides HTTP Basic Authentication according to
:rfc:`7235` and :rfc:`7617`.

""""""


import functools
import http
from typing import Any, Awaitable, Callable, Iterable, Optional, Tuple, Union, cast

from ..datastructures import Headers
from ..exceptions import InvalidHeader
from ..headers import build_www_authenticate_basic, parse_authorization_basic
from .server import HTTPResponse, WebSocketServerProtocol


__all__ = [""BasicAuthWebSocketServerProtocol"", ""basic_auth_protocol_factory""]

Credentials = Tuple[str, str]


def is_credentials(value: Any) -> bool:
    try:
        username, password = value
    except (TypeError, ValueError):
        return False
    else:
        return isinstance(username, str) and isinstance(password, str)


class BasicAuthWebSocketServerProtocol(WebSocketServerProtocol):
    """"""
    WebSocket server protocol that enforces HTTP Basic Auth.

    """"""

    def __init__(
        self,
        *args: Any,
        realm: str,
        check_credentials: Callable[[str, str], Awaitable[bool]],
        **kwargs: Any,
    ) -> None:
        self.realm = realm
        self.check_credentials = check_credentials
        super().__init__(*args, **kwargs)

    async def process_request(
        self, path: str, request_headers: Headers
    ) -> Optional[HTTPResponse]:
        """"""
        Check HTTP Basic Auth and return a HTTP 401 or 403 response if needed.

        """"""
        try:
            authorization = request_headers[""Authorization""]
        except KeyError:
            return (
                http.HTTPStatus.UNAUTHORIZED,
                [(""WWW-Authenticate"", build_www_authenticate_basic(self.realm))],
                b""Missing credentials\n"",
            )

        try:
            username, password = parse_authorization_basic(authorization)
        except InvalidHeader:
            return (
                http.HTTPStatus.UNAUTHORIZED,
                [(""WWW-Authenticate"", build_www_authenticate_basic(self.realm))],
                b""Unsupported credentials\n"",
            )

        if not await self.check_credentials(username, password):
            return (
                http.HTTPStatus.UNAUTHORIZED,
                [(""WWW-Authenticate"", build_www_authenticate_basic(self.realm))],
                b""Invalid credentials\n"",
            )

        self.username = username

        return await super().process_request(path, request_headers)


def basic_auth_protocol_factory(
    realm: str,
    credentials: Optional[Union[Credentials, Iterable[Credentials]]] = None,
    check_credentials: Optional[Callable[[str, str], Awaitable[bool]]] = None,
    create_protocol: Optional[Callable[[Any], BasicAuthWebSocketServerProtocol]] = None,
) -> Callable[[Any], BasicAuthWebSocketServerProtocol]:
    """"""
    Protocol factory that enforces HTTP Basic Auth.

    ``basic_auth_protocol_factory`` is designed to integrate with
    :func:`~websockets.legacy.server.serve` like this::

        websockets.serve(
            ...,
            create_protocol=websockets.basic_auth_protocol_factory(
                realm=""my dev server"",
                credentials=(""hello"", ""iloveyou""),
            )
        )

    ``realm`` indicates the scope of protection. It should contain only ASCII
    characters because the encoding of non-ASCII characters is undefined.
    Refer to section 2.2 of :rfc:`7235` for details.

    ``credentials`` defines hard coded authorized credentials. It can be a
    ``(username, password)`` pair or a list of such pairs.

    ``check_credentials`` defines a coroutine that checks whether credentials
    are authorized. This coroutine receives ``username`` and ``password``
    arguments and returns a :class:`bool`.

    One of ``credentials`` or ``check_credentials`` must be provided but not
    both.

    By default, ``basic_auth_protocol_factory`` creates a factory for building
    :class:`BasicAuthWebSocketServerProtocol` instances. You can override this
    with the ``create_protocol`` parameter.

    :param realm: scope of protection
    :param credentials: hard coded credentials
    :param check_credentials: coroutine that verifies credentials
    :raises TypeError: if the credentials argument has the wrong type

    """"""
    if (credentials is None) == (check_credentials is None):
        raise TypeError(""provide either credentials or check_credentials"")

    if credentials is not None:
        if is_credentials(credentials):

            async def check_credentials(username: str, password: str) -> bool:
                return (username, password) == credentials

        elif isinstance(credentials, Iterable):
            credentials_list = list(credentials)
            if all(is_credentials(item) for item in credentials_list):
                credentials_dict = dict(credentials_list)

                async def check_credentials(username: str, password: str) -> bool:
                    return credentials_dict.get(username) == password

            else:
                raise TypeError(f""invalid credentials argument: {credentials}"")

        else:
            raise TypeError(f""invalid credentials argument: {credentials}"")

    if create_protocol is None:
        # Not sure why mypy cannot figure this out.
        create_protocol = cast(
            Callable[[Any], BasicAuthWebSocketServerProtocol],
            BasicAuthWebSocketServerProtocol,
        )

    return functools.partial(
        create_protocol, realm=realm, check_credentials=check_credentials
    )
",CWE-203,163.0,1
"import unittest
import urllib.error

from websockets.exceptions import InvalidStatusCode
from websockets.headers import build_authorization_basic
from websockets.legacy.auth import *
from websockets.legacy.auth import is_credentials

from .test_client_server import ClientServerTestsMixin, with_client, with_server
from .utils import AsyncioTestCase


class AuthTests(unittest.TestCase):
    def test_is_credentials(self):
        self.assertTrue(is_credentials((""username"", ""password"")))

    def test_is_not_credentials(self):
        self.assertFalse(is_credentials(None))
        self.assertFalse(is_credentials(""username""))


class CustomWebSocketServerProtocol(BasicAuthWebSocketServerProtocol):
    async def process_request(self, path, request_headers):
        type(self).used = True
        return await super().process_request(path, request_headers)


class AuthClientServerTests(ClientServerTestsMixin, AsyncioTestCase):

    create_protocol = basic_auth_protocol_factory(
        realm=""auth-tests"", credentials=(""hello"", ""iloveyou"")
    )

    @with_server(create_protocol=create_protocol)
    @with_client(user_info=(""hello"", ""iloveyou""))
    def test_basic_auth(self):
        req_headers = self.client.request_headers
        resp_headers = self.client.response_headers
        self.assertEqual(req_headers[""Authorization""], ""Basic aGVsbG86aWxvdmV5b3U="")
        self.assertNotIn(""WWW-Authenticate"", resp_headers)

        self.loop.run_until_complete(self.client.send(""Hello!""))
        self.loop.run_until_complete(self.client.recv())

    def test_basic_auth_server_no_credentials(self):
        with self.assertRaises(TypeError) as raised:
            basic_auth_protocol_factory(realm=""auth-tests"", credentials=None)
        self.assertEqual(
            str(raised.exception), ""provide either credentials or check_credentials""
        )

    def test_basic_auth_server_bad_credentials(self):
        with self.assertRaises(TypeError) as raised:
            basic_auth_protocol_factory(realm=""auth-tests"", credentials=42)
        self.assertEqual(str(raised.exception), ""invalid credentials argument: 42"")

    create_protocol_multiple_credentials = basic_auth_protocol_factory(
        realm=""auth-tests"",
        credentials=[(""hello"", ""iloveyou""), (""goodbye"", ""stillloveu"")],
    )

    @with_server(create_protocol=create_protocol_multiple_credentials)
    @with_client(user_info=(""hello"", ""iloveyou""))
    def test_basic_auth_server_multiple_credentials(self):
        self.loop.run_until_complete(self.client.send(""Hello!""))
        self.loop.run_until_complete(self.client.recv())

    def test_basic_auth_bad_multiple_credentials(self):
        with self.assertRaises(TypeError) as raised:
            basic_auth_protocol_factory(
                realm=""auth-tests"", credentials=[(""hello"", ""iloveyou""), 42]
            )
        self.assertEqual(
            str(raised.exception),
            ""invalid credentials argument: [('hello', 'iloveyou'), 42]"",
        )

    async def check_credentials(username, password):
        return password == ""iloveyou""

    create_protocol_check_credentials = basic_auth_protocol_factory(
        realm=""auth-tests"",
        check_credentials=check_credentials,
    )

    @with_server(create_protocol=create_protocol_check_credentials)
    @with_client(user_info=(""hello"", ""iloveyou""))
    def test_basic_auth_check_credentials(self):
        self.loop.run_until_complete(self.client.send(""Hello!""))
        self.loop.run_until_complete(self.client.recv())

    create_protocol_custom_protocol = basic_auth_protocol_factory(
        realm=""auth-tests"",
        credentials=[(""hello"", ""iloveyou"")],
        create_protocol=CustomWebSocketServerProtocol,
    )

    @with_server(create_protocol=create_protocol_custom_protocol)
    @with_client(user_info=(""hello"", ""iloveyou""))
    def test_basic_auth_custom_protocol(self):
        self.assertTrue(CustomWebSocketServerProtocol.used)
        del CustomWebSocketServerProtocol.used
        self.loop.run_until_complete(self.client.send(""Hello!""))
        self.loop.run_until_complete(self.client.recv())

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_missing_credentials(self):
        with self.assertRaises(InvalidStatusCode) as raised:
            self.start_client()
        self.assertEqual(raised.exception.status_code, 401)

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_missing_credentials_details(self):
        with self.assertRaises(urllib.error.HTTPError) as raised:
            self.loop.run_until_complete(self.make_http_request())
        self.assertEqual(raised.exception.code, 401)
        self.assertEqual(
            raised.exception.headers[""WWW-Authenticate""],
            'Basic realm=""auth-tests"", charset=""UTF-8""',
        )
        self.assertEqual(raised.exception.read().decode(), ""Missing credentials\n"")

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_unsupported_credentials(self):
        with self.assertRaises(InvalidStatusCode) as raised:
            self.start_client(extra_headers={""Authorization"": ""Digest ...""})
        self.assertEqual(raised.exception.status_code, 401)

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_unsupported_credentials_details(self):
        with self.assertRaises(urllib.error.HTTPError) as raised:
            self.loop.run_until_complete(
                self.make_http_request(headers={""Authorization"": ""Digest ...""})
            )
        self.assertEqual(raised.exception.code, 401)
        self.assertEqual(
            raised.exception.headers[""WWW-Authenticate""],
            'Basic realm=""auth-tests"", charset=""UTF-8""',
        )
        self.assertEqual(raised.exception.read().decode(), ""Unsupported credentials\n"")

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_invalid_credentials(self):
        with self.assertRaises(InvalidStatusCode) as raised:
            self.start_client(user_info=(""hello"", ""ihateyou""))
        self.assertEqual(raised.exception.status_code, 401)

    @with_server(create_protocol=create_protocol)
    def test_basic_auth_invalid_credentials_details(self):
        with self.assertRaises(urllib.error.HTTPError) as raised:
            authorization = build_authorization_basic(""hello"", ""ihateyou"")
            self.loop.run_until_complete(
                self.make_http_request(headers={""Authorization"": authorization})
            )
        self.assertEqual(raised.exception.code, 401)
        self.assertEqual(
            raised.exception.headers[""WWW-Authenticate""],
            'Basic realm=""auth-tests"", charset=""UTF-8""',
        )
        self.assertEqual(raised.exception.read().decode(), ""Invalid credentials\n"")
",CWE-203,161.0,1
"# This file is part of cloud-init. See LICENSE file for license information.

from unittest import mock

from cloudinit.config import cc_set_passwords as setpass
from cloudinit.tests.helpers import CiTestCase
from cloudinit import util

MODPATH = ""cloudinit.config.cc_set_passwords.""


class TestHandleSshPwauth(CiTestCase):
    """"""Test cc_set_passwords handling of ssh_pwauth in handle_ssh_pwauth.""""""

    with_logs = True

    @mock.patch(MODPATH + ""subp.subp"")
    def test_unknown_value_logs_warning(self, m_subp):
        setpass.handle_ssh_pwauth(""floo"")
        self.assertIn(""Unrecognized value: ssh_pwauth=floo"",
                      self.logs.getvalue())
        m_subp.assert_not_called()

    @mock.patch(MODPATH + ""update_ssh_config"", return_value=True)
    @mock.patch(MODPATH + ""subp.subp"")
    def test_systemctl_as_service_cmd(self, m_subp, m_update_ssh_config):
        """"""If systemctl in service cmd: systemctl restart name.""""""
        setpass.handle_ssh_pwauth(
            True, service_cmd=[""systemctl""], service_name=""myssh"")
        self.assertEqual(mock.call([""systemctl"", ""restart"", ""myssh""]),
                         m_subp.call_args)

    @mock.patch(MODPATH + ""update_ssh_config"", return_value=True)
    @mock.patch(MODPATH + ""subp.subp"")
    def test_service_as_service_cmd(self, m_subp, m_update_ssh_config):
        """"""If systemctl in service cmd: systemctl restart name.""""""
        setpass.handle_ssh_pwauth(
            True, service_cmd=[""service""], service_name=""myssh"")
        self.assertEqual(mock.call([""service"", ""myssh"", ""restart""]),
                         m_subp.call_args)

    @mock.patch(MODPATH + ""update_ssh_config"", return_value=False)
    @mock.patch(MODPATH + ""subp.subp"")
    def test_not_restarted_if_not_updated(self, m_subp, m_update_ssh_config):
        """"""If config is not updated, then no system restart should be done.""""""
        setpass.handle_ssh_pwauth(True)
        m_subp.assert_not_called()
        self.assertIn(""No need to restart SSH"", self.logs.getvalue())

    @mock.patch(MODPATH + ""update_ssh_config"", return_value=True)
    @mock.patch(MODPATH + ""subp.subp"")
    def test_unchanged_does_nothing(self, m_subp, m_update_ssh_config):
        """"""If 'unchanged', then no updates to config and no restart.""""""
        setpass.handle_ssh_pwauth(
            ""unchanged"", service_cmd=[""systemctl""], service_name=""myssh"")
        m_update_ssh_config.assert_not_called()
        m_subp.assert_not_called()

    @mock.patch(MODPATH + ""subp.subp"")
    def test_valid_change_values(self, m_subp):
        """"""If value is a valid changen value, then update should be called.""""""
        upname = MODPATH + ""update_ssh_config""
        optname = ""PasswordAuthentication""
        for value in util.FALSE_STRINGS + util.TRUE_STRINGS:
            optval = ""yes"" if value in util.TRUE_STRINGS else ""no""
            with mock.patch(upname, return_value=False) as m_update:
                setpass.handle_ssh_pwauth(value)
                m_update.assert_called_with({optname: optval})
        m_subp.assert_not_called()


class TestSetPasswordsHandle(CiTestCase):
    """"""Test cc_set_passwords.handle""""""

    with_logs = True

    def setUp(self):
        super(TestSetPasswordsHandle, self).setUp()
        self.add_patch('cloudinit.config.cc_set_passwords.sys.stderr', 'm_err')

    def test_handle_on_empty_config(self, *args):
        """"""handle logs that no password has changed when config is empty.""""""
        cloud = self.tmp_cloud(distro='ubuntu')
        setpass.handle(
            'IGNORED', cfg={}, cloud=cloud, log=self.logger, args=[])
        self.assertEqual(
            ""DEBUG: Leaving SSH config 'PasswordAuthentication' unchanged. ""
            'ssh_pwauth=None\n',
            self.logs.getvalue())

    @mock.patch(MODPATH + ""subp.subp"")
    def test_handle_on_chpasswd_list_parses_common_hashes(self, m_subp):
        """"""handle parses command password hashes.""""""
        cloud = self.tmp_cloud(distro='ubuntu')
        valid_hashed_pwds = [
            'root:$2y$10$8BQjxjVByHA/Ee.O1bCXtO8S7Y5WojbXWqnqYpUW.BrPx/'
            'Dlew1Va',
            'ubuntu:$6$5hOurLPO$naywm3Ce0UlmZg9gG2Fl9acWCVEoakMMC7dR52q'
            'SDexZbrN9z8yHxhUM2b.sxpguSwOlbOQSW/HpXazGGx3oo1']
        cfg = {'chpasswd': {'list': valid_hashed_pwds}}
        with mock.patch(MODPATH + 'subp.subp') as m_subp:
            setpass.handle(
                'IGNORED', cfg=cfg, cloud=cloud, log=self.logger, args=[])
        self.assertIn(
            'DEBUG: Handling input for chpasswd as list.',
            self.logs.getvalue())
        self.assertIn(
            ""DEBUG: Setting hashed password for ['root', 'ubuntu']"",
            self.logs.getvalue())
        self.assertEqual(
            [mock.call(['chpasswd', '-e'],
             '\n'.join(valid_hashed_pwds) + '\n')],
            m_subp.call_args_list)

    @mock.patch(MODPATH + ""util.is_BSD"")
    @mock.patch(MODPATH + ""subp.subp"")
    def test_bsd_calls_custom_pw_cmds_to_set_and_expire_passwords(
            self, m_subp, m_is_bsd):
        """"""BSD don't use chpasswd""""""
        m_is_bsd.return_value = True
        cloud = self.tmp_cloud(distro='freebsd')
        valid_pwds = ['ubuntu:passw0rd']
        cfg = {'chpasswd': {'list': valid_pwds}}
        setpass.handle(
            'IGNORED', cfg=cfg, cloud=cloud, log=self.logger, args=[])
        self.assertEqual([
            mock.call(['pw', 'usermod', 'ubuntu', '-h', '0'], data='passw0rd',
                      logstring=""chpasswd for ubuntu""),
            mock.call(['pw', 'usermod', 'ubuntu', '-p', '01-Jan-1970'])],
            m_subp.call_args_list)

    @mock.patch(MODPATH + ""util.is_BSD"")
    @mock.patch(MODPATH + ""subp.subp"")
    def test_handle_on_chpasswd_list_creates_random_passwords(self, m_subp,
                                                              m_is_bsd):
        """"""handle parses command set random passwords.""""""
        m_is_bsd.return_value = False
        cloud = self.tmp_cloud(distro='ubuntu')
        valid_random_pwds = [
            'root:R',
            'ubuntu:RANDOM']
        cfg = {'chpasswd': {'expire': 'false', 'list': valid_random_pwds}}
        with mock.patch(MODPATH + 'subp.subp') as m_subp:
            setpass.handle(
                'IGNORED', cfg=cfg, cloud=cloud, log=self.logger, args=[])
        self.assertIn(
            'DEBUG: Handling input for chpasswd as list.',
            self.logs.getvalue())
        self.assertNotEqual(
            [mock.call(['chpasswd'],
             '\n'.join(valid_random_pwds) + '\n')],
            m_subp.call_args_list)


# vi: ts=4 expandtab
",CWE-532,156.0,1
"""""""Integration test for the set_password module.

This test specifies a combination of user/password pairs, and ensures that the
system has the correct passwords set.

There are two tests run here: one tests chpasswd's list being a YAML list, the
other tests chpasswd's list being a string.  Both expect the same results, so
they use a mixin to share their test definitions, because we can (of course)
only specify one user-data per instance.
""""""
import crypt

import pytest
import yaml


COMMON_USER_DATA = """"""\
#cloud-config
ssh_pwauth: yes
users:
  - default
  - name: tom
    # md5 gotomgo
    passwd: ""$1$S7$tT1BEDIYrczeryDQJfdPe0""
    lock_passwd: false
  - name: dick
    # md5 gocubsgo
    passwd: ""$1$ssisyfpf$YqvuJLfrrW6Cg/l53Pi1n1""
    lock_passwd: false
  - name: harry
    # sha512 goharrygo
    passwd: ""$6$LF$9Z2p6rWK6TNC1DC6393ec0As.18KRAvKDbfsGJEdWN3sRQRwpdfoh37EQ3y\
Uh69tP4GSrGW5XKHxMLiKowJgm/""
    lock_passwd: false
  - name: jane
    # sha256 gojanego
    passwd: ""$5$iW$XsxmWCdpwIW8Yhv.Jn/R3uk6A4UaicfW5Xp7C9p9pg.""
    lock_passwd: false
  - name: ""mikey""
    lock_passwd: false
""""""

LIST_USER_DATA = COMMON_USER_DATA + """"""
chpasswd:
  list:
    - tom:mypassword123!
    - dick:RANDOM
    - harry:RANDOM
    - mikey:$5$xZ$B2YGGEx2AOf4PeW48KC6.QyT1W2B4rZ9Qbltudtha89
""""""

STRING_USER_DATA = COMMON_USER_DATA + """"""
chpasswd:
    list: |
      tom:mypassword123!
      dick:RANDOM
      harry:RANDOM
      mikey:$5$xZ$B2YGGEx2AOf4PeW48KC6.QyT1W2B4rZ9Qbltudtha89
""""""

USERS_DICTS = yaml.safe_load(COMMON_USER_DATA)[""users""]
USERS_PASSWD_VALUES = {
    user_dict[""name""]: user_dict[""passwd""]
    for user_dict in USERS_DICTS
    if ""name"" in user_dict and ""passwd"" in user_dict
}


class Mixin:
    """"""Shared test definitions.""""""

    def _fetch_and_parse_etc_shadow(self, class_client):
        """"""Fetch /etc/shadow and parse it into Python data structures

        Returns: ({user: password}, [duplicate, users])
        """"""
        shadow_content = class_client.read_from_file(""/etc/shadow"")
        users = {}
        dupes = []
        for line in shadow_content.splitlines():
            user, encpw = line.split("":"")[0:2]
            if user in users:
                dupes.append(user)
            users[user] = encpw
        return users, dupes

    def test_no_duplicate_users_in_shadow(self, class_client):
        """"""Confirm that set_passwords has not added duplicate shadow entries""""""
        _, dupes = self._fetch_and_parse_etc_shadow(class_client)

        assert [] == dupes

    def test_password_in_users_dict_set_correctly(self, class_client):
        """"""Test that the password specified in the users dict is set.""""""
        shadow_users, _ = self._fetch_and_parse_etc_shadow(class_client)
        assert USERS_PASSWD_VALUES[""jane""] == shadow_users[""jane""]

    def test_password_in_chpasswd_list_set_correctly(self, class_client):
        """"""Test that a chpasswd password overrides one in the users dict.""""""
        shadow_users, _ = self._fetch_and_parse_etc_shadow(class_client)
        mikey_hash = ""$5$xZ$B2YGGEx2AOf4PeW48KC6.QyT1W2B4rZ9Qbltudtha89""
        assert mikey_hash == shadow_users[""mikey""]

    def test_random_passwords_set_correctly(self, class_client):
        """"""Test that RANDOM chpasswd entries replace users dict passwords.""""""
        shadow_users, _ = self._fetch_and_parse_etc_shadow(class_client)

        # These should have been changed
        assert shadow_users[""harry""] != USERS_PASSWD_VALUES[""harry""]
        assert shadow_users[""dick""] != USERS_PASSWD_VALUES[""dick""]

        # To random passwords
        assert shadow_users[""harry""].startswith(""$"")
        assert shadow_users[""dick""].startswith(""$"")

        # Which are not the same
        assert shadow_users[""harry""] != shadow_users[""dick""]

    def test_explicit_password_set_correctly(self, class_client):
        """"""Test that an explicitly-specified password is set correctly.""""""
        shadow_users, _ = self._fetch_and_parse_etc_shadow(class_client)

        fmt_and_salt = shadow_users[""tom""].rsplit(""$"", 1)[0]
        expected_value = crypt.crypt(""mypassword123!"", fmt_and_salt)

        assert expected_value == shadow_users[""tom""]

    def test_shadow_expected_users(self, class_client):
        """"""Test that the right set of users is in /etc/shadow.""""""
        shadow = class_client.read_from_file(""/etc/shadow"")
        for user_dict in USERS_DICTS:
            if ""name"" in user_dict:
                assert ""{}:"".format(user_dict[""name""]) in shadow

    def test_sshd_config(self, class_client):
        """"""Test that SSH password auth is enabled.""""""
        sshd_config = class_client.read_from_file(""/etc/ssh/sshd_config"")
        # We look for the exact line match, to avoid a commented line matching
        assert ""PasswordAuthentication yes"" in sshd_config.splitlines()


@pytest.mark.ci
@pytest.mark.user_data(LIST_USER_DATA)
class TestPasswordList(Mixin):
    """"""Launch an instance with LIST_USER_DATA, ensure Mixin tests pass.""""""


@pytest.mark.ci
@pytest.mark.user_data(STRING_USER_DATA)
class TestPasswordListString(Mixin):
    """"""Launch an instance with STRING_USER_DATA, ensure Mixin tests pass.""""""
",CWE-532,152.0,1
"""""""Integration tests for CLI functionality

These would be for behavior manually invoked by user from the command line
""""""

import pytest

from tests.integration_tests.instances import IntegrationInstance

VALID_USER_DATA = """"""\
#cloud-config
runcmd:
  - echo 'hi' > /var/tmp/test
""""""

INVALID_USER_DATA_HEADER = """"""\
runcmd:
  - echo 'hi' > /var/tmp/test
""""""

INVALID_USER_DATA_SCHEMA = """"""\
#cloud-config
updates:
 notnetwork: -1
apt_pipelining: bogus
""""""


@pytest.mark.user_data(VALID_USER_DATA)
def test_valid_userdata(client: IntegrationInstance):
    """"""Test `cloud-init schema` with valid userdata.

    PR #575
    """"""
    result = client.execute(""cloud-init schema --system"")
    assert result.ok
    assert ""Valid cloud-config: system userdata"" == result.stdout.strip()
    result = client.execute(""cloud-init status --long"")
    if not result.ok:
        raise AssertionError(
            f""Unexpected error from cloud-init status: {result}""
        )


@pytest.mark.user_data(INVALID_USER_DATA_HEADER)
def test_invalid_userdata(client: IntegrationInstance):
    """"""Test `cloud-init schema` with invalid userdata.

    PR #575
    """"""
    result = client.execute(""cloud-init schema --system"")
    assert not result.ok
    assert ""Cloud config schema errors"" in result.stderr
    assert 'needs to begin with ""#cloud-config""' in result.stderr
    result = client.execute(""cloud-init status --long"")
    if not result.ok:
        raise AssertionError(
            f""Unexpected error from cloud-init status: {result}""
        )


@pytest.mark.user_data(INVALID_USER_DATA_SCHEMA)
def test_invalid_userdata_schema(client: IntegrationInstance):
    """"""Test invalid schema represented as Warnings, not fatal

    PR #1175
    """"""
    result = client.execute(""cloud-init status --long"")
    assert result.ok
    log = client.read_from_file(""/var/log/cloud-init.log"")
    warning = (
        ""[WARNING]: Invalid cloud-config provided:\napt_pipelining: 'bogus'""
        "" is not valid under any of the given schemas\nupdates: Additional""
        "" properties are not allowed ('notnetwork' was unexpected)""
    )
    assert warning in log
    result = client.execute(""cloud-init status --long"")
    if not result.ok:
        raise AssertionError(
            f""Unexpected error from cloud-init status: {result}""
        )
",CWE-532,82.0,1
"# Author: Eric Benner <ebenner@vultr.com>
#
# This file is part of cloud-init. See LICENSE file for license information.

# Vultr Metadata API:
# https://www.vultr.com/metadata/

import cloudinit.sources.helpers.vultr as vultr
from cloudinit import log as log
from cloudinit import sources, stages, util, version

LOG = log.getLogger(__name__)
BUILTIN_DS_CONFIG = {
    ""url"": ""http://169.254.169.254"",
    ""retries"": 30,
    ""timeout"": 10,
    ""wait"": 5,
    ""user-agent"": ""Cloud-Init/%s - OS: %s Variant: %s""
    % (
        version.version_string(),
        util.system_info()[""system""],
        util.system_info()[""variant""],
    ),
}


class DataSourceVultr(sources.DataSource):

    dsname = ""Vultr""

    def __init__(self, sys_cfg, distro, paths):
        super(DataSourceVultr, self).__init__(sys_cfg, distro, paths)
        self.ds_cfg = util.mergemanydict(
            [
                util.get_cfg_by_path(sys_cfg, [""datasource"", ""Vultr""], {}),
                BUILTIN_DS_CONFIG,
            ]
        )

    @staticmethod
    def ds_detect():
        return vultr.is_vultr()

    # Initiate data and check if Vultr
    def _get_data(self):

        LOG.debug(""Machine is a Vultr instance"")

        # Fetch metadata
        self.metadata = self.get_metadata()
        self.userdata_raw = self.metadata[""user-data""]

        # Generate config and process data
        self.get_datasource_data(self.metadata)

        # Dump some data so diagnosing failures is manageable
        LOG.debug(""Vultr Vendor Config:"")
        LOG.debug(util.json_dumps(self.metadata[""vendor-data""]))
        LOG.debug(""SUBID: %s"", self.metadata[""instance-id""])
        LOG.debug(""Hostname: %s"", self.metadata[""local-hostname""])
        if self.userdata_raw is not None:
            LOG.debug(""User-Data:"")
            LOG.debug(self.userdata_raw)

        return True

    # Process metadata
    def get_datasource_data(self, md):
        # Generate network config
        if ""cloud_interfaces"" in md:
            # In the future we will just drop pre-configured
            # network configs into the array. They need names though.
            vultr.add_interface_names(md[""cloud_interfaces""])
            self.netcfg = md[""cloud_interfaces""]
        else:
            self.netcfg = vultr.generate_network_config(md[""interfaces""])
        # Grab vendordata
        self.vendordata_raw = md[""vendor-data""]

        # Default hostname is ""guest"" for whitelabel
        if self.metadata[""local-hostname""] == """":
            self.metadata[""local-hostname""] = ""guest""

        self.userdata_raw = md[""user-data""]
        if self.userdata_raw == """":
            self.userdata_raw = None

    # Get the metadata by flag
    def get_metadata(self):
        return vultr.get_metadata(
            self.distro,
            self.ds_cfg[""url""],
            self.ds_cfg[""timeout""],
            self.ds_cfg[""retries""],
            self.ds_cfg[""wait""],
            self.ds_cfg[""user-agent""],
            tmp_dir=self.distro.get_tmp_exec_path(),
        )

    # Compare subid as instance id
    def check_instance_id(self, sys_cfg):
        if not vultr.is_vultr():
            return False

        # Baremetal has no way to implement this in local
        if vultr.is_baremetal():
            return False

        subid = vultr.get_sysinfo()[""subid""]
        return sources.instance_id_matches_system_uuid(subid)

    # Currently unsupported
    @property
    def launch_index(self):
        return None

    @property
    def network_config(self):
        return self.netcfg


# Used to match classes to dependencies
datasources = [
    (DataSourceVultr, (sources.DEP_FILESYSTEM,)),
]


# Return a list of data sources that match this set of dependencies
def get_datasource_list(depends):
    return sources.list_from_depends(depends, datasources)


if __name__ == ""__main__"":
    import sys

    if not vultr.is_vultr():
        print(""Machine is not a Vultr instance"")
        sys.exit(1)

    # It should probably be safe to try to detect distro via stages.Init(),
    # which will fall back to Ubuntu if no distro config is found.
    # this distro object is only used for dhcp fallback. Feedback from user(s)
    # of __main__ would help determine if a better approach exists.
    #
    # we don't needReportEventStack, so reporter=True
    distro = stages.Init(reporter=True).distro

    md = vultr.get_metadata(
        distro,
        BUILTIN_DS_CONFIG[""url""],
        BUILTIN_DS_CONFIG[""timeout""],
        BUILTIN_DS_CONFIG[""retries""],
        BUILTIN_DS_CONFIG[""wait""],
        BUILTIN_DS_CONFIG[""user-agent""],
    )
    config = md[""vendor-data""]
    sysinfo = vultr.get_sysinfo()

    print(util.json_dumps(sysinfo))
    print(util.json_dumps(config))
",CWE-532,161.0,1
"import tarfile
import os
from thefuck.utils import for_app
from thefuck.shells import shell


tar_extensions = ('.tar', '.tar.Z', '.tar.bz2', '.tar.gz', '.tar.lz',
                  '.tar.lzma', '.tar.xz', '.taz', '.tb2', '.tbz', '.tbz2',
                  '.tgz', '.tlz', '.txz', '.tz')


def _is_tar_extract(cmd):
    if '--extract' in cmd:
        return True

    cmd = cmd.split()

    return len(cmd) > 1 and 'x' in cmd[1]


def _tar_file(cmd):
    for c in cmd:
        for ext in tar_extensions:
            if c.endswith(ext):
                return (c, c[0:len(c) - len(ext)])


@for_app('tar')
def match(command):
    return ('-C' not in command.script
            and _is_tar_extract(command.script)
            and _tar_file(command.script_parts) is not None)


def get_new_command(command):
    dir = shell.quote(_tar_file(command.script_parts)[1])
    return shell.and_('mkdir -p {dir}', '{cmd} -C {dir}') \
        .format(dir=dir, cmd=command.script)


def side_effect(old_cmd, command):
    with tarfile.TarFile(_tar_file(old_cmd.script_parts)[0]) as archive:
        for file in archive.getnames():
            try:
                os.remove(file)
            except OSError:
                # does not try to remove directories as we cannot know if they
                # already existed before
                pass
",CWE-22,50.0,1
"import os
import zipfile
from thefuck.utils import for_app
from thefuck.shells import shell


def _is_bad_zip(file):
    try:
        with zipfile.ZipFile(file, 'r') as archive:
            return len(archive.namelist()) > 1
    except Exception:
        return False


def _zip_file(command):
    # unzip works that way:
    # unzip [-flags] file[.zip] [file(s) ...] [-x file(s) ...]
    #                ^          ^ files to unzip from the archive
    #                archive to unzip
    for c in command.script_parts[1:]:
        if not c.startswith('-'):
            if c.endswith('.zip'):
                return c
            else:
                return u'{}.zip'.format(c)


@for_app('unzip')
def match(command):
    if '-d' in command.script:
        return False

    zip_file = _zip_file(command)
    if zip_file:
        return _is_bad_zip(zip_file)
    else:
        return False


def get_new_command(command):
    return u'{} -d {}'.format(
        command.script, shell.quote(_zip_file(command)[:-4]))


def side_effect(old_cmd, command):
    with zipfile.ZipFile(_zip_file(old_cmd), 'r') as archive:
        for file in archive.namelist():
            try:
                os.remove(file)
            except OSError:
                # does not try to remove directories as we cannot know if they
                # already existed before
                pass


requires_output = False
",CWE-22,57.0,1
"[package]
name = ""git-delta""
authors = [""Dan Davison <dandavison7@gmail.com>""]
categories = [""command-line-utilities"", ""development-tools""]
description = ""A syntax-highlighting pager for git""
documentation = ""https://github.com/dandavison/delta""
edition = ""2018""
homepage = ""https://github.com/dandavison/delta""
license = ""MIT""
repository = ""https://github.com/dandavison/delta""
version = ""0.8.3""

[[bin]]
name = ""delta""
path = ""src/main.rs""

[dependencies]
ansi_colours = ""1.0.4""
ansi_term = ""0.12.1""
atty = ""0.2.14""
bitflags = ""1.2.1""
box_drawing = ""0.1.2""
bytelines = ""2.2.2""
console = ""0.14.1""
dirs-next = ""2.0.0""
itertools = ""0.10.1""
lazy_static = ""1.4""
pathdiff = ""0.2.0""
regex = ""1.4.6""
shell-words = ""1.0.0""
structopt = ""0.3.22""
unicode-segmentation = ""1.8.0""
unicode-width = ""0.1.8""
vte = ""0.10.1""
xdg = ""2.2.0""

[dependencies.git2]
version = ""0.13.20""
default-features = false
features = []

[dependencies.syntect]
version = ""4.5.0""
default-features = false
features = [""parsing"", ""assets"", ""yaml-load"", ""dump-load"", ""regex-onig""]

[dependencies.error-chain]
version = ""0.12.4""
default-features = false
features = []
",CWE-427,51.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

import azure.functions as func
from onefuzztypes.responses import Info

from ..onefuzzlib.azure.creds import (
    get_base_region,
    get_base_resource_group,
    get_insights_appid,
    get_insights_instrumentation_key,
    get_instance_id,
    get_subscription,
)
from ..onefuzzlib.request import ok
from ..onefuzzlib.versions import versions


def main(req: func.HttpRequest) -> func.HttpResponse:
    response = ok(
        Info(
            resource_group=get_base_resource_group(),
            region=get_base_region(),
            subscription=get_subscription(),
            versions=versions(),
            instance_id=get_instance_id(),
            insights_appid=get_insights_appid(),
            insights_instrumentation_key=get_insights_instrumentation_key(),
        )
    )

    return response
",CWE-863,35.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

from typing import Optional, Tuple

from onefuzztypes.events import EventInstanceConfigUpdated
from onefuzztypes.models import InstanceConfig as BASE_CONFIG
from pydantic import Field

from .azure.creds import get_instance_name
from .events import send_event
from .orm import ORMMixin


class InstanceConfig(BASE_CONFIG, ORMMixin):
    instance_name: str = Field(default_factory=get_instance_name)

    @classmethod
    def key_fields(cls) -> Tuple[str, Optional[str]]:
        return (""instance_name"", None)

    @classmethod
    def fetch(cls) -> ""InstanceConfig"":
        entry = cls.get(get_instance_name())
        if entry is None:
            entry = cls()
            entry.save()
        return entry

    def save(self, new: bool = False, require_etag: bool = False) -> None:
        super().save(new=new, require_etag=require_etag)
        send_event(EventInstanceConfigUpdated(config=self))
",CWE-863,35.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

from typing import Optional
from uuid import UUID

import azure.functions as func
import jwt
from onefuzztypes.enums import ErrorCode
from onefuzztypes.models import Error, Result, UserInfo


def get_bearer_token(request: func.HttpRequest) -> Optional[str]:
    auth: str = request.headers.get(""Authorization"", None)
    if not auth:
        return None

    parts = auth.split()

    if len(parts) != 2:
        return None

    if parts[0].lower() != ""bearer"":
        return None

    return parts[1]


def get_auth_token(request: func.HttpRequest) -> Optional[str]:
    token = get_bearer_token(request)
    if token is not None:
        return token

    token_header = request.headers.get(""x-ms-token-aad-id-token"", None)
    if token_header is None:
        return None
    return str(token_header)


def parse_jwt_token(request: func.HttpRequest) -> Result[UserInfo]:
    """"""Obtains the Access Token from the Authorization Header""""""
    token_str = get_auth_token(request)
    if token_str is None:
        return Error(
            code=ErrorCode.INVALID_REQUEST,
            errors=[""unable to find authorization token""],
        )

    # This token has already been verified by the azure authentication layer
    token = jwt.decode(token_str, options={""verify_signature"": False})

    application_id = UUID(token[""appid""]) if ""appid"" in token else None
    object_id = UUID(token[""oid""]) if ""oid"" in token else None
    upn = token.get(""upn"")
    return UserInfo(application_id=application_id, object_id=object_id, upn=upn)
",CWE-863,58.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

import os
import unittest
from uuid import uuid4

from onefuzztypes.models import UserInfo

from __app__.onefuzzlib.config import InstanceConfig
from __app__.onefuzzlib.endpoint_authorization import (
    can_modify_config_impl,
    check_can_manage_pools_impl,
)

if ""ONEFUZZ_INSTANCE_NAME"" not in os.environ:
    os.environ[""ONEFUZZ_INSTANCE_NAME""] = ""test""


class TestAdmin(unittest.TestCase):
    def test_modify_config(self) -> None:
        user1 = uuid4()
        user2 = uuid4()

        # no admins set
        self.assertTrue(can_modify_config_impl(InstanceConfig(), UserInfo()))

        # with oid, but no admin
        self.assertTrue(
            can_modify_config_impl(InstanceConfig(), UserInfo(object_id=user1))
        )

        # is admin
        self.assertTrue(
            can_modify_config_impl(
                InstanceConfig(admins=[user1]), UserInfo(object_id=user1)
            )
        )

        # no user oid set
        self.assertFalse(
            can_modify_config_impl(InstanceConfig(admins=[user1]), UserInfo())
        )

        # not an admin
        self.assertFalse(
            can_modify_config_impl(
                InstanceConfig(admins=[user1]), UserInfo(object_id=user2)
            )
        )

    def test_manage_pools(self) -> None:
        user1 = uuid4()
        user2 = uuid4()

        # by default, any can modify
        self.assertIsNone(
            check_can_manage_pools_impl(
                InstanceConfig(allow_pool_management=True), UserInfo()
            )
        )

        # with oid, but no admin
        self.assertIsNone(
            check_can_manage_pools_impl(
                InstanceConfig(allow_pool_management=True), UserInfo(object_id=user1)
            )
        )

        # is admin
        self.assertIsNone(
            check_can_manage_pools_impl(
                InstanceConfig(allow_pool_management=False, admins=[user1]),
                UserInfo(object_id=user1),
            )
        )

        # no user oid set
        self.assertIsNotNone(
            check_can_manage_pools_impl(
                InstanceConfig(allow_pool_management=False, admins=[user1]), UserInfo()
            )
        )

        # not an admin
        self.assertIsNotNone(
            check_can_manage_pools_impl(
                InstanceConfig(allow_pool_management=False, admins=[user1]),
                UserInfo(object_id=user2),
            )
        )


if __name__ == ""__main__"":
    unittest.main()
",CWE-863,98.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

import argparse
import json
from typing import List, Optional
from uuid import UUID

from azure.common.client_factory import get_client_from_cli_profile
from azure.cosmosdb.table.tableservice import TableService
from azure.mgmt.storage import StorageManagementClient

TABLE_NAME = ""InstanceConfig""


def create_if_missing(table_service: TableService) -> None:
    if not table_service.exists(TABLE_NAME):
        table_service.create_table(TABLE_NAME)


def update_admins(
    table_service: TableService, resource_group: str, admins: List[UUID]
) -> None:
    create_if_missing(table_service)
    admins_as_str: Optional[List[str]] = None
    if admins:
        admins_as_str = [str(x) for x in admins]

    table_service.insert_or_merge_entity(
        TABLE_NAME,
        {
            ""PartitionKey"": resource_group,
            ""RowKey"": resource_group,
            ""admins"": json.dumps(admins_as_str),
        },
    )


def main() -> None:
    formatter = argparse.ArgumentDefaultsHelpFormatter
    parser = argparse.ArgumentParser(formatter_class=formatter)
    parser.add_argument(""resource_group"")
    parser.add_argument(""storage_account"")
    parser.add_argument(""admins"", type=UUID, nargs=""*"")
    args = parser.parse_args()

    client = get_client_from_cli_profile(StorageManagementClient)
    storage_keys = client.storage_accounts.list_keys(
        args.resource_group, args.storage_account
    )
    table_service = TableService(
        account_name=args.storage_account, account_key=storage_keys.keys[0].value
    )
    update_admins(table_service, args.resource_group, args.admins)


if __name__ == ""__main__"":
    main()
",CWE-863,61.0,1
"#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

from uuid import UUID
import unittest

from onefuzztypes.models import InstanceConfig


class TestInstanceConfig(unittest.TestCase):
    def test_with_admins(self) -> None:
        no_admins = InstanceConfig(admins=None)
        with_admins = InstanceConfig(admins=[UUID(int=0)])
        with_admins_2 = InstanceConfig(admins=[UUID(int=1)])

        no_admins.update(with_admins)
        self.assertEqual(no_admins.admins, None)

        with_admins.update(with_admins_2)
        self.assertEqual(with_admins.admins, with_admins_2.admins)

    def test_with_empty_admins(self) -> None:
        with self.assertRaises(ValueError):
            InstanceConfig.parse_obj({""admins"": []})


if __name__ == ""__main__"":
    unittest.main()
",CWE-863,31.0,1
"import hashlib, base64, uuid
from cryptography.hazmat.primitives import hashes
from typing import Any, final
class Hashing():
    def __init__(self) -> None:
        self.salt = None
    def __call__(self, *args:Any):
        self.salt = args[0]
    def __str__(self) -> str:
        return ""Hashing Funcitions In Here""

    def Standard_Multi_Hash(self,Data:str):
        '''Inreversable Salted Hash Function Don't Use If U Want To Get The Content Back'''
        a = hashlib.sha256(); a.update(bytes(Data.encode())); b = []
        base = hashlib.sha512()
        md = hashlib.md5()
        b.append(str(a.digest()).split(""'"")[1])
        b[0] = str(base64.urlsafe_b64encode(bytes(b[0].encode()))).split(""'"")[1]
        base.update(bytes(b[0].encode()))
        md.update(base.digest())
        b[0]=str(base64.urlsafe_b64encode(base64.standard_b64encode(md.digest()))).split(""'"")[1]
        salt = ['H', 'c', 'D', 'L', 'b', 'M', 'S', 'a', 'N', 'q', 'K', 'j', 'V', 'd', 'O', 'W', 'x']
        c = (b[0].split(""G""))or(b[0].split(""g""))or(b[0].split(""v""))or(b[0].split(""x"")); d=[]; e=[]
        for i in range(len(c)): a = salt[i]; b = c[i]; c[i] = b+a
        for i in range(len(c)):
            try: d.append(c[i+1])
            except: d.append(c[0])
            e.append(''.join(d))
            final = self.BLAKE2(bytes(str(e[0]).encode()))
            return(final)

    def __Salt(self,data,salt:bytes = None):
        if not salt:
            salts = []
            salts.append(str(hashlib.sha256(uuid.uuid4().bytes).digest()).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(hashlib.sha256(uuid.uuid4().bytes).digest()).split(""'"")[1])
            salts.append(str(hashlib.sha256(uuid.uuid4().bytes).digest()).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(hashlib.sha256(uuid.uuid4().bytes).digest()).split(""'"")[1])
            return base64.standard_b64encode(bytes((str(base64.urlsafe_b64encode(bytes(''.join(salts).encode()))).split(""'"")[1]+str(base64.urlsafe_b64encode(base64.standard_b64encode((bytes(''.join(salts).encode()))))).split(""'"")[1]).encode()))
        if salt:
            salts = []
            salts.append(str(hashlib.sha256(salt).digest()).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(hashlib.sha256(salt).digest()).split(""'"")[1])
            salts.append(str(hashlib.sha256(salt).digest()).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(data).split(""'"")[1])
            salts.append(str(hashlib.sha256(salt).digest()).split(""'"")[1])
            return base64.standard_b64encode(bytes((str(base64.urlsafe_b64encode(bytes(''.join(salts).encode()))).split(""'"")[1]+str(base64.urlsafe_b64encode(base64.standard_b64encode((bytes(''.join(salts).encode()))))).split(""'"")[1]).encode()))
        
    def SHA256(self,data:str):
        sha = hashlib.sha256(bytes(data.encode()))
        hash = sha.digest()
        return self.__Salt(hash,salt=self.salt)

    def SHA512(self,data:str):
        sha = hashlib.sha512(bytes(data.encode()))
        hash = str(sha.digest())
        return self.__Salt(hash,salt=self.salt)

    def SHA244(self,data:str):
        sha = hashlib.sha224(bytes(data.encode()))
        hash = str(sha.digest())
        return self.__Salt(hash,salt=self.salt)

    def MD5(self,data:str):
        sha = hashlib.md5(bytes(data.encode()))
        hash = str(sha.digest())
        return self.__Salt(hash,salt=self.salt)

    def SHA384(self,data:str):
        sha = hashlib.sha384(bytes(data.encode()))
        hash = str(sha.digest())
        return self.__Salt(hash,salt=self.salt)

    def BLAKE2(self,data:bytes):
        a = hashes.Hash(hashes.BLAKE2s(32))
        a.update(data)
        return self.__Salt(a.finalize(),salt=self.salt)
        ",CWE-326,83.0,1
"#!/usr/bin/env python3

# Copyright (c) Facebook, Inc. and its affiliates.
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
""""""
Config Utils.
""""""

import yaml
from collections import namedtuple

WorldConfig = namedtuple(
    ""WorldConfig"",
    [
        ""world_name"",
        ""onboarding_name"",
        ""task_name"",
        ""max_time_in_pool"",
        ""agents_required"",
        ""backup_task"",
    ],
)


def parse_configuration_file(config_path):
    """"""
    Read the config file for an experiment to get ParlAI settings.

    :param config_path:
        path to config

    :return:
        parsed configuration dictionary
    """"""
    result = {}
    result[""configs""] = {}
    with open(config_path) as f:
        cfg = yaml.load(f.read(), Loader=yaml.FullLoader)
        # get world path
        result[""world_path""] = cfg.get(""world_module"")
        if not result[""world_path""]:
            raise ValueError(""Did not specify world module"")
        result[""overworld""] = cfg.get(""overworld"")
        if not result[""overworld""]:
            raise ValueError(""Did not specify overworld"")
        result[""max_workers""] = cfg.get(""max_workers"")
        if not result[""max_workers""]:
            raise ValueError(""Did not specify max_workers"")
        result[""task_name""] = cfg.get(""task_name"")
        if not result[""task_name""]:
            raise ValueError(""Did not specify task name"")
        task_world = cfg.get(""tasks"")
        if task_world is None or len(task_world) == 0:
            raise ValueError(""task not in config file"")
        # get task file
        for task_name, configuration in task_world.items():
            if ""task_world"" not in configuration:
                raise ValueError(""{} does not specify a task"".format(task_name))
            result[""configs""][task_name] = WorldConfig(
                world_name=task_name,
                onboarding_name=configuration.get(""onboard_world""),
                task_name=configuration.get(""task_world""),
                max_time_in_pool=configuration.get(""timeout"") or 300,
                agents_required=configuration.get(""agents_required"") or 1,
                backup_task=configuration.get(""backup_task""),
            )
        # get world options, additional args
        result[""world_opt""] = cfg.get(""opt"", {})
        result[""additional_args""] = cfg.get(""additional_args"", {})

    return result
",CWE-502,73.0,1
"import os
import os.path
import shutil

from babel.messages.frontend import CommandLineInterface

from translate.convert.po2csv import main as po2csv
from translate.convert.csv2po import main as csv2po


ROOT_DIR = 'i18n'

TRANSLATIONS = os.path.join(ROOT_DIR, 'translations')

MESSAGES = os.path.join(ROOT_DIR, 'messages.pot')

# ============================================================================
class LocManager:
    def process(self, r):
        if r.name == 'list':
            r.loc_func(self)
        elif r.name == 'remove':
            r.loc_func(self, r.locale)
        else:
            r.loc_func(self, r.locale, r.no_csv)

    def extract_loc(self, locale, no_csv):
        self.extract_text()

        for loc in locale:
            loc_dir = os.path.join(TRANSLATIONS, loc)
            if os.path.isdir(loc_dir):
                self.update_catalog(loc)
            else:
                os.makedirs(loc_dir)
                self.init_catalog(loc)

            if not no_csv:
                base = os.path.join(TRANSLATIONS, loc, 'LC_MESSAGES')
                po = os.path.join(base, 'messages.po')
                csv = os.path.join(base, 'messages.csv')
                po2csv([po, csv])

    def update_loc(self, locale, no_csv):
        for loc in locale:
            if not no_csv:
                loc_dir = os.path.join(TRANSLATIONS, loc)
                base = os.path.join(TRANSLATIONS, loc, 'LC_MESSAGES')
                po = os.path.join(base, 'messages.po')
                csv = os.path.join(base, 'messages.csv')

                if os.path.isfile(csv):
                    csv2po([csv, po])

        self.compile_catalog()

    def remove_loc(self, locale):
        for loc in locale:
            loc_dir = os.path.join(TRANSLATIONS, loc)
            if not os.path.isdir(loc_dir):
                print('Locale ""{0}"" does not exist'.format(loc))
                return

            shutil.rmtree(loc_dir)
            print('Removed locale ""{0}""'.format(loc))

    def list_loc(self):
        print('Current locales:')
        print('\n'.join(' - ' + x for x in os.listdir(TRANSLATIONS)))
        print('')

    def extract_text(self):
        os.makedirs(ROOT_DIR, exist_ok=True)

        CommandLineInterface().run(['pybabel', 'extract', '-F', 'babel.ini', '-k', '_ _Q gettext ngettext', '-o', MESSAGES, './', '--omit-header'])

    def init_catalog(self, loc):
        CommandLineInterface().run(['pybabel', 'init', '-l', loc, '-i', MESSAGES, '-d', TRANSLATIONS])

    def update_catalog(self, loc):
        CommandLineInterface().run(['pybabel', 'update', '-l', loc, '-i', MESSAGES, '-d', TRANSLATIONS, '--previous'])

    def compile_catalog(self):
        CommandLineInterface().run(['pybabel', 'compile', '-d', TRANSLATIONS])


    @classmethod
    def init_parser(cls, parser):
        """"""Initializes an argument parser for acl commands

        :param argparse.ArgumentParser parser: The parser to be initialized
        :rtype: None
        """"""
        subparsers = parser.add_subparsers(dest='op')
        subparsers.required = True

        def command(name, func):
            op = subparsers.add_parser(name)
            if name != 'list':
                op.add_argument('locale', nargs='+')
                if name != 'remove':
                    op.add_argument('--no-csv', action='store_true')

            op.set_defaults(loc_func=func, name=name)

        command('extract', cls.extract_loc)
        command('update', cls.update_loc)
        command('remove', cls.remove_loc)
        command('list', cls.list_loc)
",CWE-79,110.0,1
"__version__ = '2.6.0b0'

if __name__ == '__main__':
    print(__version__)
",CWE-79,5.0,1
"#!/usr/bin/env python
# vim: set sw=4 et:

from setuptools import setup, find_packages
from setuptools.command.test import test as TestCommand
import glob
import os
import sys

from pywb import __version__


def get_long_description():
    with open('README.rst', 'r') as fh:
        long_description = fh.read()
    return long_description


class PyTest(TestCommand):
    user_options = []

    def finalize_options(self):
        TestCommand.finalize_options(self)
        self.test_suite = ' '

    def run_tests(self):
        from gevent.monkey import patch_all
        patch_all()

        import pytest
        import os
        os.environ.pop('PYWB_CONFIG_FILE', None)
        cmdline = '--cov-config .coveragerc --cov pywb'
        cmdline += ' -v --doctest-modules ./pywb/ tests/'

        errcode = pytest.main(cmdline.split(' '))

        sys.exit(errcode)


def get_git_short_hash():
    import subprocess
    try:
        hash_id = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).rstrip()
        if sys.version_info >= (3, 0):
            hash_id = hash_id.decode('utf-8')

        return hash_id
    except Exception:
        return ''


def generate_git_hash_py(pkg, filename='git_hash.py'):
    try:
        git_hash = get_git_short_hash()
        with open(os.path.join(pkg, filename), 'wt') as fh:
            fh.write('git_hash = ""{0}""\n'.format(git_hash))
    except Exception:
        pass


def load_requirements(filename):
    with open(filename, 'rt') as fh:
        requirements = fh.read().rstrip().split('\n')
    if sys.version_info > (3, 0):
        requirements.append(""py3AMF"")
    else:
        requirements.append(""pyAMF"")
    return requirements


def get_package_data():
    pkgs = ['static/*.*',
            'templates/*',
            '*.yaml']

    for root, dirs, files in os.walk(os.path.join('pywb', 'static')):
        for dir_ in dirs:
            pkgs.append(os.path.relpath(os.path.join(root, dir_, '*'), 'pywb'))

    return pkgs


generate_git_hash_py('pywb')

setup(
    name='pywb',
    version=__version__,
    url='https://github.com/webrecorder/pywb',
    author='Ilya Kreymer',
    author_email='ikreymer@gmail.com',
    description='Pywb Webrecorder web archive replay and capture tools',
    long_description=get_long_description(),
    license='GPL',
    packages=find_packages(exclude=['tests_disabled']),
    zip_safe=False,
    package_data={
        'pywb': get_package_data(),
    },
    data_files=[
        ('sample_archive/cdx', glob.glob('sample_archive/cdx/*')),
        ('sample_archive/cdxj', glob.glob('sample_archive/cdxj/*')),
        ('sample_archive/non-surt-cdx', glob.glob('sample_archive/non-surt-cdx/*')),
        ('sample_archive/zipcdx', glob.glob('sample_archive/zipcdx/*')),
        ('sample_archive/warcs', glob.glob('sample_archive/warcs/*')),
        ('sample_archive/text_content',
         glob.glob('sample_archive/text_content/*')),
    ],
    install_requires=load_requirements('requirements.txt'),
    tests_require=[
        'pytest',
        'WebTest',
        'pytest-cov',
        'mock',
        'urllib3',
        'werkzeug',
        'httpbin==0.5.0',
        'ujson',
        'lxml'
    ],
    cmdclass={'test': PyTest},
    test_suite='',
    entry_points=""""""
        [console_scripts]
        pywb = pywb.apps.cli:wayback
        wayback = pywb.apps.cli:wayback
        cdx-server = pywb.apps.cli:cdx_server
        live-rewrite-server = pywb.apps.cli:live_rewrite_server
        cdx-indexer = pywb.indexer.cdxindexer:main
        wb-manager = pywb.manager.manager:main_wrap_exc
        warcserver = pywb.apps.cli:warcserver
        """""",
    classifiers=[
        'Development Status :: 4 - Beta',
        'Environment :: Web Environment',
        'License :: OSI Approved :: GNU General Public License (GPL)',
        'License :: OSI Approved :: GNU General Public License v3 (GPLv3)',
        'Programming Language :: Python :: 2',
        'Programming Language :: Python :: 2.7',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.3',
        'Programming Language :: Python :: 3.4',
        'Programming Language :: Python :: 3.5',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
        'Topic :: Internet :: Proxy Servers',
        'Topic :: Internet :: WWW/HTTP',
        'Topic :: Internet :: WWW/HTTP :: WSGI',
        'Topic :: Internet :: WWW/HTTP :: WSGI :: Application',
        'Topic :: Internet :: WWW/HTTP :: WSGI :: Middleware',
        'Topic :: Internet :: WWW/HTTP :: WSGI :: Server',
        'Topic :: Software Development :: Libraries :: Python Modules',
        'Topic :: System :: Archiving',
        'Topic :: System :: Archiving :: Backup',
        'Topic :: Utilities',
    ])
",CWE-79,159.0,1
"""""""
django-helpdesk - A Django powered ticket tracker for small enterprise.

(c) Copyright 2008 Jutda. All Rights Reserved. See LICENSE for details.

lib.py - Common functions (eg multipart e-mail)
""""""

import logging
import mimetypes

from django.conf import settings
from django.utils.encoding import smart_text

from helpdesk.models import FollowUpAttachment


logger = logging.getLogger('helpdesk')


def ticket_template_context(ticket):
    context = {}

    for field in ('title', 'created', 'modified', 'submitter_email',
                  'status', 'get_status_display', 'on_hold', 'description',
                  'resolution', 'priority', 'get_priority_display',
                  'last_escalation', 'ticket', 'ticket_for_url', 'merged_to',
                  'get_status', 'ticket_url', 'staff_url', '_get_assigned_to'
                  ):
        attr = getattr(ticket, field, None)
        if callable(attr):
            context[field] = '%s' % attr()
        else:
            context[field] = attr
    context['assigned_to'] = context['_get_assigned_to']

    return context


def queue_template_context(queue):
    context = {}

    for field in ('title', 'slug', 'email_address', 'from_address', 'locale'):
        attr = getattr(queue, field, None)
        if callable(attr):
            context[field] = attr()
        else:
            context[field] = attr

    return context


def safe_template_context(ticket):
    """"""
    Return a dictionary that can be used as a template context to render
    comments and other details with ticket or queue parameters. Note that
    we don't just provide the Ticket & Queue objects to the template as
    they could reveal confidential information. Just imagine these two options:
        * {{ ticket.queue.email_box_password }}
        * {{ ticket.assigned_to.password }}

    Ouch!

    The downside to this is that if we make changes to the model, we will also
    have to update this code. Perhaps we can find a better way in the future.
    """"""

    context = {
        'queue': queue_template_context(ticket.queue),
        'ticket': ticket_template_context(ticket),
    }
    context['ticket']['queue'] = context['queue']

    return context


def text_is_spam(text, request):
    # Based on a blog post by 'sciyoshi':
    # http://sciyoshi.com/blog/2008/aug/27/using-akismet-djangos-new-comments-framework/
    # This will return 'True' is the given text is deemed to be spam, or
    # False if it is not spam. If it cannot be checked for some reason, we
    # assume it isn't spam.
    from django.contrib.sites.models import Site
    from django.core.exceptions import ImproperlyConfigured
    try:
        from akismet import Akismet
    except ImportError:
        return False
    try:
        site = Site.objects.get_current()
    except ImproperlyConfigured:
        site = Site(domain='configure-django-sites.com')

    # see https://akismet.readthedocs.io/en/latest/overview.html#using-akismet

    apikey = None

    if hasattr(settings, 'TYPEPAD_ANTISPAM_API_KEY'):
        apikey = settings.TYPEPAD_ANTISPAM_API_KEY
    elif hasattr(settings, 'PYTHON_AKISMET_API_KEY'):
        # new env var expected by python-akismet package
        apikey = settings.PYTHON_AKISMET_API_KEY
    elif hasattr(settings, 'AKISMET_API_KEY'):
        # deprecated, but kept for backward compatibility
        apikey = settings.AKISMET_API_KEY
    else:
        return False

    ak = Akismet(
        blog_url='http://%s/' % site.domain,
        key=apikey,
    )

    if hasattr(settings, 'TYPEPAD_ANTISPAM_API_KEY'):
        ak.baseurl = 'api.antispam.typepad.com/1.1/'

    if ak.verify_key():
        ak_data = {
            'user_ip': request.META.get('REMOTE_ADDR', '127.0.0.1'),
            'user_agent': request.META.get('HTTP_USER_AGENT', ''),
            'referrer': request.META.get('HTTP_REFERER', ''),
            'comment_type': 'comment',
            'comment_author': '',
        }

        return ak.comment_check(smart_text(text), data=ak_data)

    return False


def process_attachments(followup, attached_files):
    max_email_attachment_size = getattr(settings, 'HELPDESK_MAX_EMAIL_ATTACHMENT_SIZE', 512000)
    attachments = []

    for attached in attached_files:

        if attached.size:
            filename = smart_text(attached.name)
            att = FollowUpAttachment(
                followup=followup,
                file=attached,
                filename=filename,
                mime_type=attached.content_type or
                mimetypes.guess_type(filename, strict=False)[0] or
                'application/octet-stream',
                size=attached.size,
            )
            att.save()

            if attached.size < max_email_attachment_size:
                # Only files smaller than 512kb (or as defined in
                # settings.HELPDESK_MAX_EMAIL_ATTACHMENT_SIZE) are sent via email.
                attachments.append([filename, att.file])

    return attachments


def format_time_spent(time_spent):
    """"""Format time_spent attribute to ""[H]HHh:MMm"" text string to be allign in
    all graphical outputs
    """"""

    if time_spent:
        time_spent = ""{0:02d}h:{1:02d}m"".format(
            time_spent.seconds // 3600,
            time_spent.seconds // 60
        )
    else:
        time_spent = """"
    return time_spent
",CWE-79,171.0,1
"############################
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# ""License""); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
import logging

from ansible_runner.config._base import BaseConfig, BaseExecutionMode
from ansible_runner.exceptions import ConfigurationError
from ansible_runner.utils import get_executable_path

logger = logging.getLogger('ansible-runner')


class DocConfig(BaseConfig):
    """"""
    A ``Runner`` configuration object that's meant to encapsulate the configuration used by the
    :py:mod:`ansible_runner.runner.DocConfig` object to launch and manage the invocation of
    command execution.

    Typically this object is initialized for you when using the standard ``get_plugin_docs`` or ``get_plugin_list`` interfaces
    in :py:mod:`ansible_runner.interface` but can be used to construct the ``DocConfig`` configuration to be invoked elsewhere.
    It can also be overridden to provide different functionality to the DocConfig object.

    :Example:

    >>> dc = DocConfig(...)
    >>> r = Runner(config=dc)
    >>> r.run()

    """"""

    def __init__(self, runner_mode=None, **kwargs):
        # runner params
        self.runner_mode = runner_mode if runner_mode else 'subprocess'
        if self.runner_mode not in ['pexpect', 'subprocess']:
            raise ConfigurationError(""Invalid runner mode {0}, valid value is either 'pexpect' or 'subprocess'"".format(self.runner_mode))

        if kwargs.get(""process_isolation""):
            self._ansible_doc_exec_path = ""ansible-doc""
        else:
            self._ansible_doc_exec_path = get_executable_path(""ansible-doc"")

        self.execution_mode = BaseExecutionMode.ANSIBLE_COMMANDS
        super(DocConfig, self).__init__(**kwargs)

    _supported_response_formats = ('json', 'human')

    def prepare_plugin_docs_command(self, plugin_names, plugin_type=None, response_format=None,
                                    snippet=False, playbook_dir=None, module_path=None):

        if response_format and response_format not in DocConfig._supported_response_formats:
            raise ConfigurationError(""Invalid response_format {0}, valid value is one of either {1}"".format(response_format,
                                                                                                            "", "".join(DocConfig._supported_response_formats)))

        if not isinstance(plugin_names, list):
            raise ConfigurationError(""plugin_names should be of type list, instead received {0} of type {1}"".format(plugin_names, type(plugin_names)))

        self._prepare_env(runner_mode=self.runner_mode)
        self.cmdline_args = []

        if response_format == 'json':
            self.cmdline_args.append('-j')

        if snippet:
            self.cmdline_args.append('-s')

        if plugin_type:
            self.cmdline_args.extend(['-t', plugin_type])

        if playbook_dir:
            self.cmdline_args.extend(['--playbook-dir', playbook_dir])

        if module_path:
            self.cmdline_args.extend(['-M', module_path])

        self.cmdline_args.append("" "".join(plugin_names))

        self.command = [self._ansible_doc_exec_path] + self.cmdline_args
        self._handle_command_wrap(self.execution_mode, self.cmdline_args)

    def prepare_plugin_list_command(self, list_files=None, response_format=None, plugin_type=None,
                                    playbook_dir=None, module_path=None):

        if response_format and response_format not in DocConfig._supported_response_formats:
            raise ConfigurationError(""Invalid response_format {0}, valid value is one of either {1}"".format(response_format,
                                                                                                            "", "".join(DocConfig._supported_response_formats)))

        self._prepare_env(runner_mode=self.runner_mode)
        self.cmdline_args = []

        if list_files:
            self.cmdline_args.append('-F')
        else:
            self.cmdline_args.append('-l')

        if response_format == 'json':
            self.cmdline_args.append('-j')

        if plugin_type:
            self.cmdline_args.extend(['-t', plugin_type])

        if playbook_dir:
            self.cmdline_args.extend(['--playbook-dir', playbook_dir])

        if module_path:
            self.cmdline_args.extend(['-M', module_path])

        self.command = [self._ansible_doc_exec_path] + self.cmdline_args
        self._handle_command_wrap(self.execution_mode, self.cmdline_args)
",CWE-116,124.0,1
"# -*- coding: utf-8 -*-

import os
import pytest

from ansible_runner.config.doc import DocConfig
from ansible_runner.config._base import BaseExecutionMode
from ansible_runner.exceptions import ConfigurationError
from ansible_runner.utils import get_executable_path


def test_ansible_doc_defaults(tmp_path, patch_private_data_dir):
    rc = DocConfig()

    # Check that the private data dir is placed in our default location with our default prefix
    # and has some extra uniqueness on the end.
    base_private_data_dir = tmp_path.joinpath('.ansible-runner-').as_posix()
    assert rc.private_data_dir.startswith(base_private_data_dir)
    assert len(rc.private_data_dir) > len(base_private_data_dir)

    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS
    assert rc.runner_mode == 'subprocess'


def test_invalid_runner_mode_value():
    with pytest.raises(ConfigurationError) as exc:
        DocConfig(runner_mode='test')

    assert ""Invalid runner mode"" in exc.value.args[0]


def test_invalid_response_format_value():
    with pytest.raises(ConfigurationError) as exc:
        rc = DocConfig()
        plugin_names = ['copy', 'file']
        rc.prepare_plugin_docs_command(plugin_names, response_format='test')

    assert ""Invalid response_format test, valid value is one of either json, human"" == exc.value.args[0]


def test_invalid_plugin_name_value():
    with pytest.raises(ConfigurationError) as exc:
        rc = DocConfig()
        plugin_names = 'copy', 'file'
        rc.prepare_plugin_docs_command(plugin_names)

    assert ""plugin_names should be of type list"" in exc.value.args[0]


def test_prepare_plugin_docs_command():
    rc = DocConfig()
    plugin_names = ['copy', 'file']
    plugin_type = 'module'
    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')
    expected_command = [get_executable_path('ansible-doc'), '-s', '-t', 'module', '--playbook-dir', '/tmp/test', 'copy file']
    assert rc.command == expected_command
    assert rc.runner_mode == 'subprocess'
    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS


@pytest.mark.test_all_runtimes
def test_prepare_plugin_docs_command_with_containerization(tmp_path, runtime, mocker):
    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)
    tmp_path.joinpath('.ssh').mkdir()

    kwargs = {
        'private_data_dir': tmp_path,
        'process_isolation': True,
        'container_image': 'my_container',
        'process_isolation_executable': runtime
    }
    rc = DocConfig(**kwargs)
    rc.ident = 'foo'

    plugin_names = ['copy', 'file']
    plugin_type = 'module'
    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')

    assert rc.runner_mode == 'subprocess'
    extra_container_args = []

    if runtime == 'podman':
        extra_container_args = ['--quiet']
    else:
        extra_container_args = [f'--user={os.getuid()}']

    expected_command_start = [
        runtime,
        'run',
        '--rm',
        '--interactive',
        '--workdir',
        '/runner/project',
        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),
        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),
    ]

    if runtime == 'podman':
        expected_command_start.extend(['--group-add=root', '--ipc=host'])

    expected_command_start.extend([
        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),
        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),
        '--env-file', '{}/env.list'.format(rc.artifact_dir),
    ])

    expected_command_start.extend(extra_container_args)

    expected_command_start.extend([
        '--name', 'ansible_runner_foo',
        'my_container',
        'ansible-doc',
        '-s',
        '-t', 'module',
        '--playbook-dir', '/tmp/test',
        'copy '
        'file',
    ])

    assert expected_command_start == rc.command


def test_prepare_plugin_list_command():
    rc = DocConfig()
    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')
    expected_command = [get_executable_path('ansible-doc'), '-F', '-t', 'module', '--playbook-dir', '/tmp/test', '-M', '/test/module']
    assert rc.command == expected_command
    assert rc.runner_mode == 'subprocess'
    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS


@pytest.mark.test_all_runtimes
def test_prepare_plugin_list_command_with_containerization(tmp_path, runtime, mocker):
    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)
    tmp_path.joinpath('.ssh').mkdir()

    kwargs = {
        'private_data_dir': tmp_path,
        'process_isolation': True,
        'container_image': 'my_container',
        'process_isolation_executable': runtime
    }
    rc = DocConfig(**kwargs)
    rc.ident = 'foo'
    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')

    assert rc.runner_mode == 'subprocess'
    extra_container_args = []

    if runtime == 'podman':
        extra_container_args = ['--quiet']
    else:
        extra_container_args = [f'--user={os.getuid()}']

    expected_command_start = [
        runtime,
        'run',
        '--rm',
        '--interactive',
        '--workdir',
        '/runner/project',
        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),
        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),
    ]

    if runtime == 'podman':
        expected_command_start.extend(['--group-add=root', '--ipc=host'])

    expected_command_start.extend([
        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),
        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),
        '--env-file', '{}/env.list'.format(rc.artifact_dir),
    ])

    expected_command_start.extend(extra_container_args)

    expected_command_start.extend([
        '--name', 'ansible_runner_foo',
        'my_container',
        'ansible-doc',
        '-F',
        '-t', 'module',
        '--playbook-dir', '/tmp/test',
        '-M', '/test/module'
    ])

    assert expected_command_start == rc.command
",CWE-116,188.0,1
"# -*- coding: utf-8 -*-

BOT_NAME = 'scrashtest'

SPIDER_MODULES = ['scrashtest.spiders']
NEWSPIDER_MODULE = 'scrashtest.spiders'

DOWNLOADER_MIDDLEWARES = {
    # Engine side
    'scrapy_splash.SplashCookiesMiddleware': 723,
    'scrapy_splash.SplashMiddleware': 725,
    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,
    # Downloader side
}

SPIDER_MIDDLEWARES = {
    'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,
}
SPLASH_URL = 'http://127.0.0.1:8050/'
# SPLASH_URL = 'http://192.168.59.103:8050/'
DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter'
HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage'
",CWE-200,23.0,1
"import os

import pytest
from scrapy.settings import Settings


@pytest.fixture()
def settings(request):
    """""" Default scrapy-splash settings """"""
    s = dict(
        # collect scraped items to .collected_items attribute
        ITEM_PIPELINES={
            'tests.utils.CollectorPipeline': 100,
        },

        # scrapy-splash settings
        SPLASH_URL=os.environ.get('SPLASH_URL'),
        DOWNLOADER_MIDDLEWARES={
            # Engine side
            'scrapy_splash.SplashCookiesMiddleware': 723,
            'scrapy_splash.SplashMiddleware': 725,
            'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,
            # Downloader side
        },
        SPIDER_MIDDLEWARES={
            'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,
        },
        DUPEFILTER_CLASS='scrapy_splash.SplashAwareDupeFilter',
        HTTPCACHE_STORAGE='scrapy_splash.SplashAwareFSCacheStorage',
    )
    return Settings(s)


",CWE-200,34.0,1
,CWE-200,,1
"# -*- coding: utf-8 -*-
import os
import pytest
from pytest_twisted import inlineCallbacks
from twisted.internet.defer import returnValue
from twisted.web.resource import Resource
from scrapy.crawler import Crawler

from scrapy_splash.utils import to_bytes
from tests.mockserver import MockServer


requires_splash = pytest.mark.skipif(
    not os.environ.get('SPLASH_URL', ''),
    reason=""set SPLASH_URL environment variable to run integrational tests""
)


class HtmlResource(Resource):
    isLeaf = True
    content_type = 'text/html'
    html = ''
    extra_headers = {}
    status_code = 200

    def render_GET(self, request):
        request.setHeader(b'content-type', to_bytes(self.content_type))
        for name, value in self.extra_headers.items():
            request.setHeader(to_bytes(name), to_bytes(value))
        request.setResponseCode(self.status_code)
        return to_bytes(self.html)


@inlineCallbacks
def crawl_items(spider_cls, resource_cls, settings, spider_kwargs=None):
    """""" Use spider_cls to crawl resource_cls. URL of the resource is passed
    to the spider as ``url`` argument.
    Return ``(items, resource_url, crawler)`` tuple.
    """"""
    spider_kwargs = {} if spider_kwargs is None else spider_kwargs
    crawler = make_crawler(spider_cls, settings)
    with MockServer(resource_cls) as s:
        root_url = s.root_url
        yield crawler.crawl(url=root_url, **spider_kwargs)
    result = crawler.spider.collected_items, s.root_url, crawler
    returnValue(result)


def make_crawler(spider_cls, settings):
    if not getattr(spider_cls, 'name', None):
        class Spider(spider_cls):
            name = 'test_spider'
        Spider.__name__ = spider_cls.__name__
        Spider.__module__ = spider_cls.__module__
        spider_cls = Spider
    return Crawler(spider_cls, settings)


class CollectorPipeline:
    def process_item(self, item, spider):
        if not hasattr(spider, 'collected_items'):
            spider.collected_items = []
        spider.collected_items.append(item)
        return item
",CWE-200,65.0,1
"import logging
from urllib.parse import urljoin, urlparse

from w3lib.url import safe_url_string

from scrapy.http import HtmlResponse
from scrapy.utils.response import get_meta_refresh
from scrapy.exceptions import IgnoreRequest, NotConfigured


logger = logging.getLogger(__name__)


class BaseRedirectMiddleware:

    enabled_setting = 'REDIRECT_ENABLED'

    def __init__(self, settings):
        if not settings.getbool(self.enabled_setting):
            raise NotConfigured

        self.max_redirect_times = settings.getint('REDIRECT_MAX_TIMES')
        self.priority_adjust = settings.getint('REDIRECT_PRIORITY_ADJUST')

    @classmethod
    def from_crawler(cls, crawler):
        return cls(crawler.settings)

    def _redirect(self, redirected, request, spider, reason):
        ttl = request.meta.setdefault('redirect_ttl', self.max_redirect_times)
        redirects = request.meta.get('redirect_times', 0) + 1

        if ttl and redirects <= self.max_redirect_times:
            redirected.meta['redirect_times'] = redirects
            redirected.meta['redirect_ttl'] = ttl - 1
            redirected.meta['redirect_urls'] = request.meta.get('redirect_urls', []) + [request.url]
            redirected.meta['redirect_reasons'] = request.meta.get('redirect_reasons', []) + [reason]
            redirected.dont_filter = request.dont_filter
            redirected.priority = request.priority + self.priority_adjust
            logger.debug(""Redirecting (%(reason)s) to %(redirected)s from %(request)s"",
                         {'reason': reason, 'redirected': redirected, 'request': request},
                         extra={'spider': spider})
            return redirected
        else:
            logger.debug(""Discarding %(request)s: max redirections reached"",
                         {'request': request}, extra={'spider': spider})
            raise IgnoreRequest(""max redirections reached"")

    def _redirect_request_using_get(self, request, redirect_url):
        redirected = request.replace(url=redirect_url, method='GET', body='')
        redirected.headers.pop('Content-Type', None)
        redirected.headers.pop('Content-Length', None)
        return redirected


class RedirectMiddleware(BaseRedirectMiddleware):
    """"""
    Handle redirection of requests based on response status
    and meta-refresh html tag.
    """"""

    def process_response(self, request, response, spider):
        if (
            request.meta.get('dont_redirect', False)
            or response.status in getattr(spider, 'handle_httpstatus_list', [])
            or response.status in request.meta.get('handle_httpstatus_list', [])
            or request.meta.get('handle_httpstatus_all', False)
        ):
            return response

        allowed_status = (301, 302, 303, 307, 308)
        if 'Location' not in response.headers or response.status not in allowed_status:
            return response

        location = safe_url_string(response.headers['Location'])
        if response.headers['Location'].startswith(b'//'):
            request_scheme = urlparse(request.url).scheme
            location = request_scheme + '://' + location.lstrip('/')

        redirected_url = urljoin(request.url, location)

        if response.status in (301, 307, 308) or request.method == 'HEAD':
            redirected = request.replace(url=redirected_url)
            return self._redirect(redirected, request, spider, response.status)

        redirected = self._redirect_request_using_get(request, redirected_url)
        return self._redirect(redirected, request, spider, response.status)


class MetaRefreshMiddleware(BaseRedirectMiddleware):

    enabled_setting = 'METAREFRESH_ENABLED'

    def __init__(self, settings):
        super().__init__(settings)
        self._ignore_tags = settings.getlist('METAREFRESH_IGNORE_TAGS')
        self._maxdelay = settings.getint('METAREFRESH_MAXDELAY')

    def process_response(self, request, response, spider):
        if (
            request.meta.get('dont_redirect', False)
            or request.method == 'HEAD'
            or not isinstance(response, HtmlResponse)
        ):
            return response

        interval, url = get_meta_refresh(response,
                                         ignore_tags=self._ignore_tags)
        if url and interval < self._maxdelay:
            redirected = self._redirect_request_using_get(request, url)
            return self._redirect(redirected, request, spider, 'meta refresh')

        return response
",CWE-863,114.0,1
"# Copyright The PyTorch Lightning team.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
from argparse import Namespace
from unittest.mock import MagicMock

import pytest
import torch

from pytorch_lightning.core.saving import load_hparams_from_yaml
from pytorch_lightning.loggers import CSVLogger
from pytorch_lightning.loggers.csv_logs import ExperimentWriter


def test_file_logger_automatic_versioning(tmpdir):
    """"""Verify that automatic versioning works.""""""

    root_dir = tmpdir.mkdir(""exp"")
    root_dir.mkdir(""version_0"")
    root_dir.mkdir(""version_1"")

    logger = CSVLogger(save_dir=tmpdir, name=""exp"")

    assert logger.version == 2


def test_file_logger_manual_versioning(tmpdir):
    """"""Verify that manual versioning works.""""""

    root_dir = tmpdir.mkdir(""exp"")
    root_dir.mkdir(""version_0"")
    root_dir.mkdir(""version_1"")
    root_dir.mkdir(""version_2"")

    logger = CSVLogger(save_dir=tmpdir, name=""exp"", version=1)

    assert logger.version == 1


def test_file_logger_named_version(tmpdir):
    """"""Verify that manual versioning works for string versions, e.g. '2020-02-05-162402'.""""""

    exp_name = ""exp""
    tmpdir.mkdir(exp_name)
    expected_version = ""2020-02-05-162402""

    logger = CSVLogger(save_dir=tmpdir, name=exp_name, version=expected_version)
    logger.log_hyperparams({""a"": 1, ""b"": 2})
    logger.save()
    assert logger.version == expected_version
    assert os.listdir(tmpdir / exp_name) == [expected_version]
    assert os.listdir(tmpdir / exp_name / expected_version)


@pytest.mark.parametrize(""name"", ["""", None])
def test_file_logger_no_name(tmpdir, name):
    """"""Verify that None or empty name works.""""""
    logger = CSVLogger(save_dir=tmpdir, name=name)
    logger.save()
    assert logger.root_dir == tmpdir
    assert os.listdir(tmpdir / ""version_0"")


@pytest.mark.parametrize(""step_idx"", [10, None])
def test_file_logger_log_metrics(tmpdir, step_idx):
    logger = CSVLogger(tmpdir)
    metrics = {""float"": 0.3, ""int"": 1, ""FloatTensor"": torch.tensor(0.1), ""IntTensor"": torch.tensor(1)}
    logger.log_metrics(metrics, step_idx)
    logger.save()

    path_csv = os.path.join(logger.log_dir, ExperimentWriter.NAME_METRICS_FILE)
    with open(path_csv) as fp:
        lines = fp.readlines()
    assert len(lines) == 2
    assert all(n in lines[0] for n in metrics)


def test_file_logger_log_hyperparams(tmpdir):
    logger = CSVLogger(tmpdir)
    hparams = {
        ""float"": 0.3,
        ""int"": 1,
        ""string"": ""abc"",
        ""bool"": True,
        ""dict"": {""a"": {""b"": ""c""}},
        ""list"": [1, 2, 3],
        ""namespace"": Namespace(foo=Namespace(bar=""buzz"")),
        ""layer"": torch.nn.BatchNorm1d,
    }
    logger.log_hyperparams(hparams)
    logger.save()

    path_yaml = os.path.join(logger.log_dir, ExperimentWriter.NAME_HPARAMS_FILE)
    params = load_hparams_from_yaml(path_yaml)
    assert all(n in params for n in hparams)


def test_flush_n_steps(tmpdir):
    logger = CSVLogger(tmpdir, flush_logs_every_n_steps=2)
    metrics = {""float"": 0.3, ""int"": 1, ""FloatTensor"": torch.tensor(0.1), ""IntTensor"": torch.tensor(1)}
    logger.save = MagicMock()
    logger.log_metrics(metrics, step=0)

    logger.save.assert_not_called()
    logger.log_metrics(metrics, step=1)
    logger.save.assert_called_once()
",CWE-502,118.0,1
"import logging
from pathlib import Path
from shutil import which

from elasticsearch.exceptions import RequestError
from flask import Flask
from flask_compress import Compress
from flask_login import LoginManager

from archivy import helpers
from archivy.api import api_bp
from archivy.models import User
from archivy.config import Config
from archivy.helpers import load_config, get_elastic_client

app = Flask(__name__)
app.logger.setLevel(logging.INFO)
config = Config()
try:
    # if it exists, load user config
    config.override(load_config(config.INTERNAL_DIR))
except FileNotFoundError:
    pass

app.config.from_object(config)
(Path(app.config[""USER_DIR""]) / ""data"").mkdir(parents=True, exist_ok=True)
(Path(app.config[""USER_DIR""]) / ""images"").mkdir(parents=True, exist_ok=True)

with app.app_context():
    app.config[""RG_INSTALLED""] = which(""rg"") != None
    app.config[""HOOKS""] = helpers.load_hooks()
    app.config[""SCRAPING_PATTERNS""] = helpers.load_scraper()
if app.config[""SEARCH_CONF""][""enabled""]:
    with app.app_context():
        search_engines = [""elasticsearch"", ""ripgrep""]
        es = None
        if (
            ""engine"" not in app.config[""SEARCH_CONF""]
            or app.config[""SEARCH_CONF""][""engine""] not in search_engines
        ):
            # try to guess desired search engine if present
            app.logger.warning(
                ""Search is enabled but engine option is invalid or absent. Archivy will""
                "" try to guess preferred search engine.""
            )
            app.config[""SEARCH_CONF""][""engine""] = ""none""

            es = get_elastic_client(error_if_invalid=False)
            if es:
                app.config[""SEARCH_CONF""][""engine""] = ""elasticsearch""
            else:
                if which(""rg""):
                    app.config[""SEARCH_CONF""][""engine""] = ""ripgrep""
            engine = app.config[""SEARCH_CONF""][""engine""]
            if engine == ""none"":
                app.logger.warning(""No working search engine found. Disabling search."")
                app.config[""SEARCH_CONF""][""enabled""] = 0
            else:
                app.logger.info(f""Running {engine} installation found."")

        if app.config[""SEARCH_CONF""][""engine""] == ""elasticsearch"":
            es = es or get_elastic_client()
            try:
                es.indices.create(
                    index=app.config[""SEARCH_CONF""][""index_name""],
                    body=app.config[""SEARCH_CONF""][""es_processing_conf""],
                )
            except RequestError:
                app.logger.info(""Elasticsearch index already created"")
        if app.config[""SEARCH_CONF""][""engine""] == ""ripgrep"" and not which(""rg""):
            app.logger.info(""Ripgrep not found on system. Disabling search."")
            app.config[""SEARCH_CONF""][""enabled""] = 0


# login routes / setup
login_manager = LoginManager()
login_manager.login_view = ""login""
login_manager.init_app(app)
app.register_blueprint(api_bp, url_prefix=""/api"")

# compress files
Compress(app)


@login_manager.user_loader
def load_user(user_id):
    db = helpers.get_db()
    res = db.get(doc_id=int(user_id))
    if res and res[""type""] == ""user"":
        return User.from_db(res)
    return None


app.jinja_options[""extensions""].append(""jinja2.ext.do"")


@app.template_filter(""pluralize"")
def pluralize(number, singular="""", plural=""s""):
    if number == 1:
        return singular
    else:
        return plural


from archivy import routes  # noqa:
",CWE-352,106.0,1
"import logging

from django.template.response import TemplateResponse
from django.utils.safestring import mark_safe

import orjson
from bs4 import BeautifulSoup
from bs4.element import Tag
from bs4.formatter import HTMLFormatter

from django_unicorn.utils import sanitize_html

from ..decorators import timed
from ..utils import generate_checksum


logger = logging.getLogger(__name__)


class UnsortedAttributes(HTMLFormatter):
    """"""
    Prevent beautifulsoup from re-ordering attributes.
    """"""

    def attributes(self, tag: Tag):
        for k, v in tag.attrs.items():
            yield k, v


class UnicornTemplateResponse(TemplateResponse):
    def __init__(
        self,
        template,
        request,
        context=None,
        content_type=None,
        status=None,
        charset=None,
        using=None,
        component=None,
        init_js=False,
        **kwargs,
    ):
        super().__init__(
            template=template,
            request=request,
            context=context,
            content_type=content_type,
            status=status,
            charset=charset,
            using=using,
        )

        self.component = component
        self.init_js = init_js

    @timed
    def render(self):
        response = super().render()

        if not self.component or not self.component.component_id:
            return response

        content = response.content.decode(""utf-8"")

        frontend_context_variables = self.component.get_frontend_context_variables()
        frontend_context_variables_dict = orjson.loads(frontend_context_variables)
        checksum = generate_checksum(orjson.dumps(frontend_context_variables_dict))

        soup = BeautifulSoup(content, features=""html.parser"")
        root_element = get_root_element(soup)
        root_element[""unicorn:id""] = self.component.component_id
        root_element[""unicorn:name""] = self.component.component_name
        root_element[""unicorn:key""] = self.component.component_key
        root_element[""unicorn:checksum""] = checksum

        # Generate the hash based on the rendered content (without script tag)
        hash = generate_checksum(UnicornTemplateResponse._desoupify(soup))

        if self.init_js:
            init = {
                ""id"": self.component.component_id,
                ""name"": self.component.component_name,
                ""key"": self.component.component_key,
                ""data"": orjson.loads(frontend_context_variables),
                ""calls"": self.component.calls,
                ""hash"": hash,
            }
            init = orjson.dumps(init).decode(""utf-8"")
            json_element_id = f""unicorn:data:{self.component.component_id}""
            init_script = f""Unicorn.componentInit(JSON.parse(document.getElementById('{json_element_id}').textContent));""

            json_tag = soup.new_tag(""script"")
            json_tag[""type""] = ""application/json""
            json_tag[""id""] = json_element_id
            json_tag.string = sanitize_html(init)

            if self.component.parent:
                self.component._init_script = init_script
                self.component._json_tag = json_tag
            else:
                json_tags = []
                json_tags.append(json_tag)

                for child in self.component.children:
                    init_script = f""{init_script} {child._init_script}""
                    json_tags.append(child._json_tag)

                script_tag = soup.new_tag(""script"")
                script_tag[""type""] = ""module""
                script_tag.string = f""if (typeof Unicorn === 'undefined') {{ console.error('Unicorn is missing. Do you need {{% load unicorn %}} or {{% unicorn_scripts %}}?') }} else {{ {init_script} }}""
                root_element.insert_after(script_tag)

                for t in json_tags:
                    root_element.insert_after(t)

        rendered_template = UnicornTemplateResponse._desoupify(soup)
        rendered_template = mark_safe(rendered_template)
        self.component.rendered(rendered_template)

        response.content = rendered_template

        return response

    @staticmethod
    def _desoupify(soup):
        soup.smooth()
        return soup.encode(formatter=UnsortedAttributes()).decode(""utf-8"")


def get_root_element(soup: BeautifulSoup) -> Tag:
    """"""
    Gets the first tag element.

    Returns:
        BeautifulSoup tag element.

        Raises an Exception if an element cannot be found.
    """"""
    for element in soup.contents:
        if isinstance(element, Tag) and element.name:
            return element

    raise Exception(""No root element found"")
",CWE-79,145.0,1
"import types

import orjson
import pytest

from django_unicorn.components import UnicornView


class ExampleComponent(UnicornView):
    name = ""World""

    def get_name(self):
        return ""World""


@pytest.fixture()
def component():
    return ExampleComponent(component_id=""asdf1234"", component_name=""example"")


def test_init_with_template_name():
    class TestComponent(UnicornView):
        template_name = ""unicorn/test.html""

    component = TestComponent(component_id=""asdf1234"", component_name=""hello-world"")
    assert component.template_name == ""unicorn/test.html""


def test_init_with_get_template_names():
    class TestComponent(UnicornView):
        def get_template_names(self):
            return []

    component = TestComponent(component_id=""asdf1234"", component_name=""hello-world"")
    assert component.template_name is None


def test_init_attribute_names_cache(component):
    attribute_names_cache = component._attribute_names_cache
    assert len(attribute_names_cache) == 1
    assert attribute_names_cache[0] == ""name""


def test_init_attribute_names(component):
    attribute_names = component._attribute_names()
    assert len(attribute_names) == 1
    assert attribute_names[0] == ""name""


def test_init_attributes(component):
    attributes = component._attributes()
    assert len(attributes) == 1
    assert attributes[""name""] == ""World""


def test_init_properties():
    class TestComponent(UnicornView):
        @property
        def name(self):
            return ""World""

    component = TestComponent(component_id=""asdf1234"", component_name=""hello-world"")
    attributes = component._attributes()
    assert len(attributes) == 1
    assert attributes[""name""] == ""World""


def test_init_methods_cache(component):
    assert len(component._methods_cache) == 1


def test_init_methods(component):
    methods = component._methods()
    assert len(methods) == 1
    assert methods[""get_name""]() == ""World""


def test_get_frontend_context_variables(component):
    frontend_context_variables = component.get_frontend_context_variables()
    frontend_context_variables_dict = orjson.loads(frontend_context_variables)
    assert len(frontend_context_variables_dict) == 1
    assert frontend_context_variables_dict.get(""name"") == ""World""


def test_get_frontend_context_variables_xss(component):
    # Set component.name to a potential XSS attack
    component.name = '<a><style>@keyframes x{}</style><a style=""animation-name:x"" onanimationend=""alert(1)""></a>'

    frontend_context_variables = component.get_frontend_context_variables()
    frontend_context_variables_dict = orjson.loads(frontend_context_variables)
    assert len(frontend_context_variables_dict) == 1
    assert (
        frontend_context_variables_dict.get(""name"")
        == ""&lt;a&gt;&lt;style&gt;@keyframes x{}&lt;/style&gt;&lt;a style=&quot;animation-name:x&quot; onanimationend=&quot;alert(1)&quot;&gt;&lt;/a&gt;""
    )


def test_get_frontend_context_variables_safe(component):
    # Set component.name to a potential XSS attack
    component.name = '<a><style>@keyframes x{}</style><a style=""animation-name:x"" onanimationend=""alert(1)""></a>'

    class Meta:
        safe = [
            ""name"",
        ]

    setattr(component, ""Meta"", Meta())

    frontend_context_variables = component.get_frontend_context_variables()
    frontend_context_variables_dict = orjson.loads(frontend_context_variables)
    assert len(frontend_context_variables_dict) == 1
    assert (
        frontend_context_variables_dict.get(""name"")
        == '<a><style>@keyframes x{}</style><a style=""animation-name:x"" onanimationend=""alert(1)""></a>'
    )


def test_get_context_data(component):
    context_data = component.get_context_data()
    assert (
        len(context_data) == 4
    )  # `unicorn` and `view` are added to context data by default
    assert context_data.get(""name"") == ""World""
    assert isinstance(context_data.get(""get_name""), types.MethodType)


def test_is_public(component):
    assert component._is_public(""test_name"")


def test_is_public_protected(component):
    assert component._is_public(""_test_name"") == False


def test_is_public_http_method_names(component):
    assert component._is_public(""http_method_names"") == False


def test_meta_javascript_exclude():
    class TestComponent(UnicornView):
        name = ""World""

        class Meta:
            javascript_exclude = (""name"",)

    component = TestComponent(component_id=""asdf1234"", component_name=""hello-world"")
    assert ""name"" not in component.get_frontend_context_variables()
    assert ""name"" in component.get_context_data()


def test_meta_exclude():
    class TestComponent(UnicornView):
        name = ""World""

        class Meta:
            exclude = (""name"",)

    component = TestComponent(component_id=""asdf1234"", component_name=""hello-world"")
    assert ""name"" not in component.get_frontend_context_variables()
    assert ""name"" not in component.get_context_data()
",CWE-79,161.0,1
"import pytest
from bs4 import BeautifulSoup

from django_unicorn.components.unicorn_template_response import get_root_element


def test_get_root_element():
    expected = ""<div>test</div>""

    component_html = ""<div>test</div>""
    soup = BeautifulSoup(component_html, features=""html.parser"")
    actual = get_root_element(soup)

    assert str(actual) == expected


def test_get_root_element_with_comment():
    expected = ""<div>test</div>""

    component_html = ""<!-- some comment --><div>test</div>""
    soup = BeautifulSoup(component_html, features=""html.parser"")
    actual = get_root_element(soup)

    assert str(actual) == expected


def test_get_root_element_with_blank_string():
    expected = ""<div>test</div>""

    component_html = ""\n<div>test</div>""
    soup = BeautifulSoup(component_html, features=""html.parser"")
    actual = get_root_element(soup)

    assert str(actual) == expected


def test_get_root_element_no_element():
    expected = ""<div>test</div>""

    component_html = ""\n""
    soup = BeautifulSoup(component_html, features=""html.parser"")

    with pytest.raises(Exception):
        actual = get_root_element(soup)

        assert str(actual) == expected
",CWE-79,47.0,1
"import orjson

from tests.views.message.utils import post_and_get_response


def test_message_nested_sync_input(client):
    data = {""dictionary"": {""name"": ""test""}}
    action_queue = [
        {""payload"": {""name"": ""dictionary.name"", ""value"": ""test1""}, ""type"": ""syncInput"",}
    ]
    response = post_and_get_response(
        client,
        url=""/message/tests.views.fake_components.FakeComponent"",
        data=data,
        action_queue=action_queue,
    )

    assert not response[""errors""]
    assert response[""data""].get(""dictionary"") == {""name"": ""test1""}
",CWE-79,20.0,1
,CWE-79,,1
"import logging
from logging.handlers import RotatingFileHandler
import random
import re

from flask import Flask, render_template, request
from flask_wtf import FlaskForm
from wtforms import SelectField, TextAreaField

from .generate.generator import PoemMaker

pm = PoemMaker()
pm.setup()

app = Flask(__name__)
app.config.update(WTF_CSRF_ENABLED=False)

handler = RotatingFileHandler('poems.log', maxBytes=10000, backupCount=1)
handler.setLevel(logging.INFO)
formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
handler.setFormatter(formatter)
app.logger.addHandler(handler)


def alphanum(s):
    return re.sub(r'[^a-z]+', '', s.lower())


class GeneratePoemForm(FlaskForm):
    source = SelectField('Source', choices=[(k, k) for k in pm.text_sources.keys()])
    style = SelectField('Style', choices=[(k, k) for k in pm.poem_styles.keys()])


class UploadTextForm(FlaskForm):
    poem_format = SelectField('Format', choices=[(k, k) for k in pm.poem_styles.keys()])
    source_text = TextAreaField('Text', render_kw={'rows': 20, 'cols': 200})


@app.route('/', methods=['GET', 'POST'])
def generate_page():
    def valid_param(param, d):
        if param is not None:
            for k in d.keys():
                if alphanum(param) == alphanum(k):
                    return k

    form = GeneratePoemForm()

    app.logger.debug(form.validate())
    if form.errors:
        app.logger.warning(form.errors)

    if form.validate_on_submit():
        source = form.source.data
        style = form.style.data
    else:
        try:
            source_ask = request.args.get('source') or request.args.get('style')
            source_param = valid_param(source_ask, pm.text_sources)
            if source_param is not None:
                source = source_param
            else:
                source = random.choice(list(pm.text_sources.keys()))
            form.source.data = source

            style_ask = request.args.get('poem') or request.args.get('style')
            style_param = valid_param(style_ask, pm.poem_styles)
            if style_param is not None:
                style = style_param
            else:
                style = random.choice(list(pm.poem_styles.keys()))
            form.style.data = style
        except:
            app.logger.exception('Failed to select source and style')

    poem = pm.generate(source, style)
    app.logger.info(poem)
    print(poem)
    return render_template('generate.html', form=form, poem=poem)


@app.route('/custom', methods=['GET', 'POST'])
def upload():
    form = UploadTextForm()

    if form.validate_on_submit():
        print('asdf')
        source_text = form.source_text.data
        poem_format = form.poem_format.data

        form.source_text.render_kw['hidden'] = True

        try:
            poem = pm.generate_custom(source_text, poem_format)
            app.logger.info(poem)
            print(poem)
        except IndexError:
            poem=""Sorry! I couldn't find a valid poem with that input. :(""
        return render_template('custom_poem.html', form=form, poem=poem)

    if 'hidden' in form.source_text.render_kw:
        del form.source_text.render_kw['hidden']
    return render_template('custom.html', form=form)


if __name__ == '__main__':
    app.run()
",CWE-352,108.0,1
"from ellipticcurve.utils.compatibility import *
from ellipticcurve.privateKey import PrivateKey
from ellipticcurve.publicKey import PublicKey
from ellipticcurve.signature import Signature
from ellipticcurve.utils.file import File
from ellipticcurve.ecdsa import Ecdsa
",CWE-347,7.0,1
"from hashlib import sha256
from .signature import Signature
from .math import Math
from .utils.integer import RandomInteger
from .utils.binary import numberFromByteString
from .utils.compatibility import *


class Ecdsa:

    @classmethod
    def sign(cls, message, privateKey, hashfunc=sha256):
        byteMessage = hashfunc(toBytes(message)).digest()
        numberMessage = numberFromByteString(byteMessage)
        curve = privateKey.curve

        r, s, randSignPoint = 0, 0, None
        while r == 0 or s == 0:
            randNum = RandomInteger.between(1, curve.N - 1)
            randSignPoint = Math.multiply(curve.G, n=randNum, A=curve.A, P=curve.P, N=curve.N)
            r = randSignPoint.x % curve.N
            s = ((numberMessage + r * privateKey.secret) * (Math.inv(randNum, curve.N))) % curve.N
        recoveryId = randSignPoint.y & 1
        if randSignPoint.y > curve.N:
            recoveryId += 2

        return Signature(r=r, s=s, recoveryId=recoveryId)

    @classmethod
    def verify(cls, message, signature, publicKey, hashfunc=sha256):
        byteMessage = hashfunc(toBytes(message)).digest()
        numberMessage = numberFromByteString(byteMessage)
        curve = publicKey.curve
        r = signature.r
        s = signature.s
        inv = Math.inv(s, curve.N)
        u1 = Math.multiply(curve.G, n=(numberMessage * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)
        u2 = Math.multiply(publicKey.point, n=(r * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)
        add = Math.add(u1, u2, A=curve.A, P=curve.P)
        modX = add.x % curve.N
        return r == modX
",CWE-347,42.0,1
"{
  ""name"": ""@joeattardi/emoji-button"",
  ""version"": ""4.6.0"",
  ""description"": ""Vanilla JavaScript emoji picker"",
  ""keywords"": [
    ""emoji"",
    ""javascript""
  ],
  ""main"": ""dist/index.js"",
  ""module"": ""dist/index.js"",
  ""types"": ""dist/index.d.ts"",
  ""scripts"": {
    ""build"": ""cross-env NODE_ENV=production rollup -c"",
    ""build:watch"": ""rollup -cw"",
    ""start"": ""npm run build:watch"",
    ""prepublishOnly"": ""cross-env NODE_ENV=production rollup -c"",
    ""test"": ""jest src/**.test.ts"",
    ""test:watch"": ""jest --watchAll"",
    ""lint"": ""eslint src/*.ts"",
    ""prettify"": ""prettier src/*.ts --write""
  },
  ""author"": ""Joe Attardi <jattardi@gmail.com> (https://joeattardi.codes)"",
  ""repository"": {
    ""type"": ""git"",
    ""url"": ""https://github.com/joeattardi/emoji-button.git""
  },
  ""homepage"": ""https://emoji-button.js.org"",
  ""bugs"": ""https://github.com/joeattardi/emoji-button/issues"",
  ""license"": ""MIT"",
  ""devDependencies"": {
    ""@babel/core"": ""^7.10.2"",
    ""@babel/preset-env"": ""^7.10.2"",
    ""@babel/preset-typescript"": ""^7.10.1"",
    ""@rollup/plugin-replace"": ""^2.3.3"",
    ""@types/jest"": ""^25.2.3"",
    ""@typescript-eslint/eslint-plugin"": ""^3.1.0"",
    ""@typescript-eslint/parser"": ""^3.1.0"",
    ""babel-jest"": ""^26.0.1"",
    ""babel-plugin-transform-class-properties"": ""^6.24.1"",
    ""cross-env"": ""^7.0.2"",
    ""eslint"": ""^7.2.0"",
    ""eslint-config-prettier"": ""^6.11.0"",
    ""eslint-plugin-prettier"": ""^3.1.3"",
    ""jest"": ""^26.0.1"",
    ""prettier"": ""^2.0.5"",
    ""rollup"": ""^2.22.1"",
    ""rollup-plugin-babel"": ""^4.4.0"",
    ""rollup-plugin-commonjs"": ""^10.1.0"",
    ""rollup-plugin-node-resolve"": ""^5.2.0"",
    ""rollup-plugin-postcss"": ""^3.1.2"",
    ""rollup-plugin-terser"": ""^7.0.2"",
    ""rollup-plugin-typescript2"": ""^0.29.0"",
    ""ts-jest"": ""^26.1.0"",
    ""typescript"": ""^3.9.5""
  },
  ""dependencies"": {
    ""@fortawesome/fontawesome-svg-core"": ""^1.2.28"",
    ""@fortawesome/free-regular-svg-icons"": ""^5.13.0"",
    ""@fortawesome/free-solid-svg-icons"": ""^5.13.0"",
    ""@popperjs/core"": ""^2.4.0"",
    ""@types/twemoji"": ""^12.1.1"",
    ""focus-trap"": ""^5.1.0"",
    ""fuzzysort"": ""^1.1.4"",
    ""tiny-emitter"": ""^2.1.0"",
    ""tslib"": ""^2.0.0"",
    ""twemoji"": ""^13.0.0""
  },
  ""files"": [
    ""dist""
  ]
}
",CWE-79,72.0,1
"# -*- coding: utf-8 -*-

from django.conf import settings
from django.conf.urls import include, url
from django.conf.urls import handler400, handler403, handler404, handler500
from django.urls import path
from django.contrib import admin
from django.contrib.staticfiles.urls import staticfiles_urlpatterns
from django.contrib.auth.views import LogoutView
from django.views.generic import RedirectView
from rest_framework_swagger.views import get_swagger_view
from rest_framework_simplejwt.views import (
    TokenObtainPairView,
    TokenRefreshView,
    TokenVerifyView,
)

from users import views as user_views


def i18n_javascript(request):
    return admin.site.i18n_javascript(request)


handler400 = 'app.views.custom_bad_request'
handler403 = 'app.views.custom_permission_denied'
handler404 = 'app.views.custom_page_not_found'
handler500 = 'app.views.custom_error'


api_schema_view = get_swagger_view(title='PatrOwl Manager REST-API')

urlpatterns = [
    url(r'^apis-doc', api_schema_view),
    url(r'^ht/', include('health_check.urls')),
    url(r'^auth-jwt/obtain_jwt_token/', TokenObtainPairView.as_view(), name='token_obtain_pair'),
    url(r'^auth-jwt/refresh_jwt_token/', TokenRefreshView.as_view(), name='token_refresh'),
    url(r'^auth-jwt/verify/', TokenVerifyView.as_view(), name='token_verify'),
    url(r'^admin/', admin.site.urls),
    url(r'^engines/', include('engines.urls')),
    url(r'^findings/', include('findings.urls')),
    url(r'^assets/', include('assets.urls')),
    url(r'^users/', include('users.urls')),
    url(r'^scans/', include('scans.urls')),
    url(r'^events/', include('events.urls')),
    url(r'^rules/', include('rules.urls')),
    url(r'^reportings/', include('reportings.urls')),
    url(r'^settings/', include('settings.urls')),
    url(r'^search', include('search.urls')),
    url(r'^', include('users.urls'), name='home'),

    url(r'^login$', user_views.login, name='login'),
    url(r'^logout$', LogoutView.as_view(), {'next_page': settings.LOGOUT_REDIRECT_URL}, name='logout'),
    # url(r'^signup$', user_views.signup, name='signup'),

    url(r'^favicon\.ico$', RedirectView.as_view(url='/static/favicon.ico')),
]

# Debug toolbar & download file
# if settings.DEBUG:
#     import debug_toolbar
#     urlpatterns = [
#         path('__debug__/', include(debug_toolbar.urls)),
#     ] + urlpatterns
# if settings.DEBUG:
import debug_toolbar
urlpatterns = [
    path('__debug__/', include(debug_toolbar.urls)),
] + urlpatterns

# urlpatterns += staticfiles_urlpatterns()

# Add PRO edition urls
if settings.PRO_EDITION:
    # print(""urls-PRO_EDITION"", settings.PRO_EDITION)
    try:
        from pro.urls import pro_urlpatterns
        urlpatterns += pro_urlpatterns
    except ImportError as e:
        print(e)

urlpatterns += staticfiles_urlpatterns()
",CWE-434,83.0,1
"# -*- coding: utf-8 -*-

from django import forms
from .models import Finding, FINDING_SEVERITIES

ENGINE_TYPES = (
    ('json', 'json'),
    ('nessus', 'Nessus'),
)


class ImportFindingsForm(forms.Form):
    class Meta:
        fields = ['engine', 'min_level', 'file']

    engine = forms.CharField(widget=forms.Select(
        attrs={'class': 'form-control form-control-sm'},
        choices=ENGINE_TYPES))
    min_level = forms.CharField(widget=forms.Select(
        attrs={'class': 'form-control form-control-sm'},
        choices=FINDING_SEVERITIES),
        label='Minimum severity')
    file = forms.FileField()


class FindingForm(forms.ModelForm):
    class Meta:
        model = Finding
        fields = ['title', 'type', 'severity', 'status', 'description', 'tags',
            'solution', 'risk_info', 'vuln_refs', 'links', 'comments', 'asset']
        widgets = {
            'description': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'solution': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'tags': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'risk_info': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'title': forms.TextInput(
                attrs={'class': 'form-control form-control-sm'}),
            'vuln_refs': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'links': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'type': forms.TextInput(
                attrs={'class': 'form-control form-control-sm'}),
            'severity': forms.Select(
                attrs={'class': 'form-control form-control-sm'}),
            'comments': forms.Textarea(
                attrs={'class': 'form-control form-control-sm'}),
            'status': forms.Select(
                attrs={'class': 'form-control form-control-sm'}),
            'asset': forms.Select(
                attrs={'class': 'form-control form-control-sm'})
        }

        #tags = forms.CharField(widget=forms.TextInput(attrs={""data-role"": ""tagsinput""}))
",CWE-434,59.0,1
"'''
A script that benchmarks the queue performance, can be used to compare the performance 
of the queue on a given branch vs the main branch. By default, runs 100 jobs in batches
of 20 and prints the average time per job. The inference time for each job (without the
network overhead of sending/receiving the data) is 0.5 seconds. Each job sends one of:
a text, image, audio, or video input and the output is the same as the input.

Navigate to the root directory of the gradio repo and run:
>> python scripts/benchmark_queue.py

You can specify the number of jobs to run and the batch size with the -n parameter:
>> python scripts/benchmark_queue.py -n 1000

The results are printed to the console, but you can specify a path to save the results 
to with the -o parameter:
>> python scripts/benchmark_queue.py -n 1000 -o results.json
'''

import argparse
import asyncio
import json
import random
import time

import pandas as pd
import websockets

import gradio as gr
from gradio_client import media_data


def identity_with_sleep(x):
    time.sleep(0.5)
    return x


with gr.Blocks() as demo:
    with gr.Row():
        with gr.Column():
            input_txt = gr.Text()
            output_text = gr.Text()
            submit_text = gr.Button()
            submit_text.click(identity_with_sleep, input_txt, output_text, api_name=""text"")
        with gr.Column():
            input_img = gr.Image()
            output_img = gr.Image()
            submit_img = gr.Button()
            submit_img.click(identity_with_sleep, input_img, output_img, api_name=""img"")
        with gr.Column():
            input_audio = gr.Audio()
            output_audio = gr.Audio()
            submit_audio = gr.Button()
            submit_audio.click(identity_with_sleep, input_audio, output_audio, api_name=""audio"")
        with gr.Column():
            input_video = gr.Video()
            output_video = gr.Video()
            submit_video = gr.Button()
            submit_video.click(identity_with_sleep, input_video, output_video, api_name=""video"")
demo.queue(max_size=50).launch(prevent_thread_lock=True, quiet=True)


FN_INDEX_TO_DATA = {
    ""text"": (0, ""A longish text "" * 15),
    ""image"": (1, media_data.BASE64_IMAGE),
    ""audio"": (2, media_data.BASE64_AUDIO),
    ""video"": (3, media_data.BASE64_VIDEO)
}


async def get_prediction(host):
    async with websockets.connect(host) as ws:
        completed = False
        name = random.choice([""image"", ""text"", ""audio"", ""video""])
        fn_to_hit, data = FN_INDEX_TO_DATA[name]
        start = time.time()

        while not completed:
            msg = json.loads(await ws.recv())
            if msg[""msg""] == ""send_data"":
                await ws.send(json.dumps({""data"": [data], ""fn_index"": fn_to_hit}))
            if msg[""msg""] == ""send_hash"":
                await ws.send(json.dumps({""fn_index"": fn_to_hit, ""session_hash"": ""shdce""}))
            if msg[""msg""] == ""process_completed"":
                completed = True
                end = time.time()
                return {""fn_to_hit"": name, ""duration"": end - start}


async def main(host, n_results=100):
    results = []
    while len(results) < n_results:
        batch_results = await asyncio.gather(*[get_prediction(host) for _ in range(20)])
        for result in batch_results:
            if result:
                results.append(result)

    data = pd.DataFrame(results).groupby(""fn_to_hit"").agg({""mean""})
    data.columns = data.columns.get_level_values(0)
    data = data.reset_index()
    data = {""fn_to_hit"": data[""fn_to_hit""].to_list(), ""duration"": data[""duration""].to_list()}                
    return data


if __name__ == ""__main__"":
    parser = argparse.ArgumentParser(description=""Upload a demo to a space"")
    parser.add_argument(""-n"", ""--n_jobs"", type=int, help=""number of jobs"", default=100, required=False)
    parser.add_argument(""-o"", ""--output"", type=str, help=""path to write output to"", required=False)     
    args = parser.parse_args()

    host = f""{demo.local_url.replace('http', 'ws')}queue/join""
    data = asyncio.run(main(host, n_results=args.n_jobs))
    data = dict(zip(data[""fn_to_hit""], data[""duration""]))
    
    print(data)
    
    if args.output:
        print(""Writing results to:"", args.output)
        json.dump(data, open(args.output, ""w""))
",CWE-22,119.0,1
,CWE-918,,1
"""""""Predefined button to sign in with Hugging Face in a Gradio Space.""""""
from __future__ import annotations

import json
import warnings
from typing import Literal

from gradio_client.documentation import document

from gradio.components import Button
from gradio.context import Context
from gradio.routes import Request


@document()
class LoginButton(Button):
    """"""
    Creates a button that redirects the user to Sign with Hugging Face using OAuth.
    """"""

    is_template = True

    def __init__(
        self,
        value: str = ""Sign in with Hugging Face"",
        logout_value: str = ""Logout ({})"",
        *,
        every: float | None = None,
        variant: Literal[""primary"", ""secondary"", ""stop""] = ""secondary"",
        size: Literal[""sm"", ""lg""] | None = None,
        icon: str
        | None = ""https://huggingface.co/front/assets/huggingface_logo-noborder.svg"",
        link: str | None = None,
        visible: bool = True,
        interactive: bool = True,
        elem_id: str | None = None,
        elem_classes: list[str] | str | None = None,
        render: bool = True,
        scale: int | None = 0,
        min_width: int | None = None,
        signed_in_value: str = ""Signed in as {}"",
    ):
        """"""
        Parameters:
            logout_value: The text to display when the user is signed in. The string should contain a placeholder for the username with a call-to-action to logout, e.g. ""Logout ({})"".
        """"""
        if signed_in_value != ""Signed in as {}"":
            warnings.warn(
                ""The `signed_in_value` parameter is deprecated. Please use `logout_value` instead.""
            )
        self.logout_value = logout_value
        super().__init__(
            value,
            every=every,
            variant=variant,
            size=size,
            icon=icon,
            link=link,
            visible=visible,
            interactive=interactive,
            elem_id=elem_id,
            elem_classes=elem_classes,
            render=render,
            scale=scale,
            min_width=min_width,
        )
        if Context.root_block:
            self.activate()
        else:
            warnings.warn(
                ""LoginButton created outside of a Blocks context. May not work unless you call its `activate()` method manually.""
            )

    def activate(self):
        # Taken from https://cmgdo.com/external-link-in-gradio-button/
        # Taking `self` as input to check if user is logged in
        # ('self' value will be either ""Sign in with Hugging Face"" or ""Signed in as ..."")
        _js = _js_handle_redirect.replace(
            ""BUTTON_DEFAULT_VALUE"", json.dumps(self.value)
        )
        self.click(fn=None, inputs=[self], outputs=None, js=_js)

        self.attach_load_event(self._check_login_status, None)

    def _check_login_status(self, request: Request) -> LoginButton:
        # Each time the page is refreshed or loaded, check if the user is logged in and adapt label
        session = getattr(request, ""session"", None) or getattr(
            request.request, ""session"", None
        )
        if session is None or ""oauth_info"" not in session:
            return LoginButton(value=self.value, interactive=True)
        else:
            username = session[""oauth_info""][""userinfo""][""preferred_username""]
            logout_text = self.logout_value.format(username)
            return LoginButton(logout_text, interactive=True)


# JS code to redirects to /login/huggingface if user is not logged in.
# If the app is opened in an iframe, open the login page in a new tab.
# Otherwise, redirects locally. Taken from https://stackoverflow.com/a/61596084.
# If user is logged in, redirect to logout page (always in-place).
_js_handle_redirect = """"""
(buttonValue) => {
    if (buttonValue === BUTTON_DEFAULT_VALUE) {
        url = '/login/huggingface' + window.location.search;
        if ( window !== window.parent ) {
            window.open(url, '_blank');
        } else {
            window.location.assign(url);
        }
    } else {
        url = '/logout' + window.location.search
        window.location.assign(url);
    }
}
""""""
",CWE-918,117.0,1
"""""""gr.JSON() component.""""""

from __future__ import annotations

import json
from typing import Any, Callable

import orjson
from gradio_client.documentation import document

from gradio.components.base import Component
from gradio.events import Events


@document()
class JSON(Component):
    """"""
    Used to display arbitrary JSON output prettily. As this component does not accept user input, it is rarely used as an input component.

    Demos: zip_to_json, blocks_xray
    """"""

    EVENTS = [Events.change]

    def __init__(
        self,
        value: str | dict | list | Callable | None = None,
        *,
        label: str | None = None,
        every: float | None = None,
        show_label: bool | None = None,
        container: bool = True,
        scale: int | None = None,
        min_width: int = 160,
        visible: bool = True,
        elem_id: str | None = None,
        elem_classes: list[str] | str | None = None,
        render: bool = True,
        key: int | str | None = None,
    ):
        """"""
        Parameters:
            value: Default value as a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. If callable, the function will be called whenever the app loads to set the initial value of the component.
            label: The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.
            every: If `value` is a callable, run the function 'every' number of seconds while the client connection is open. Has no effect otherwise. The event can be accessed (e.g. to cancel it) via this component's .load_event attribute.
            show_label: if True, will display label.
            container: If True, will place the component in a container - providing some extra padding around the border.
            scale: relative size compared to adjacent Components. For example if Components A and B are in a Row, and A has scale=2, and B has scale=1, A will be twice as wide as B. Should be an integer. scale applies in Rows, and to top-level Components in Blocks where fill_height=True.
            min_width: minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.
            visible: If False, component will be hidden.
            elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.
            elem_classes: An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.
            render: If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.
            key: if assigned, will be used to assume identity across a re-render. Components that have the same key across a re-render will have their value preserved.
        """"""
        super().__init__(
            label=label,
            every=every,
            show_label=show_label,
            container=container,
            scale=scale,
            min_width=min_width,
            visible=visible,
            elem_id=elem_id,
            elem_classes=elem_classes,
            render=render,
            key=key,
            value=value,
        )

    def preprocess(self, payload: dict | list | None) -> dict | list | None:
        """"""
        Parameters:
            payload: JSON value as a `dict` or `list`
        Returns:
            Passes the JSON value as a `dict` or `list` depending on the value.
        """"""
        return payload

    def postprocess(self, value: dict | list | str | None) -> dict | list | None:
        """"""
        Parameters:
            value: Expects a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. The `list` or `dict` value can contain numpy arrays.
        Returns:
            Returns the JSON as a `list` or `dict`.
        """"""
        if value is None:
            return None
        if isinstance(value, str):
            return orjson.loads(value)
        else:
            # Use orjson to convert NumPy arrays and datetime objects to JSON.
            # This ensures a backward compatibility with the previous behavior.
            # See https://github.com/gradio-app/gradio/pull/8041
            return orjson.loads(
                orjson.dumps(
                    value,
                    option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_PASSTHROUGH_DATETIME,
                    default=str,
                )
            )

    def example_payload(self) -> Any:
        return {""foo"": ""bar""}

    def example_value(self) -> Any:
        return {""foo"": ""bar""}

    def read_from_flag(self, payload: Any):
        return json.loads(payload)

    def api_info(self) -> dict[str, Any]:
        return {""type"": {}, ""description"": ""any valid json""}
",CWE-20,114.0,1
"import json

import numpy as np
import pytest

import gradio as gr


class TestJSON:
    def test_component_functions(self):
        """"""
        Postprocess
        """"""
        js_output = gr.JSON()
        assert js_output.postprocess('{""a"":1, ""b"": 2}'), '""{\\""a\\"":1, \\""b\\"": 2}""'
        assert js_output.get_config() == {
            ""container"": True,
            ""min_width"": 160,
            ""scale"": None,
            ""elem_id"": None,
            ""elem_classes"": [],
            ""visible"": True,
            ""value"": None,
            ""show_label"": True,
            ""label"": None,
            ""name"": ""json"",
            ""proxy_url"": None,
            ""_selectable"": False,
            ""key"": None,
        }

    def test_chatbot_selectable_in_config(self):
        with gr.Blocks() as demo:
            cb = gr.Chatbot(label=""Chatbot"")
            cb.like(lambda: print(""foo""))
            gr.Chatbot(label=""Chatbot2"")

        assertion_count = 0
        for component in demo.config[""components""]:
            if component[""props""][""label""] == ""Chatbot"":
                assertion_count += 1
                assert component[""props""][""likeable""]
            elif component[""props""][""label""] == ""Chatbot2"":
                assertion_count += 1
                assert not component[""props""][""likeable""]

        assert assertion_count == 2

    @pytest.mark.asyncio
    async def test_in_interface(self):
        """"""
        Interface, process
        """"""

        def get_avg_age_per_gender(data):
            return {
                ""M"": int(data[data[""gender""] == ""M""][""age""].mean()),
                ""F"": int(data[data[""gender""] == ""F""][""age""].mean()),
                ""O"": int(data[data[""gender""] == ""O""][""age""].mean()),
            }

        iface = gr.Interface(
            get_avg_age_per_gender,
            gr.Dataframe(headers=[""gender"", ""age""]),
            ""json"",
        )
        y_data = [
            [""M"", 30],
            [""F"", 20],
            [""M"", 40],
            [""O"", 20],
            [""F"", 30],
        ]
        assert (
            await iface.process_api(
                0, [{""data"": y_data, ""headers"": [""gender"", ""age""]}], state={}
            )
        )[""data""][0] == {
            ""M"": 35,
            ""F"": 25,
            ""O"": 20,
        }

    @pytest.mark.parametrize(
        ""value, expected"",
        [
            (None, None),
            (True, True),
            ([1, 2, 3], [1, 2, 3]),
            ([np.array([1, 2, 3])], [[1, 2, 3]]),
            ({""foo"": [1, 2, 3]}, {""foo"": [1, 2, 3]}),
            ({""foo"": np.array([1, 2, 3])}, {""foo"": [1, 2, 3]}),
        ],
    )
    def test_postprocess_returns_json_serializable_value(self, value, expected):
        json_component = gr.JSON()
        postprocessed_value = json_component.postprocess(value)
        assert postprocessed_value == expected
        assert json.loads(json.dumps(postprocessed_value)) == expected
",CWE-20,100.0,1
"# coding: utf-8

from django.conf import settings
from django.contrib import messages
from django.contrib.admin.views.decorators import staff_member_required
from django.contrib.auth import load_backend, login
from django.core.exceptions import ObjectDoesNotExist
from django.http import Http404
from django.shortcuts import redirect
from django.utils.html import escape
from django.utils.translation import gettext_lazy as _

from grappelli.settings import SWITCH_USER_ORIGINAL, SWITCH_USER_TARGET

try:
    from django.contrib.auth import get_user_model
    User = get_user_model()
except ImportError:
    from django.contrib.auth.models import User


@staff_member_required
def switch_user(request, object_id):

    # current/session user
    current_user = request.user
    session_user = request.session.get(""original_user"", {""id"": current_user.id, ""username"": current_user.get_username()})

    # check redirect
    redirect_url = request.GET.get(""redirect"", None)
    if redirect_url is None or not redirect_url.startswith(""/""):
        raise Http404()

    # check original_user
    try:
        original_user = User.objects.get(pk=session_user[""id""], is_staff=True)
        if not SWITCH_USER_ORIGINAL(original_user):
            messages.add_message(request, messages.ERROR, _(""Permission denied.""))
            return redirect(request.GET.get(""redirect""))
    except ObjectDoesNotExist:
        msg = _('%(name)s object with primary key %(key)r does not exist.') % {'name': ""User"", 'key': escape(session_user[""id""])}
        messages.add_message(request, messages.ERROR, msg)
        return redirect(request.GET.get(""redirect""))

    # check new user
    try:
        target_user = User.objects.get(pk=object_id, is_staff=True)
        if target_user != original_user and not SWITCH_USER_TARGET(original_user, target_user):
            messages.add_message(request, messages.ERROR, _(""Permission denied.""))
            return redirect(request.GET.get(""redirect""))
    except ObjectDoesNotExist:
        msg = _('%(name)s object with primary key %(key)r does not exist.') % {'name': ""User"", 'key': escape(object_id)}
        messages.add_message(request, messages.ERROR, msg)
        return redirect(request.GET.get(""redirect""))

    # find backend
    if not hasattr(target_user, 'backend'):
        for backend in settings.AUTHENTICATION_BACKENDS:
            if target_user == load_backend(backend).get_user(target_user.pk):
                target_user.backend = backend
                break

    # target user login, set original as session
    if hasattr(target_user, 'backend'):
        login(request, target_user)
        if original_user.id != target_user.id:
            request.session[""original_user""] = {""id"": original_user.id, ""username"": original_user.get_username()}

    return redirect(request.GET.get(""redirect""))
",CWE-601,70.0,1
"# Copyright IBM Corp. 2020. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import os
import tempfile

from shlex import quote

from horovod.runner.common.util import safe_shell_exec
from horovod.runner.util import lsf
from distutils.spawn import find_executable
from horovod.runner.mpi_run import _get_mpi_implementation_flags, _MPI_NOT_FOUND_ERROR_MSG


def is_jsrun_installed():
    """"""Returns True if jsrun is installed.""""""
    return find_executable('jsrun') is not None


def js_run(settings, nics, env, command, stdout=None, stderr=None):
    """"""
    Runs Horovod with jsrun.

    Args:
        settings: Settings for running jsrun.
                  Note: settings.num_proc and settings.hosts must not be None.
        nics: Interfaces to include by jsrun.
        env: Environment dictionary to use for running jsrun.
        command: Command and arguments to run as a list of string.
        stdout: Stdout of the mpi process.
                Only used when settings.run_func_mode is True.
        stderr: Stderr of the mpi process.
                Only used when settings.run_func_mode is True.
    """"""
    mpi_impl_flags, _ = _get_mpi_implementation_flags(settings.tcp_flag, env=env)
    if mpi_impl_flags is None:
        raise Exception(_MPI_NOT_FOUND_ERROR_MSG)

    if not is_jsrun_installed():
        raise Exception(
            'horovod does not find the jsrun command.\n\n'
            'Please, make sure you are running on a cluster with jsrun installed or '
            'use one of the other launchers.')

    if nics and 'NCCL_SOCKET_IFNAME' not in env:
        env['NCCL_SOCKET_IFNAME'] = ','.join(nics)

    smpiargs = ' '.join(mpi_impl_flags)
    if settings.extra_mpi_args:
        smpiargs += ' ' + settings.extra_mpi_args

    if settings.binding_args:
        binding_args = settings.binding_args
    else:
        rf = generate_jsrun_rankfile(settings)
        if settings.verbose >= 2:
            safe_shell_exec.execute('cat {rf}'.format(rf=rf))
        binding_args = '--erf_input {rf}'.format(rf=rf)

    jsrun_command = (
        'jsrun {binding_args} '
        '{output_filename_arg} '
        '{smpiargs} '
        '{command}'
        .format(binding_args = binding_args,
                output_filename_arg='--stdio_stderr {file} --stdio_stdout {file}'.format(file=settings.output_filename)
                                    if settings.output_filename else '',
                smpiargs= '--smpiargs {args}'.format(args=quote(smpiargs)) if smpiargs else '',
                command=' '.join(quote(par) for par in command))
    )

    if settings.verbose >= 2:
        print(jsrun_command)

    # Execute the jsrun command.
    if settings.run_func_mode:
        exit_code = safe_shell_exec.execute(jsrun_command, env=env, stdout=stdout, stderr=stderr)
        if exit_code != 0:
            raise RuntimeError(""jsrun failed with exit code {exit_code}"".format(exit_code=exit_code))
    else:
        os.execve('/bin/sh', ['/bin/sh', '-c', jsrun_command], env)


def generate_jsrun_rankfile(settings, path=None):
    """"""
    Generates rankfile to use with jsrun.
    It splits the cores among the processes, which leads to best performance according to experiments.

    Args:
        settings: Settings for running jsrun.
                  Note: settings.num_proc and settings.hosts must not be None.
        path: Optional path of the rankfile.
              Note: this file will be overwritten.
    """"""
    cpu_per_gpu = (lsf.LSFUtils.get_num_cores() * lsf.LSFUtils.get_num_threads()) // lsf.LSFUtils.get_num_gpus()
    host_list = (x.split(':') for x in settings.hosts.split(','))

    # Verify and truncate host list if necessary
    validated_list = []
    remaining_slots = settings.num_proc
    for host, slots in host_list:
        slots = int(slots)
        if slots > lsf.LSFUtils.get_num_gpus():
            raise ValueError('Invalid host input, slot count for host \'{host}:{slots}\' is greater '
                             'than number of GPUs per host \'{gpus}\'.'.format(
                host=host, slots=slots, gpus=lsf.LSFUtils.get_num_gpus()))
        needed_slots = min(slots, remaining_slots)
        validated_list.append((host, needed_slots))
        remaining_slots -= needed_slots
        if remaining_slots == 0:
            break
    if remaining_slots != 0:
        raise ValueError('Not enough slots on the hosts to fulfill the {slots} requested.'.format(
            slots=settings.num_proc))

    # Generate rankfile
    path = tempfile.mktemp() if path is None else path
    with open(path, 'w') as tmp:
        tmp.write('overlapping_rs: allow\n')
        tmp.write('cpu_index_using: logical\n')
        rank = 0
        for host, slots in validated_list:
            cpu_val = 0
            tmp.write('\n')
            for s in range(slots):
                tmp.write('rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\n'.format(
                    rank=rank,
                    host=host,
                    scpu=cpu_val,
                    ecpu=cpu_val + cpu_per_gpu - 1
                ))
                rank += 1
                cpu_val += cpu_per_gpu
    return path
",CWE-668,147.0,1
"import json
import os
from pathlib import Path
from typing import Union

from . import __version__
from .compat import is_windows
from .encoding import UTF8


ENV_XDG_CONFIG_HOME = 'XDG_CONFIG_HOME'
ENV_HTTPIE_CONFIG_DIR = 'HTTPIE_CONFIG_DIR'
DEFAULT_CONFIG_DIRNAME = 'httpie'
DEFAULT_RELATIVE_XDG_CONFIG_HOME = Path('.config')
DEFAULT_RELATIVE_LEGACY_CONFIG_DIR = Path('.httpie')
DEFAULT_WINDOWS_CONFIG_DIR = Path(
    os.path.expandvars('%APPDATA%')) / DEFAULT_CONFIG_DIRNAME


def get_default_config_dir() -> Path:
    """"""
    Return the path to the httpie configuration directory.

    This directory isn't guaranteed to exist, and nor are any of its
    ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).

    XDG Base Directory Specification support:

        <https://wiki.archlinux.org/index.php/XDG_Base_Directory>

        $XDG_CONFIG_HOME is supported; $XDG_CONFIG_DIRS is not

    """"""
    # 1. explicitly set through env
    env_config_dir = os.environ.get(ENV_HTTPIE_CONFIG_DIR)
    if env_config_dir:
        return Path(env_config_dir)

    # 2. Windows
    if is_windows:
        return DEFAULT_WINDOWS_CONFIG_DIR

    home_dir = Path.home()

    # 3. legacy ~/.httpie
    legacy_config_dir = home_dir / DEFAULT_RELATIVE_LEGACY_CONFIG_DIR
    if legacy_config_dir.exists():
        return legacy_config_dir

    # 4. XDG
    xdg_config_home_dir = os.environ.get(
        ENV_XDG_CONFIG_HOME,  # 4.1. explicit
        home_dir / DEFAULT_RELATIVE_XDG_CONFIG_HOME  # 4.2. default
    )
    return Path(xdg_config_home_dir) / DEFAULT_CONFIG_DIRNAME


DEFAULT_CONFIG_DIR = get_default_config_dir()


class ConfigFileError(Exception):
    pass


class BaseConfigDict(dict):
    name = None
    helpurl = None
    about = None

    def __init__(self, path: Path):
        super().__init__()
        self.path = path

    def ensure_directory(self):
        self.path.parent.mkdir(mode=0o700, parents=True, exist_ok=True)

    def is_new(self) -> bool:
        return not self.path.exists()

    def load(self):
        config_type = type(self).__name__.lower()
        try:
            with self.path.open(encoding=UTF8) as f:
                try:
                    data = json.load(f)
                except ValueError as e:
                    raise ConfigFileError(
                        f'invalid {config_type} file: {e} [{self.path}]'
                    )
                self.update(data)
        except FileNotFoundError:
            pass
        except OSError as e:
            raise ConfigFileError(f'cannot read {config_type} file: {e}')

    def save(self):
        self['__meta__'] = {
            'httpie': __version__
        }
        if self.helpurl:
            self['__meta__']['help'] = self.helpurl

        if self.about:
            self['__meta__']['about'] = self.about

        self.ensure_directory()

        json_string = json.dumps(
            obj=self,
            indent=4,
            sort_keys=True,
            ensure_ascii=True,
        )
        self.path.write_text(json_string + '\n', encoding=UTF8)


class Config(BaseConfigDict):
    FILENAME = 'config.json'
    DEFAULTS = {
        'default_options': []
    }

    def __init__(self, directory: Union[str, Path] = DEFAULT_CONFIG_DIR):
        self.directory = Path(directory)
        super().__init__(path=self.directory / self.FILENAME)
        self.update(self.DEFAULTS)

    @property
    def default_options(self) -> list:
        return self['default_options']

    @property
    def plugins_dir(self) -> Path:
        return Path(self.get('plugins_dir', self.directory / 'plugins')).resolve()
",CWE-200,135.0,1
"from textwrap import dedent
from httpie.cli.argparser import HTTPieManagerArgumentParser
from httpie import __version__

COMMANDS = {
    'plugins': {
        'help': 'Manage HTTPie plugins.',
        'install': [
            'Install the given targets from PyPI '
            'or from a local paths.',
            {
                'dest': 'targets',
                'nargs': '+',
                'help': 'targets to install'
            }
        ],
        'upgrade': [
            'Upgrade the given plugins',
            {
                'dest': 'targets',
                'nargs': '+',
                'help': 'targets to upgrade'
            }
        ],
        'uninstall': [
            'Uninstall the given HTTPie plugins.',
            {
                'dest': 'targets',
                'nargs': '+',
                'help': 'targets to install'
            }
        ],
        'list': [
            'List all installed HTTPie plugins.'
        ],
    },
}


def missing_subcommand(*args) -> str:
    base = COMMANDS
    for arg in args:
        base = base[arg]

    assert isinstance(base, dict)
    subcommands = ', '.join(map(repr, base.keys()))
    return f'Please specify one of these: {subcommands}'


def generate_subparsers(root, parent_parser, definitions):
    action_dest = '_'.join(parent_parser.prog.split()[1:] + ['action'])
    actions = parent_parser.add_subparsers(
        dest=action_dest
    )
    for command, properties in definitions.items():
        is_subparser = isinstance(properties, dict)
        descr = properties.pop('help', None) if is_subparser else properties.pop(0)
        command_parser = actions.add_parser(command, description=descr)
        command_parser.root = root
        if is_subparser:
            generate_subparsers(root, command_parser, properties)
            continue

        for argument in properties:
            command_parser.add_argument(**argument)


parser = HTTPieManagerArgumentParser(
    prog='httpie',
    description=dedent(
        '''
        Managing interface for the HTTPie itself. <https://httpie.io/docs#manager>

        Be aware that you might be looking for http/https commands for sending
        HTTP requests. This command is only available for managing the HTTTPie
        plugins and the configuration around it.
        '''
    ),
)

parser.add_argument(
    '--debug',
    action='store_true',
    default=False,
    help='''
    Prints the exception traceback should one occur, as well as other
    information useful for debugging HTTPie itself and for reporting bugs.

    '''
)

parser.add_argument(
    '--traceback',
    action='store_true',
    default=False,
    help='''
    Prints the exception traceback should one occur.

    '''
)

parser.add_argument(
    '--version',
    action='version',
    version=__version__,
    help='''
    Show version and exit.

    '''
)

generate_subparsers(parser, parser, COMMANDS)
",CWE-200,113.0,1
"import argparse

from httpie.context import Environment
from httpie.manager.plugins import PluginInstaller
from httpie.status import ExitStatus
from httpie.manager.cli import missing_subcommand, parser

MSG_COMMAND_CONFUSION = '''\
This command is only for managing HTTPie plugins.
To send a request, please use the http/https commands:

  $ http {args}

  $ https {args}
'''

# noinspection PyStringFormat
MSG_NAKED_INVOCATION = f'''\
{missing_subcommand()}

{MSG_COMMAND_CONFUSION}
'''.rstrip(""\n"").format(args='POST pie.dev/post hello=world')


def program(args: argparse.Namespace, env: Environment) -> ExitStatus:
    if args.action is None:
        parser.error(MSG_NAKED_INVOCATION)

    if args.action == 'plugins':
        plugins = PluginInstaller(env, debug=args.debug)
        return plugins.run(args.plugins_action, args)

    return ExitStatus.SUCCESS
",CWE-200,34.0,1
,CWE-200,,1
"# This is purely the result of trial and error.

import sys

from setuptools import setup, find_packages

import httpie


# Note: keep requirements here to ease distributions packaging
tests_require = [
    'pytest',
    'pytest-httpbin>=0.0.6',
    'responses',
]
dev_require = [
    *tests_require,
    'flake8',
    'flake8-comprehensions',
    'flake8-deprecated',
    'flake8-mutable',
    'flake8-tuple',
    'pyopenssl',
    'pytest-cov',
    'pyyaml',
    'twine',
    'wheel',
    'Jinja2'
]
install_requires = [
    'charset_normalizer>=2.0.0',
    'defusedxml>=0.6.0',
    'requests[socks]>=2.22.0',
    'Pygments>=2.5.2',
    'requests-toolbelt>=0.9.1',
    'multidict>=4.7.0',
    'setuptools',
    'importlib-metadata>=1.4.0; python_version < ""3.8""',
]
install_requires_win_only = [
    'colorama>=0.2.4',
]

# Conditional dependencies:

# sdist
if 'bdist_wheel' not in sys.argv:

    if 'win32' in str(sys.platform).lower():
        # Terminal colors for Windows
        install_requires.extend(install_requires_win_only)


# bdist_wheel
extras_require = {
    'dev': dev_require,
    'test': tests_require,
    # https://wheel.readthedocs.io/en/latest/#defining-conditional-dependencies
    ':sys_platform == ""win32""': install_requires_win_only,
}


def long_description():
    with open('README.md', encoding='utf-8') as f:
        return f.read()


setup(
    name='httpie',
    version=httpie.__version__,
    description=httpie.__doc__.strip(),
    long_description=long_description(),
    long_description_content_type='text/markdown',
    url='https://httpie.io/',
    download_url=f'https://github.com/httpie/httpie/archive/{httpie.__version__}.tar.gz',
    author=httpie.__author__,
    author_email='jakub@roztocil.co',
    license=httpie.__licence__,
    packages=find_packages(include=['httpie', 'httpie.*']),
    entry_points={
        'console_scripts': [
            'http = httpie.__main__:main',
            'https = httpie.__main__:main',
            'httpie = httpie.manager.__main__:main',
        ],
    },
    python_requires='>=3.7',
    extras_require=extras_require,
    install_requires=install_requires,
    classifiers=[
        'Development Status :: 5 - Production/Stable',
        'Programming Language :: Python',
        'Programming Language :: Python :: 3 :: Only',
        'Environment :: Console',
        'Intended Audience :: Developers',
        'Intended Audience :: System Administrators',
        'License :: OSI Approved :: BSD License',
        'Topic :: Internet :: WWW/HTTP',
        'Topic :: Software Development',
        'Topic :: System :: Networking',
        'Topic :: Terminals',
        'Topic :: Text Processing',
        'Topic :: Utilities'
    ],
    project_urls={
        'GitHub': 'https://github.com/httpie/httpie',
        'Twitter': 'https://twitter.com/httpie',
        'Discord': 'https://httpie.io/discord',
        'Documentation': 'https://httpie.io/docs',
        'Online Demo': 'https://httpie.io/run',
    },
)
",CWE-200,113.0,1
"import os
import socket

import pytest
from pytest_httpbin import certs

from .utils import HTTPBIN_WITH_CHUNKED_SUPPORT_DOMAIN, HTTPBIN_WITH_CHUNKED_SUPPORT
from .utils.plugins_cli import ( # noqa
    broken_plugin,
    dummy_plugin,
    dummy_plugins,
    httpie_plugins,
    httpie_plugins_success,
    interface,
)
from .utils.http_server import http_server # noqa


@pytest.fixture(scope='function', autouse=True)
def httpbin_add_ca_bundle(monkeypatch):
    """"""
    Make pytest-httpbin's CA trusted by default.

    (Same as `httpbin_ca_bundle`, just auto-used.).

    """"""
    monkeypatch.setenv('REQUESTS_CA_BUNDLE', certs.where())


@pytest.fixture(scope='function')
def httpbin_secure_untrusted(monkeypatch, httpbin_secure):
    """"""
    Like the `httpbin_secure` fixture, but without the
    make-CA-trusted-by-default.

    """"""
    monkeypatch.delenv('REQUESTS_CA_BUNDLE')
    return httpbin_secure


@pytest.fixture(scope='session')
def _httpbin_with_chunked_support_available():
    try:
        socket.gethostbyname(HTTPBIN_WITH_CHUNKED_SUPPORT_DOMAIN)
        return True
    except OSError:
        return False


@pytest.fixture(scope='function')
def httpbin_with_chunked_support(_httpbin_with_chunked_support_available):
    if _httpbin_with_chunked_support_available:
        return HTTPBIN_WITH_CHUNKED_SUPPORT
    pytest.skip(f'{HTTPBIN_WITH_CHUNKED_SUPPORT_DOMAIN} not resolvable')


@pytest.fixture(autouse=True, scope='session')
def pyopenssl_inject():
    """"""
    Injects `pyOpenSSL` module to make sure `requests` will use it.
    <https://github.com/psf/requests/pull/5443#issuecomment-645740394>
    """"""
    if os.getenv('HTTPIE_TEST_WITH_PYOPENSSL', '0') == '1':
        try:
            import urllib3.contrib.pyopenssl
            urllib3.contrib.pyopenssl.inject_into_urllib3()
        except ModuleNotFoundError:
            pytest.fail('Missing ""pyopenssl"" module.')

    yield
",CWE-200,71.0,1
"""""""Test data""""""
from pathlib import Path

from httpie.encoding import UTF8
from httpie.output.formatters.xml import pretty_xml, parse_xml


def patharg(path):
    """"""
    Back slashes need to be escaped in ITEM args,
    even in Windows paths.

    """"""
    return str(path).replace('\\', '\\\\\\')


FIXTURES_ROOT = Path(__file__).parent
FILE_PATH = FIXTURES_ROOT / 'test.txt'
JSON_FILE_PATH = FIXTURES_ROOT / 'test.json'
JSON_WITH_DUPE_KEYS_FILE_PATH = FIXTURES_ROOT / 'test_with_dupe_keys.json'
BIN_FILE_PATH = FIXTURES_ROOT / 'test.bin'
XML_FILES_PATH = FIXTURES_ROOT / 'xmldata'
XML_FILES_VALID = list((XML_FILES_PATH / 'valid').glob('*_raw.xml'))
XML_FILES_INVALID = list((XML_FILES_PATH / 'invalid').glob('*.xml'))

FILE_PATH_ARG = patharg(FILE_PATH)
BIN_FILE_PATH_ARG = patharg(BIN_FILE_PATH)
JSON_FILE_PATH_ARG = patharg(JSON_FILE_PATH)

# Strip because we don't want new lines in the data so that we can
# easily count occurrences also when embedded in JSON (where the new
# line would be escaped).
FILE_CONTENT = FILE_PATH.read_text(encoding=UTF8).strip()

ASCII_FILE_CONTENT = ""random text"" * 10


JSON_FILE_CONTENT = JSON_FILE_PATH.read_text(encoding=UTF8)
BIN_FILE_CONTENT = BIN_FILE_PATH.read_bytes()
UNICODE = FILE_CONTENT
XML_DATA_RAW = '<?xml version=""1.0"" encoding=""utf-8""?><root><e>text</e></root>'
XML_DATA_FORMATTED = pretty_xml(parse_xml(XML_DATA_RAW))
",CWE-200,43.0,1
,CWE-200,,1
"import threading

from collections import defaultdict
from http import HTTPStatus
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse

import pytest


class TestHandler(BaseHTTPRequestHandler):
    handlers = defaultdict(dict)

    @classmethod
    def handler(cls, method, path):
        def inner(func):
            cls.handlers[method][path] = func
            return func
        return inner

    def do_generic(self):
        parse_result = urlparse(self.path)
        func = self.handlers[self.command].get(parse_result.path)
        if func is None:
            return self.send_error(HTTPStatus.NOT_FOUND)

        return func(self)

    do_GET = do_generic
    do_POST = do_generic


@TestHandler.handler('GET', '/headers')
def get_headers(handler):
    handler.send_response(200)
    for key, value in handler.headers.items():
        handler.send_header(key, value)
    handler.send_header('Content-Length', 0)
    handler.end_headers()


@TestHandler.handler('GET', '/drip')
def chunked_drip(handler):
    handler.send_response(200)
    accept = handler.headers.get('Accept')
    if accept is not None:
        handler.send_header('Content-Type', accept)
    handler.send_header('Transfer-Encoding', 'chunked')
    handler.end_headers()

    for _ in range(3):
        body = 'test\n'
        handler.wfile.write(f'{len(body):X}\r\n{body}\r\n'.encode('utf-8'))

    handler.wfile.write('0\r\n\r\n'.encode('utf-8'))


@TestHandler.handler('GET', '/stream/encoding/random')
def random_encoding(handler):
    from tests.fixtures import ASCII_FILE_CONTENT, FILE_CONTENT as UNICODE_FILE_CONTENT

    handler.send_response(200)
    handler.send_header('Transfer-Encoding', 'chunked')
    handler.end_headers()

    for body in [
        ASCII_FILE_CONTENT,
        ASCII_FILE_CONTENT,
        UNICODE_FILE_CONTENT,
        UNICODE_FILE_CONTENT,
        UNICODE_FILE_CONTENT,
    ]:
        body += ""\n""
        handler.wfile.write(f'{len(body.encode()):X}\r\n{body}\r\n'.encode())

    handler.wfile.write('0\r\n\r\n'.encode('utf-8'))


@TestHandler.handler('POST', '/status/msg')
def status_custom_msg(handler):
    content_len = int(handler.headers.get('content-length', 0))
    post_body = handler.rfile.read(content_len).decode()

    handler.send_response(200, post_body)
    handler.end_headers()


@pytest.fixture(scope=""function"")
def http_server():
    """"""A custom HTTP server implementation for our tests, that is
    built on top of the http.server module. Handy when we need to
    deal with details which httpbin can not capture.""""""

    server = HTTPServer(('localhost', 0), TestHandler)
    thread = threading.Thread(target=server.serve_forever)
    thread.start()
    yield '{}:{}'.format(*server.socket.getsockname())
    server.shutdown()
    thread.join(timeout=0.5)
",CWE-200,100.0,1
"import re
import secrets
from typing import Any, Dict, Optional, Tuple
from urllib.parse import urlparse

from django.conf import settings
from django.http import HttpRequest, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from rest_framework import status
from sentry_sdk import capture_exception
from statshog.defaults.django import statsd

from posthog.api.utils import get_token
from posthog.exceptions import RequestParsingError, generate_exception_response
from posthog.models import Team, User
from posthog.models.feature_flag import get_overridden_feature_flags
from posthog.utils import cors_response, load_data_from_request

from .utils import get_project_id


def on_permitted_domain(team: Team, request: HttpRequest) -> bool:
    permitted_domains = [""127.0.0.1"", ""localhost""]

    for url in team.app_urls:
        hostname = parse_domain(url)
        if hostname:
            permitted_domains.append(hostname)

    origin = parse_domain(request.headers.get(""Origin""))
    referer = parse_domain(request.headers.get(""Referer""))
    for permitted_domain in permitted_domains:
        if ""*"" in permitted_domain:
            pattern = ""^{}$"".format(permitted_domain.replace(""."", ""\\."").replace(""*"", ""(.*)""))
            if (origin and re.search(pattern, origin)) or (referer and re.search(pattern, referer)):
                return True
        else:
            if permitted_domain == origin or permitted_domain == referer:
                return True
    return False


def decide_editor_params(request: HttpRequest) -> Tuple[Dict[str, Any], bool]:
    if request.user.is_anonymous:
        return {}, False

    team = request.user.team
    if team and on_permitted_domain(team, request):
        response: Dict[str, Any] = {""isAuthenticated"": True}
        editor_params = {}

        if request.user.toolbar_mode != ""disabled"":
            editor_params[""toolbarVersion""] = ""toolbar""

        if settings.JS_URL:
            editor_params[""jsURL""] = settings.JS_URL

        response[""editorParams""] = editor_params
        return response, not request.user.temporary_token
    else:
        return {}, False


def parse_domain(url: Any) -> Optional[str]:
    return urlparse(url).hostname


@csrf_exempt
def get_decide(request: HttpRequest):
    response = {
        ""config"": {""enable_collect_everything"": True},
        ""editorParams"": {},
        ""isAuthenticated"": False,
        ""supportedCompression"": [""gzip"", ""gzip-js"", ""lz64""],
    }

    if request.COOKIES.get(settings.TOOLBAR_COOKIE_NAME) and request.user.is_authenticated:
        response[""isAuthenticated""] = True
        if settings.JS_URL and request.user.toolbar_mode == User.TOOLBAR:
            response[""editorParams""] = {""jsURL"": settings.JS_URL, ""toolbarVersion"": ""toolbar""}

    if request.user.is_authenticated:
        r, update_user_token = decide_editor_params(request)
        response.update(r)
        if update_user_token:
            request.user.temporary_token = secrets.token_urlsafe(32)
            request.user.save()

    response[""featureFlags""] = []
    response[""sessionRecording""] = False

    if request.method == ""POST"":
        try:
            data = load_data_from_request(request)
            api_version_string = request.GET.get(""v"")
            # NOTE: This does not support semantic versioning e.g. 2.1.0
            api_version = int(api_version_string) if api_version_string else 1
        except ValueError:
            # default value added because of bug in posthog-js 1.19.0
            # see https://sentry.io/organizations/posthog2/issues/2738865125/?project=1899813
            # as a tombstone if the below statsd counter hasn't seen errors for N days
            # then it is likely that no clients are running posthog-js 1.19.0
            # and this defaulting could be removed
            statsd.incr(
                f""posthog_cloud_decide_defaulted_api_version_on_value_error"",
                tags={""endpoint"": ""decide"", ""api_version_string"": api_version_string},
            )
            api_version = 2
        except RequestParsingError as error:
            capture_exception(error)  # We still capture this on Sentry to identify actual potential bugs
            return cors_response(
                request,
                generate_exception_response(""decide"", f""Malformed request data: {error}"", code=""malformed_data""),
            )

        token = get_token(data, request)
        team = Team.objects.get_team_from_token(token)
        if team is None and token:
            project_id = get_project_id(data, request)

            if not project_id:
                return cors_response(
                    request,
                    generate_exception_response(
                        ""decide"",
                        ""Project API key invalid. You can find your project API key in PostHog project settings."",
                        code=""invalid_api_key"",
                        type=""authentication_error"",
                        status_code=status.HTTP_401_UNAUTHORIZED,
                    ),
                )

            user = User.objects.get_from_personal_api_key(token)
            if user is None:
                return cors_response(
                    request,
                    generate_exception_response(
                        ""decide"",
                        ""Invalid Personal API key."",
                        code=""invalid_personal_key"",
                        type=""authentication_error"",
                        status_code=status.HTTP_401_UNAUTHORIZED,
                    ),
                )
            team = user.teams.get(id=project_id)

        if team:
            feature_flags = get_overridden_feature_flags(team.pk, data[""distinct_id""], data.get(""groups"", {}))
            response[""featureFlags""] = feature_flags if api_version >= 2 else list(feature_flags.keys())

            if team.session_recording_opt_in and (on_permitted_domain(team, request) or len(team.app_urls) == 0):
                response[""sessionRecording""] = {""endpoint"": ""/s/""}
    statsd.incr(
        f""posthog_cloud_raw_endpoint_success"", tags={""endpoint"": ""decide"",},
    )
    return cors_response(request, JsonResponse(response))
",CWE-601,157.0,1
"import uuid

from rest_framework import status

from posthog.test.base import APIBaseTest


class TestUrls(APIBaseTest):
    def test_logout_temporary_token_reset(self):

        # update temporary token
        self.user.temporary_token = ""token123""
        self.user.save()

        # logout
        with self.settings(TEST=False):
            response = self.client.post(""/logout"", follow=True)
            self.assertRedirects(response, ""/login"")

        # no more token
        self.user.refresh_from_db()
        self.assertEqual(self.user.temporary_token, None)

    def test_logged_out_user_is_redirected_to_login(self):
        self.client.logout()

        response = self.client.get(""/events"")
        self.assertRedirects(response, ""/login?next=/events"")

        # Complex URL
        response = self.client.get(
            '/insights/new?interval=day&display=ActionsLineGraph&events=[{""id"":""$pageview"",""name"":""$pageview"",""type"":""events"",""order"":0}]&properties=[]',
        )

        # Test that the URL is properly encoded to redirect the user to the final destination
        self.assertRedirects(
            response,
            ""/login?next=/insights/new%3Finterval%3Dday%26display%3DActionsLineGraph%26events%3D%5B%257B%2522id%2522%3A%2522%24pageview%2522%2C%2522name%2522%3A%2522%24pageview%2522%2C%2522type%2522%3A%2522events%2522%2C%2522order%2522%3A0%257D%5D%26properties%3D%5B%5D"",
            fetch_redirect_response=False,
        )

    def test_unauthenticated_routes_get_loaded_on_the_frontend(self):

        self.client.logout()

        response = self.client.get(""/signup"")
        self.assertEqual(response.status_code, status.HTTP_200_OK)  # no redirect

        response = self.client.get(f""/signup/{uuid.uuid4()}"")
        self.assertEqual(response.status_code, status.HTTP_200_OK)

        response = self.client.get(f""/preflight"")
        self.assertEqual(response.status_code, status.HTTP_200_OK)

        response = self.client.get(f""/login"")
        self.assertEqual(response.status_code, status.HTTP_200_OK)

    def test_authorize_and_redirect_domain(self):
        response = self.client.get(
            ""/authorize_and_redirect/?redirect=https://domain.com"", HTTP_REFERER=""https://not.com""
        )
        self.assertEqual(response.status_code, status.HTTP_400_BAD_REQUEST)
        self.assertTrue(""Can only redirect to the same domain as the referer: not.com"" in str(response.content))

        response = self.client.get(
            ""/authorize_and_redirect/?redirect=http://domain.com"", HTTP_REFERER=""https://domain.com""
        )
        self.assertEqual(response.status_code, status.HTTP_400_BAD_REQUEST)
        self.assertTrue(""Can only redirect to the same scheme as the referer: https"" in str(response.content))

        response = self.client.get(
            ""/authorize_and_redirect/?redirect=https://domain.com:555"", HTTP_REFERER=""https://domain.com:443""
        )
        self.assertEqual(response.status_code, status.HTTP_400_BAD_REQUEST)
        self.assertTrue(""Can only redirect to the same port as the referer: 443"" in str(response.content))

        response = self.client.get(
            ""/authorize_and_redirect/?redirect=https://domain.com:555"", HTTP_REFERER=""https://domain.com/no-port""
        )
        self.assertEqual(response.status_code, status.HTTP_400_BAD_REQUEST)
        self.assertTrue(""Can only redirect to the same port as the referer: no port in URL"" in str(response.content))

        response = self.client.get(
            ""/authorize_and_redirect/?redirect=https://domain.com/sdf"", HTTP_REFERER=""https://domain.com/asd""
        )
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        # TODO: build frontend before backend tests, or find a way to mock the template
        # self.assertContains(
        #     response,
        #     ""Do you want to give the PostHog Toolbar on <strong>https://domain.com/sdf</strong> access to your PostHog data?"",
        # )
",CWE-601,92.0,1
"from typing import Any, Callable, List, Optional
from urllib.parse import urlparse

from django.conf import settings
from django.http import HttpResponse
from django.urls import URLPattern, include, path, re_path
from django.views.decorators import csrf
from django.views.decorators.csrf import csrf_exempt
from drf_spectacular.views import SpectacularAPIView, SpectacularRedocView, SpectacularSwaggerView

from posthog.api import (
    api_not_found,
    authentication,
    capture,
    dashboard,
    decide,
    organizations_router,
    project_dashboards_router,
    projects_router,
    router,
    signup,
    user,
)
from posthog.demo import demo

from .utils import render_template
from .views import health, login_required, preflight_check, robots_txt, security_txt, sso_login, stats

ee_urlpatterns: List[Any] = []
try:
    from ee.urls import extend_api_router
    from ee.urls import urlpatterns as ee_urlpatterns
except ImportError:
    pass
else:
    extend_api_router(router, projects_router=projects_router, project_dashboards_router=project_dashboards_router)


try:
    # See https://github.com/PostHog/posthog-cloud/blob/master/multi_tenancy/router.py
    from multi_tenancy.router import extend_api_router as extend_api_router_cloud  # noqa
except ImportError:
    pass
else:
    extend_api_router_cloud(router, organizations_router=organizations_router, projects_router=projects_router)


@csrf.ensure_csrf_cookie
def home(request, *args, **kwargs):
    return render_template(""index.html"", request)


def authorize_and_redirect(request):
    if not request.GET.get(""redirect""):
        return HttpResponse(""You need to pass a url to ?redirect="", status=401)
    if not request.META.get(""HTTP_REFERER""):
        return HttpResponse('You need to make a request that includes the ""Referer"" header.', status=400)

    referer_url = urlparse(request.META[""HTTP_REFERER""])
    redirect_url = urlparse(request.GET[""redirect""])

    if referer_url.hostname != redirect_url.hostname:
        return HttpResponse(f""Can only redirect to the same domain as the referer: {referer_url.hostname}"", status=400)

    if referer_url.scheme != redirect_url.scheme:
        return HttpResponse(f""Can only redirect to the same scheme as the referer: {referer_url.scheme}"", status=400)

    if referer_url.port != redirect_url.port:
        return HttpResponse(
            f""Can only redirect to the same port as the referer: {referer_url.port or 'no port in URL'}"", status=400
        )

    return render_template(
        ""authorize_and_redirect.html"",
        request=request,
        context={""domain"": redirect_url.hostname, ""redirect_url"": request.GET[""redirect""]},
    )


def opt_slash_path(route: str, view: Callable, name: Optional[str] = None) -> URLPattern:
    """"""Catches path with or without trailing slash, taking into account query param and hash.""""""
    # Ignoring the type because while name can be optional on re_path, mypy doesn't agree
    return re_path(fr""^{route}/?(?:[?#].*)?$"", view, name=name)  # type: ignore


urlpatterns = [
    path(""api/schema/"", SpectacularAPIView.as_view(), name=""schema""),
    # Optional UI:
    path(""api/schema/swagger-ui/"", SpectacularSwaggerView.as_view(url_name=""schema""), name=""swagger-ui""),
    path(""api/schema/redoc/"", SpectacularRedocView.as_view(url_name=""schema""), name=""redoc""),
    # Health check probe endpoints for K8s
    # NOTE: We have _health, livez, and _readyz. _health is deprecated and
    # is only included for compatability with old installations. For new
    # operations livez and readyz should be used.
    opt_slash_path(""_health"", health),
    opt_slash_path(""_stats"", stats),
    opt_slash_path(""_preflight"", preflight_check),
    # ee
    *ee_urlpatterns,
    # api
    path(""api/"", include(router.urls)),
    opt_slash_path(""api/user/redirect_to_site"", user.redirect_to_site),
    opt_slash_path(""api/user/test_slack_webhook"", user.test_slack_webhook),
    opt_slash_path(""api/signup"", signup.SignupViewset.as_view()),
    opt_slash_path(""api/social_signup"", signup.SocialSignupViewset.as_view()),
    path(""api/signup/<str:invite_id>/"", signup.InviteSignupViewset.as_view()),
    path(
        ""api/reset/<str:user_uuid>/"",
        authentication.PasswordResetCompleteViewSet.as_view({""get"": ""retrieve"", ""post"": ""create""}),
    ),
    re_path(r""^api.+"", api_not_found),
    path(""authorize_and_redirect/"", login_required(authorize_and_redirect)),
    path(""shared_dashboard/<str:share_token>"", dashboard.shared_dashboard),
    re_path(r""^demo.*"", login_required(demo)),
    # ingestion
    opt_slash_path(""decide"", decide.get_decide),
    opt_slash_path(""e"", capture.get_event),
    opt_slash_path(""engage"", capture.get_event),
    opt_slash_path(""track"", capture.get_event),
    opt_slash_path(""capture"", capture.get_event),
    opt_slash_path(""batch"", capture.get_event),
    opt_slash_path(""s"", capture.get_event),  # session recordings
    opt_slash_path(""robots.txt"", robots_txt),
    opt_slash_path("".well-known/security.txt"", security_txt),
    # auth
    path(""logout"", authentication.logout, name=""login""),
    path(""signup/finish/"", signup.finish_social_signup, name=""signup_finish""),
    path(
        ""login/<str:backend>/"", sso_login, name=""social_begin""
    ),  # overrides from `social_django.urls` to validate proper license
    path("""", include(""social_django.urls"", namespace=""social"")),
]

if settings.TEST:

    # Used in posthog-js e2e tests
    @csrf_exempt
    def delete_events(request):
        from ee.clickhouse.sql.events import TRUNCATE_EVENTS_TABLE_SQL
        from posthog.client import sync_execute

        sync_execute(TRUNCATE_EVENTS_TABLE_SQL())
        return HttpResponse()

    urlpatterns.append(path(""delete_events/"", delete_events))


# Routes added individually to remove login requirement
frontend_unauthenticated_routes = [
    ""preflight"",
    ""signup"",
    r""signup\/[A-Za-z0-9\-]*"",
    ""reset"",
    ""organization/billing/subscribed"",
    ""login"",
]
for route in frontend_unauthenticated_routes:
    urlpatterns.append(re_path(route, home))

urlpatterns.append(re_path(r""^.*"", login_required(home)))
",CWE-601,161.0,1
"from subprocess import Popen

import sys
import os
import logging
import socket
import time

import mlflow
from mlflow.server import BACKEND_STORE_URI_ENV_VAR, ARTIFACT_ROOT_ENV_VAR
from tests.helper_functions import LOCALHOST, get_safe_port

_logger = logging.getLogger(__name__)


def _await_server_up_or_die(port, timeout=10):
    """"""Waits until the local flask server is listening on the given port.""""""
    _logger.info(f""Awaiting server to be up on {LOCALHOST}:{port}"")
    start_time = time.time()
    while time.time() - start_time < timeout:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(2)
            if sock.connect_ex((LOCALHOST, port)) == 0:
                _logger.info(f""Server is up on {LOCALHOST}:{port}!"")
                break
        _logger.info(""Server not yet up, waiting..."")
        time.sleep(0.5)
    else:
        raise Exception(f""Failed to connect on {LOCALHOST}:{port} within {timeout} seconds"")


# NB: We explicitly wait and timeout on server shutdown in order to ensure that pytest output
# reveals the cause in the event of a test hang due to the subprocess not exiting.
def _terminate_server(process, timeout=10):
    """"""Waits until the local flask server process is terminated.""""""
    _logger.info(""Terminating server..."")
    process.terminate()
    process.wait(timeout=timeout)


def _init_server(backend_uri, root_artifact_uri):
    """"""
    Launch a new REST server using the tracking store specified by backend_uri and root artifact
    directory specified by root_artifact_uri.
    :returns A tuple (url, process) containing the string URL of the server and a handle to the
             server process (a multiprocessing.Process object).
    """"""
    mlflow.set_tracking_uri(None)
    server_port = get_safe_port()
    process = Popen(
        [
            sys.executable,
            ""-c"",
            f'from mlflow.server import app; app.run(""{LOCALHOST}"", {server_port})',
        ],
        env={
            **os.environ,
            BACKEND_STORE_URI_ENV_VAR: backend_uri,
            ARTIFACT_ROOT_ENV_VAR: root_artifact_uri,
        },
    )

    _await_server_up_or_die(server_port)
    url = f""http://{LOCALHOST}:{server_port}""
    _logger.info(f""Launching tracking server against backend URI {backend_uri}. Server URL: {url}"")
    return url, process


def _send_rest_tracking_post_request(tracking_server_uri, api_path, json_payload):
    """"""
    Make a POST request to the specified MLflow Tracking API and retrieve the
    corresponding `requests.Response` object
    """"""
    import requests

    url = tracking_server_uri + api_path
    response = requests.post(url, json=json_payload)
    return response
",CWE-29,79.0,1
,CWE-36,,1
,CWE-78,,1
,CWE-79,,1
"import os
import posixpath
import re
from typing import Any, Dict
from urllib.parse import urlparse

from mlflow.data.dataset_source import DatasetSource
from mlflow.exceptions import MlflowException
from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE
from mlflow.utils.file_utils import create_tmp_dir
from mlflow.utils.rest_utils import augmented_raise_for_status, cloud_storage_http_request


class HTTPDatasetSource(DatasetSource):
    """"""
    Represents the source of a dataset stored at a web location and referred to
    by an HTTP or HTTPS URL.
    """"""

    def __init__(self, url):
        self._url = url

    @property
    def url(self):
        """"""
        The HTTP/S URL referring to the dataset source location.

        :return: The HTTP/S URL referring to the dataset source location.
        """"""
        return self._url

    @staticmethod
    def _get_source_type() -> str:
        return ""http""

    def load(self, dst_path=None) -> str:
        """"""
        Downloads the dataset source to the local filesystem.

        :param dst_path: Path of the local filesystem destination directory to which to download the
                         dataset source. If the directory does not exist, it is created. If
                         unspecified, the dataset source is downloaded to a new uniquely-named
                         directory on the local filesystem.
        :return: The path to the downloaded dataset source on the local filesystem.
        """"""
        resp = cloud_storage_http_request(
            method=""GET"",
            url=self.url,
            stream=True,
        )
        augmented_raise_for_status(resp)

        path = urlparse(self.url).path
        content_disposition = resp.headers.get(""Content-Disposition"")
        if content_disposition is not None and (
            file_name := next(re.finditer(r""filename=(.+)"", content_disposition), None)
        ):
            # NB: If the filename is quoted, unquote it
            basename = file_name[1].strip(""'\"""")
        elif path is not None and len(posixpath.basename(path)) > 0:
            basename = posixpath.basename(path)
        else:
            basename = ""dataset_source""

        if dst_path is None:
            dst_path = create_tmp_dir()

        dst_path = os.path.join(dst_path, basename)
        with open(dst_path, ""wb"") as f:
            chunk_size = 1024 * 1024  # 1 MB
            for chunk in resp.iter_content(chunk_size=chunk_size):
                f.write(chunk)

        return dst_path

    @staticmethod
    def _can_resolve(raw_source: Any) -> bool:
        """"""
        :param raw_source: The raw source, e.g. a string like ""http://mysite/mydata.tar.gz"".
        :return: True if this DatsetSource can resolve the raw source, False otherwise.
        """"""
        if not isinstance(raw_source, str):
            return False

        try:
            parsed_source = urlparse(str(raw_source))
            return parsed_source.scheme in [""http"", ""https""]
        except Exception:
            return False

    @classmethod
    def _resolve(cls, raw_source: Any) -> ""HTTPDatasetSource"":
        """"""
        :param raw_source: The raw source, e.g. a string like ""http://mysite/mydata.tar.gz"".
        """"""
        return HTTPDatasetSource(raw_source)

    def _to_dict(self) -> Dict[Any, Any]:
        """"""
        :return: A JSON-compatible dictionary representation of the HTTPDatasetSource.
        """"""
        return {
            ""url"": self.url,
        }

    @classmethod
    def _from_dict(cls, source_dict: Dict[Any, Any]) -> ""HTTPDatasetSource"":
        """"""
        :param source_dict: A dictionary representation of the HTTPDatasetSource.
        """"""
        url = source_dict.get(""url"")
        if url is None:
            raise MlflowException(
                'Failed to parse HTTPDatasetSource. Missing expected key: ""url""',
                INVALID_PARAMETER_VALUE,
            )

        return cls(url=url)
",CWE-23,119.0,1
"import json
import os
from unittest import mock

import pandas as pd
import pytest

from mlflow.data.dataset_source_registry import get_dataset_source_from_json, resolve_dataset_source
from mlflow.data.http_dataset_source import HTTPDatasetSource
from mlflow.exceptions import MlflowException
from mlflow.utils.rest_utils import cloud_storage_http_request


def test_source_to_and_from_json():
    url = ""http://mywebsite.com/path/to/my/dataset.txt""
    source = HTTPDatasetSource(url)
    assert source.to_json() == json.dumps({""url"": url})

    reloaded_source = get_dataset_source_from_json(
        source.to_json(), source_type=source._get_source_type()
    )
    assert isinstance(reloaded_source, HTTPDatasetSource)
    assert type(source) == type(reloaded_source)
    assert source.url == reloaded_source.url == url


def test_http_dataset_source_is_registered_and_resolvable():
    source1 = resolve_dataset_source(
        ""http://mywebsite.com/path/to/my/dataset.txt"", candidate_sources=[HTTPDatasetSource]
    )
    assert isinstance(source1, HTTPDatasetSource)
    assert source1.url == ""http://mywebsite.com/path/to/my/dataset.txt""

    source2 = resolve_dataset_source(
        ""https://otherwebsite.net"", candidate_sources=[HTTPDatasetSource]
    )
    assert isinstance(source2, HTTPDatasetSource)
    assert source2.url == ""https://otherwebsite.net""

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""s3://mybucket"", candidate_sources=[HTTPDatasetSource])

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""otherscheme://mybucket"", candidate_sources=[HTTPDatasetSource])

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""htp://mybucket"", candidate_sources=[HTTPDatasetSource])


def test_source_load(tmp_path):
    source1 = HTTPDatasetSource(
        ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
    )

    loaded1 = source1.load()
    parsed1 = pd.read_csv(loaded1, sep="";"")
    # Verify that the expected data was downloaded by checking for an expected column and asserting
    # that several rows are present
    assert ""fixed acidity"" in parsed1.columns
    assert len(parsed1) > 10

    loaded2 = source1.load(dst_path=tmp_path)
    assert loaded2 == str(tmp_path / ""winequality-red.csv"")
    parsed2 = pd.read_csv(loaded2, sep="";"")
    # Verify that the expected data was downloaded by checking for an expected column and asserting
    # that several rows are present
    assert ""fixed acidity"" in parsed2.columns
    assert len(parsed1) > 10

    source2 = HTTPDatasetSource(
        ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv#foo?query=param""
    )
    loaded3 = source2.load(dst_path=tmp_path)
    assert loaded3 == str(tmp_path / ""winequality-red.csv"")
    parsed3 = pd.read_csv(loaded3, sep="";"")
    assert ""fixed acidity"" in parsed3.columns
    assert len(parsed1) > 10

    source3 = HTTPDatasetSource(""https://github.com/"")
    loaded4 = source3.load()
    assert os.path.exists(loaded4)
    assert os.path.basename(loaded4) == ""dataset_source""

    source4 = HTTPDatasetSource(""https://github.com"")
    loaded5 = source4.load()
    assert os.path.exists(loaded5)
    assert os.path.basename(loaded5) == ""dataset_source""

    def cloud_storage_http_request_with_fast_fail(*args, **kwargs):
        kwargs[""max_retries""] = 1
        kwargs[""timeout""] = 5
        return cloud_storage_http_request(*args, **kwargs)

    source5 = HTTPDatasetSource(""https://nonexistentwebsitebuiltbythemlflowteam112312.com"")
    with mock.patch(
        ""mlflow.data.http_dataset_source.cloud_storage_http_request"",
        side_effect=cloud_storage_http_request_with_fast_fail,
    ), pytest.raises(Exception, match=""Max retries exceeded with url""):
        source5.load()


@pytest.mark.parametrize(
    (""attachment_filename"", ""expected_filename""),
    [
        (""testfile.txt"", ""testfile.txt""),
        ('""testfile.txt""', ""testfile.txt""),
        (""'testfile.txt'"", ""testfile.txt""),
        (None, ""winequality-red.csv""),
    ],
)
def test_source_load_with_content_disposition_header(attachment_filename, expected_filename):
    def download_with_mock_content_disposition_headers(*args, **kwargs):
        response = cloud_storage_http_request(*args, **kwargs)
        if attachment_filename is not None:
            response.headers[""Content-Disposition""] = f""attachment; filename={attachment_filename}""
        else:
            response.headers[""Content-Disposition""] = ""attachment""
        return response

    with mock.patch(
        ""mlflow.data.http_dataset_source.cloud_storage_http_request"",
        side_effect=download_with_mock_content_disposition_headers,
    ):
        source = HTTPDatasetSource(
            ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
        )
        source.load()
        loaded = source.load()
        assert os.path.exists(loaded)
        assert os.path.basename(loaded) == expected_filename
",CWE-23,131.0,1
"import os
import posixpath
import re
from typing import Any, Dict
from urllib.parse import urlparse

from mlflow.data.dataset_source import DatasetSource
from mlflow.exceptions import MlflowException
from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE
from mlflow.utils.file_utils import create_tmp_dir
from mlflow.utils.rest_utils import augmented_raise_for_status, cloud_storage_http_request


def _is_path(filename: str) -> bool:
    """"""
    Return True if `filename` is a path, False otherwise. For example,
    ""foo/bar"" is a path, but ""bar"" is not.
    """"""
    return os.path.basename(filename) != filename


class HTTPDatasetSource(DatasetSource):
    """"""
    Represents the source of a dataset stored at a web location and referred to
    by an HTTP or HTTPS URL.
    """"""

    def __init__(self, url):
        self._url = url

    @property
    def url(self):
        """"""
        The HTTP/S URL referring to the dataset source location.

        :return: The HTTP/S URL referring to the dataset source location.
        """"""
        return self._url

    @staticmethod
    def _get_source_type() -> str:
        return ""http""

    def load(self, dst_path=None) -> str:
        """"""
        Downloads the dataset source to the local filesystem.

        :param dst_path: Path of the local filesystem destination directory to which to download the
                         dataset source. If the directory does not exist, it is created. If
                         unspecified, the dataset source is downloaded to a new uniquely-named
                         directory on the local filesystem.
        :return: The path to the downloaded dataset source on the local filesystem.
        """"""
        resp = cloud_storage_http_request(
            method=""GET"",
            url=self.url,
            stream=True,
        )
        augmented_raise_for_status(resp)

        path = urlparse(self.url).path
        content_disposition = resp.headers.get(""Content-Disposition"")
        if content_disposition is not None and (
            file_name := next(re.finditer(r""filename=(.+)"", content_disposition), None)
        ):
            # NB: If the filename is quoted, unquote it
            basename = file_name[1].strip(""'\"""")
            if _is_path(basename):
                raise MlflowException.invalid_parameter_value(
                    f""Invalid filename in Content-Disposition header: {basename}. ""
                    ""It must be a file name, not a path.""
                )
        elif path is not None and len(posixpath.basename(path)) > 0:
            basename = posixpath.basename(path)
        else:
            basename = ""dataset_source""

        if dst_path is None:
            dst_path = create_tmp_dir()

        dst_path = os.path.join(dst_path, basename)
        with open(dst_path, ""wb"") as f:
            chunk_size = 1024 * 1024  # 1 MB
            for chunk in resp.iter_content(chunk_size=chunk_size):
                f.write(chunk)

        return dst_path

    @staticmethod
    def _can_resolve(raw_source: Any) -> bool:
        """"""
        :param raw_source: The raw source, e.g. a string like ""http://mysite/mydata.tar.gz"".
        :return: True if this DatsetSource can resolve the raw source, False otherwise.
        """"""
        if not isinstance(raw_source, str):
            return False

        try:
            parsed_source = urlparse(str(raw_source))
            return parsed_source.scheme in [""http"", ""https""]
        except Exception:
            return False

    @classmethod
    def _resolve(cls, raw_source: Any) -> ""HTTPDatasetSource"":
        """"""
        :param raw_source: The raw source, e.g. a string like ""http://mysite/mydata.tar.gz"".
        """"""
        return HTTPDatasetSource(raw_source)

    def _to_dict(self) -> Dict[Any, Any]:
        """"""
        :return: A JSON-compatible dictionary representation of the HTTPDatasetSource.
        """"""
        return {
            ""url"": self.url,
        }

    @classmethod
    def _from_dict(cls, source_dict: Dict[Any, Any]) -> ""HTTPDatasetSource"":
        """"""
        :param source_dict: A dictionary representation of the HTTPDatasetSource.
        """"""
        url = source_dict.get(""url"")
        if url is None:
            raise MlflowException(
                'Failed to parse HTTPDatasetSource. Missing expected key: ""url""',
                INVALID_PARAMETER_VALUE,
            )

        return cls(url=url)
",CWE-22,132.0,1
"import json
import os
from unittest import mock

import pandas as pd
import pytest

from mlflow.data.dataset_source_registry import get_dataset_source_from_json, resolve_dataset_source
from mlflow.data.http_dataset_source import HTTPDatasetSource
from mlflow.exceptions import MlflowException
from mlflow.utils.rest_utils import cloud_storage_http_request


def test_source_to_and_from_json():
    url = ""http://mywebsite.com/path/to/my/dataset.txt""
    source = HTTPDatasetSource(url)
    assert source.to_json() == json.dumps({""url"": url})

    reloaded_source = get_dataset_source_from_json(
        source.to_json(), source_type=source._get_source_type()
    )
    assert isinstance(reloaded_source, HTTPDatasetSource)
    assert type(source) == type(reloaded_source)
    assert source.url == reloaded_source.url == url


def test_http_dataset_source_is_registered_and_resolvable():
    source1 = resolve_dataset_source(
        ""http://mywebsite.com/path/to/my/dataset.txt"", candidate_sources=[HTTPDatasetSource]
    )
    assert isinstance(source1, HTTPDatasetSource)
    assert source1.url == ""http://mywebsite.com/path/to/my/dataset.txt""

    source2 = resolve_dataset_source(
        ""https://otherwebsite.net"", candidate_sources=[HTTPDatasetSource]
    )
    assert isinstance(source2, HTTPDatasetSource)
    assert source2.url == ""https://otherwebsite.net""

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""s3://mybucket"", candidate_sources=[HTTPDatasetSource])

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""otherscheme://mybucket"", candidate_sources=[HTTPDatasetSource])

    with pytest.raises(MlflowException, match=""Could not find a source information resolver""):
        resolve_dataset_source(""htp://mybucket"", candidate_sources=[HTTPDatasetSource])


def test_source_load(tmp_path):
    source1 = HTTPDatasetSource(
        ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
    )

    loaded1 = source1.load()
    parsed1 = pd.read_csv(loaded1, sep="";"")
    # Verify that the expected data was downloaded by checking for an expected column and asserting
    # that several rows are present
    assert ""fixed acidity"" in parsed1.columns
    assert len(parsed1) > 10

    loaded2 = source1.load(dst_path=tmp_path)
    assert loaded2 == str(tmp_path / ""winequality-red.csv"")
    parsed2 = pd.read_csv(loaded2, sep="";"")
    # Verify that the expected data was downloaded by checking for an expected column and asserting
    # that several rows are present
    assert ""fixed acidity"" in parsed2.columns
    assert len(parsed1) > 10

    source2 = HTTPDatasetSource(
        ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv#foo?query=param""
    )
    loaded3 = source2.load(dst_path=tmp_path)
    assert loaded3 == str(tmp_path / ""winequality-red.csv"")
    parsed3 = pd.read_csv(loaded3, sep="";"")
    assert ""fixed acidity"" in parsed3.columns
    assert len(parsed1) > 10

    source3 = HTTPDatasetSource(""https://github.com/"")
    loaded4 = source3.load()
    assert os.path.exists(loaded4)
    assert os.path.basename(loaded4) == ""dataset_source""

    source4 = HTTPDatasetSource(""https://github.com"")
    loaded5 = source4.load()
    assert os.path.exists(loaded5)
    assert os.path.basename(loaded5) == ""dataset_source""

    def cloud_storage_http_request_with_fast_fail(*args, **kwargs):
        kwargs[""max_retries""] = 1
        kwargs[""timeout""] = 5
        return cloud_storage_http_request(*args, **kwargs)

    source5 = HTTPDatasetSource(""https://nonexistentwebsitebuiltbythemlflowteam112312.com"")
    with mock.patch(
        ""mlflow.data.http_dataset_source.cloud_storage_http_request"",
        side_effect=cloud_storage_http_request_with_fast_fail,
    ), pytest.raises(Exception, match=""Max retries exceeded with url""):
        source5.load()


@pytest.mark.parametrize(
    (""attachment_filename"", ""expected_filename""),
    [
        (""testfile.txt"", ""testfile.txt""),
        ('""testfile.txt""', ""testfile.txt""),
        (""'testfile.txt'"", ""testfile.txt""),
        (None, ""winequality-red.csv""),
    ],
)
def test_source_load_with_content_disposition_header(attachment_filename, expected_filename):
    def download_with_mock_content_disposition_headers(*args, **kwargs):
        response = cloud_storage_http_request(*args, **kwargs)
        if attachment_filename is not None:
            response.headers[""Content-Disposition""] = f""attachment; filename={attachment_filename}""
        else:
            response.headers[""Content-Disposition""] = ""attachment""
        return response

    with mock.patch(
        ""mlflow.data.http_dataset_source.cloud_storage_http_request"",
        side_effect=download_with_mock_content_disposition_headers,
    ):
        source = HTTPDatasetSource(
            ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
        )
        source.load()
        loaded = source.load()
        assert os.path.exists(loaded)
        assert os.path.basename(loaded) == expected_filename


@pytest.mark.parametrize(
    ""filename"",
    [
        ""/foo/bar.txt"",
        ""./foo/bar.txt"",
        ""../foo/bar.txt"",
        ""foo/bar.txt"",
    ],
)
def test_source_load_with_content_disposition_header_invalid_filename(filename):
    def download_with_mock_content_disposition_headers(*args, **kwargs):
        response = cloud_storage_http_request(*args, **kwargs)
        response.headers[""Content-Disposition""] = f""attachment; filename={filename}""
        return response

    with mock.patch(
        ""mlflow.data.http_dataset_source.cloud_storage_http_request"",
        side_effect=download_with_mock_content_disposition_headers,
    ):
        source = HTTPDatasetSource(
            ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
        )

        with pytest.raises(MlflowException, match=""Invalid filename in Content-Disposition header""):
            source.load()
",CWE-22,158.0,1
"import ftplib
import os
import posixpath
import urllib.parse
from contextlib import contextmanager
from ftplib import FTP
from urllib.parse import unquote

from mlflow.entities.file_info import FileInfo
from mlflow.exceptions import MlflowException
from mlflow.store.artifact.artifact_repo import ArtifactRepository
from mlflow.utils.file_utils import relative_path_to_artifact_path


class FTPArtifactRepository(ArtifactRepository):
    """"""Stores artifacts as files in a remote directory, via ftp.""""""

    def __init__(self, artifact_uri):
        self.uri = artifact_uri
        parsed = urllib.parse.urlparse(artifact_uri)
        self.config = {
            ""host"": parsed.hostname,
            ""port"": 21 if parsed.port is None else parsed.port,
            ""username"": parsed.username,
            ""password"": parsed.password,
        }
        self.path = parsed.path or ""/""

        if self.config[""host""] is None:
            self.config[""host""] = ""localhost""
        if self.config[""password""] is None:
            self.config[""password""] = """"
        else:
            self.config[""password""] = unquote(parsed.password)

        super().__init__(artifact_uri)

    @contextmanager
    def get_ftp_client(self):
        ftp = FTP()
        ftp.connect(self.config[""host""], self.config[""port""])
        ftp.login(self.config[""username""], self.config[""password""])
        yield ftp
        ftp.close()

    @staticmethod
    def _is_dir(ftp, full_file_path):
        try:
            ftp.cwd(full_file_path)
            return True
        except ftplib.error_perm:
            return False

    @staticmethod
    def _mkdir(ftp, artifact_dir):
        try:
            if not FTPArtifactRepository._is_dir(ftp, artifact_dir):
                ftp.mkd(artifact_dir)
        except ftplib.error_perm:
            head, _ = posixpath.split(artifact_dir)
            FTPArtifactRepository._mkdir(ftp, head)
            FTPArtifactRepository._mkdir(ftp, artifact_dir)

    @staticmethod
    def _size(ftp, full_file_path):
        ftp.voidcmd(""TYPE I"")
        size = ftp.size(full_file_path)
        ftp.voidcmd(""TYPE A"")
        return size

    def log_artifact(self, local_file, artifact_path=None):
        with self.get_ftp_client() as ftp:
            artifact_dir = posixpath.join(self.path, artifact_path) if artifact_path else self.path
            self._mkdir(ftp, artifact_dir)
            with open(local_file, ""rb"") as f:
                ftp.cwd(artifact_dir)
                ftp.storbinary(""STOR "" + os.path.basename(local_file), f)

    def log_artifacts(self, local_dir, artifact_path=None):
        dest_path = posixpath.join(self.path, artifact_path) if artifact_path else self.path

        local_dir = os.path.abspath(local_dir)
        for root, _, filenames in os.walk(local_dir):
            upload_path = dest_path
            if root != local_dir:
                rel_path = os.path.relpath(root, local_dir)
                rel_upload_path = relative_path_to_artifact_path(rel_path)
                upload_path = posixpath.join(dest_path, rel_upload_path)
            if not filenames:
                with self.get_ftp_client() as ftp:
                    self._mkdir(ftp, upload_path)
            for f in filenames:
                if os.path.isfile(os.path.join(root, f)):
                    self.log_artifact(os.path.join(root, f), upload_path)

    def _is_directory(self, artifact_path):
        artifact_dir = self.path
        list_dir = posixpath.join(artifact_dir, artifact_path) if artifact_path else artifact_dir
        with self.get_ftp_client() as ftp:
            return self._is_dir(ftp, list_dir)

    def list_artifacts(self, path=None):
        with self.get_ftp_client() as ftp:
            artifact_dir = self.path
            list_dir = posixpath.join(artifact_dir, path) if path else artifact_dir
            if not self._is_dir(ftp, list_dir):
                return []
            artifact_files = ftp.nlst(list_dir)
            artifact_files = list(filter(lambda x: x != ""."" and x != "".."", artifact_files))
            # Make sure artifact_files is a list of file names because ftp.nlst
            # may return absolute paths.
            artifact_files = [os.path.basename(f) for f in artifact_files]
            infos = []
            for file_name in artifact_files:
                file_path = file_name if path is None else posixpath.join(path, file_name)
                full_file_path = posixpath.join(list_dir, file_name)
                if self._is_dir(ftp, full_file_path):
                    infos.append(FileInfo(file_path, True, None))
                else:
                    size = self._size(ftp, full_file_path)
                    infos.append(FileInfo(file_path, False, size))
        return infos

    def _download_file(self, remote_file_path, local_path):
        remote_full_path = (
            posixpath.join(self.path, remote_file_path) if remote_file_path else self.path
        )
        with self.get_ftp_client() as ftp:
            with open(local_path, ""wb"") as f:
                ftp.retrbinary(""RETR "" + remote_full_path, f.write)

    def delete_artifacts(self, artifact_path=None):
        raise MlflowException(""Not implemented yet"")
",CWE-29,134.0,1
"import subprocess
import sys
from unittest import mock

import pytest

from mlflow.utils import request_utils


def test_request_utils_does_not_import_mlflow(tmp_path):
    file_content = f""""""
import importlib.util
import os
import sys

file_path = r""{request_utils.__file__}""
module_name = ""mlflow.utils.request_utils""

spec = importlib.util.spec_from_file_location(module_name, file_path)
module = importlib.util.module_from_spec(spec)
sys.modules[module_name] = module
spec.loader.exec_module(module)

assert ""mlflow"" not in sys.modules
assert ""mlflow.utils.request_utils"" in sys.modules
""""""
    test_file = tmp_path.joinpath(""test_request_utils_does_not_import_mlflow.py"")
    test_file.write_text(file_content)

    subprocess.run([sys.executable, str(test_file)], check=True)


class IncompleteResponse:
    def __init__(self):
        self.headers = {""Content-Length"": ""100""}
        raw = mock.MagicMock()
        raw.tell.return_value = 50
        self.raw = raw

    def __enter__(self):
        return self

    def __exit__(self, *args):
        pass


def test_download_chunk_incomplete_read(tmp_path):
    with mock.patch.object(
        request_utils, ""cloud_storage_http_request"", return_value=IncompleteResponse()
    ):
        download_path = tmp_path / ""chunk""
        download_path.touch()
        with pytest.raises(IOError, match=""Incomplete read""):
            request_utils.download_chunk(
                range_start=0,
                range_end=999,
                headers={},
                download_path=download_path,
                http_uri=""https://example.com"",
            )
",CWE-918,61.0,1
"import sys

import pytest

from convert2rhel import redhatrelease, utils
from convert2rhel.logger import setup_logger_handler
from convert2rhel.systeminfo import system_info
from convert2rhel.toolopts import tool_opts


@pytest.fixture(scope=""session"")
def is_py26():
    return sys.version_info[:2] == (2, 6)


@pytest.fixture(scope=""session"")
def is_py2():
    return sys.version_info[:2] <= (2, 7)


@pytest.fixture()
def read_std(capsys, is_py2):
    """"""Multipython compatible, modified version of capsys.

    Example:
    >>> def test_example(read_std):
    >>>     import sys
    >>>     sys.stdout.write(""stdout"")
    >>>     sys.stderr.write(""stderr"")
    >>>     std_out, std_err = read_std()
    >>>     assert ""stdout"" in std_out
    >>>     assert ""stderr"" in std_err

    :returns: Callable[Tuple[str, str]] Factory that reads the stdouterr and
        returns captured stdout and stderr strings
    """"""

    def factory():
        stdouterr = capsys.readouterr()
        if is_py2:
            return stdouterr
        else:
            return stdouterr.out, stdouterr.err

    return factory


@pytest.fixture()
def pkg_root(is_py2):
    """"""Return the pathlib.Path of the convert2rhel package root.""""""
    if is_py2:
        import pathlib2 as pathlib  # pylint: disable=import-error
    else:
        import pathlib  # pylint: disable=import-error
    return pathlib.Path(__file__).parents[2]


@pytest.fixture(autouse=True)
def setup_logger(tmpdir):
    setup_logger_handler(log_name=""convert2rhel"", log_dir=str(tmpdir))


@pytest.fixture()
def pretend_os(request, pkg_root, monkeypatch):
    """"""Parametric fixture to pretend to be one of available OS for convertion.

    See https://docs.pytest.org/en/6.2.x/example/parametrize.html#indirect-parametrization
    for more information.

    Fixture parameters are:
        system_version - i.e. ""7.9.9""
        system_name - i.e. ""CentOS Linux""

    Examples:

    >>> # low level mode
    >>> @pytest.mark.parametrize(
    >>>     ""pretend_os"",
    >>>     (
    >>>         (""7.9.1111"", ""CentOS Linux""),
    >>>         (""7.9.1111"", ""Oracle Linux Server""),
    >>>         (""8.4.1111"", ""CentOS Linux""),
    >>>         (""8.4.1111"", ""Oracle Linux Server""),
    >>>     ),
    >>>     indirect=True,
    >>> )
    >>> def example_test(pretend_os):
    >>>     # Will run 4 tests for each of specified systems.
    >>>     pass


    >>> # using the shortcut
    >>> @all_systems
    >>> def example_test(pretend_os):
    >>>     # Will do the same.
    >>>     pass


    >>> @centos8
    >>> def example_test(pretend_os):
    >>>     # Will pretend CentOS 8.
    >>>     pass


    >>> @pytest.mark.parametrize(
    >>>     ""param"",
    >>>     (
    >>>         (""param_value1"",),
    >>>         (""param_value2"",),
    >>>     ),
    >>> )
    >>> @all_systems
    >>> def example_test(pretend_os):
    >>>     # Will run 8 tests.

    >>>     # for each of 4 systems it will run the test with each param value.
    >>>     pass

    """"""
    system_version, system_name = request.param
    system_version_major, system_version_minor, _ = system_version.split(""."")

    monkeypatch.setattr(
        utils,
        ""DATA_DIR"",
        value=str(pkg_root / (""convert2rhel/data/%s/x86_64/"" % system_version_major)),
    )
    monkeypatch.setattr(
        redhatrelease,
        ""get_system_release_filepath"",
        value=lambda: ""/etc/system-release"",
    )
    monkeypatch.setattr(
        utils,
        ""get_file_content"",
        value=lambda _: ""%s release %s"" % (system_name, system_version),
    )
    monkeypatch.setattr(
        system_info,
        ""_get_architecture"",
        value=lambda: ""x86_64"",
    )
    tool_opts.no_rpm_va = True
    system_info.resolve_system_info()


all_systems = pytest.mark.parametrize(
    ""pretend_os"",
    (
        (""7.9.1111"", ""CentOS Linux""),
        (""7.9.1111"", ""Oracle Linux Server""),
        (""8.4.1111"", ""CentOS Linux""),
        (""8.4.1111"", ""Oracle Linux Server""),
    ),
    indirect=True,
)
centos8 = pytest.mark.parametrize(
    ""pretend_os"",
    ((""8.4.1111"", ""CentOS Linux""),),
    indirect=True,
)
centos7 = pytest.mark.parametrize(
    ""pretend_os"",
    ((""7.9.1111"", ""CentOS Linux""),),
    indirect=True,
)
oracle8 = pytest.mark.parametrize(
    ""pretend_os"",
    ((""8.4.1111"", ""Oracle Linux Server""),),
    indirect=True,
)
oracle7 = pytest.mark.parametrize(
    ""pretend_os"",
    ((""7.9.1111"", ""Oracle Linux Server""),),
    indirect=True,
)
",CWE-359,177.0,1
,CWE-359,,1
"from envparse import env


def test_check_user_response_user_and_password(convert2rhel):
    # Run c2r registration with no username and password provided
    # check for user prompt enforcing input, then continue with registration
    with convert2rhel(
        ""-y --no-rpm-va --serverurl {}"".format(
            env.str(""RHSM_SERVER_URL""),
        )
    ) as c2r:
        c2r.expect_exact("" ... activation key not found, username and password required"")
        c2r.expect_exact(""Username"")
        c2r.sendline()
        # Assert the prompt loops and returns ""Username:""
        # when the input is empty, hence the '0' index.
        # In case the loop doesn't work, the prompt returns
        # ""Password"" and raises the assertion error.
        assert c2r.expect_exact([""Username"", ""Password""]) == 0
        # Provide username, expect password prompt
        c2r.sendline(env.str(""RHSM_USERNAME""))
        c2r.expect_exact(""Password: "")
        c2r.sendline()
        assert c2r.expect_exact([""Password"", ""Enter number of the chosen subscription""]) == 0
        # Provide password, expect successful registration and subscription prompt
        c2r.sendline(env.str(""RHSM_PASSWORD""))
        c2r.expect_exact(""Enter number of the chosen subscription: "")
        # Due to inconsistent behavior of Ctrl+c
        # the Ctrl+d is used to terminate the process instead
        c2r.sendcontrol(""d"")
    assert c2r.exitstatus != 0


def test_check_user_response_organization(convert2rhel):
    substitute_org = ""foo""
    # Run c2r registration with activation key provided
    # check for user prompt while organization left blank
    with convert2rhel(
        ""-y --no-rpm-va --serverurl {} -k {}"".format(
            env.str(""RHSM_SERVER_URL""),
            env.str(""RHSM_KEY""),
        )
    ) as c2r:
        c2r.expect_exact("" ... activation key detected: "")
        c2r.expect_exact(""Organization: "")
        c2r.sendline()
        assert c2r.expect_exact([""Organization"", ""Registering the system""]) == 0
        c2r.sendline(substitute_org)
        c2r.expect_exact(""Registering the system using subscription-manager ..."")
        # Due to inconsistent behavior of Ctrl+c
        # the Ctrl+d is used to terminate the process instead
        c2r.sendcontrol(""d"")
    assert c2r.exitstatus != 0


def test_auto_attach_pool_submgr(convert2rhel):
    single_pool_id = env.str(""RHSM_SINGLE_SUB_POOL"")
    with convert2rhel(
        ""-y --no-rpm-va --serverurl {} --username {} --password {} --debug"".format(
            env.str(""RHSM_SERVER_URL""),
            env.str(""RHSM_SINGLE_SUB_USERNAME""),
            env.str(""RHSM_SINGLE_SUB_PASSWORD""),
        )
    ) as c2r:
        c2r.expect(
            f""{single_pool_id} is the only subscription available, it will automatically be selected for the conversion.""
        )
        c2r.sendcontrol(""d"")

        assert c2r.exitstatus != 0
",CWE-359,71.0,1
"# -*- coding: utf-8 -*-

from django.shortcuts import render, redirect
from django.contrib import messages
from django.utils.translation import gettext as _
from django.contrib.auth import get_user_model

import spirit
import django
from spirit.category.models import Category
from spirit.comment.flag.models import CommentFlag
from spirit.comment.like.models import CommentLike
from spirit.comment.models import Comment
from spirit.topic.models import Topic
from spirit.core.utils.views import is_post, post_data
from spirit.core.utils.decorators import administrator_required
from .forms import BasicConfigForm

User = get_user_model()


@administrator_required
def config_basic(request):
    form = BasicConfigForm(data=post_data(request))
    if is_post(request) and form.is_valid():
        form.save()
        messages.info(request, _(""Settings updated!""))
        return redirect(request.GET.get(""next"", request.get_full_path()))
    return render(
        request=request,
        template_name='spirit/admin/config_basic.html',
        context={'form': form})


@administrator_required
def dashboard(request):
    # Strongly inaccurate counters below...
    context = {
        'version': spirit.__version__,
        'django_version': django.get_version(),
        'category_count': Category.objects.all().count() - 1,  # - private
        'topics_count': Topic.objects.all().count(),
        'comments_count': Comment.objects.all().count(),
        'users_count': User.objects.all().count(),
        'flags_count': CommentFlag.objects.filter(is_closed=False).count(),
        'likes_count': CommentLike.objects.all().count()
    }

    return render(request, 'spirit/admin/dashboard.html', context)
",CWE-601,50.0,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404

from ...core.utils.views import is_post, post_data
from ..models import Comment
from .forms import FlagForm


@login_required
def create(request, comment_id):
    comment = get_object_or_404(Comment, pk=comment_id)
    form = FlagForm(
        user=request.user,
        comment=comment,
        data=post_data(request))

    if is_post(request) and form.is_valid():
        form.save()
        return redirect(request.POST.get('next', comment.get_absolute_url()))

    return render(
        request=request,
        template_name='spirit/comment/flag/create.html',
        context={
            'form': form,
            'comment': comment})
",CWE-601,29.0,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.urls import reverse

from spirit.core.utils.views import is_post, post_data, is_ajax
from spirit.core.utils import json_response
from spirit.comment.models import Comment
from .models import CommentLike
from .forms import LikeForm


@login_required
def create(request, comment_id):
    comment = get_object_or_404(
        Comment.objects.exclude(user=request.user),
        pk=comment_id)
    form = LikeForm(
        user=request.user,
        comment=comment,
        data=post_data(request))

    if is_post(request) and form.is_valid():
        like = form.save()
        like.comment.increase_likes_count()

        if is_ajax(request):
            return json_response({'url_delete': like.get_delete_url()})

        return redirect(request.POST.get('next', comment.get_absolute_url()))

    return render(
        request=request,
        template_name='spirit/comment/like/create.html',
        context={
            'form': form,
            'comment': comment})


@login_required
def delete(request, pk):
    like = get_object_or_404(CommentLike, pk=pk, user=request.user)

    if is_post(request):
        like.delete()
        like.comment.decrease_likes_count()

        if is_ajax(request):
            url = reverse(
                'spirit:comment:like:create',
                kwargs={'comment_id': like.comment.pk})
            return json_response({'url_create': url, })

        return redirect(request.POST.get('next', like.comment.get_absolute_url()))

    return render(
        request=request,
        template_name='spirit/comment/like/delete.html',
        context={'like': like})
",CWE-601,61.0,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.views.decorators.http import require_POST
from django.contrib import messages
from django.contrib.auth.views import redirect_to_login
from django.utils import timezone
from django.core.exceptions import PermissionDenied

from djconfig import config

from ...core import utils
from ...core.utils.paginator import yt_paginate
from .models import CommentPoll, CommentPollChoice, CommentPollVote
from .forms import PollVoteManyForm


@login_required
@require_POST
def close_or_open(request, pk, close=True):
    # todo: moderators should be able to close it
    poll = get_object_or_404(
        CommentPoll,
        pk=pk,
        comment__user=request.user
    )

    if close:
        close_at = timezone.now()
    else:
        close_at = None

    (CommentPoll.objects
     .filter(pk=poll.pk)
     .update(close_at=close_at))

    return redirect(request.GET.get('next', poll.get_absolute_url()))


@require_POST
def vote(request, pk):
    # TODO: check if user has access to this topic/poll
    poll = get_object_or_404(
        CommentPoll.objects.unremoved(),
        pk=pk
    )

    if not request.user.is_authenticated:
        return redirect_to_login(next=poll.get_absolute_url())

    form = PollVoteManyForm(user=request.user, poll=poll, data=request.POST)

    if form.is_valid():
        CommentPollChoice.decrease_vote_count(poll=poll, voter=request.user)
        form.save_m2m()
        CommentPollChoice.increase_vote_count(poll=poll, voter=request.user)
        return redirect(request.POST.get('next', poll.get_absolute_url()))

    messages.error(request, utils.render_form_errors(form))
    return redirect(request.POST.get('next', poll.get_absolute_url()))


@login_required
def voters(request, pk):
    # TODO: check if user has access to this topic/poll
    choice = get_object_or_404(
        CommentPollChoice.objects
            .unremoved()
            .select_related('poll'),
        pk=pk
    )

    if not choice.poll.can_show_results:
        raise PermissionDenied

    choice_votes = (
        CommentPollVote.objects
        .unremoved()
        .for_choice(choice=choice)
        .select_related('voter__st'))

    choice_votes = yt_paginate(
        choice_votes,
        per_page=config.topics_per_page,
        page_number=request.GET.get('page', 1)
    )

    context = {
        'choice': choice,
        'votes': choice_votes
    }

    return render(request, 'spirit/comment/poll/voters.html', context)
",CWE-601,95.0,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.views.decorators.http import require_POST
from django.contrib import messages
from django.http import Http404

from djconfig import config

from spirit.core.utils.views import is_post, post_data, is_ajax
from spirit.core.utils.ratelimit.decorators import ratelimit
from spirit.core.utils.decorators import moderator_required
from spirit.core.utils import markdown, paginator, render_form_errors, json_response
from spirit.topic.models import Topic
from .models import Comment
from .forms import CommentForm, CommentMoveForm, CommentImageForm, CommentFileForm
from .utils import comment_posted, post_comment_update, pre_comment_update, post_comment_move


@login_required
@ratelimit(rate='1/10s')
def publish(request, topic_id, pk=None):
    initial = None
    if pk:  # todo: move to form
        comment = get_object_or_404(
            Comment.objects.for_access(user=request.user), pk=pk)
        quote = markdown.quotify(comment.comment, comment.user.st.nickname)
        initial = {'comment': quote}

    user = request.user
    topic = get_object_or_404(
        Topic.objects.opened().for_access(user),
        pk=topic_id)
    form = CommentForm(
        user=user,
        topic=topic,
        data=post_data(request),
        initial=initial)

    if is_post(request) and not request.is_limited() and form.is_valid():
        if not user.st.update_post_hash(form.get_comment_hash()):
            # Hashed comment may have not been saved yet
            return redirect(
                request.POST.get('next', None) or
                Comment
                .get_last_for_topic(topic_id)
                .get_absolute_url())

        comment = form.save()
        comment_posted(comment=comment, mentions=form.mentions)
        return redirect(request.POST.get('next', comment.get_absolute_url()))

    return render(
        request=request,
        template_name='spirit/comment/publish.html',
        context={
            'form': form,
            'topic': topic})


@login_required
def update(request, pk):
    comment = Comment.objects.for_update_or_404(pk, request.user)
    form = CommentForm(data=post_data(request), instance=comment)
    if is_post(request) and form.is_valid():
        pre_comment_update(comment=Comment.objects.get(pk=comment.pk))
        comment = form.save()
        post_comment_update(comment=comment)
        return redirect(request.POST.get('next', comment.get_absolute_url()))
    return render(
        request=request,
        template_name='spirit/comment/update.html',
        context={'form': form})


@moderator_required
def delete(request, pk, remove=True):
    comment = get_object_or_404(Comment, pk=pk)
    if is_post(request):
        (Comment.objects
         .filter(pk=pk)
         .update(is_removed=remove))
        return redirect(request.GET.get('next', comment.get_absolute_url()))
    return render(
        request=request,
        template_name='spirit/comment/moderate.html',
        context={'comment': comment})


@require_POST
@moderator_required
def move(request, topic_id):
    topic = get_object_or_404(Topic, pk=topic_id)
    form = CommentMoveForm(topic=topic, data=request.POST)

    if form.is_valid():
        comments = form.save()

        for comment in comments:
            comment_posted(comment=comment, mentions=None)
            topic.decrease_comment_count()
            post_comment_move(comment=comment, topic=topic)
    else:
        messages.error(request, render_form_errors(form))

    return redirect(request.POST.get('next', topic.get_absolute_url()))


def find(request, pk):
    comment = get_object_or_404(Comment.objects.select_related('topic'), pk=pk)
    comment_number = (
        Comment.objects
        .filter(topic=comment.topic, date__lte=comment.date)
        .count())
    url = paginator.get_url(
        comment.topic.get_absolute_url(),
        comment_number,
        config.comments_per_page,
        'page')
    return redirect(url)


@require_POST
@login_required
def image_upload_ajax(request):
    if not is_ajax(request):
        return Http404()

    form = CommentImageForm(
        user=request.user, data=request.POST, files=request.FILES)

    if form.is_valid():
        image = form.save()
        return json_response({'url': image.url})

    return json_response({'error': dict(form.errors.items())})


@require_POST
@login_required
def file_upload_ajax(request):
    if not is_ajax(request):
        return Http404()

    form = CommentFileForm(
        user=request.user, data=request.POST, files=request.FILES)

    if form.is_valid():
        file = form.save()
        return json_response({'url': file.url})

    return json_response({'error': dict(form.errors.items())})
",CWE-601,154.0,1
"# -*- coding: utf-8 -*-

from functools import wraps

from django.core.exceptions import PermissionDenied
from django.contrib.auth.views import redirect_to_login
from django.shortcuts import redirect

from spirit.core.conf import settings


def moderator_required(view_func):
    @wraps(view_func)
    def wrapper(request, *args, **kwargs):
        user = request.user

        if not user.is_authenticated:
            return redirect_to_login(next=request.get_full_path(),
                                     login_url=settings.LOGIN_URL)

        if not user.st.is_moderator:
            raise PermissionDenied

        return view_func(request, *args, **kwargs)

    return wrapper


def administrator_required(view_func):
    @wraps(view_func)
    def wrapper(request, *args, **kwargs):
        user = request.user

        if not user.is_authenticated:
            return redirect_to_login(next=request.get_full_path(),
                                     login_url=settings.LOGIN_URL)

        if not user.st.is_administrator:
            raise PermissionDenied

        return view_func(request, *args, **kwargs)

    return wrapper


def guest_only(view_func):
    # TODO: test!
    @wraps(view_func)
    def wrapper(request, *args, **kwargs):
        if request.user.is_authenticated:
            return redirect(request.GET.get('next', request.user.st.get_absolute_url()))

        return view_func(request, *args, **kwargs)

    return wrapper
",CWE-601,56.0,1
,CWE-601,,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import get_object_or_404
from django.shortcuts import redirect
from django.views.decorators.http import require_POST
from django.contrib import messages

from .models import TopicFavorite
from .forms import FavoriteForm
from ..models import Topic
from ...core import utils


@require_POST
@login_required
def create(request, topic_id):
    topic = get_object_or_404(Topic, pk=topic_id)
    form = FavoriteForm(user=request.user, topic=topic, data=request.POST)

    if form.is_valid():
        form.save()
    else:
        messages.error(request, utils.render_form_errors(form))

    return redirect(request.POST.get('next', topic.get_absolute_url()))


@require_POST
@login_required
def delete(request, pk):
    favorite = get_object_or_404(TopicFavorite, pk=pk, user=request.user)
    favorite.delete()
    return redirect(request.POST.get('next', favorite.topic.get_absolute_url()))
",CWE-601,35.0,1
"# -*- coding: utf-8 -*-

from django.utils import timezone
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib import messages
from django.utils.translation import gettext as _

from spirit.core.utils.views import is_post
from spirit.core.utils.decorators import moderator_required
from spirit.comment.models import Comment
from spirit.topic.models import Topic


@moderator_required
def _moderate(request, pk, field_name, to_value, action=None, message=None):
    topic = get_object_or_404(Topic, pk=pk)

    if is_post(request):
        count = (
            Topic.objects
            .filter(pk=pk)
            .exclude(**{field_name: to_value})
            .update(**{
                field_name: to_value,
                'reindex_at': timezone.now()}))

        if count and action is not None:
            Comment.create_moderation_action(
                user=request.user,
                topic=topic,
                action=action)

        if message is not None:
            messages.info(request, message)

        return redirect(request.POST.get(
            'next', topic.get_absolute_url()))

    return render(
        request=request,
        template_name='spirit/topic/moderate.html',
        context={'topic': topic})


def delete(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_removed',
        to_value=True,
        message=_(""The topic has been deleted""))


def undelete(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_removed',
        to_value=False,
        message=_(""The topic has been undeleted""))


def lock(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_closed',
        to_value=True,
        action=Comment.CLOSED,
        message=_(""The topic has been locked""))


def unlock(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_closed',
        to_value=False,
        action=Comment.UNCLOSED,
        message=_(""The topic has been unlocked""))


def pin(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_pinned',
        to_value=True,
        action=Comment.PINNED,
        message=_(""The topic has been pinned""))


def unpin(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_pinned',
        to_value=False,
        action=Comment.UNPINNED,
        message=_(""The topic has been unpinned""))


def global_pin(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_globally_pinned',
        to_value=True,
        action=Comment.PINNED,
        message=_(""The topic has been globally pinned""))


def global_unpin(request, pk):
    return _moderate(
        request=request,
        pk=pk,
        field_name='is_globally_pinned',
        to_value=False,
        action=Comment.UNPINNED,
        message=_(""The topic has been globally unpinned""))
",CWE-601,121.0,1
"# -*- coding: utf-8 -*-

import json

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.views.decorators.http import require_POST
from django.http import Http404, HttpResponse
from django.contrib import messages
from django.utils.html import escape
from django.urls import reverse

from djconfig import config
from infinite_scroll_pagination.serializers import to_page_key

from spirit.core.conf import settings
from spirit.core import utils
from spirit.core.utils.paginator import yt_paginate
from spirit.core.utils.paginator.infinite_paginator import paginate
from spirit.core.utils.views import is_ajax
from spirit.topic.models import Topic
from .models import TopicNotification
from .forms import NotificationForm, NotificationCreationForm


@require_POST
@login_required
def create(request, topic_id):
    topic = get_object_or_404(
        Topic.objects.for_access(request.user),
        pk=topic_id)
    form = NotificationCreationForm(
        user=request.user,
        topic=topic,
        data=request.POST)

    if form.is_valid():
        form.save()
    else:
        messages.error(request, utils.render_form_errors(form))

    return redirect(request.POST.get('next', topic.get_absolute_url()))


@require_POST
@login_required
def update(request, pk):
    notification = get_object_or_404(TopicNotification, pk=pk, user=request.user)
    form = NotificationForm(data=request.POST, instance=notification)

    if form.is_valid():
        form.save()
    else:
        messages.error(request, utils.render_form_errors(form))

    return redirect(request.POST.get(
        'next', notification.topic.get_absolute_url()))


@login_required
def index_ajax(request):
    if not is_ajax(request):
        return Http404()

    notifications = (
        TopicNotification.objects
            .for_access(request.user)
            .order_by(""is_read"", ""-date"")
            .with_related_data())
    notifications = notifications[:settings.ST_NOTIFICATIONS_PER_PAGE]
    notifications = [
        {'user': escape(n.comment.user.st.nickname),
         'action': n.action,
         'title': escape(n.topic.title),
         'url': n.get_absolute_url(),
         'is_read': n.is_read}
        for n in notifications]

    return HttpResponse(
        json.dumps({'n': notifications}),
        content_type=""application/json"")


@login_required
def index_unread(request):
    notifications = (
        TopicNotification.objects
            .for_access(request.user)
            .filter(is_read=False)
            .with_related_data())
    page = paginate(
        request,
        query_set=notifications,
        lookup_field='date',
        page_var='p',
        per_page=settings.ST_NOTIFICATIONS_PER_PAGE)
    return render(
        request=request,
        template_name='spirit/topic/notification/index_unread.html',
        context={
            'page': page,
            'next_page': to_page_key(**page.next_page())})


@login_required
def index(request):
    notifications = yt_paginate(
        TopicNotification.objects
            .for_access(request.user)
            .with_related_data(),
        per_page=config.topics_per_page,
        page_number=request.GET.get('page', 1))

    return render(
        request=request,
        template_name='spirit/topic/notification/index.html',
        context={'notifications': notifications})


@require_POST
@login_required
def mark_all_as_read(request):
    (TopicNotification.objects
        .for_access(request.user)
        .filter(is_read=False)
        .update(is_read=True))
    return redirect(request.POST.get(
        'next', reverse('spirit:topic:notification:index')))
",CWE-601,129.0,1
"# -*- coding: utf-8 -*-

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.http import HttpResponsePermanentRedirect

from djconfig import config

from spirit.core.utils.views import is_post, post_data
from spirit.core.utils.paginator import paginate, yt_paginate
from spirit.core.utils.ratelimit.decorators import ratelimit
from spirit.category.models import Category
from spirit.comment.forms import CommentForm
from spirit.comment.utils import comment_posted
from spirit.comment.models import Comment
from .models import Topic
from .forms import TopicForm
from . import utils


@login_required
@ratelimit(rate='1/10s')
def publish(request, category_id=None):
    if category_id:
        get_object_or_404(
            Category.objects.visible(),
            pk=category_id)

    user = request.user
    form = TopicForm(
        user=user,
        data=post_data(request),
        initial={'category': category_id})
    cform = CommentForm(
        user=user,
        data=post_data(request))
    if (is_post(request) and
            all([form.is_valid(), cform.is_valid()]) and
            not request.is_limited()):
        if not user.st.update_post_hash(form.get_topic_hash()):
            return redirect(
                request.POST.get('next', None) or
                form.get_category().get_absolute_url())
        # wrap in transaction.atomic?
        topic = form.save()
        cform.topic = topic
        comment = cform.save()
        comment_posted(comment=comment, mentions=cform.mentions)
        return redirect(topic.get_absolute_url())
    return render(
        request=request,
        template_name='spirit/topic/publish.html',
        context={'form': form, 'cform': cform})


@login_required
def update(request, pk):
    topic = Topic.objects.for_update_or_404(pk, request.user)
    category_id = topic.category_id
    form = TopicForm(
        user=request.user,
        data=post_data(request),
        instance=topic)
    if is_post(request) and form.is_valid():
        topic = form.save()
        if topic.category_id != category_id:
            Comment.create_moderation_action(
                user=request.user, topic=topic, action=Comment.MOVED)
        return redirect(request.POST.get('next', topic.get_absolute_url()))
    return render(
        request=request,
        template_name='spirit/topic/update.html',
        context={'form': form})


def detail(request, pk, slug):
    topic = Topic.objects.get_public_or_404(pk, request.user)

    if topic.slug != slug:
        return HttpResponsePermanentRedirect(topic.get_absolute_url())

    utils.topic_viewed(request=request, topic=topic)

    comments = (
        Comment.objects
        .for_topic(topic=topic)
        .with_likes(user=request.user)
        .with_polls(user=request.user)
        .order_by('date'))

    comments = paginate(
        comments,
        per_page=config.comments_per_page,
        page_number=request.GET.get('page', 1))

    return render(
        request=request,
        template_name='spirit/topic/detail.html',
        context={
            'topic': topic,
            'comments': comments})


def index_active(request):
    categories = (
        Category.objects
        .visible()
        .parents()
        .ordered())

    topics = (
        Topic.objects
        .visible()
        .global_()
        .with_bookmarks(user=request.user)
        .order_by('-is_globally_pinned', '-last_active')
        .select_related('category'))

    topics = yt_paginate(
        topics,
        per_page=config.topics_per_page,
        page_number=request.GET.get('page', 1))

    return render(
        request=request,
        template_name='spirit/topic/active.html',
        context={
            'categories': categories,
            'topics': topics})
",CWE-601,130.0,1
"# -*- coding: utf-8 -*-

from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth import get_user_model
from django.contrib import messages
from django.utils.translation import gettext as _

from djconfig import config

from ...core.utils.views import is_post, post_data
from ...core.utils.paginator import yt_paginate
from ...core.utils.decorators import administrator_required
from .forms import UserForm, UserProfileForm

User = get_user_model()


@administrator_required
def edit(request, user_id):
    user = get_object_or_404(User, pk=user_id)
    uform = UserForm(data=post_data(request), instance=user)
    form = UserProfileForm(data=post_data(request), instance=user.st)
    if is_post(request) and all([uform.is_valid(), form.is_valid()]):
        uform.save()
        form.save()
        messages.info(request, _(""This profile has been updated!""))
        return redirect(request.GET.get(""next"", request.get_full_path()))
    return render(
        request=request,
        template_name='spirit/user/admin/edit.html',
        context={'form': form, 'uform': uform})


@administrator_required
def _index(request, queryset, template):
    users = yt_paginate(
        queryset.order_by('-date_joined', '-pk'),
        per_page=config.topics_per_page,
        page_number=request.GET.get('page', 1)
    )
    return render(request, template, context={'users': users})


def index(request):
    return _index(
        request,
        queryset=User.objects.all(),
        template='spirit/user/admin/index.html'
    )


def index_admins(request):
    return _index(
        request,
        queryset=User.objects.filter(st__is_administrator=True),
        template='spirit/user/admin/admins.html'
    )


def index_mods(request):
    return _index(
        request,
        queryset=User.objects.filter(st__is_moderator=True, st__is_administrator=False),
        template='spirit/user/admin/mods.html'
    )


def index_unactive(request):
    return _index(
        request,
        queryset=User.objects.filter(is_active=False),
        template='spirit/user/admin/unactive.html'
    )
",CWE-601,74.0,1
"# -*- coding: utf-8 -*-

from django.contrib import messages
from django.contrib.auth import views as django_views
from django.urls import reverse
from django.shortcuts import redirect, render, get_object_or_404
from django.utils.translation import gettext as _
from django.contrib.auth import get_user_model
from django.urls import reverse_lazy

from spirit.core.conf import settings
from spirit.core.utils.views import is_post, post_data
from spirit.core.utils.ratelimit.decorators import ratelimit
from spirit.user.utils.email import send_activation_email
from spirit.user.utils.tokens import UserActivationTokenGenerator
from .forms import (
    RegistrationForm,
    LoginForm,
    ResendActivationForm,
    CustomPasswordResetForm)

User = get_user_model()


# I wish django would not force its crappy CBV on me
class _CustomPasswordResetView(django_views.PasswordResetView):
    template_name = 'spirit/user/auth/password_reset_form.html'
    email_template_name = 'spirit/user/auth/password_reset_email.html'
    subject_template_name = 'spirit/user/auth/password_reset_subject.txt'
    success_url = reverse_lazy('spirit:user:auth:password-reset-done')
    form_class = CustomPasswordResetForm


class _CustomPasswordResetConfirmView(django_views.PasswordResetConfirmView):
    template_name = 'spirit/user/auth/password_reset_confirm.html'
    success_url = reverse_lazy('spirit:user:auth:password-reset-complete')


class _CustomPasswordResetCompleteView(django_views.PasswordResetCompleteView):
    template_name = 'spirit/user/auth/password_reset_complete.html'


class _CustomPasswordResetDoneView(django_views.PasswordResetDoneView):
    template_name = 'spirit/user/auth/password_reset_done.html'


class _CustomLoginView(django_views.LoginView):
    template_name = 'spirit/user/auth/login.html'


# Make views sane again
_login_view = _CustomLoginView.as_view()
_logout_view = django_views.LogoutView.as_view()
_password_reset_view = _CustomPasswordResetView.as_view()
custom_password_reset_confirm = _CustomPasswordResetConfirmView.as_view()
custom_password_reset_complete = _CustomPasswordResetCompleteView.as_view()
custom_password_reset_done = _CustomPasswordResetDoneView.as_view()


@ratelimit(field='username', rate='5/5m')
# TODO: @guest_only
def custom_login(request, **kwargs):
    # Currently, Django 1.5 login view does not redirect somewhere if the user is logged in
    if request.user.is_authenticated:
        return redirect(request.GET.get('next', request.user.st.get_absolute_url()))

    if request.method == ""POST"" and request.is_limited():
        return redirect(request.get_full_path())

    return _login_view(request, authentication_form=LoginForm, **kwargs)


# TODO: @login_required ?
def custom_logout(request, **kwargs):
    if not request.user.is_authenticated:
        return redirect(request.GET.get('next', reverse(settings.LOGIN_URL)))

    if request.method == 'POST':
        return _logout_view(request, **kwargs)

    return render(request, 'spirit/user/auth/logout.html')


@ratelimit(field='email', rate='5/5m')
def custom_password_reset(request, **kwargs):
    if request.method == ""POST"" and request.is_limited():
        return redirect(reverse(""spirit:user:auth:password-reset""))

    return _password_reset_view(request, **kwargs)


@ratelimit(rate='2/10s')
# TODO: @guest_only
def register(request, registration_form=RegistrationForm):
    if request.user.is_authenticated:
        return redirect(request.GET.get('next', reverse('spirit:user:update')))

    form = registration_form(data=post_data(request))
    if (is_post(request) and
            not request.is_limited() and
            form.is_valid()):
        user = form.save()
        send_activation_email(request, user)
        messages.info(
            request, _(
                ""We have sent you an email to %(email)s ""
                ""so you can activate your account!"") % {'email': form.get_email()})

        # TODO: email-less activation
        # if not settings.REGISTER_EMAIL_ACTIVATION_REQUIRED:
        # login(request, user)
        # return redirect(request.GET.get('next', reverse('spirit:user:update')))

        return redirect(reverse(settings.LOGIN_URL))
    return render(
        request=request,
        template_name='spirit/user/auth/register.html',
        context={'form': form})


def registration_activation(request, pk, token):
    user = get_object_or_404(User, pk=pk)
    activation = UserActivationTokenGenerator()

    if activation.is_valid(user, token):
        user.st.is_verified = True
        user.is_active = True
        user.save()
        messages.info(request, _(""Your account has been activated!""))

    return redirect(reverse(settings.LOGIN_URL))


@ratelimit(field='email', rate='5/5m')
# TODO: @guest_only
def resend_activation_email(request):
    if request.user.is_authenticated:
        return redirect(request.GET.get('next', reverse('spirit:user:update')))

    form = ResendActivationForm(data=post_data(request))
    if is_post(request):
        if not request.is_limited() and form.is_valid():
            user = form.get_user()
            send_activation_email(request, user)

        # TODO: show if is_valid only
        messages.info(
            request, _(
                ""If you don't receive an email, please make sure you've entered ""
                ""the address you registered with, and check your spam folder.""))
        return redirect(reverse(settings.LOGIN_URL))
    return render(
        request=request,
        template_name='spirit/user/auth/activation_resend.html',
        context={'form': form})
",CWE-601,156.0,1
"from enum import Enum


class PaymentError(Exception):
    def __init__(self, message, code=None):
        super(PaymentError, self).__init__(message, code)
        self.message = message
        self.code = code

    def __str__(self):
        return self.message


class GatewayError(IOError):
    pass


class CustomPaymentChoices:
    MANUAL = ""manual""

    CHOICES = [(MANUAL, ""Manual"")]


class OperationType(Enum):
    PROCESS_PAYMENT = ""process_payment""
    AUTH = ""authorize""
    CAPTURE = ""capture""
    VOID = ""void""
    REFUND = ""refund""
    CONFIRM = ""confirm""


class TransactionError(Enum):
    """"""Represents a transaction error.""""""

    INCORRECT_NUMBER = ""incorrect_number""
    INVALID_NUMBER = ""invalid_number""
    INCORRECT_CVV = ""incorrect_cvv""
    INVALID_CVV = ""invalid_cvv""
    INCORRECT_ZIP = ""incorrect_zip""
    INCORRECT_ADDRESS = ""incorrect_address""
    INVALID_EXPIRY_DATE = ""invalid_expiry_date""
    EXPIRED = ""expired""
    PROCESSING_ERROR = ""processing_error""
    DECLINED = ""declined""


class TransactionKind:
    """"""Represents the type of a transaction.

    The following transactions types are possible:
    - AUTH - an amount reserved against the customer's funding source. Money
    does not change hands until the authorization is captured.
    - VOID - a cancellation of a pending authorization or capture.
    - CAPTURE - a transfer of the money that was reserved during the
    authorization stage.
    - REFUND - full or partial return of captured funds to the customer.
    """"""

    AUTH = ""auth""
    CAPTURE = ""capture""
    VOID = ""void""
    PENDING = ""pending""
    REFUND = ""refund""
    REFUND_ONGOING = ""refund_ongoing""
    CONFIRM = ""confirm""
    # FIXME we could use another status like WAITING_FOR_AUTH for transactions
    # Which were authorized, but needs to be confirmed manually by staff
    # eg. Braintree with ""submit_for_settlement"" enabled
    CHOICES = [
        (AUTH, ""Authorization""),
        (PENDING, ""Pending""),
        (REFUND, ""Refund""),
        (REFUND_ONGOING, ""Refund in progress""),
        (CAPTURE, ""Capture""),
        (VOID, ""Void""),
        (CONFIRM, ""Confirm""),
    ]


class ChargeStatus:
    """"""Represents possible statuses of a payment.

    The following statuses are possible:
    - NOT_CHARGED - no funds were take off the customer founding source yet.
    - PARTIALLY_CHARGED - funds were taken off the customer's funding source,
    partly covering the payment amount.
    - FULLY_CHARGED - funds were taken off the customer founding source,
    partly or completely covering the payment amount.
    - PARTIALLY_REFUNDED - part of charged funds were returned to the customer.
    - FULLY_REFUNDED - all charged funds were returned to the customer.
    """"""

    NOT_CHARGED = ""not-charged""
    PENDING = ""pending""
    PARTIALLY_CHARGED = ""partially-charged""
    FULLY_CHARGED = ""fully-charged""
    PARTIALLY_REFUNDED = ""partially-refunded""
    FULLY_REFUNDED = ""fully-refunded""

    CHOICES = [
        (NOT_CHARGED, ""Not charged""),
        (PENDING, ""Pending""),
        (PARTIALLY_CHARGED, ""Partially charged""),
        (FULLY_CHARGED, ""Fully charged""),
        (PARTIALLY_REFUNDED, ""Partially refunded""),
        (FULLY_REFUNDED, ""Fully refunded""),
    ]
",CWE-203,109.0,1
"import logging
from decimal import Decimal
from typing import Any, Callable, Dict

import Adyen
from babel.numbers import get_currency_precision
from django.conf import settings
from django_countries.fields import Country

from ....checkout.models import Checkout
from ....core.prices import quantize_price
from ... import PaymentError
from ...interface import PaymentData

logger = logging.getLogger(__name__)


def get_price_amount(value: Decimal, currency: str):
    """"""Adyen doesn't use values with comma.

    Take the value, discover the precision of currency and multiply value by
    Decimal('10.0'), then change quantization to remove the comma.
    """"""
    value = quantize_price(value, currency=currency)
    precision = get_currency_precision(currency)
    number_places = Decimal(""10.0"") ** precision
    value_without_comma = value * number_places
    return str(value_without_comma.quantize(Decimal(""1"")))


def api_call(requst_data: Dict[str, Any], method: Callable) -> Adyen.Adyen:
    try:
        return method(requst_data)
    except (Adyen.AdyenError, ValueError, TypeError) as e:
        logger.error(f""Unable to process the payment: {e}"")
        raise PaymentError(""Unable to process the payment request."")


def request_data_for_payment(
    payment_information: ""PaymentData"", return_url, merchant_account, origin_url
) -> Dict[str, Any]:
    payment_data = payment_information.data or {}

    if not payment_data.pop(""is_valid"", True):
        raise PaymentError(""Payment data are not valid"")

    extra_request_params = {}
    if ""browserInfo"" in payment_data:
        extra_request_params[""browserInfo""] = payment_data[""browserInfo""]
    if ""billingAddress"" in payment_data:
        extra_request_params[""billingAddress""] = payment_data[""billingAddress""]
    if ""shopperIP"" in payment_data:
        extra_request_params[""shopperIP""] = payment_data[""shopperIP""]
    if (
        ""browserInfo"" in extra_request_params
        and ""billingAddress"" in extra_request_params
    ):
        # Replace this assigment. Add note that customer_ip_address has incorrect name
        # Add to dashboard config the flow to combine channel with url like:
        # web1:https://shop.com, web2:https://shop1.com
        extra_request_params[""origin""] = origin_url
    print(
        float(quantize_price(payment_information.amount, payment_information.currency))
    )
    request = {
        ""amount"": {
            ""value"": get_price_amount(
                payment_information.amount, payment_information.currency
            ),
            ""currency"": payment_information.currency,
        },
        ""reference"": payment_information.payment_id,
        ""paymentMethod"": payment_data[""paymentMethod""],
        ""returnUrl"": return_url,
        ""merchantAccount"": merchant_account,
        **extra_request_params,
    }
    return request


def request_data_for_gateway_config(
    checkout: ""Checkout"", merchant_account
) -> Dict[str, str]:
    address = checkout.billing_address or checkout.shipping_address

    # FIXME check how it works if we have None here
    country = address.country if address else None
    if country:
        country_code = country.code
    else:
        country_code = Country(settings.DEFAULT_COUNTRY).code
    channel = checkout.get_value_from_metadata(""channel"", ""web"")
    return {
        ""merchantAccount"": merchant_account,
        ""countryCode"": country_code,
        ""channel"": channel,
    }


def request_for_payment_refund(
    payment_information: ""PaymentData"", merchant_account, token
) -> Dict[str, Any]:
    return {
        ""merchantAccount"": merchant_account,
        ""modificationAmount"": {
            ""value"": get_price_amount(
                payment_information.amount, payment_information.currency
            ),
            ""currency"": payment_information.currency,
        },
        ""originalReference"": token,
        ""reference"": payment_information.payment_id,
    }
",CWE-203,114.0,1
"import re

from graphql.utils import schema_printer

from .utils import get_graphql_content


def test_multiple_interface_separator_in_schema(api_client):
    query = """"""
    query __ApolloGetServiceDefinition__ {
        _service {
            sdl
        }
    }
    """"""
    response = api_client.post_graphql(query)

    content = get_graphql_content(response)
    sdl = content[""data""][""_service""][""sdl""]
    comma_separated_interfaces = re.findall(""implements (\\w+,) (\\w+)"", sdl)
    ampersand_separated_interfaces = re.findall(""implements (\\w+) & (\\w+)"", sdl)
    assert not comma_separated_interfaces
    assert ampersand_separated_interfaces


def test_graphql_core_contains_patched_function():
    assert hasattr(schema_printer, ""_print_object"")
",CWE-209,28.0,1
"{
  ""name"": ""sqlpad"",
  ""version"": ""6.10.0"",
  ""description"": ""Web app. Write SQL and visualize the results. Supports Postgres, MySQL, SQL Server, Crate, Vertica, SAP HANA, and BigQuery."",
  ""license"": ""MIT"",
  ""engines"": {
    ""node"": "">=12""
  },
  ""keywords"": [
    ""sql"",
    ""mssql"",
    ""drill"",
    ""postgres"",
    ""postgresql"",
    ""mysql"",
    ""crate"",
    ""presto"",
    ""vertica"",
    ""sap"",
    ""hana"",
    ""bigquery"",
    ""bq""
  ],
  ""repository"": {
    ""type"": ""git"",
    ""url"": ""git://github.com/sqlpad/sqlpad""
  },
  ""bugs"": {
    ""url"": ""https://github.com/sqlpad/sqlpad/issues""
  },
  ""scripts"": {
    ""prepublishOnly"": ""cd .. && ./scripts/build.sh"",
    ""start"": ""node-dev server.js -- --config \""./config.dev.env\"" | pino-pretty"",
    ""test"": ""mocha test --timeout 20000 --recursive --exit --bail"",
    ""testmssql"": ""env SQLPAD_BACKEND_DB_URI='mssql://sa:SuperP4ssw0rd!@localhost:1433/dbname' npm run test"",
    ""testmysql"": ""env SQLPAD_BACKEND_DB_URI='mysql://root:root@localhost:23306/db2' npm run test"",
    ""testmariadb"": ""env SQLPAD_BACKEND_DB_URI='mariadb://root:password@localhost:13306/db?timezone=Etc%2FGMT0&autoJsonMap=false' npm run test"",
    ""testpostgres"": ""env SQLPAD_BACKEND_DB_URI='postgres://sqlpad:sqlpad@localhost:5432/sqlpad' npm run test"",
    ""fixlint"": ""eslint --fix \""**/*.js\"" && prettier --write ."",
    ""lint"": ""eslint \""**/*.js\"" && prettier --check .""
  },
  ""dependencies"": {
    ""@google-cloud/bigquery"": ""^5.11.0"",
    ""athena-express"": ""^7.1.4"",
    ""aws-sdk"": ""^2.1092.0"",
    ""bcryptjs"": ""^2.4.3"",
    ""body-parser"": ""^1.19.2"",
    ""cassandra-driver"": ""^4.6.3"",
    ""clickhouse"": ""^2.4.4"",
    ""compression"": ""^1.7.4"",
    ""connect-redis"": ""^6.1.1"",
    ""connect-session-sequelize"": ""^7.1.2"",
    ""cryptr"": ""^6.0.2"",
    ""detect-port"": ""^1.3.0"",
    ""dotenv"": ""^16.0.0"",
    ""express"": ""^4.17.3"",
    ""express-pino-logger"": ""^7.0.0"",
    ""express-session"": ""^1.17.2"",
    ""format-link-header"": ""^3.1.1"",
    ""hdb"": ""^0.19.0"",
    ""helmet"": ""^4.6.0"",
    ""jsonwebtoken"": ""^8.5.1"",
    ""ldapjs"": ""^2.3.2"",
    ""lodash"": ""^4.17.20"",
    ""lru-cache"": ""^7.4.4"",
    ""mariadb"": ""^2.5.6"",
    ""memorystore"": ""^1.6.7"",
    ""minimist"": ""^1.2.5"",
    ""mkdirp"": ""^1.0.4"",
    ""moment"": ""^2.29.1"",
    ""mssql"": ""^8.0.2"",
    ""mysql"": ""^2.18.1"",
    ""mysql2"": ""^2.3.3"",
    ""node-crate"": ""^2.0.6"",
    ""node-fetch"": ""^2.6.7"",
    ""node-xlsx"": ""^0.21.0"",
    ""openid-client"": ""^4.9.1"",
    ""papaparse"": ""^5.3.1"",
    ""passport"": ""^0.4.1"",
    ""passport-custom"": ""^1.1.1"",
    ""passport-google-oauth20"": ""^2.0.0"",
    ""passport-http"": ""^0.3.0"",
    ""passport-jwt"": ""^4.0.0"",
    ""passport-ldapauth"": ""^3.0.1"",
    ""passport-local"": ""^1.0.0"",
    ""passport-openidconnect"": ""0.0.2"",
    ""passport-saml"": ""^3.2.1"",
    ""pg"": ""^8.7.3"",
    ""pino"": ""^7.8.1"",
    ""prettier"": ""^2.5.1"",
    ""query-string"": ""^7.1.1"",
    ""redis"": ""^4.0.4"",
    ""request"": ""^2.88.2"",
    ""rimraf"": ""^3.0.2"",
    ""sanitize-filename"": ""^1.6.3"",
    ""sequelize"": ""^6.17.0"",
    ""serve-favicon"": ""^2.5.0"",
    ""session-file-store"": ""^1.5.0"",
    ""snowflake-sdk"": ""^1.6.7"",
    ""socksjs"": ""^0.5.0"",
    ""sql-formatter"": ""^2.3.3"",
    ""sql-limiter"": ""^2.6.0"",
    ""sqlite3"": ""npm:@vscode/sqlite3@^5.0.7"",
    ""umzug"": ""^2.3.0"",
    ""uuid"": ""^8.3.2"",
    ""vertica"": ""^0.5.5""
  },
  ""main"": ""./app.js"",
  ""bin"": {
    ""sqlpad"": ""server.js""
  },
  ""optionalDependencies"": {
    ""odbc"": ""^2.2.2""
  },
  ""devDependencies"": {
    ""aws-sdk-mock"": ""^5.6.2"",
    ""bytes"": ""^3.1.2"",
    ""eslint"": ""^8.11.0"",
    ""eslint-config-airbnb-base"": ""^15.0.0"",
    ""eslint-config-prettier"": ""^8.5.0"",
    ""eslint-plugin-import"": ""^2.25.4"",
    ""mocha"": ""^9.2.2"",
    ""ncp"": ""^2.0.0"",
    ""nise"": ""^5.1.1"",
    ""node-dev"": ""^7.2.0"",
    ""parse-link-header"": ""^2.0.0"",
    ""pino-pretty"": ""^7.5.3"",
    ""supertest"": ""^6.2.2"",
    ""traverse"": ""^0.6.6""
  }
}
",CWE-94,132.0,1
"/*
 *       .                             .o8                     oooo
 *    .o8                             ""888                     `888
 *  .o888oo oooo d8b oooo  oooo   .oooo888   .ooooo.   .oooo.o  888  oooo
 *    888   `888""""8P `888  `888  d88' `888  d88' `88b d88(  ""8  888 .8P'
 *    888    888      888   888  888   888  888ooo888 `""Y88b.   888888.
 *    888 .  888      888   888  888   888  888    .o o.  )88b  888 `88b.
 *    ""888"" d888b     `V88V""V8P' `Y8bod88P"" `Y8bod8P' 8""""888P' o888o o888o
 *  ========================================================================
 *  Author:     Chris Brame
 *  Updated:    2/14/19 12:07 AM
 *  Copyright (c) 2014-2019. All rights reserved.
 */

module.exports = function (middleware, router, controllers) {
  // Shorten Vars
  const apiv2Auth = middleware.apiv2
  const apiv2 = controllers.api.v2
  const isAdmin = middleware.isAdmin
  const isAgent = middleware.isAgent
  const isAgentOrAdmin = middleware.isAgentOrAdmin
  const canUser = middleware.canUser

  // Common
  router.post('/api/v2/login', controllers.api.v2.common.login)
  router.post('/api/v2/token', controllers.api.v2.common.token)

  // Accounts
  router.get('/api/v2/accounts', apiv2Auth, apiv2.accounts.get)
  router.post('/api/v2/accounts', apiv2Auth, apiv2.accounts.create)
  router.put('/api/v2/accounts/:username', apiv2Auth, apiv2.accounts.update)

  // Tickets
  router.get('/api/v2/tickets', apiv2Auth, apiv2.tickets.get)
  router.post('/api/v2/tickets', apiv2Auth, apiv2.tickets.create)
  router.post('/api/v2/tickets/transfer/:uid', apiv2Auth, isAdmin, apiv2.tickets.transferToThirdParty)
  router.get('/api/v2/tickets/:uid', apiv2Auth, apiv2.tickets.single)
  router.put('/api/v2/tickets/batch', apiv2Auth, apiv2.tickets.batchUpdate)
  router.put('/api/v2/tickets/:uid', apiv2Auth, apiv2.tickets.update)
  router.delete('/api/v2/tickets/:uid', apiv2Auth, apiv2.tickets.delete)
  router.delete('/api/v2/tickets/deleted/:id', apiv2Auth, isAdmin, apiv2.tickets.permDelete)

  // Groups
  router.get('/api/v2/groups', apiv2Auth, apiv2.groups.get)
  router.post('/api/v2/groups', apiv2Auth, apiv2.groups.create)
  router.put('/api/v2/groups/:id', apiv2Auth, apiv2.groups.update)
  router.delete('/api/v2/groups/:id', apiv2Auth, apiv2.groups.delete)

  // Teams
  router.get('/api/v2/teams', apiv2Auth, apiv2.teams.get)
  router.post('/api/v2/teams', apiv2Auth, apiv2.teams.create)
  router.put('/api/v2/teams/:id', apiv2Auth, apiv2.teams.update)
  router.delete('/api/v2/teams/:id', apiv2Auth, apiv2.teams.delete)

  // Departments
  router.get('/api/v2/departments', apiv2Auth, apiv2.departments.get)
  router.post('/api/v2/departments', apiv2Auth, apiv2.departments.create)
  router.put('/api/v2/departments/:id', apiv2Auth, apiv2.departments.update)
  router.delete('/api/v2/departments/:id', apiv2Auth, apiv2.departments.delete)

  // Notices
  router.get('/api/v2/notices', apiv2Auth, apiv2.notices.get)
  router.put('/api/v2/notices/:id', apiv2Auth, canUser('notices:update'), apiv2.notices.update)
  router.put('/api/v2/notices/:id/activate', apiv2Auth, canUser('notices:activate'), apiv2.notices.activate)
  router.get('/api/v2/notices/clear', apiv2Auth, canUser('notices:deactivate'), apiv2.notices.clear)
  router.delete('/api/v2/notices/:id', apiv2Auth, canUser('notices:delete'), apiv2.notices.delete)

  // ElasticSearch
  router.get('/api/v2/es/search', middleware.api, apiv2.elasticsearch.search)
  router.get('/api/v2/es/rebuild', apiv2Auth, isAdmin, apiv2.elasticsearch.rebuild)
  router.get('/api/v2/es/status', apiv2Auth, isAdmin, apiv2.elasticsearch.status)

  router.get('/api/v2/mailer/check', apiv2Auth, isAdmin, apiv2.mailer.check)
}
",CWE-269,75.0,1
,CWE-290,,1
,CWE-290,,1
"""""""Validators module.""""""
import re


def valid_regex(regex):
    """"""Check if string is a valid regular expression.""""""
    if regex is None:
        return True, None, None

    try:
        compiled_regex = re.compile(regex)
    except re.error as regex_err:
        err = ""Invalid regex: "" + regex_err.msg + "".""
        return False, None, err

    return True, compiled_regex, None


def valid_exclude_list(exclude_list):
    """"""Check if the list is composed of valid regex.""""""
    if not exclude_list:
        return True, None, None

    combined_regex = ""("" + "")|("".join(exclude_list) + "")""
    return valid_regex(combined_regex)


def valid_hex(value):
    """"""Check if the string is a valid hex number representation.""""""
    try:
        int(value, 16)
    except Exception:
        return False
    return True
",CWE-290,35.0,1
"import unittest

from keylime.common import validators


class TestValidRegex(unittest.TestCase):
    """"""Tests for valid_regex.""""""

    def test_none(self):
        """"""Check that None is a valid regex.""""""
        self.assertEqual(validators.valid_regex(None), (True, None, None))

    def test_valid(self):
        """"""Check a well formed regex.""""""
        value = validators.valid_regex(r""a.*"")
        self.assertTrue(value[0])
        self.assertEqual(value[1].pattern, r""a.*"")
        self.assertEqual(value[2], None)

    def test_invalid(self):
        """"""Check a not valid regex.""""""
        value = validators.valid_regex(r""a["")
        self.assertEqual(
            value, (False, None, ""Invalid regex: unterminated character set."")
        )


class TestValidExcludeList(unittest.TestCase):
    """"""Tests for valid_exclude_list.""""""

    def test_none(self):
        """"""Check that the empty list is valid.""""""
        self.assertEqual(validators.valid_exclude_list(None), (True, None, None))

    def test_single(self):
        """"""Check a single exclude list element.""""""
        value = validators.valid_exclude_list([r""a.*""])
        self.assertTrue(value[0])
        self.assertEqual(value[1].pattern, r""(a.*)"")
        self.assertEqual(value[2], None)

    def test_multi(self):
        """"""Check a multiple elements exclude list.""""""
        value = validators.valid_exclude_list([r""a.*"", r""b.*""])
        self.assertTrue(value[0])
        self.assertEqual(value[1].pattern, r""(a.*)|(b.*)"")
        self.assertEqual(value[2], None)

    def test_invalid(self):
        """"""Check an invalid exclude list.""""""
        value = validators.valid_exclude_list([r""a[""])
        self.assertEqual(
            value, (False, None, ""Invalid regex: unterminated character set."")
        )


class TestValidHex(unittest.TestCase):
    """"""Tests for valid_hex.""""""

    def test_none(self):
        """"""Check that None is not valid.""""""
        self.assertFalse(validators.valid_hex(None))

    def test_empty(self):
        """"""Check that the empty string is not valid.""""""
        self.assertFalse(validators.valid_hex(""""))

    def test_valid_lower(self):
        """"""Check a valid lower case hexadecimal number.""""""
        self.assertTrue(validators.valid_hex(""123abc""))

    def test_valid_upper(self):
        """"""Check a valid upper case hexadecimal number.""""""
        self.assertTrue(validators.valid_hex(""123ABC""))

    def test_invalid(self):
        """"""Check and invalid hexadecimal number.""""""
        self.assertFalse(validators.valid_hex(""123xyz""))


if __name__ == ""__main__"":
    unittest.main()
",CWE-290,83.0,1
"import sqlite3
import re
import timeit
import sys
import os

pathlist = os.path.realpath(__file__).split(os.path.sep)
RTXindex = pathlist.index(""RTX"")
sys.path.append(os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code']))
from RTXConfiguration import RTXConfiguration

RTXConfig = RTXConfiguration()
autocomplete_filepath = os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code', 'autocomplete'])


conn = None
cursor = None


def load():
    global conn
    global cursor
    database_name = f""{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}""
    conn = sqlite3.connect(database_name)
    cursor = conn.cursor()
    return True


def get_nodes_like(word,requested_limit):

    debug = False

    t0 = timeit.default_timer()
    requested_limit = int(requested_limit)

    values = []
    n_values = 0

    if len(word) < 2:
        return values

    floor = word[:-1]
    ceiling = floor + 'zz'

    #### Get a list of matching node names that begin with these letters
    if debug:
        print(f""INFO: Query 1"")
    #cursor.execute(""SELECT term FROM term WHERE term LIKE \""%s%%\"" ORDER BY length(term),term LIMIT %s"" % (word,1000))
    cursor.execute(f""SELECT term FROM terms WHERE term > \""{floor}\"" AND term < \""{ceiling}\"" AND term LIKE \""{word}%%\"" ORDER BY length(term),term LIMIT {requested_limit}"")
    rows = cursor.fetchall()
    values_dict = {}
    for row in rows:
        term = row[0]
        if term.upper() not in values_dict:
            if debug:
                print(f""    - {term}"")
            properties = { ""curie"": '??', ""name"": term, ""type"": '??' }
            values.append(properties)
            values_dict[term.upper()] = 1
            n_values += 1
            if n_values >= requested_limit:
                break
    t1 = timeit.default_timer()
    if debug:
        print(f""INFO: Query 1 in {t1-t0} sec"")

    #### If we haven't reached the limit yet, add a list of matching terms that contain this string
    if n_values < requested_limit:
        if debug:
            print(f""INFO: Query 2"")

        #### See if there is a cached entry already
        word_part = word
        found_fragment = None
        while len(word_part) > 2:
            cursor.execute(f""SELECT rowid, fragment FROM cached_fragments WHERE fragment == \""{word_part}\"""")
            rows = cursor.fetchall()
            if len(rows) > 0:
                fragment_id = rows[0][0]
                found_fragment = rows[0][1]
                break
            word_part = word_part[:-1]

        if found_fragment:
            if debug:
                print(f""Found matching fragment {found_fragment} as fragment_id {fragment_id}"")

            cursor.execute(f""SELECT term FROM cached_fragment_terms WHERE fragment_id = {fragment_id} AND term LIKE \""%%{word}%%\"""")
            rows = cursor.fetchall()

            for row in rows:
                term = row[0]
                if term.upper() not in values_dict:

                    if n_values < requested_limit:
                        if debug:
                            print(f""    - {term}"")
                        properties = { ""curie"": '??', ""name"": term, ""type"": '??' }
                        values.append(properties)
                        n_values += 1


        if found_fragment is None:

            #### Cache this fragment in the database
            cursor.execute(""INSERT INTO cached_fragments(fragment) VALUES(?)"", (word,))
            fragment_id = cursor.lastrowid
            if debug:
                print(f""fragment_id = {fragment_id}"")

            #### Execute an expensive LIKE query
            cursor.execute(""SELECT term FROM terms WHERE term LIKE \""%%%s%%\"" ORDER BY length(term),term LIMIT %s"" % (word,10000))
            rows = cursor.fetchall()

            for row in rows:
                term = row[0]
                if term.upper() not in values_dict:

                    if n_values < requested_limit:
                        if debug:
                            print(f""    - {term}"")
                        properties = { ""curie"": '??', ""name"": term, ""type"": '??' }
                        values.append(properties)
                        n_values += 1

                    values_dict[term.upper()] = 1
                    cursor.execute(""INSERT INTO cached_fragment_terms(fragment_id, term) VALUES(?,?)"", (fragment_id, term,))
            conn.commit()

        t2 = timeit.default_timer()
        if debug:
            print(f""INFO: Query 2 in {t2-t1} sec"")


    return(values)

",CWE-89,137.0,1
"import tornado.ioloop
import tornado.web
import os
#import sqlite3
import json
import sys
import rtxcomplete
import traceback

#class MainHandler(tornado.web.RequestHandler):
#    def get(self):
#        self.write(""Hello, world"")
#print __file__

root = os.path.dirname(os.path.abspath(__file__))
rtxcomplete.load()
#conn = sqlite3.connect('dict.db')
#conn.enable_load_extension(True)
#conn.load_extension(""./spellfix"")
#cursor = conn.cursor()

class autoSearch(tornado.web.RequestHandler):

    def get(self, arg,word=None):
        #print ""match auto""
        try:
            limit = self.get_argument(""limit"")
            word = self.get_argument(""word"")
            callback = self.get_argument(""callback"") #jsonp

            result = rtxcomplete.prefix(word,limit)

            result = callback+""(""+json.dumps(result)+"");"" #jsonp
            #result = json.dumps(result) #typeahead
            
            self.write(result)
            
        except:
            print(sys.exc_info()[:])
            traceback.print_tb(sys.exc_info()[-1])
            #print sys.exc_info()[2]
            self.write(""error"")

class fuzzySearch(tornado.web.RequestHandler):
    def get(self, arg,word=None):
        #print ""matched fuzzy""
        try:
            limit = self.get_argument(""limit"")
            word = self.get_argument(""word"")
            callback = self.get_argument(""callback"")
            #print word
            #cursor.execute(""SELECT word FROM spell WHERE word MATCH \"""" + word + ""\"" LIMIT "" + limit)
            #cursor.execute(""SELECT word FROM spell WHERE word MATCH \"""" + word + ""*\"" LIMIT "" + limit)
            result = rtxcomplete.fuzzy(word,limit);
            #rows = cursor.fetchall()
            #print type(rows)
            result = callback+""(""+json.dumps(result)+"");""
            #print arg, result
            #if (len(rows) > 0):
            self.write(result)
            #else:
            #self.write(callback+""(""+json.dumps([[""NO SUGGESTIONS""]])+"");"")
            #self.write(json.dumps(rows))
        except:
            print(sys.exc_info()[:])
            traceback.print_tb(sys.exc_info()[-1])
            #print sys.exc_info()[:]
            self.write(""error"")

class autofuzzySearch(tornado.web.RequestHandler):
    def get(self, arg,word=None):
        #print ""matched autofuzzy""
        try:
            limit = self.get_argument(""limit"")
            word = self.get_argument(""word"")
            callback = self.get_argument(""callback"")
            #print word
            #cursor.execute(""SELECT word FROM spell WHERE word MATCH \"""" + word + ""\"" LIMIT "" + limit)
            #cursor.execute(""SELECT word FROM spell WHERE word MATCH \"""" + word + ""*\"" LIMIT "" + limit)
            result = rtxcomplete.autofuzzy(word,limit);
            #rows = cursor.fetchall()
            #print type(rows)
            result = callback+""(""+json.dumps(result)+"");""
            #print arg, result
            #if (len(rows) > 0):
            self.write(result)
            #else:
            #self.write(callback+""(""+json.dumps([[""NO SUGGESTIONS""]])+"");"")
            #self.write(json.dumps(rows))
        except:
            print(sys.exc_info()[:])
            traceback.print_tb(sys.exc_info()[-1])
            #print sys.exc_info()[:]
            self.write(""error"")


class nodesLikeSearch(tornado.web.RequestHandler):
    def get(self, arg,word=None):
        #try:
        if 1 == 1:
            limit = self.get_argument(""limit"")
            word = self.get_argument(""word"")
            callback = self.get_argument(""callback"")
            result = rtxcomplete.get_nodes_like(word,limit);
            result = callback+""(""+json.dumps(result)+"");""
            self.write(result)
        #except:
        #    print(sys.exc_info()[:])
        #    traceback.print_tb(sys.exc_info()[-1])
        #    self.write(""error"")


class defineSearch(tornado.web.RequestHandler):
    def get(self, arg,word=None):
        print(""matched define search: not implemented"")
        self.write("""")
            
def make_https_app():
    return tornado.web.Application([
        #(r""/"", MainHandler),
        (r""/autofuzzy(.*)"", autofuzzySearch),
        (r""/auto(.*)"", autoSearch),
        (r""/fuzzy(.*)"", fuzzySearch),
        (r""/define(.*)"", defineSearch),
        (r""/nodeslike(.*)"", nodesLikeSearch),
        (r""/(.*)"", tornado.web.StaticFileHandler,
         {""path"": root, ""default_filename"": ""rtxcomplete.html""}),
    ],
        compress_response= True)

class redirect_handler(tornado.web.RequestHandler):
    def prepare(self):
        if self.request.protocol == 'http':
            if self.request.host == ""rtxcomplete.ixlab.org"":
                self.redirect('https://'+self.request.host, permanent=False)
                
    def get(self):
        self.write(""Looks like you're trying to access rtxcomplete at the wrong host name."")
        self.write(""<br>Please make sure the address is correct: 'rtxcomplete.ixlab.org'"")

def make_redirect_app():
    return tornado.web.Application([
        (r'/', redirect_handler)
    ])

if __name__ == ""__main__"":
    print(""root: "" + root)

    if True: #FW/EWD: clean this up later
        http_app = make_https_app()
        http_server = tornado.httpserver.HTTPServer(http_app)
        http_server.listen(4999)

    else:
        redirect_app = make_redirect_app()
        redirect_app.listen(80)

        https_app = make_https_app()
        https_server = tornado.httpserver.HTTPServer(https_app, ssl_options={
            ""certfile"": ""/etc/letsencrypt/live/rtxcomplete.ixlab.org/fullchain.pem"",
            ""keyfile"" : ""/etc/letsencrypt/live/rtxcomplete.ixlab.org/privkey.pem"",
            })
        https_server.listen(443)

    tornado.ioloop.IOLoop.current().start()
",CWE-79,166.0,1
"# -*- coding: utf-8 -*-
import logging

import requests
from flask import (
    Blueprint,
    Response,
    abort,
    copy_current_request_context,
    render_template,
    request,
    session,
)
from flask_login import current_user

from scout.server.extensions import store
from scout.server.utils import institute_and_case

from . import controllers
from .partial import send_file_partial

alignviewers_bp = Blueprint(
    ""alignviewers"",
    __name__,
    template_folder=""templates"",
    static_folder=""static"",
    static_url_path=""/alignviewers/static"",
)

LOG = logging.getLogger(__name__)


@alignviewers_bp.route(""/remote/cors/<path:remote_url>"", methods=[""OPTIONS"", ""GET""])
def remote_cors(remote_url):
    """"""Proxy a remote URL.
    Useful to e.g. eliminate CORS issues when the remote site does not
        communicate CORS headers well, as in cloud tracks on figshare for IGV.js.

    Based on code from answers to this thread:
        https://stackoverflow.com/questions/6656363/proxying-to-another-web-service-with-flask/
    """"""
    resp = requests.request(
        method=request.method,
        url=remote_url,
        headers={key: value for (key, value) in request.headers if key != ""Host""},
        data=request.get_data(),
        cookies=request.cookies,
        allow_redirects=True,
    )

    excluded_headers = [
        ""content-encoding"",
        ""content-length"",
        ""transfer-encoding"",
        ""connection"",
    ]
    headers = [
        (name, value)
        for (name, value) in resp.raw.headers.items()
        if name.lower() not in excluded_headers
    ]

    response = Response(resp.content, resp.status_code, headers)
    return response


@alignviewers_bp.route(""/remote/static"", methods=[""OPTIONS"", ""GET""])
def remote_static():
    """"""Stream *large* static files with special requirements.""""""
    file_path = request.args.get(""file"") or "".""

    # Check that user is logged in or that file extension is valid
    if current_user.is_authenticated is False or file_path not in session.get(""igv_tracks"", []):
        LOG.warning(f""{file_path} not in {session.get('igv_tracks', [])}"")
        return abort(403)

    range_header = request.headers.get(""Range"", None)
    if not range_header and (file_path.endswith("".bam"") or file_path.endswith("".cram"")):
        return abort(500)

    new_resp = send_file_partial(file_path)
    return new_resp


@alignviewers_bp.route(
    ""/<institute_id>/<case_name>/<variant_id>/igv-splice-junctions"", methods=[""GET""]
)
def sashimi_igv(institute_id, case_name, variant_id):
    """"""Visualize splice junctions on igv.js sashimi-like viewer for one or more individuals of a case.
    wiki: https://github.com/igvteam/igv.js/wiki/Splice-Junctions
    """"""
    _, case_obj = institute_and_case(
        store, institute_id, case_name
    )  # This function takes care of checking if user is authorized to see resource

    display_obj = controllers.make_sashimi_tracks(case_obj, variant_id)
    controllers.set_session_tracks(display_obj)

    response = Response(render_template(""alignviewers/igv_sashimi_viewer.html"", **display_obj))

    @response.call_on_close
    @copy_current_request_context
    def clear_session_tracks():
        session.pop(""igv_tracks"", None)  # clean up igv session tracks

    return response


@alignviewers_bp.route(""/<institute_id>/<case_name>/igv"", methods=[""GET""])  # from case page
@alignviewers_bp.route(
    ""/<institute_id>/<case_name>/<variant_id>/igv"", methods=[""GET""]
)  # from SNV and STR variant page
@alignviewers_bp.route(
    ""/<institute_id>/<case_name>/<variant_id>/<chrom>/<start>/<stop>/igv"", methods=[""GET""]
)  # from SV variant page, where you have to pass breakpoints coordinates
def igv(institute_id, case_name, variant_id=None, chrom=None, start=None, stop=None):
    """"""Visualize BAM alignments using igv.js (https://github.com/igvteam/igv.js)

    Args:
        institute_id(str): _id of an institute
        case_name(str): dislay_name of a case
        variant_id(str/None): variant _id or None
        chrom(str/None): requested chromosome [1-22], X, Y, [M-MT]
        start(int/None): start of the genomic interval to be displayed
        stop(int/None): stop of the genomic interval to be displayed

    Returns:
        a string, corresponging to the HTML rendering of the IGV alignments page
    """"""
    _, case_obj = institute_and_case(
        store, institute_id, case_name
    )  # This function takes care of checking if user is authorized to see resource

    display_obj = controllers.make_igv_tracks(case_obj, variant_id, chrom, start, stop)
    controllers.set_session_tracks(display_obj)

    response = Response(render_template(""alignviewers/igv_viewer.html"", **display_obj))

    @response.call_on_close
    @copy_current_request_context
    def clear_session_tracks():
        session.pop(""igv_tracks"", None)  # clean up igv session tracks

    return response
",CWE-918,145.0,1
"# -*- coding: utf-8 -*-
import requests
from flask import session, url_for

from scout.server.extensions import store


def test_remote_static_no_auth(app):
    """"""Test endpoint that serves alignment files as non-logged user""""""
    # GIVEN a running demo app
    with app.test_client() as client:
        # GIVEN that user is not logged in
        resp = client.get(
            url_for(
                ""alignviewers.remote_static"",
                file=""../demo/ACC5963A1_lanes_1234_star_sorted_sj_filtered_sorted.bed.gz"",
            )
        )
        # THEN endpoint should return forbidden (403)
        assert resp.status_code == 403


def test_test_remote_static_not_in_session(app):
    """"""Test endpoint that serves alignment files that are not saved in the session""""""

    # GIVEN a running demo app
    with app.test_client() as client:
        # GIVEN that user is logged in
        client.get(url_for(""auto_login""))
        # If requested file doesn't have a valid extension
        resp = client.get(
            url_for(
                ""alignviewers.remote_static"",
                file=""config.py"",
            )
        )
        # THEN endpoint should return forbidden (403)
        assert resp.status_code == 403


def test_remote_static(app):
    """"""Test endpoint that serves files as a logged user""""""
    # GIVEN a file on disk
    file = ""../demo/ACC5963A1_lanes_1234_star_sorted_sj_filtered_sorted.bed.gz""

    # GIVEN a running demo app
    with app.test_client() as client:
        # GIVEN that user is logged in
        client.get(url_for(""auto_login""))
        with client.session_transaction() as session:
            # GIVEN that resource file exists in user session
            session[""igv_tracks""] = [file]

        # THEN the resource should be available to the user
        resp = client.get(
            url_for(
                ""alignviewers.remote_static"",
                file=file,
            )
        )
        assert resp.status_code == 200


def test_remote_cors(app):
    """"""Test endpoint that serves as a proxy to the actual remote track on the cloud""""""
    cloud_track_url = ""http://google.com""

    # GIVEN an initialized app
    # GIVEN a valid user and institute
    with app.test_client() as client:
        # GIVEN that the user could be logged in
        resp = client.get(url_for(""auto_login""))
        assert resp.status_code == 200

        # WHEN the remote cors endpoint is invoked with an url
        resp = client.get(url_for(""alignviewers.remote_cors"", remote_url=cloud_track_url))
        # THEN it should return success response
        assert resp.status_code == 200


def test_igv_not_authorized(app, user_obj, case_obj, variant_obj):
    """"""Test view requests and produces igv alignments, when the user dosn't have access to the case""""""

    # GIVEN a user that is not an admin nor has access to demo case:
    store.user_collection.find_one_and_update(
        {""_id"": user_obj[""_id""]},
        {""$set"": {""roles"": [], ""institutes"": []}},
    )

    # GIVEN an initialized app
    with app.test_client() as client:

        # GIVEN that the user is logged in
        client.get(url_for(""auto_login""))

        # WHEN the igv endpoint is invoked with the right parameters
        resp = client.get(
            url_for(
                ""alignviewers.igv"",
                institute_id=case_obj[""owner""],
                case_name=case_obj[""display_name""],
                variant_id=variant_obj[""_id""],
            )
        )

        # THEN the response should be ""not authorized"" (403)
        assert resp.status_code == 403


def test_igv_authorized(app, user_obj, case_obj, variant_obj):
    """"""Test view requests and produces igv alignments, when the user has access to the case""""""

    # GIVEN an initialized app
    with app.test_client() as client:

        # GIVEN that the user is logged in
        client.get(url_for(""auto_login""))

        # WHEN the igv endpoint is invoked with the right parameters
        resp = client.get(
            url_for(
                ""alignviewers.igv"",
                institute_id=case_obj[""owner""],
                case_name=case_obj[""display_name""],
                variant_id=variant_obj[""_id""],
            )
        )

        # THEN the response should be a valid HTML page
        assert resp.status_code == 200
        # AND when the reponse is closed case IGV tracks should be removed from session
        resp.close()
        assert session.get(""igv_tracks"") is None
",CWE-918,134.0,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
"""""""Custom fields used in InvenTree.""""""

import sys
from decimal import Decimal

from django import forms
from django.core import validators
from django.db import models as models
from django.forms.fields import URLField as FormURLField
from django.utils.translation import gettext_lazy as _

from djmoney.forms.fields import MoneyField
from djmoney.models.fields import MoneyField as ModelMoneyField
from djmoney.models.validators import MinMoneyValidator

import InvenTree.helpers

from .validators import allowable_url_schemes


class InvenTreeURLFormField(FormURLField):
    """"""Custom URL form field with custom scheme validators.""""""

    default_validators = [validators.URLValidator(schemes=allowable_url_schemes())]


class InvenTreeURLField(models.URLField):
    """"""Custom URL field which has custom scheme validators.""""""

    default_validators = [validators.URLValidator(schemes=allowable_url_schemes())]

    def formfield(self, **kwargs):
        """"""Return a Field instance for this field.""""""
        return super().formfield(**{
            'form_class': InvenTreeURLFormField
        })


def money_kwargs():
    """"""Returns the database settings for MoneyFields.""""""
    from common.settings import currency_code_default, currency_code_mappings

    kwargs = {}
    kwargs['currency_choices'] = currency_code_mappings()
    kwargs['default_currency'] = currency_code_default()
    return kwargs


class InvenTreeModelMoneyField(ModelMoneyField):
    """"""Custom MoneyField for clean migrations while using dynamic currency settings.""""""

    def __init__(self, **kwargs):
        """"""Overwrite default values and validators.""""""
        # detect if creating migration
        if 'migrate' in sys.argv or 'makemigrations' in sys.argv:
            # remove currency information for a clean migration
            kwargs['default_currency'] = ''
            kwargs['currency_choices'] = []
        else:
            # set defaults
            kwargs.update(money_kwargs())

        # Set a minimum value validator
        validators = kwargs.get('validators', [])

        if len(validators) == 0:
            validators.append(
                MinMoneyValidator(0),
            )

        kwargs['validators'] = validators

        super().__init__(**kwargs)

    def formfield(self, **kwargs):
        """"""Override form class to use own function.""""""
        kwargs['form_class'] = InvenTreeMoneyField
        return super().formfield(**kwargs)


class InvenTreeMoneyField(MoneyField):
    """"""Custom MoneyField for clean migrations while using dynamic currency settings.""""""
    def __init__(self, *args, **kwargs):
        """"""Override initial values with the real info from database.""""""
        kwargs.update(money_kwargs())
        super().__init__(*args, **kwargs)


class DatePickerFormField(forms.DateField):
    """"""Custom date-picker field.""""""

    def __init__(self, **kwargs):
        """"""Set up custom values.""""""
        help_text = kwargs.get('help_text', _('Enter date'))
        label = kwargs.get('label', None)
        required = kwargs.get('required', False)
        initial = kwargs.get('initial', None)

        widget = forms.DateInput(
            attrs={
                'type': 'date',
            }
        )

        forms.DateField.__init__(
            self,
            required=required,
            initial=initial,
            help_text=help_text,
            widget=widget,
            label=label
        )


def round_decimal(value, places):
    """"""Round value to the specified number of places.""""""
    if value is not None:
        # see https://docs.python.org/2/library/decimal.html#decimal.Decimal.quantize for options
        return value.quantize(Decimal(10) ** -places)
    return value


class RoundingDecimalFormField(forms.DecimalField):
    """"""Custom FormField that automatically rounds inputs.""""""

    def to_python(self, value):
        """"""Convert value to python type.""""""
        value = super().to_python(value)
        value = round_decimal(value, self.decimal_places)
        return value

    def prepare_value(self, value):
        """"""Override the 'prepare_value' method, to remove trailing zeros when displaying.

        Why? It looks nice!
        """"""
        if type(value) == Decimal:
            return InvenTree.helpers.normalize(value)
        else:
            return value


class RoundingDecimalField(models.DecimalField):
    """"""Custom Field that automatically rounds inputs.""""""

    def to_python(self, value):
        """"""Convert value to python type.""""""
        value = super().to_python(value)
        return round_decimal(value, self.decimal_places)

    def formfield(self, **kwargs):
        """"""Return a Field instance for this field.""""""
        defaults = {
            'form_class': RoundingDecimalFormField
        }

        defaults.update(kwargs)

        return super().formfield(**kwargs)
",CWE-770,160.0,1
"""""""Top-level URL lookup for InvenTree application.

Passes URL lookup downstream to each app as required.
""""""

from django.conf import settings
from django.conf.urls.static import static
from django.contrib import admin
from django.urls import include, path, re_path
from django.views.generic.base import RedirectView

from rest_framework.documentation import include_docs_urls

from build.api import build_api_urls
from build.urls import build_urls
from common.api import common_api_urls, settings_api_urls
from common.urls import common_urls
from company.api import company_api_urls
from company.urls import (company_urls, manufacturer_part_urls,
                          supplier_part_urls)
from label.api import label_api_urls
from order.api import order_api_urls
from order.urls import order_urls
from part.api import bom_api_urls, part_api_urls
from part.urls import part_urls
from plugin.api import plugin_api_urls
from plugin.urls import get_plugin_urls
from report.api import report_api_urls
from stock.api import stock_api_urls
from stock.urls import stock_urls
from users.api import user_urls

from .api import InfoView, NotFoundView
from .views import (AboutView, AppearanceSelectView, CurrencyRefreshView,
                    CustomConnectionsView, CustomEmailView,
                    CustomPasswordResetFromKeyView,
                    CustomSessionDeleteOtherView, CustomSessionDeleteView,
                    DatabaseStatsView, DynamicJsView, EditUserView, IndexView,
                    NotificationsView, SearchView, SetPasswordView,
                    SettingsView, auth_request)

admin.site.site_header = ""InvenTree Admin""


apipatterns = [
    re_path(r'^settings/', include(settings_api_urls)),
    re_path(r'^part/', include(part_api_urls)),
    re_path(r'^bom/', include(bom_api_urls)),
    re_path(r'^company/', include(company_api_urls)),
    re_path(r'^stock/', include(stock_api_urls)),
    re_path(r'^build/', include(build_api_urls)),
    re_path(r'^order/', include(order_api_urls)),
    re_path(r'^label/', include(label_api_urls)),
    re_path(r'^report/', include(report_api_urls)),
    re_path(r'^user/', include(user_urls)),

    # Plugin endpoints
    path('', include(plugin_api_urls)),

    # Webhook enpoint
    path('', include(common_api_urls)),

    # InvenTree information endpoint
    path('', InfoView.as_view(), name='api-inventree-info'),

    # Unknown endpoint
    re_path(r'^.*$', NotFoundView.as_view(), name='api-404'),
]

settings_urls = [

    re_path(r'^i18n/?', include('django.conf.urls.i18n')),

    re_path(r'^appearance/?', AppearanceSelectView.as_view(), name='settings-appearance'),
    re_path(r'^currencies-refresh/', CurrencyRefreshView.as_view(), name='settings-currencies-refresh'),

    # Catch any other urls
    re_path(r'^.*$', SettingsView.as_view(template_name='InvenTree/settings/settings.html'), name='settings'),
]

notifications_urls = [

    # Catch any other urls
    re_path(r'^.*$', NotificationsView.as_view(), name='notifications'),
]

# These javascript files are served ""dynamically"" - i.e. rendered on demand
dynamic_javascript_urls = [
    re_path(r'^calendar.js', DynamicJsView.as_view(template_name='js/dynamic/calendar.js'), name='calendar.js'),
    re_path(r'^nav.js', DynamicJsView.as_view(template_name='js/dynamic/nav.js'), name='nav.js'),
    re_path(r'^settings.js', DynamicJsView.as_view(template_name='js/dynamic/settings.js'), name='settings.js'),
]

# These javascript files are pased through the Django translation layer
translated_javascript_urls = [
    re_path(r'^api.js', DynamicJsView.as_view(template_name='js/translated/api.js'), name='api.js'),
    re_path(r'^attachment.js', DynamicJsView.as_view(template_name='js/translated/attachment.js'), name='attachment.js'),
    re_path(r'^barcode.js', DynamicJsView.as_view(template_name='js/translated/barcode.js'), name='barcode.js'),
    re_path(r'^bom.js', DynamicJsView.as_view(template_name='js/translated/bom.js'), name='bom.js'),
    re_path(r'^build.js', DynamicJsView.as_view(template_name='js/translated/build.js'), name='build.js'),
    re_path(r'^company.js', DynamicJsView.as_view(template_name='js/translated/company.js'), name='company.js'),
    re_path(r'^filters.js', DynamicJsView.as_view(template_name='js/translated/filters.js'), name='filters.js'),
    re_path(r'^forms.js', DynamicJsView.as_view(template_name='js/translated/forms.js'), name='forms.js'),
    re_path(r'^helpers.js', DynamicJsView.as_view(template_name='js/translated/helpers.js'), name='helpers.js'),
    re_path(r'^label.js', DynamicJsView.as_view(template_name='js/translated/label.js'), name='label.js'),
    re_path(r'^model_renderers.js', DynamicJsView.as_view(template_name='js/translated/model_renderers.js'), name='model_renderers.js'),
    re_path(r'^modals.js', DynamicJsView.as_view(template_name='js/translated/modals.js'), name='modals.js'),
    re_path(r'^order.js', DynamicJsView.as_view(template_name='js/translated/order.js'), name='order.js'),
    re_path(r'^part.js', DynamicJsView.as_view(template_name='js/translated/part.js'), name='part.js'),
    re_path(r'^report.js', DynamicJsView.as_view(template_name='js/translated/report.js'), name='report.js'),
    re_path(r'^search.js', DynamicJsView.as_view(template_name='js/translated/search.js'), name='search.js'),
    re_path(r'^stock.js', DynamicJsView.as_view(template_name='js/translated/stock.js'), name='stock.js'),
    re_path(r'^plugin.js', DynamicJsView.as_view(template_name='js/translated/plugin.js'), name='plugin.js'),
    re_path(r'^tables.js', DynamicJsView.as_view(template_name='js/translated/tables.js'), name='tables.js'),
    re_path(r'^table_filters.js', DynamicJsView.as_view(template_name='js/translated/table_filters.js'), name='table_filters.js'),
    re_path(r'^notification.js', DynamicJsView.as_view(template_name='js/translated/notification.js'), name='notification.js'),
]

backendpatterns = [
    # ""Dynamic"" javascript files which are rendered using InvenTree templating.
    re_path(r'^js/dynamic/', include(dynamic_javascript_urls)),
    re_path(r'^js/i18n/', include(translated_javascript_urls)),

    re_path(r'^auth/', include('rest_framework.urls', namespace='rest_framework')),
    re_path(r'^auth/?', auth_request),

    re_path(r'^api/', include(apipatterns)),
    re_path(r'^api-doc/', include_docs_urls(title='InvenTree API')),

    # 3rd party endpoints
    re_path(r'^markdownx/', include('markdownx.urls')),
]

frontendpatterns = [

    # Apps
    re_path(r'^build/', include(build_urls)),
    re_path(r'^common/', include(common_urls)),
    re_path(r'^company/', include(company_urls)),
    re_path(r'^order/', include(order_urls)),
    re_path(r'^manufacturer-part/', include(manufacturer_part_urls)),
    re_path(r'^part/', include(part_urls)),
    re_path(r'^stock/', include(stock_urls)),
    re_path(r'^supplier-part/', include(supplier_part_urls)),

    re_path(r'^edit-user/', EditUserView.as_view(), name='edit-user'),
    re_path(r'^set-password/', SetPasswordView.as_view(), name='set-password'),

    re_path(r'^index/', IndexView.as_view(), name='index'),
    re_path(r'^notifications/', include(notifications_urls)),
    re_path(r'^search/', SearchView.as_view(), name='search'),
    re_path(r'^settings/', include(settings_urls)),
    re_path(r'^about/', AboutView.as_view(), name='about'),
    re_path(r'^stats/', DatabaseStatsView.as_view(), name='stats'),

    # admin sites
    re_path(f'^{settings.INVENTREE_ADMIN_URL}/error_log/', include('error_report.urls')),
    re_path(f'^{settings.INVENTREE_ADMIN_URL}/shell/', include('django_admin_shell.urls')),
    re_path(f'^{settings.INVENTREE_ADMIN_URL}/', admin.site.urls, name='inventree-admin'),

    # DB user sessions
    path('accounts/sessions/other/delete/', view=CustomSessionDeleteOtherView.as_view(), name='session_delete_other', ),
    re_path(r'^accounts/sessions/(?P<pk>\w+)/delete/$', view=CustomSessionDeleteView.as_view(), name='session_delete', ),

    # Single Sign On / allauth
    # overrides of urlpatterns
    re_path(r'^accounts/email/', CustomEmailView.as_view(), name='account_email'),
    re_path(r'^accounts/social/connections/', CustomConnectionsView.as_view(), name='socialaccount_connections'),
    re_path(r""^accounts/password/reset/key/(?P<uidb36>[0-9A-Za-z]+)-(?P<key>.+)/$"", CustomPasswordResetFromKeyView.as_view(), name=""account_reset_password_from_key""),
    re_path(r'^accounts/', include('allauth_2fa.urls')),    # MFA support
    re_path(r'^accounts/', include('allauth.urls')),        # included urlpatterns
]

# Append custom plugin URLs (if plugin support is enabled)
if settings.PLUGINS_ENABLED:
    frontendpatterns.append(get_plugin_urls())

urlpatterns = [
    re_path('', include(frontendpatterns)),
    re_path('', include(backendpatterns)),
]

# Server running in ""DEBUG"" mode?
if settings.DEBUG:
    # Static file access
    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)

    # Media file access
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)

    # Debug toolbar access (only allowed in DEBUG mode)
    if settings.DEBUG_TOOLBAR_ENABLED:
        import debug_toolbar
        urlpatterns = [
            path('__debug__/', include(debug_toolbar.urls)),
        ] + urlpatterns

# Send any unknown URLs to the parts page
urlpatterns += [re_path(r'^.*$', RedirectView.as_view(url='/index/', permanent=False), name='index')]
",CWE-770,200.0,1
"# Generated by Django 2.2.9 on 2020-02-01 12:47

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('build', '0007_auto_20191118_2321'),
    ]

    operations = [
        migrations.AlterField(
            model_name='build',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Extra build notes'),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 3.0.5 on 2020-04-25 12:43

import InvenTree.fields
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion
import markdownx.models
import mptt.fields


class Migration(migrations.Migration):

    dependencies = [
        ('part', '0035_auto_20200406_0045'),
        ('stock', '0031_auto_20200422_0209'),
        ('order', '0029_auto_20200423_1042'),
        ('build', '0013_auto_20200425_0507'),
    ]

    operations = [
        migrations.AlterField(
            model_name='build',
            name='batch',
            field=models.CharField(blank=True, help_text='Batch code for this build output', max_length=100, null=True, verbose_name='Batch Code'),
        ),
        migrations.AlterField(
            model_name='build',
            name='link',
            field=InvenTree.fields.InvenTreeURLField(blank=True, help_text='Link to external URL', verbose_name='External Link'),
        ),
        migrations.AlterField(
            model_name='build',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Extra build notes', verbose_name='Notes'),
        ),
        migrations.AlterField(
            model_name='build',
            name='parent',
            field=mptt.fields.TreeForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='children', to='build.Build', verbose_name='Parent Build'),
        ),
        migrations.AlterField(
            model_name='build',
            name='part',
            field=models.ForeignKey(help_text='Select part to build', limit_choices_to={'active': True, 'assembly': True, 'is_template': False, 'virtual': False}, on_delete=django.db.models.deletion.CASCADE, related_name='builds', to='part.Part', verbose_name='Part'),
        ),
        migrations.AlterField(
            model_name='build',
            name='quantity',
            field=models.PositiveIntegerField(default=1, help_text='Number of parts to build', validators=[django.core.validators.MinValueValidator(1)], verbose_name='Build Quantity'),
        ),
        migrations.AlterField(
            model_name='build',
            name='sales_order',
            field=models.ForeignKey(blank=True, help_text='SalesOrder to which this build is allocated', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='builds', to='order.SalesOrder', verbose_name='Sales Order Reference'),
        ),
        migrations.AlterField(
            model_name='build',
            name='status',
            field=models.PositiveIntegerField(choices=[(10, 'Pending'), (20, 'Allocated'), (30, 'Cancelled'), (40, 'Complete')], default=10, help_text='Build status code', validators=[django.core.validators.MinValueValidator(0)], verbose_name='Build Status'),
        ),
        migrations.AlterField(
            model_name='build',
            name='take_from',
            field=models.ForeignKey(blank=True, help_text='Select location to take stock from for this build (leave blank to take from any stock location)', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='sourcing_builds', to='stock.StockLocation', verbose_name='Source Location'),
        ),
        migrations.AlterField(
            model_name='build',
            name='title',
            field=models.CharField(help_text='Brief description of the build', max_length=100, verbose_name='Build Title'),
        ),
    ]
",CWE-770,72.0,1
,CWE-770,,1
"# Generated by Django 2.2.9 on 2020-02-01 12:31

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('company', '0009_auto_20191118_2323'),
    ]

    operations = [
        migrations.AlterField(
            model_name='company',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 3.0.7 on 2021-04-03 18:37

import InvenTree.fields
import company.models
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion
import markdownx.models
import stdimage.models


class Migration(migrations.Migration):

    dependencies = [
        ('company', '0031_auto_20210103_2215'),
    ]

    operations = [
        migrations.AlterField(
            model_name='company',
            name='image',
            field=stdimage.models.StdImageField(blank=True, null=True, upload_to=company.models.rename_company_image, verbose_name='Image'),
        ),
        migrations.AlterField(
            model_name='company',
            name='is_customer',
            field=models.BooleanField(default=False, help_text='Do you sell items to this company?', verbose_name='is customer'),
        ),
        migrations.AlterField(
            model_name='company',
            name='is_manufacturer',
            field=models.BooleanField(default=False, help_text='Does this company manufacture parts?', verbose_name='is manufacturer'),
        ),
        migrations.AlterField(
            model_name='company',
            name='is_supplier',
            field=models.BooleanField(default=True, help_text='Do you purchase items from this company?', verbose_name='is supplier'),
        ),
        migrations.AlterField(
            model_name='company',
            name='link',
            field=InvenTree.fields.InvenTreeURLField(blank=True, help_text='Link to external company information', verbose_name='Link'),
        ),
        migrations.AlterField(
            model_name='company',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, verbose_name='Notes'),
        ),
        migrations.AlterField(
            model_name='supplierpart',
            name='base_cost',
            field=models.DecimalField(decimal_places=3, default=0, help_text='Minimum charge (e.g. stocking fee)', max_digits=10, validators=[django.core.validators.MinValueValidator(0)], verbose_name='base cost'),
        ),
        migrations.AlterField(
            model_name='supplierpart',
            name='multiple',
            field=models.PositiveIntegerField(default=1, help_text='Order multiple', validators=[django.core.validators.MinValueValidator(1)], verbose_name='multiple'),
        ),
        migrations.AlterField(
            model_name='supplierpart',
            name='packaging',
            field=models.CharField(blank=True, help_text='Part packaging', max_length=50, null=True, verbose_name='Packaging'),
        ),
        migrations.AlterField(
            model_name='supplierpricebreak',
            name='part',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='pricebreaks', to='company.SupplierPart', verbose_name='Part'),
        ),
    ]
",CWE-770,70.0,1
,CWE-770,,1
"# Generated by Django 2.2.9 on 2020-02-01 23:46

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('order', '0014_auto_20191118_2328'),
    ]

    operations = [
        migrations.AlterField(
            model_name='purchaseorder',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Order notes'),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 3.0.5 on 2020-04-20 09:40

import InvenTree.fields
import InvenTree.models
from django.conf import settings
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('company', '0021_remove_supplierpart_manufacturer_name'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
        ('order', '0019_purchaseorder_supplier_reference'),
    ]

    operations = [
        migrations.CreateModel(
            name='SalesOrder',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('reference', models.CharField(help_text='Order reference', max_length=64, unique=True)),
                ('description', models.CharField(help_text='Order description', max_length=250)),
                ('link', models.URLField(blank=True, help_text='Link to external page')),
                ('creation_date', models.DateField(blank=True, null=True)),
                ('status', models.PositiveIntegerField(choices=[(10, 'Pending'), (20, 'Placed'), (30, 'Complete'), (40, 'Cancelled'), (50, 'Lost'), (60, 'Returned')], default=10, help_text='Order status')),
                ('issue_date', models.DateField(blank=True, null=True)),
                ('complete_date', models.DateField(blank=True, null=True)),
                ('notes', markdownx.models.MarkdownxField(blank=True, help_text='Order notes')),
                ('customer_reference', models.CharField(blank=True, help_text='Customer order reference code', max_length=64)),
                ('created_by', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='+', to=settings.AUTH_USER_MODEL)),
                ('customer', models.ForeignKey(help_text='Customer', limit_choices_to={True, 'is_supplier'}, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='sales_orders', to='company.Company')),
            ],
            options={
                'abstract': False,
            },
        ),
        migrations.AlterField(
            model_name='purchaseorder',
            name='supplier',
            field=models.ForeignKey(help_text='Supplier', limit_choices_to={'is_supplier': True}, on_delete=django.db.models.deletion.CASCADE, related_name='purchase_orders', to='company.Company'),
        ),
        migrations.AlterField(
            model_name='purchaseorder',
            name='supplier_reference',
            field=models.CharField(blank=True, help_text='Supplier order reference code', max_length=64),
        ),
        migrations.CreateModel(
            name='SalesOrderLineItem',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('quantity', InvenTree.fields.RoundingDecimalField(decimal_places=5, default=1, help_text='Item quantity', max_digits=15, validators=[django.core.validators.MinValueValidator(0)])),
                ('reference', models.CharField(blank=True, help_text='Line item reference', max_length=100)),
                ('notes', models.CharField(blank=True, help_text='Line item notes', max_length=500)),
                ('order', models.ForeignKey(help_text='Sales Order', on_delete=django.db.models.deletion.CASCADE, related_name='lines', to='order.SalesOrder')),
            ],
            options={
                'abstract': False,
            },
        ),
        migrations.CreateModel(
            name='SalesOrderAttachment',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('attachment', models.FileField(help_text='Select file to attach', upload_to=InvenTree.models.rename_attachment)),
                ('comment', models.CharField(help_text='File comment', max_length=100)),
                ('order', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='attachments', to='order.SalesOrder')),
            ],
            options={
                'abstract': False,
            },
        ),
    ]
",CWE-770,77.0,1
"# Generated by Django 3.2.5 on 2021-10-25 02:08

from django.conf import settings
from django.db import migrations, models
import django.db.models.deletion

import order.models

import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
        ('order', '0053_auto_20211128_0151'),
    ]

    operations = [
        migrations.CreateModel(
            name='SalesOrderShipment',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('shipment_date', models.DateField(blank=True, help_text='Date of shipment', null=True, verbose_name='Shipment Date')),
                ('reference', models.CharField(default='1', help_text='Shipment reference', max_length=100, verbose_name='Reference')),
                ('notes', markdownx.models.MarkdownxField(blank=True, help_text='Shipment notes', verbose_name='Notes')),
                ('checked_by', models.ForeignKey(blank=True, help_text='User who checked this shipment', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='+', to=settings.AUTH_USER_MODEL, verbose_name='Checked By')),
                ('order', models.ForeignKey(help_text='Sales Order', on_delete=django.db.models.deletion.CASCADE, related_name='shipments', to='order.salesorder', verbose_name='Order')),
            ],
        ),
    ]
",CWE-770,32.0,1
,CWE-770,,1
"# Generated by Django 2.2.9 on 2020-01-31 10:22

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('part', '0025_auto_20191118_2316'),
    ]

    operations = [
        migrations.AlterField(
            model_name='part',
            name='notes',
            field=markdownx.models.MarkdownxField(help_text='Part notes - supports Markdown formatting'),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 2.2.9 on 2020-02-23 09:01

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('part', '0028_auto_20200203_1007'),
    ]

    operations = [
        migrations.AlterField(
            model_name='part',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Part notes - supports Markdown formatting'),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 3.0.7 on 2020-09-02 14:04

import InvenTree.fields
import InvenTree.validators

import markdownx

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('part', '0047_auto_20200808_0715'),
    ]

    operations = [
        migrations.AlterField(
            model_name='part',
            name='IPN',
            field=models.CharField(blank=True, help_text='Internal Part Number', max_length=100, null=True, validators=[InvenTree.validators.validate_part_ipn]),
        ),
        migrations.AlterField(
            model_name='part',
            name='keywords',
            field=models.CharField(blank=True, help_text='Part keywords to improve visibility in search results', max_length=250, null=True),
        ),
        migrations.AlterField(
            model_name='part',
            name='link',
            field=InvenTree.fields.InvenTreeURLField(blank=True, help_text='Link to extenal URL', null=True),
        ),
        migrations.AlterField(
            model_name='part',
            name='revision',
            field=models.CharField(blank=True, help_text='Part revision or version number', max_length=100, null=True),
        ),
        migrations.AlterField(
            model_name='part',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Part notes - supports Markdown formatting', null=True),
        ),
        migrations.AlterField(
            model_name='part',
            name='units',
            field=models.CharField(blank=True, default='', help_text='Stock keeping units for this part', max_length=20, null=True),
        ),
    ]
",CWE-770,49.0,1
"# Generated by Django 3.0.7 on 2021-01-03 12:13

import InvenTree.fields
import InvenTree.validators
from django.db import migrations, models
import django.db.models.deletion
import markdownx.models
import mptt.fields
import part.settings


class Migration(migrations.Migration):

    dependencies = [
        ('stock', '0055_auto_20201117_1453'),
        ('part', '0060_merge_20201112_1722'),
    ]

    operations = [
        migrations.AlterField(
            model_name='part',
            name='IPN',
            field=models.CharField(blank=True, help_text='Internal Part Number', max_length=100, null=True, validators=[InvenTree.validators.validate_part_ipn], verbose_name='IPN'),
        ),
        migrations.AlterField(
            model_name='part',
            name='assembly',
            field=models.BooleanField(default=part.settings.part_assembly_default, help_text='Can this part be built from other parts?', verbose_name='Assembly'),
        ),
        migrations.AlterField(
            model_name='part',
            name='category',
            field=mptt.fields.TreeForeignKey(blank=True, help_text='Part category', null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='parts', to='part.PartCategory', verbose_name='Category'),
        ),
        migrations.AlterField(
            model_name='part',
            name='default_location',
            field=mptt.fields.TreeForeignKey(blank=True, help_text='Where is this item normally stored?', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='default_parts', to='stock.StockLocation', verbose_name='Default Location'),
        ),
        migrations.AlterField(
            model_name='part',
            name='description',
            field=models.CharField(help_text='Part description', max_length=250, verbose_name='Description'),
        ),
        migrations.AlterField(
            model_name='part',
            name='is_template',
            field=models.BooleanField(default=part.settings.part_template_default, help_text='Is this part a template part?', verbose_name='Is Template'),
        ),
        migrations.AlterField(
            model_name='part',
            name='keywords',
            field=models.CharField(blank=True, help_text='Part keywords to improve visibility in search results', max_length=250, null=True, verbose_name='Keywords'),
        ),
        migrations.AlterField(
            model_name='part',
            name='link',
            field=InvenTree.fields.InvenTreeURLField(blank=True, help_text='Link to external URL', null=True, verbose_name='Link'),
        ),
        migrations.AlterField(
            model_name='part',
            name='name',
            field=models.CharField(help_text='Part name', max_length=100, validators=[InvenTree.validators.validate_part_name], verbose_name='Name'),
        ),
        migrations.AlterField(
            model_name='part',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Part notes - supports Markdown formatting', null=True, verbose_name='Notes'),
        ),
        migrations.AlterField(
            model_name='part',
            name='revision',
            field=models.CharField(blank=True, help_text='Part revision or version number', max_length=100, null=True, verbose_name='Revision'),
        ),
        migrations.AlterField(
            model_name='part',
            name='variant_of',
            field=models.ForeignKey(blank=True, help_text='Is this part a variant of another part?', limit_choices_to={'active': True, 'is_template': True}, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='variants', to='part.Part', verbose_name='Variant Of'),
        ),
        migrations.AlterField(
            model_name='part',
            name='virtual',
            field=models.BooleanField(default=part.settings.part_virtual_default, help_text='Is this a virtual part, such as a software product or license?', verbose_name='Virtual'),
        ),
    ]
",CWE-770,86.0,1
,CWE-770,,1
"# Generated by Django 2.2.9 on 2020-02-02 01:03

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('stock', '0017_auto_20191118_2311'),
    ]

    operations = [
        migrations.AlterField(
            model_name='stockitem',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Stock Item Notes'),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 2.2.9 on 2020-02-06 12:13

from django.db import migrations
import markdownx.models


class Migration(migrations.Migration):

    dependencies = [
        ('stock', '0019_auto_20200202_1024'),
    ]

    operations = [
        migrations.AlterField(
            model_name='stockitem',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Stock Item Notes', null=True),
        ),
    ]
",CWE-770,20.0,1
"# Generated by Django 3.0.5 on 2020-04-26 06:02

import InvenTree.fields
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion
import markdownx.models
import mptt.fields


class Migration(migrations.Migration):

    dependencies = [
        ('order', '0030_auto_20200426_0551'),
        ('build', '0016_auto_20200426_0551'),
        ('part', '0035_auto_20200406_0045'),
        ('company', '0021_remove_supplierpart_manufacturer_name'),
        ('stock', '0033_auto_20200426_0539'),
    ]

    operations = [
        migrations.RemoveField(
            model_name='stockitem',
            name='customer',
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='batch',
            field=models.CharField(blank=True, help_text='Batch code for this stock item', max_length=100, null=True, verbose_name='Batch Code'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='belongs_to',
            field=models.ForeignKey(blank=True, help_text='Is this item installed in another item?', null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='owned_parts', to='stock.StockItem', verbose_name='Installed In'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='build',
            field=models.ForeignKey(blank=True, help_text='Build for this stock item', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='build_outputs', to='build.Build', verbose_name='Source Build'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='build_order',
            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='stock_items', to='build.Build', verbose_name='Destination Build Order'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='link',
            field=InvenTree.fields.InvenTreeURLField(blank=True, help_text='Link to external URL', max_length=125, verbose_name='External Link'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='location',
            field=mptt.fields.TreeForeignKey(blank=True, help_text='Where is this stock item located?', null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='stock_items', to='stock.StockLocation', verbose_name='Stock Location'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='notes',
            field=markdownx.models.MarkdownxField(blank=True, help_text='Stock Item Notes', null=True, verbose_name='Notes'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='parent',
            field=mptt.fields.TreeForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='children', to='stock.StockItem', verbose_name='Parent Stock Item'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='part',
            field=models.ForeignKey(help_text='Base part', limit_choices_to={'active': True, 'is_template': False, 'virtual': False}, on_delete=django.db.models.deletion.CASCADE, related_name='stock_items', to='part.Part', verbose_name='Base Part'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='purchase_order',
            field=models.ForeignKey(blank=True, help_text='Purchase order for this stock item', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='stock_items', to='order.PurchaseOrder', verbose_name='Source Purchase Order'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='quantity',
            field=models.DecimalField(decimal_places=5, default=1, max_digits=15, validators=[django.core.validators.MinValueValidator(0)], verbose_name='Stock Quantity'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='sales_order',
            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='stock_items', to='order.SalesOrder', verbose_name='Destination Sales Order'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='serial',
            field=models.PositiveIntegerField(blank=True, help_text='Serial number for this item', null=True, verbose_name='Serial Number'),
        ),
        migrations.AlterField(
            model_name='stockitem',
            name='supplier_part',
            field=models.ForeignKey(blank=True, help_text='Select a matching supplier part for this stock item', null=True, on_delete=django.db.models.deletion.SET_NULL, to='company.SupplierPart', verbose_name='Supplier Part'),
        ),
    ]
",CWE-770,97.0,1
,CWE-770,,1
"# Please keep this list sorted
Django==3.2.13                          # Django package
bleach==4.1.0                           # HTML santization
certifi                                 # Certifi is (most likely) installed through one of the requirements above
coreapi==2.3.0                          # API documentation
coverage==5.3                           # Unit test coverage
coveralls==2.1.2                        # Coveralls linking (for Travis)
cryptography==3.4.8                     # Cryptography support
django-admin-shell==0.1.2               # Python shell for the admin interface
django-allauth==0.48.0                  # SSO for external providers via OpenID
django-allauth-2fa==0.9                 # MFA / 2FA
django-cleanup==5.1.0                   # Manage deletion of old / unused uploaded files
django-cors-headers==3.2.0              # CORS headers extension for DRF
django-crispy-forms==1.11.2             # Form helpers
django-debug-toolbar==3.2.4             # Debug / profiling toolbar
django-error-report==0.2.0              # Error report viewer for the admin interface
django-filter==2.4.0                    # Extended filtering options
django-formtools==2.3                   # Form wizard tools
django-import-export==2.5.0             # Data import / export for admin interface
django-maintenance-mode==0.16.1         # Shut down application while reloading etc.
django-markdownify==0.8.0               # Markdown rendering
django-markdownx==3.0.1                 # Markdown form fields
django-money==1.1                       # Django app for currency management
django-mptt==0.11.0                     # Modified Preorder Tree Traversal
django-redis>=5.0.0                     # Redis integration
django-q==1.3.4                         # Background task scheduling
django-sql-utils==0.5.0                 # Advanced query annotation / aggregation
django-sslserver==0.22                  # Secure HTTP development server
django-stdimage==5.1.1                  # Advanced ImageField management
django-test-migrations==1.1.0           # Unit testing for database migrations
django-user-sessions==1.7.1             # user sessions in DB
django-weasyprint==2.1.0                # django weasyprint integration
djangorestframework==3.12.4             # DRF framework
django-xforwardedfor-middleware==2.0    # IP forwarding metadata
flake8==3.8.3                           # PEP checking
flake8-docstrings==1.6.0                # docstring format testing
gunicorn>=20.1.0                        # Gunicorn web server
importlib_metadata                      # Backport for importlib.metadata
isort==5.10.1                           # DEV: python import sorting
markdown==3.3.4                         # Force particular version of markdown
pdf2image==1.16.0                       # PDF to image conversion
pep8-naming==0.11.1                     # PEP naming convention extension
pre-commit==2.19.0                      # Git pre-commit
pillow==9.1.1                           # Image manipulation
py-moneyed==0.8.0                       # Specific version requirement for py-moneyed
pygments==2.7.4                         # Syntax highlighting
python-barcode[images]==0.13.1          # Barcode generator
qrcode[pil]==6.1                        # QR code generator
rapidfuzz==0.7.6                        # Fuzzy string matching
sentry-sdk==1.5.12                      # Error reporting (optional)
tablib[xls,xlsx,yaml]                   # Support for XLS and XLSX formats
weasyprint==55.0                        # PDF generation library
",CWE-770,53.0,1
,CWE-79,,1
"{
  ""database_data"": {
    ""LocalNode"": {
      ""help"": ""Settings for PGSQL Database (data)"",
      ""node"": ""LocalNode"",
      ""user"": ""homer_user"",
      ""pass"": ""homer_password"",
      ""name"": ""homer_data"",
      ""keepalive"": true,
      ""host"": ""127.0.0.1""
    }
  },
  ""hep_relay"": {
    ""help"": ""UDP socket to send HEP data on"",
    ""host"": ""127.0.0.1"",
    ""port"": 9060
  },
  ""database_config"": {
    ""help"": ""Settings for PGSQL Database (settings)"",
    ""node"": ""LocalConfig"",
    ""user"": ""homer_user"",
    ""pass"": ""homer_password"",
    ""name"": ""homer_config"",
    ""keepalive"": true,
    ""host"": ""localhost""
  },
  ""influxdb_config"": {
    ""enable"": true,
    ""help"": ""Settings for InfluxDB Database (optional)"",
    ""user"": ""influx_user"",
    ""pass"": ""influx_password"",
    ""name"": ""homer_config"",
    ""host"": ""http://127.0.0.1:8086"",
    ""database"": ""homer"",
    ""policy"": ""autogen""
  },
  ""prometheus_config"": {
    ""enable"": true,
    ""help"": ""Settings for Prometheus Database (optional)"",
    ""user"": ""admin"",
    ""pass"": ""admin"",
    ""host"": ""http://127.0.0.1:9090"",
    ""api"": ""api/v1""
  },
  ""swagger"": {
    ""enable"": true,
    ""api_json"": ""/usr/local/homer/etc/swagger.json"",
    ""api_host"": ""127.0.0.1:9080""
  },
  ""loki_config"": {
    ""enable"": true,
    ""help"": ""Settings for LOKI Database (optional)"",
    ""user"": ""admin"",
    ""pass"": ""admin"",
    ""host"": ""http://127.0.0.1:3100"",
    ""api"": ""loki/api/v1"",
    ""param_query"": ""query_range""
  },
  ""grafana_config"": {
    ""enable"": true,
    ""help"": ""Settings for Grafana"",
    ""host"": ""http://127.0.0.1:3000"",
    ""path"": ""/grafana"",
    ""token"": """"
  },
  ""http_settings"": {
    ""help"": ""Settings for the HOMER Webapp Server. If you have gzip_static = false, please be sure that your dist directory has uncompressed .js files"",
    ""host"": ""0.0.0.0"",
    ""port"": 9080,
    ""root"": ""/usr/local/homer/dist"",
    ""gzip"": true,
    ""gzip_static"": true,
    ""debug"": false
  },
  ""transaction_settings"": {
    ""deduplicate"": {
        ""global"": false
    }
  },
  ""api_settings"": {
    ""add_captid_to_resolve"": false
  },
  ""https_settings"": {
    ""help"": ""SSL settings for homer-app"",
    ""enable"": false,
    ""host"": ""0.0.0.0"",
    ""port"": 443,
    ""cert"": ""/usr/local/homer/tls/cert.pem"",
    ""key"": ""/usr/local/homer/tls/key.pem""
  },
  ""system_settings"": {
    ""help"": ""Settings for HOMER logs"",
    ""logpath"": ""/usr/local/homer/log"",
    ""logname"": ""homer-app.log"",
    ""_loglevels"": ""can be: fatal, error, warn, info, debug, trace"",
    ""loglevel"": ""error"",
    ""logstdout"": false
  },
  ""dashboard_settings"": {
    ""_comment"": ""Here you can define a customs dashboards home"",
    ""dashboard_home"": ""/usr/local/homer/etc/dashboard_home.json""
  },
  ""auth_settings"": {
    ""_comment"": ""The type param can be internal, ldap, http_auth"",
    ""type"": ""internal"",
    ""gravatar"": false,
    ""gravatar_url"": ""https://www.gravatar.com/avatar/%s.jpg"",
    ""token_expire"": 1200,
    ""user_groups"": [""admin"", ""user"", ""support""]
  },
  ""ldap_config"": {
    ""base"": ""dc=example,dc=com"",
    ""host"": ""ldap.example.com"",
    ""port"": 389,
    ""usessl"": false,
    ""skiptls"": true,
    ""binddn"": ""uid=readonlysuer,ou=People,dc=example,dc=com"",
    ""bindpassword"": ""readonlypassword"",
    ""userfilter"": ""(uid=%s)"",
    ""groupfilter"": ""(memberUid=%s)"",
    ""group_attributes"": [
      ""cn"",
      ""memberOf"",
      ""GroupAttribute"",
      ""distinguishedName"",
      ""dn"",
      ""member""
    ],
    ""admingroup"": ""admin"",
    ""adminmode"": true,
    ""usergroup"": ""HOMER_user"",
    ""usermode"": true,
    ""attributes"": [""dn"", ""givenName"", ""sn"", ""mail"", ""uid""],
    ""skipverify"": true,
    ""anonymous"": false,
    ""userdn"": ""uid=%s,ou=People,dc=example,dc=com""
  },
  ""http_auth"": {
    ""url"": ""http://localhost:1323"",
    ""skipverify"": true
  },
  ""oauth2"": {
    ""enable"": false,
    ""client_id"": ""1234565"",
    ""client_secret"": ""FAKE"",
    ""project_id"": ""Homer OAuth"",
    ""auth_uri"": ""https://accounts.google.com/o/oauth2/auth"",
    ""token_uri"": ""https://oauth2.googleapis.com/token"",
    ""auth_provider_x509_cert_url"":  ""https://www.googleapis.com/oauth2/v1/certs"",
    ""redirect_uri"": ""http://localhost:80/api/v3/oauth2/auth"",
    ""service_redirect"": ""/api/v3/oauth2/redirect"",
    ""profile_url"": ""https://www.googleapis.com/oauth2/v1/userinfo"",
    ""provider_name"": ""google"",
    ""scope"": [""email"", ""openid"", ""profile""],
    ""gravatar"": false,
    ""gravatar_url"": ""https://www.gravatar.com/avatar/%s.jpg"",
    ""provider_image"": """"
  },
  ""decoder_shark"": {
    ""_comment"": ""Here you can do packet decoding using tshark application. Please define uid, gid if you run the app under root"",
    ""active"": false,
    ""bin"": ""/usr/bin/tshark"",
    ""protocols"": [""1_call"", ""1_registration"", ""1_default""]
  }
}
",CWE-798,166.0,1
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Frappe Technologies and contributors
# For license information, please see license.txt

from __future__ import unicode_literals
import frappe
from frappe.core.doctype.report.report import is_prepared_report_disabled
from frappe.model.document import Document

class RolePermissionforPageandReport(Document):
	def set_report_page_data(self):
		self.set_custom_roles()
		self.check_prepared_report_disabled()

	def set_custom_roles(self):
		args = self.get_args()
		self.set('roles', [])

		name = frappe.db.get_value('Custom Role', args, ""name"")
		if name:
			doc = frappe.get_doc('Custom Role', name)
			roles = doc.roles
		else:
			roles = self.get_standard_roles()

		self.set('roles', roles)

	def check_prepared_report_disabled(self):
		if self.report:
			self.disable_prepared_report = is_prepared_report_disabled(self.report)

	def get_standard_roles(self):
		doctype = self.set_role_for
		docname = self.page if self.set_role_for == 'Page' else self.report
		doc = frappe.get_doc(doctype, docname)
		return doc.roles

	def reset_roles(self):
		roles = self.get_standard_roles()
		self.set('roles', roles)
		self.update_custom_roles()
		self.update_disable_prepared_report()

	def update_report_page_data(self):
		self.update_custom_roles()
		self.update_disable_prepared_report()

	def update_custom_roles(self):
		args = self.get_args()
		name = frappe.db.get_value('Custom Role', args, ""name"")

		args.update({
			'doctype': 'Custom Role',
			'roles': self.get_roles()
		})

		if self.report:
			args.update({'ref_doctype': frappe.db.get_value('Report', self.report, 'ref_doctype')})

		if name:
			custom_role = frappe.get_doc(""Custom Role"", name)
			custom_role.set('roles', self.get_roles())
			custom_role.save()
		else:
			frappe.get_doc(args).insert()

	def update_disable_prepared_report(self):
		if self.report:
			# intentionally written update query in frappe.db.sql instead of frappe.db.set_value
			frappe.db.sql("""""" update `tabReport` set disable_prepared_report = %s
				where name = %s"""""", (self.disable_prepared_report, self.report))

	def get_args(self, row=None):
		name = self.page if self.set_role_for == 'Page' else self.report
		check_for_field = self.set_role_for.replace("" "",""_"").lower()

		return {
			check_for_field: name
		}

	def get_roles(self):
		roles = []
		for data in self.roles:
			if data.role != ""All"":
				roles.append({
					'role': data.role,
					'parenttype': 'Custom Role'
				})
		return roles

	def update_status(self):
		return frappe.render_template
",CWE-79,93.0,1
"# -*- coding: utf-8 -*-
# Copyright (c) 2015, Frappe Technologies and contributors
# For license information, please see license.txt

from __future__ import unicode_literals
import frappe
from frappe.model.document import Document

class PortalSettings(Document):
	def add_item(self, item):
		'''insert new portal menu item if route is not set, or role is different'''
		exists = [d for d in self.get('menu', []) if d.get('route')==item.get('route')]
		if exists and item.get('role'):
			if exists[0].role != item.get('role'):
				exists[0].role = item.get('role')
				return True
		elif not exists:
			item['enabled'] = 1
			self.append('menu', item)
			return True

	def reset(self):
		'''Restore defaults'''
		self.menu = []
		self.sync_menu()

	def sync_menu(self):
		'''Sync portal menu items'''
		dirty = False
		for item in frappe.get_hooks('standard_portal_menu_items'):
			if item.get('role') and not frappe.db.exists(""Role"", item.get('role')):
				frappe.get_doc({""doctype"": ""Role"", ""role_name"": item.get('role'), ""desk_access"": 0}).insert()
			if self.add_item(item):
				dirty = True

		if dirty:
			self.save()

	def on_update(self):
		self.clear_cache()

	def clear_cache(self):
		# make js and css
		# clear web cache (for menus!)
		frappe.clear_cache(user='Guest')

		from frappe.website.render import clear_cache
		clear_cache()

		# clears role based home pages
		frappe.clear_cache()

",CWE-79,53.0,1
"# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and contributors
# For license information, please see license.txt

from __future__ import unicode_literals
import frappe
from frappe import _
from frappe.model.document import Document
from frappe.utils import get_path
from os.path import join as join_path, exists as path_exists, abspath, splitext

class WebsiteTheme(Document):
	def validate(self):
		self.validate_if_customizable()
		self.generate_bootstrap_theme()

	def on_update(self):
		if (not self.custom
			and frappe.local.conf.get('developer_mode')
			and not (frappe.flags.in_import or frappe.flags.in_test)):

			self.export_doc()

		self.clear_cache_if_current_theme()

	def is_standard_and_not_valid_user(self):
		return (not self.custom
			and not frappe.local.conf.get('developer_mode')
			and not (frappe.flags.in_import or frappe.flags.in_test or frappe.flags.in_migrate))

	def on_trash(self):
		if self.is_standard_and_not_valid_user():
			frappe.throw(_(""You are not allowed to delete a standard Website Theme""),
				frappe.PermissionError)

	def validate_if_customizable(self):
		if self.is_standard_and_not_valid_user():
			frappe.throw(_(""Please Duplicate this Website Theme to customize.""))

	def export_doc(self):
		""""""Export to standard folder `[module]/website_theme/[name]/[name].json`.""""""
		from frappe.modules.export_file import export_to_files
		export_to_files(record_list=[['Website Theme', self.name]], create_init=True)


	def clear_cache_if_current_theme(self):
		if frappe.flags.in_install == 'frappe': return
		website_settings = frappe.get_doc(""Website Settings"", ""Website Settings"")
		if getattr(website_settings, ""website_theme"", None) == self.name:
			website_settings.clear_cache()

	def generate_bootstrap_theme(self):
		from subprocess import Popen, PIPE

		self.theme_scss = frappe.render_template('frappe/website/doctype/website_theme/website_theme_template.scss', self.as_dict())

		# create theme file in site public files folder
		folder_path = abspath(frappe.utils.get_files_path('website_theme', is_private=False))
		# create folder if not exist
		frappe.create_folder(folder_path)

		if self.custom:
			self.delete_old_theme_files(folder_path)

		# add a random suffix
		suffix = frappe.generate_hash('Website Theme', 8) if self.custom else 'style'
		file_name = frappe.scrub(self.name) + '_' + suffix + '.css'
		output_path = join_path(folder_path, file_name)

		self.theme_scss = content = get_scss(self)
		content = content.replace('\n', '\\n')
		command = ['node', 'generate_bootstrap_theme.js', output_path, content]

		process = Popen(command, cwd=frappe.get_app_path('frappe', '..'), stdout=PIPE, stderr=PIPE)

		stderr = process.communicate()[1]

		if stderr:
			stderr = frappe.safe_decode(stderr)
			stderr = stderr.replace('\n', '<br>')
			frappe.throw('<div style=""font-family: monospace;"">{stderr}</div>'.format(stderr=stderr))
		else:
			self.theme_url = '/files/website_theme/' + file_name

		frappe.msgprint(_('Compiled Successfully'), alert=True)

	def delete_old_theme_files(self, folder_path):
		import os
		for fname in os.listdir(folder_path):
			if fname.startswith(frappe.scrub(self.name) + '_') and fname.endswith('.css'):
				os.remove(os.path.join(folder_path, fname))

	def generate_theme_if_not_exist(self):
		bench_path = frappe.utils.get_bench_path()
		if self.theme_url:
			theme_path = join_path(bench_path, 'sites', self.theme_url[1:])
			if not path_exists(theme_path):
				self.generate_bootstrap_theme()
		else:
			self.generate_bootstrap_theme()

	def set_as_default(self):
		self.generate_bootstrap_theme()
		self.save()
		website_settings = frappe.get_doc('Website Settings')
		website_settings.website_theme = self.name
		website_settings.ignore_validate = True
		website_settings.save()

	def get_apps(self):
		from frappe.utils.change_log import get_versions
		apps = get_versions()
		out = []
		for app, values in apps.items():
			out.append({
				'name': app,
				'title': values['title']
			})
		return out


def add_website_theme(context):
	context.theme = frappe._dict()

	if not context.disable_website_theme:
		website_theme = get_active_theme()
		context.theme = website_theme or frappe._dict()

def get_active_theme():
	website_theme = frappe.db.get_single_value(""Website Settings"", ""website_theme"")
	if website_theme:
		try:
			return frappe.get_doc(""Website Theme"", website_theme)
		except frappe.DoesNotExistError:
			pass



def get_scss(website_theme):
	""""""
	Render `website_theme_template.scss` with the values defined in Website Theme.

	params:
	website_theme - instance of a Website Theme
	""""""
	apps_to_ignore = tuple((d.app + '/') for d in website_theme.ignored_apps)
	available_imports = get_scss_paths()
	imports_to_include = [d for d in available_imports if not d.startswith(apps_to_ignore)]
	context = website_theme.as_dict()
	context['website_theme_scss'] = imports_to_include
	return frappe.render_template('frappe/website/doctype/website_theme/website_theme_template.scss', context)


def get_scss_paths():
	""""""
	Return a set of SCSS import paths from all apps that provide `website.scss`.

	If `$BENCH_PATH/apps/frappe/frappe/public/scss/website.scss` exists, the
	returned set will contain 'frappe/public/scss/website'.
	""""""
	import_path_list = []
	bench_path = frappe.utils.get_bench_path()

	for app in frappe.get_installed_apps():
		relative_path = join_path(app, 'public/scss/website.scss')
		full_path = get_path('apps', app, relative_path, base=bench_path)
		if path_exists(full_path):
			import_path = splitext(relative_path)[0]
			import_path_list.append(import_path)

	return import_path_list


def after_migrate():
	""""""
	Regenerate Active Theme CSS file after migration.

	Necessary to reflect possible changes in the imported SCSS files. Called at
	the end of every `bench migrate`.
	""""""
	website_theme = frappe.db.get_single_value('Website Settings', 'website_theme')
	if website_theme == 'Standard':
		return

	doc = frappe.get_doc('Website Theme', website_theme)
	doc.generate_bootstrap_theme()
	doc.save()
",CWE-79,187.0,1
"import base64
import gzip
import json
import re
from gettext import gettext as _
from io import BytesIO

import requests
import yaml

from cookbook.helper.ingredient_parser import IngredientParser
from cookbook.helper.recipe_html_import import get_recipe_from_source
from cookbook.helper.recipe_url_import import iso_duration_to_minutes
from cookbook.integration.integration import Integration
from cookbook.models import Ingredient, Keyword, Recipe, Step


class CookBookApp(Integration):

    def import_file_name_filter(self, zip_info_object):
        return zip_info_object.filename.endswith('.html')

    def get_recipe_from_file(self, file):
        recipe_html = file.getvalue().decode(""utf-8"")

        recipe_json, recipe_tree, html_data, images = get_recipe_from_source(recipe_html, 'CookBookApp', self.request)

        recipe = Recipe.objects.create(
            name=recipe_json['name'].strip(),
            created_by=self.request.user, internal=True,
            space=self.request.space)

        try:
            recipe.servings = re.findall('([0-9])+', recipe_json['recipeYield'])[0]
        except Exception as e:
            pass

        try:
            recipe.working_time = iso_duration_to_minutes(recipe_json['prepTime'])
            recipe.waiting_time = iso_duration_to_minutes(recipe_json['cookTime'])
        except Exception:
            pass

        step = Step.objects.create(instruction=recipe_json['recipeInstructions'], space=self.request.space, )

        if 'nutrition' in recipe_json:
            step.instruction = step.instruction + '\n\n' + recipe_json['nutrition']

        step.save()
        recipe.steps.add(step)

        ingredient_parser = IngredientParser(self.request, True)
        for ingredient in recipe_json['recipeIngredient']:
            f = ingredient_parser.get_food(ingredient['ingredient']['text'])
            u = ingredient_parser.get_unit(ingredient['unit']['text'])
            step.ingredients.add(Ingredient.objects.create(
                food=f, unit=u, amount=ingredient['amount'], note=ingredient['note'],  space=self.request.space,
            ))

        if len(images) > 0:
            try:
                response = requests.get(images[0])
                self.import_recipe_image(recipe, BytesIO(response.content))
            except Exception as e:
                print('failed to import image ', str(e))

        recipe.save()
        return recipe
",CWE-918,69.0,1
"import base64
import json
from io import BytesIO

from gettext import gettext as _

import requests
from lxml import etree

from cookbook.helper.ingredient_parser import IngredientParser
from cookbook.helper.recipe_url_import import parse_servings, parse_time, parse_servings_text
from cookbook.integration.integration import Integration
from cookbook.models import Ingredient, Keyword, Recipe, Step


class Cookmate(Integration):

    def import_file_name_filter(self, zip_info_object):
        return zip_info_object.filename.endswith('.xml')

    def get_files_from_recipes(self, recipes, el, cookie):
        raise NotImplementedError('Method not implemented in storage integration')

    def get_recipe_from_file(self, file):
        recipe_xml = file

        recipe = Recipe.objects.create(
            name=recipe_xml.find('title').text.strip(),
            created_by=self.request.user, internal=True, space=self.request.space)

        if recipe_xml.find('preptime') is not None and recipe_xml.find('preptime').text is not None:
            recipe.working_time = parse_time(recipe_xml.find('preptime').text.strip())

        if recipe_xml.find('cooktime') is not None and recipe_xml.find('cooktime').text is not None:
            recipe.waiting_time = parse_time(recipe_xml.find('cooktime').text.strip())

        if recipe_xml.find('quantity') is not None and recipe_xml.find('quantity').text is not None:
            recipe.servings = parse_servings(recipe_xml.find('quantity').text.strip())
            recipe.servings_text = parse_servings_text(recipe_xml.find('quantity').text.strip())

        if recipe_xml.find('url') is not None and recipe_xml.find('url').text is not None:
            recipe.source_url = recipe_xml.find('url').text.strip()

        if recipe_xml.find('description') is not None:  # description is a list of <li>'s with text
            if len(recipe_xml.find('description')) > 0:
                recipe.description = recipe_xml.find('description')[0].text[:512]

        for step in recipe_xml.find('recipetext').getchildren():
            step = Step.objects.create(
                instruction=step.text.strip(), space=self.request.space,
            )
            recipe.steps.add(step)

        ingredient_parser = IngredientParser(self.request, True)

        for ingredient in recipe_xml.find('ingredient').getchildren():
            if ingredient.text.strip() != '':
                amount, unit, food, note = ingredient_parser.parse(ingredient.text.strip())
                f = ingredient_parser.get_food(food)
                u = ingredient_parser.get_unit(unit)
                recipe.steps.first().ingredients.add(Ingredient.objects.create(
                    food=f, unit=u, amount=amount, note=note, original_text=ingredient.text.strip(), space=self.request.space,
                ))

        if recipe_xml.find('imageurl') is not None:
            try:
                response = requests.get(recipe_xml.find('imageurl').text.strip())
                self.import_recipe_image(recipe, BytesIO(response.content))
            except Exception as e:
                print('failed to import image ', str(e))

        recipe.save()

        return recipe

    def get_file_from_recipe(self, recipe):
        raise NotImplementedError('Method not implemented in storage integration')
",CWE-918,78.0,1
"import imghdr
import json
import re
from io import BytesIO
from zipfile import ZipFile

import requests

from django.utils.translation import gettext as _
from cookbook.helper.image_processing import get_filetype
from cookbook.helper.ingredient_parser import IngredientParser
from cookbook.integration.integration import Integration
from cookbook.models import Ingredient, Keyword, Recipe, Step


class RecetteTek(Integration):

    def import_file_name_filter(self, zip_info_object):
        print(""testing"", zip_info_object.filename)
        return re.match(r'^recipes_0.json$', zip_info_object.filename) or re.match(r'^recipes.json$', zip_info_object.filename)

    def split_recipe_file(self, file):

        recipe_json = json.loads(file)

        recipe_list = [r for r in recipe_json]

        return recipe_list

    def get_recipe_from_file(self, file):

        # Create initial recipe with just a title and a description
        recipe = Recipe.objects.create(name=file['title'], created_by=self.request.user, internal=True, space=self.request.space, )

        # set the description as an empty string for later use for the source URL, in case there is no description text.
        recipe.description = ''

        try:
            if file['description'] != '':
                recipe.description = file['description'].strip()
        except Exception as e:
            print(recipe.name, ': failed to parse recipe description ', str(e))

        instructions = file['instructions']
        if not instructions:
            instructions = ''

        step = Step.objects.create(instruction=instructions, space=self.request.space,)

        # Append the original import url to the step (if it exists)
        try:
            if file['url'] != '':
                step.instruction += '\n\n' + _('Imported from') + ': ' + file['url']
                step.save()
        except Exception as e:
            print(recipe.name, ': failed to import source url ', str(e))

        try:
            # Process the ingredients. Assumes 1 ingredient per line.
            ingredient_parser = IngredientParser(self.request, True)
            for ingredient in file['ingredients'].split('\n'):
                if len(ingredient.strip()) > 0:
                    amount, unit, food, note = ingredient_parser.parse(food)
                    f = ingredient_parser.get_food(ingredient)
                    u = ingredient_parser.get_unit(unit)
                    step.ingredients.add(Ingredient.objects.create(
                        food=f, unit=u, amount=amount, note=note, original_text=ingredient, space=self.request.space,
                    ))
        except Exception as e:
            print(recipe.name, ': failed to parse recipe ingredients ', str(e))
        recipe.steps.add(step)

        # Attempt to import prep/cooking times
        # quick hack, this assumes only one number in the quantity field.
        try:
            if file['quantity'] != '':
                for item in file['quantity'].split(' '):
                    if item.isdigit():
                        recipe.servings = int(item)
                        break
        except Exception as e:
            print(recipe.name, ': failed to parse quantity ', str(e))

        try:
            if file['totalTime'] != '':
                recipe.waiting_time = int(file['totalTime'])
        except Exception as e:
            print(recipe.name, ': failed to parse total times ', str(e))

        try:
            if file['preparationTime'] != '':
                recipe.working_time = int(file['preparationTime'])
        except Exception as e:
            print(recipe.name, ': failed to parse prep time ', str(e))

        try:
            if file['cookingTime'] != '':
                recipe.waiting_time = int(file['cookingTime'])
        except Exception as e:
            print(recipe.name, ': failed to parse cooking time ', str(e))

        recipe.save()

        # Import the recipe keywords
        try:
            if file['keywords'] != '':
                for keyword in file['keywords'].split(';'):
                    k, created = Keyword.objects.get_or_create(name=keyword.strip(), space=self.request.space)
                    recipe.keywords.add(k)
            recipe.save()
        except Exception as e:
            print(recipe.name, ': failed to parse keywords ', str(e))

        # TODO: Parse Nutritional Information

        # Import the original image from the zip file, if we cannot do that, attempt to download it again.
        try:
            if file['pictures'][0] != '':
                image_file_name = file['pictures'][0].split('/')[-1]
                for f in self.files:
                    if '.rtk' in f['name']:
                        import_zip = ZipFile(f['file'])
                        self.import_recipe_image(recipe, BytesIO(import_zip.read(image_file_name)), filetype=get_filetype(image_file_name))
            else:
                if file['originalPicture'] != '':
                    response = requests.get(file['originalPicture'])
                    if imghdr.what(BytesIO(response.content)) is not None:
                        self.import_recipe_image(recipe, BytesIO(response.content), filetype=get_filetype(file['originalPicture']))
                    else:
                        raise Exception(""Original image failed to download."")
        except Exception as e:
            print(recipe.name, ': failed to import image ', str(e))

        return recipe

    def get_file_from_recipe(self, recipe):
        raise NotImplementedError('Method not implemented in storage integration')
",CWE-918,138.0,1
"import json
from io import BytesIO

import requests

from cookbook.helper.ingredient_parser import IngredientParser
from cookbook.integration.integration import Integration
from cookbook.models import Ingredient, Recipe, Step


class RecipeSage(Integration):

    def get_recipe_from_file(self, file):

        recipe = Recipe.objects.create(
            name=file['name'].strip(),
            created_by=self.request.user, internal=True,
            space=self.request.space)

        try:
            if file['recipeYield'] != '':
                recipe.servings = int(file['recipeYield'])

            if file['totalTime'] != '':
                recipe.waiting_time = int(file['totalTime']) - int(file['timePrep'])

            if file['prepTime'] != '':
                recipe.working_time = int(file['timePrep'])

            recipe.save()
        except Exception as e:
            print('failed to parse yield or time ', str(e))

        ingredient_parser = IngredientParser(self.request, True)
        ingredients_added = False
        for s in file['recipeInstructions']:
            step = Step.objects.create(
                instruction=s['text'], space=self.request.space,
            )
            if not ingredients_added:
                ingredients_added = True

                for ingredient in file['recipeIngredient']:
                    amount, unit, food, note = ingredient_parser.parse(ingredient)
                    f = ingredient_parser.get_food(food)
                    u = ingredient_parser.get_unit(unit)
                    step.ingredients.add(Ingredient.objects.create(
                        food=f, unit=u, amount=amount, note=note, original_text=ingredient, space=self.request.space,
                    ))
            recipe.steps.add(step)

        if len(file['image']) > 0:
            try:
                response = requests.get(file['image'][0])
                self.import_recipe_image(recipe, BytesIO(response.content))
            except Exception as e:
                print('failed to import image ', str(e))

        return recipe

    def get_file_from_recipe(self, recipe):
        data = {
            '@context': 'http://schema.org',
            '@type': 'Recipe',
            'creditText': '',
            'isBasedOn': '',
            'name': recipe.name,
            'description': recipe.description,
            'prepTime': str(recipe.working_time),
            'totalTime': str(recipe.waiting_time + recipe.working_time),
            'recipeYield': str(recipe.servings),
            'image': [],
            'recipeCategory': [],
            'comment': [],
            'recipeIngredient': [],
            'recipeInstructions': [],
        }

        for s in recipe.steps.all():
            data['recipeInstructions'].append({
                '@type': 'HowToStep',
                'text': s.instruction
            })

            for i in s.ingredients.all():
                data['recipeIngredient'].append(f'{float(i.amount)} {i.unit} {i.food}')

        return data

    def get_files_from_recipes(self, recipes, el, cookie):
        json_list = []
        for r in recipes:
            json_list.append(self.get_file_from_recipe(r))

            el.exported_recipes += 1
            el.msg += self.get_recipe_processed_msg(r)
            el.save()

        return [[self.get_export_file_name('json'), json.dumps(json_list)]]

    def split_recipe_file(self, file):
        return json.loads(file.read().decode(""utf-8""))
",CWE-918,103.0,1
"import io
import json
import os
from datetime import datetime

import requests
from cookbook.models import Recipe, RecipeImport, SyncLog
from cookbook.provider.provider import Provider


class Dropbox(Provider):

    @staticmethod
    def import_all(monitor):
        url = ""https://api.dropboxapi.com/2/files/list_folder""

        headers = {
            ""Authorization"": ""Bearer "" + monitor.storage.token,
            ""Content-Type"": ""application/json""
        }

        data = {
            ""path"": monitor.path
        }

        r = requests.post(url, headers=headers, data=json.dumps(data))
        try:
            recipes = r.json()
        except ValueError:
            log_entry = SyncLog(status='ERROR', msg=str(r), sync=monitor)
            log_entry.save()
            return r

        import_count = 0
        # TODO check if has_more is set and import that as well
        for recipe in recipes['entries']:
            path = recipe['path_lower']
            if not Recipe.objects.filter(file_path__iexact=path, space=monitor.space).exists() and not RecipeImport.objects.filter(file_path=path, space=monitor.space).exists():
                name = os.path.splitext(recipe['name'])[0]
                new_recipe = RecipeImport(
                    name=name,
                    file_path=path,
                    storage=monitor.storage,
                    file_uid=recipe['id'],
                    space=monitor.space,
                )
                new_recipe.save()
                import_count += 1

        log_entry = SyncLog(
            status='SUCCESS',
            msg='Imported ' + str(import_count) + ' recipes',
            sync=monitor,
        )
        log_entry.save()

        monitor.last_checked = datetime.now()
        monitor.save()

        return True

    @staticmethod
    def create_share_link(recipe):
        url = ""https://api.dropboxapi.com/2/sharing/create_shared_link_with_settings""  # noqa: E501

        headers = {
            ""Authorization"": ""Bearer "" + recipe.storage.token,
            ""Content-Type"": ""application/json""
        }

        data = {
            ""path"": recipe.file_uid
        }

        r = requests.post(url, headers=headers, data=json.dumps(data))

        return r.json()

    @staticmethod
    def get_share_link(recipe):
        url = ""https://api.dropboxapi.com/2/sharing/list_shared_links""

        headers = {
            ""Authorization"": ""Bearer "" + recipe.storage.token,
            ""Content-Type"": ""application/json""
        }

        data = {
            ""path"": recipe.file_path,
        }

        r = requests.post(url, headers=headers, data=json.dumps(data))
        p = r.json()

        for link in p['links']:
            return link['url']

        response = Dropbox.create_share_link(recipe)
        return response['url']

    @staticmethod
    def get_file(recipe):
        if not recipe.link:
            recipe.link = Dropbox.get_share_link(recipe)
            recipe.save()

        response = requests.get(recipe.link.replace('www.dropbox.', 'dl.dropboxusercontent.'))

        return io.BytesIO(response.content)

    @staticmethod
    def rename_file(recipe, new_name):
        url = ""https://api.dropboxapi.com/2/files/move_v2""

        headers = {
            ""Authorization"": ""Bearer "" + recipe.storage.token,
            ""Content-Type"": ""application/json""
        }

        data = {
            ""from_path"": recipe.file_path,
            ""to_path"": ""%s/%s%s"" % (
                os.path.dirname(recipe.file_path),
                new_name,
                os.path.splitext(recipe.file_path)[1]
            )
        }

        r = requests.post(url, headers=headers, data=json.dumps(data))

        return r.json()

    @staticmethod
    def delete_file(recipe):
        url = ""https://api.dropboxapi.com/2/files/delete_v2""

        headers = {
            ""Authorization"": ""Bearer "" + recipe.storage.token,
            ""Content-Type"": ""application/json""
        }

        data = {
            ""path"": recipe.file_path
        }

        r = requests.post(url, headers=headers, data=json.dumps(data))

        return r.json()
",CWE-918,149.0,1
"import io
import os
import tempfile
from datetime import datetime

import requests
import webdav3.client as wc
from cookbook.models import Recipe, RecipeImport, SyncLog
from cookbook.provider.provider import Provider
from requests.auth import HTTPBasicAuth

from recipes.settings import DEBUG


class Nextcloud(Provider):

    @staticmethod
    def get_client(storage):
        options = {
            'webdav_hostname': storage.url,
            'webdav_login': storage.username,
            'webdav_password': storage.password,
            'webdav_root': '/remote.php/dav/files/' + storage.username
        }
        if storage.path != '':
            options['webdav_root'] = storage.path
        return wc.Client(options)

    @staticmethod
    def import_all(monitor):
        client = Nextcloud.get_client(monitor.storage)

        if DEBUG:
            print(f'TANDOOR_PROVIDER_DEBUG checking path  {monitor.path} with client {client}')

        files = client.list(monitor.path)

        if DEBUG:
            print(f'TANDOOR_PROVIDER_DEBUG file list  {files}')

        import_count = 0
        for file in files:
            if DEBUG:
                print(f'TANDOOR_PROVIDER_DEBUG importing file {file}')
            path = monitor.path + '/' + file
            if not Recipe.objects.filter(file_path__iexact=path, space=monitor.space).exists() and not RecipeImport.objects.filter(file_path=path, space=monitor.space).exists():
                name = os.path.splitext(file)[0]
                new_recipe = RecipeImport(
                    name=name,
                    file_path=path,
                    storage=monitor.storage,
                    space=monitor.space,
                )
                new_recipe.save()
                import_count += 1

        log_entry = SyncLog(
            status='SUCCESS',
            msg='Imported ' + str(import_count) + ' recipes',
            sync=monitor,
        )
        log_entry.save()

        monitor.last_checked = datetime.now()
        monitor.save()

        return True

    @staticmethod
    def create_share_link(recipe):
        url = recipe.storage.url + '/ocs/v2.php/apps/files_sharing/api/v1/shares?format=json'  # noqa: E501

        headers = {
            ""OCS-APIRequest"": ""true"",
            ""Content-Type"": ""application/x-www-form-urlencoded""
        }

        data = {'path': recipe.file_path, 'shareType': 3}

        r = requests.post(url, headers=headers, auth=HTTPBasicAuth(recipe.storage.username, recipe.storage.password), data=data)

        response_json = r.json()

        return response_json['ocs']['data']['url']

    @staticmethod
    def get_share_link(recipe):
        url = recipe.storage.url + '/ocs/v2.php/apps/files_sharing/api/v1/shares?format=json&path=' + recipe.file_path  # noqa: E501

        headers = {
            ""OCS-APIRequest"": ""true"",
            ""Content-Type"": ""application/json""
        }

        r = requests.get(
            url,
            headers=headers,
            auth=HTTPBasicAuth(
                recipe.storage.username, recipe.storage.password
            )
        )

        response_json = r.json()
        for element in response_json['ocs']['data']:
            if element['share_type'] == '3':
                return element['url']

        return Nextcloud.create_share_link(recipe)

    @staticmethod
    def get_file(recipe):
        client = Nextcloud.get_client(recipe.storage)

        tmp_file_path = tempfile.gettempdir() + '/' + recipe.name + '.pdf'

        client.download_file(
            remote_path=recipe.file_path,
            local_path=tmp_file_path
        )

        file = io.BytesIO(open(tmp_file_path, 'rb').read())
        os.remove(tmp_file_path)

        return file

    @staticmethod
    def rename_file(recipe, new_name):
        client = Nextcloud.get_client(recipe.storage)

        client.move(
            recipe.file_path,
            ""%s/%s%s"" % (
                os.path.dirname(recipe.file_path),
                new_name,
                os.path.splitext(recipe.file_path)[1]
            )
        )

        return True

    @staticmethod
    def delete_file(recipe):
        client = Nextcloud.get_client(recipe.storage)

        client.clean(recipe.file_path)

        return True
",CWE-918,148.0,1
"import os
from typing import List, Tuple

from paste import request
from paste.fileapp import FileApp
from paste.httpheaders import ETAG
from paste.urlparser import StaticURLParser


class CacheableStaticURLParser(StaticURLParser):

    def __init__(self, directory, cache_seconds=None, directory_per_host=None):
        StaticURLParser.__init__(self, directory)
        self.cache_seconds = cache_seconds
        self.directory_per_host = directory_per_host

    def __call__(self, environ, start_response):
        path_info = environ.get('PATH_INFO', '')
        if not path_info:
            # See if this is a static file hackishly mapped.
            if os.path.exists(self.directory) and os.path.isfile(self.directory):
                app = FileApp(self.directory)
                if self.cache_seconds:
                    app.cache_control(max_age=int(self.cache_seconds))
                return app(environ, start_response)
            return self.add_slash(environ, start_response)
        if path_info == '/':
            # @@: This should obviously be configurable
            filename = 'index.html'
        else:
            filename = request.path_info_pop(environ)

        directory = self.directory
        host = environ.get('HTTP_HOST')
        if self.directory_per_host and host:
            for host_key, host_val in self.directory_per_host.items():
                if host_key in host:
                    directory = host_val
                    break

        full = os.path.join(directory, filename)
        if not os.path.exists(full):
            return self.not_found(environ, start_response)
        if os.path.isdir(full):
            # @@: Cache?
            return self.__class__(full)(environ, start_response)
        if environ.get('PATH_INFO') and environ.get('PATH_INFO') != '/':
            return self.error_extra_path(environ, start_response)
        if_none_match = environ.get('HTTP_IF_NONE_MATCH')
        if if_none_match:
            mytime = os.stat(full).st_mtime
            if str(mytime) == if_none_match:
                headers: List[Tuple[str, str]] = []
                ETAG.update(headers, mytime)
                start_response('304 Not Modified', headers)
                return ['']  # empty body
        app = FileApp(full)
        if self.cache_seconds:
            app.cache_control(max_age=int(self.cache_seconds))
        return app(environ, start_response)


def make_static(global_conf, document_root, cache_seconds=None):
    return CacheableStaticURLParser(document_root, cache_seconds)
",CWE-22,65.0,1
"import json
import os
import shutil
import tarsafe  # type: ignore
import tempfile
import requests

from guarddog.analyzer.analyzer import Analyzer
from guarddog.scanners.scanner import Scanner
from guarddog.utils.package_info import get_package_info


class PackageScanner(Scanner):
    """"""
    Scans package for attack vectors based on source code and metadata rules

    Attributes:
        analyzer (Analyzer): Analyzer for source code and metadata rules
    """"""

    def __init__(self) -> None:
        self.analyzer = Analyzer()
        super(Scanner)

    def scan_local(self, path, rules=None) -> dict:
        """"""
        Scans local package

        Args:
            path (str): path to package
            rules (set, optional): Set of rule names to use. Defaults to all rules.

        Raises:
            Exception: Analyzer exception

        Returns:
            dict: Analyzer output with rules to results mapping
        """"""

        if rules is not None:
            rules = set(rules)

        if os.path.exists(path):
            if path.endswith('.tar.gz'):
                with tempfile.TemporaryDirectory() as tmpdirname:
                    tarsafe.open(path).extractall(tmpdirname)
                    return self.analyzer.analyze_sourcecode(tmpdirname, rules=rules)
            elif os.path.isdir(path):
                return self.analyzer.analyze_sourcecode(path, rules=rules)
            else:
                raise Exception(f""Path {path} is not a directory nor a tar.gz archive."")
        raise Exception(f""Path {path} does not exist."")

    def _scan_remote(self, name, base_dir, version=None, rules=None, write_package_info=False):
        directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), base_dir)
        file_path = os.path.join(directory, name)

        self.download_package(name, directory, version)

        package_info = get_package_info(name)

        results = self.analyzer.analyze(file_path, package_info, rules)
        if write_package_info:
            suffix = f""{name}-{version}"" if version is not None else name
            with open(os.path.join(results[""path""], f'package_info-{suffix}.json'), ""w"") as file:
                file.write(json.dumps(package_info))

        return results

    def scan_remote(self, name, version=None, rules=None, base_dir=None, write_package_info=False):
        """"""
        Scans a remote package

        Args:
            * `name` (str): name of the package on PyPI
            * `version` (str, optional): version of package (ex. 0.0.1). If not specified, the latest version is
            assumed.
            * `rules` (set, optional): Set of rule names to use. Defaults to all rules.
            * `base_dir` (str, optional): directory to use to download package to. If not specified, a temporary folder
            is created and cleaned up automatically. If not specified, the provided directory is not removed after the
            scan.
            * `write_package_info` (bool, default False): if set to true, the result of the PyPI metadata API is written
             to a json file

        Raises:
            Exception: Analyzer exception

        Returns:
            dict: Analyzer output with rules to results mapping
        """"""
        if (base_dir is not None):
            return self._scan_remote(name, base_dir, version, rules, write_package_info)

        with tempfile.TemporaryDirectory() as tmpdirname:
            # Directory to download compressed and uncompressed package
            return self._scan_remote(name, tmpdirname, version, rules, write_package_info)

    def download_package(self, package_name, directory, version=None) -> None:
        """"""Downloads the PyPI distribution for a given package and version

        Args:
            package_name (str): name of the package
            directory (str): directory to download package to
            version (str): version of the package

        Raises:
            Exception: ""Received status code: "" + <not 200> + "" from PyPI""
            Exception: ""Version "" + version + "" for package "" + package_name + "" doesn't exist.""
            Exception: ""Compressed file for package does not exist.""
            Exception: ""Error retrieving package: "" + <error message>
        Returns:
            None
        """"""

        data = get_package_info(package_name)
        releases = data[""releases""]

        if version is None:
            version = data[""info""][""version""]

        if version in releases:
            files = releases[version]

            url = None
            file_extension = None

            for file in files:
                # Store url to compressed package and appropriate file extension
                if file[""filename""].endswith("".tar.gz""):
                    url = file[""url""]
                    file_extension = "".tar.gz""

                if file[""filename""].endswith("".egg"") or file[""filename""].endswith("".whl"") \
                        or file[""filename""].endswith("".zip""):
                    url = file[""url""]
                    file_extension = "".zip""

            if url and file_extension:
                # Path to compressed package
                zippath = os.path.join(directory, package_name + file_extension)
                unzippedpath = zippath.removesuffix(file_extension)

                self.download_compressed(url, zippath, unzippedpath)
            else:
                raise Exception(f""Compressed file for {package_name} does not exist on PyPI."")
        else:
            raise Exception(""Version "" + version + "" for package "" + package_name + "" doesn't exist."")

    def download_compressed(self, url, zippath, unzippedpath):
        """"""Downloads a compressed file and extracts it

        Args:
            url (str): download link
            zippath (str): path to download compressed file
            unzippedpath (str): path to unzip compressed file
        """"""

        response = requests.get(url, stream=True)

        with open(zippath, ""wb"") as f:
            f.write(response.raw.read())

        shutil.unpack_archive(zippath, unzippedpath)
        os.remove(zippath)
",CWE-22,165.0,1
"def try_get_cached(domain, dict):
    import ast
    import json

    import requests

    title = dict[""title""]
    singer = dict[""singer""]
    album = dict[""album""]

    api = f""http://{domain}:7873/Y2hlY2tfY2FjaGVkX2ZpbGVz""
    headers = {""Content-type"": ""application/json"", ""Accept"": ""text/plain""}
    payload = json.dumps({""title"": title, ""singer"": singer, ""album"": album})
    response = requests.post(api, data=payload, headers=headers)

    status = ast.literal_eval(response.text)

    return status


def get(image_file, domain, title, singer, album):
    import ast
    import base64
    import json
    import os
    from html import unescape

    import requests

    api = f""http://{domain}:7873/bGVhdmVfcmlnaHRfbm93""

    with open(image_file, ""rb"") as f:
        im_bytes = f.read()
        f.close()
    im_b64 = base64.b64encode(im_bytes).decode(""utf8"")

    headers = {""Content-type"": ""application/json"", ""Accept"": ""text/plain""}

    status = try_get_cached(domain, {""title"": title, ""singer"": singer, ""album"": album})
    status = ast.literal_eval(str(status))

    if status is None:
        print(""Cached version not found. Uploading image with song metadata."")
        payload = json.dumps(
            {""image"": im_b64, ""title"": title, ""singer"": singer, ""album"": album}
        )
        response = requests.post(api, data=payload, headers=headers)

        data = unescape(response.text)
        print(data)

        data = ast.literal_eval(data)[""entry""]
        print(data)

    else:
        data = status

    # data = [{""title"": title, ""singer"": singer, ""album"": album}, file_name, file_ending]

    cmd = ""del "" + image_file
    os.system(cmd)

    return data


# print(get(""sample_image.jpg"", ""localhost"", ""title"", ""artist"", ""album""))

# try_get_cached(""localhost"", {""title"": ""title"", ""singer"": ""singer"", ""album"": ""album""})

# print(get(""sample_image.png"", ""localhost"", ""not_title"", ""singer"", ""album""))
",CWE-78,71.0,1
"arrow>=0.8.0,<1.0.0; python_version <= '3.5'
arrow>=1.0.2,<2.0.0; python_version >= '3.6'
b2sdk>=1.14.0,<2.0.0
docutils==0.16
idna>=2.2.0; platform_system == 'Java'
importlib-metadata>=2.1.1,<3.0.0; python_version <= '3.5'
importlib-metadata>=3.3.0; python_version > '3.5' and python_version < '3.8'
phx-class-registry==3.0.5
rst2ansi==0.1.5
",CWE-367,10.0,1
,CWE-601,,1
,CWE-918,,1
"from math import ceil

from vyper.codegen.core import ensure_in_memory
from vyper.codegen.ir_node import IRnode
from vyper.codegen.types import BaseType, ByteArrayLike, is_base_type
from vyper.exceptions import CompilerPanic
from vyper.utils import MemoryPositions, bytes_to_int, keccak256


def _check_byteslike(typ, _expr):
    if not isinstance(typ, ByteArrayLike) and not is_base_type(typ, ""bytes32""):
        # NOTE this may be checked at a higher level, but just be safe
        raise CompilerPanic(
            ""keccak256 only accepts bytes-like objects"",
        )


def _gas_bound(num_words):
    SHA3_BASE = 30
    SHA3_PER_WORD = 6
    return SHA3_BASE + num_words * SHA3_PER_WORD


def keccak256_helper(expr, ir_arg, context):
    sub = ir_arg  # TODO get rid of useless variable
    _check_byteslike(sub.typ, expr)

    # Can hash literals
    # TODO this is dead code.
    if isinstance(sub, bytes):
        return IRnode.from_list(bytes_to_int(keccak256(sub)), typ=BaseType(""bytes32""))

    # Can hash bytes32 objects
    if is_base_type(sub.typ, ""bytes32""):
        return IRnode.from_list(
            [
                ""seq"",
                [""mstore"", MemoryPositions.FREE_VAR_SPACE, sub],
                [""sha3"", MemoryPositions.FREE_VAR_SPACE, 32],
            ],
            typ=BaseType(""bytes32""),
            add_gas_estimate=_gas_bound(1),
        )

    sub = ensure_in_memory(sub, context)

    return IRnode.from_list(
        [
            ""with"",
            ""_buf"",
            sub,
            [""sha3"", [""add"", ""_buf"", 32], [""mload"", ""_buf""]],
        ],
        typ=BaseType(""bytes32""),
        annotation=""keccak256"",
        add_gas_estimate=_gas_bound(ceil(sub.typ.maxlen / 32)),
    )
",CWE-697,58.0,1
"# transition module to convert from new types to old types

import vyper.codegen.types as old
import vyper.semantics.types as new
from vyper.exceptions import InvalidType


def new_type_to_old_type(typ: new.BasePrimitive) -> old.NodeType:
    if isinstance(typ, new.BoolDefinition):
        return old.BaseType(""bool"")
    if isinstance(typ, new.AddressDefinition):
        return old.BaseType(""address"")
    if isinstance(typ, new.InterfaceDefinition):
        return old.InterfaceType(typ._id)
    if isinstance(typ, new.BytesMDefinition):
        m = typ._length  # type: ignore
        return old.BaseType(f""bytes{m}"")
    if isinstance(typ, new.BytesArrayDefinition):
        return old.ByteArrayType(typ.length)
    if isinstance(typ, new.StringDefinition):
        return old.StringType(typ.length)
    if isinstance(typ, new.DecimalDefinition):
        return old.BaseType(""decimal"")
    if isinstance(typ, new.SignedIntegerAbstractType):
        bits = typ._bits  # type: ignore
        return old.BaseType(""int"" + str(bits))
    if isinstance(typ, new.UnsignedIntegerAbstractType):
        bits = typ._bits  # type: ignore
        return old.BaseType(""uint"" + str(bits))
    if isinstance(typ, new.ArrayDefinition):
        return old.SArrayType(new_type_to_old_type(typ.value_type), typ.length)
    if isinstance(typ, new.DynamicArrayDefinition):
        return old.DArrayType(new_type_to_old_type(typ.value_type), typ.length)
    if isinstance(typ, new.TupleDefinition):
        return old.TupleType(typ.value_type)
    if isinstance(typ, new.StructDefinition):
        return old.StructType(
            {n: new_type_to_old_type(t) for (n, t) in typ.members.items()}, typ._id
        )
    raise InvalidType(f""unknown type {typ}"")
",CWE-119,41.0,1
"# transition module to convert from new types to old types

import vyper.codegen.types as old
import vyper.semantics.types as new
from vyper.exceptions import InvalidType


def new_type_to_old_type(typ: new.BasePrimitive) -> old.NodeType:
    if isinstance(typ, new.BoolDefinition):
        return old.BaseType(""bool"")
    if isinstance(typ, new.AddressDefinition):
        return old.BaseType(""address"")
    if isinstance(typ, new.InterfaceDefinition):
        return old.InterfaceType(typ._id)
    if isinstance(typ, new.BytesMDefinition):
        m = typ._length  # type: ignore
        return old.BaseType(f""bytes{m}"")
    if isinstance(typ, new.BytesArrayDefinition):
        return old.ByteArrayType(typ.length)
    if isinstance(typ, new.StringDefinition):
        return old.StringType(typ.length)
    if isinstance(typ, new.DecimalDefinition):
        return old.BaseType(""decimal"")
    if isinstance(typ, new.SignedIntegerAbstractType):
        bits = typ._bits  # type: ignore
        return old.BaseType(""int"" + str(bits))
    if isinstance(typ, new.UnsignedIntegerAbstractType):
        bits = typ._bits  # type: ignore
        return old.BaseType(""uint"" + str(bits))
    if isinstance(typ, new.ArrayDefinition):
        return old.SArrayType(new_type_to_old_type(typ.value_type), typ.length)
    if isinstance(typ, new.DynamicArrayDefinition):
        return old.DArrayType(new_type_to_old_type(typ.value_type), typ.length)
    if isinstance(typ, new.TupleDefinition):
        return old.TupleType(typ.value_type)
    if isinstance(typ, new.StructDefinition):
        return old.StructType(
            {n: new_type_to_old_type(t) for (n, t) in typ.members.items()}, typ._id
        )
    raise InvalidType(f""unknown type {typ}"")
",CWE-190,41.0,1
"import vyper


def test_basic_init_function(get_contract):
    code = """"""
val: public(uint256)

@external
def __init__(a: uint256):
    self.val = a
    """"""

    c = get_contract(code, *[123])

    assert c.val() == 123

    # Make sure the init code does not access calldata
    opcodes = vyper.compile_code(code, [""opcodes""])[""opcodes""].split("" "")
    ir_return_idx = opcodes.index(""JUMP"")

    assert ""CALLDATALOAD"" in opcodes
    assert ""CALLDATACOPY"" not in opcodes[:ir_return_idx]
    assert ""CALLDATALOAD"" not in opcodes[:ir_return_idx]


def test_init_calls_internal(get_contract, assert_compile_failed, assert_tx_failed):
    code = """"""
foo: public(uint8)
@internal
def bar(x: uint256) -> uint8:
    return convert(x, uint8) * 7
@external
def __init__(a: uint256):
    self.foo = self.bar(a)

@external
def baz() -> uint8:
    return self.bar(convert(self.foo, uint256))
    """"""
    n = 5
    c = get_contract(code, n)
    assert c.foo() == n * 7
    assert c.baz() == 245  # 5*7*7

    n = 6
    c = get_contract(code, n)
    assert c.foo() == n * 7
    assert_tx_failed(lambda: c.baz())

    n = 255
    assert_compile_failed(lambda: get_contract(code, n))

    n = 256
    assert_compile_failed(lambda: get_contract(code, n))
",CWE-670,55.0,1
"# a contract.vy -- all functions and constructor

from typing import Any, Dict, List, Optional, Tuple

from vyper import ast as vy_ast
from vyper.ast.signatures.function_signature import FunctionSignature, FunctionSignatures
from vyper.codegen.core import shr
from vyper.codegen.function_definitions import generate_ir_for_function
from vyper.codegen.global_context import GlobalContext
from vyper.codegen.ir_node import IRnode
from vyper.exceptions import CompilerPanic
from vyper.semantics.types.function import StateMutability


def _topsort_helper(functions, lookup):
    #  single pass to get a global topological sort of functions (so that each
    # function comes after each of its callees). may have duplicates, which get
    # filtered out in _topsort()

    ret = []
    for f in functions:
        # called_functions is a list of ContractFunctions, need to map
        # back to FunctionDefs.
        callees = [lookup[t.name] for t in f._metadata[""type""].called_functions]
        ret.extend(_topsort_helper(callees, lookup))
        ret.append(f)

    return ret


def _topsort(functions):
    lookup = {f.name: f for f in functions}
    # strip duplicates
    return list(dict.fromkeys(_topsort_helper(functions, lookup)))


def _is_init_func(func_ast):
    return func_ast._metadata[""signature""].is_init_func


def _is_default_func(func_ast):
    return func_ast._metadata[""signature""].is_default_func


def _is_internal(func_ast):
    return func_ast._metadata[""type""].is_internal


def _is_payable(func_ast):
    return func_ast._metadata[""type""].mutability == StateMutability.PAYABLE


# codegen for all runtime functions + callvalue/calldata checks + method selector routines
def _runtime_ir(runtime_functions, all_sigs, global_ctx):
    # categorize the runtime functions because we will organize the runtime
    # code into the following sections:
    # payable functions, nonpayable functions, fallback function, internal_functions
    internal_functions = [f for f in runtime_functions if _is_internal(f)]

    external_functions = [f for f in runtime_functions if not _is_internal(f)]
    default_function = next((f for f in external_functions if _is_default_func(f)), None)

    # functions that need to go exposed in the selector section
    regular_functions = [f for f in external_functions if not _is_default_func(f)]
    payables = [f for f in regular_functions if _is_payable(f)]
    nonpayables = [f for f in regular_functions if not _is_payable(f)]

    # create a map of the IR functions since they might live in both
    # runtime and deploy code (if init function calls them)
    internal_functions_map: Dict[str, IRnode] = {}

    for func_ast in internal_functions:
        func_ir = generate_ir_for_function(func_ast, all_sigs, global_ctx, False)
        internal_functions_map[func_ast.name] = func_ir

    # for some reason, somebody may want to deploy a contract with no
    # external functions, or more likely, a ""pure data"" contract which
    # contains immutables
    if len(external_functions) == 0:
        # TODO: prune internal functions in this case?
        runtime = [""seq""] + list(internal_functions_map.values())
        return runtime, internal_functions_map

    # note: if the user does not provide one, the default fallback function
    # reverts anyway. so it does not hurt to batch the payable check.
    default_is_nonpayable = default_function is None or not _is_payable(default_function)

    # when a contract has a nonpayable default function,
    # we can do a single check for all nonpayable functions
    batch_payable_check = len(nonpayables) > 0 and default_is_nonpayable
    skip_nonpayable_check = batch_payable_check

    selector_section = [""seq""]

    for func_ast in payables:
        func_ir = generate_ir_for_function(func_ast, all_sigs, global_ctx, False)
        selector_section.append(func_ir)

    if batch_payable_check:
        selector_section.append([""assert"", [""iszero"", ""callvalue""]])

    for func_ast in nonpayables:
        func_ir = generate_ir_for_function(func_ast, all_sigs, global_ctx, skip_nonpayable_check)
        selector_section.append(func_ir)

    if default_function:
        fallback_ir = generate_ir_for_function(
            default_function, all_sigs, global_ctx, skip_nonpayable_check
        )
    else:
        fallback_ir = IRnode.from_list(
            [""revert"", 0, 0], annotation=""Default function"", error_msg=""fallback function""
        )

    # ensure the external jumptable section gets closed out
    # (for basic block hygiene and also for zksync interpreter)
    # NOTE: this jump gets optimized out in assembly since the
    # fallback label is the immediate next instruction,
    close_selector_section = [""goto"", ""fallback""]

    runtime = [
        ""seq"",
        # check that calldatasize is at least 4, otherwise
        # calldataload will load zeros (cf. yellow paper).
        [""if"", [""lt"", ""calldatasize"", 4], [""goto"", ""fallback""]],
        [""with"", ""_calldata_method_id"", shr(224, [""calldataload"", 0]), selector_section],
        close_selector_section,
        [""label"", ""fallback"", [""var_list""], fallback_ir],
    ]

    # TODO: prune unreachable functions?
    runtime.extend(internal_functions_map.values())

    return runtime, internal_functions_map


# take a GlobalContext, which is basically
# and generate the runtime and deploy IR, also return the dict of all signatures
def generate_ir_for_module(global_ctx: GlobalContext) -> Tuple[IRnode, IRnode, FunctionSignatures]:
    # order functions so that each function comes after all of its callees
    function_defs = _topsort(global_ctx.functions)

    # FunctionSignatures for all interfaces defined in this module
    all_sigs: Dict[str, FunctionSignatures] = {}

    init_function: Optional[vy_ast.FunctionDef] = None
    local_sigs: FunctionSignatures = {}  # internal/local functions

    # generate all signatures
    # TODO really this should live in GlobalContext
    for f in function_defs:
        sig = FunctionSignature.from_definition(f, global_ctx)
        # add it to the global namespace.
        local_sigs[sig.name] = sig
        # a little hacky, eventually FunctionSignature should be
        # merged with ContractFunction and we can remove this.
        f._metadata[""signature""] = sig

    assert ""self"" not in all_sigs
    all_sigs[""self""] = local_sigs

    runtime_functions = [f for f in function_defs if not _is_init_func(f)]
    init_function = next((f for f in function_defs if _is_init_func(f)), None)

    runtime, internal_functions = _runtime_ir(runtime_functions, all_sigs, global_ctx)

    deploy_code: List[Any] = [""seq""]
    immutables_len = global_ctx.immutable_section_bytes
    if init_function:
        init_func_ir = generate_ir_for_function(init_function, all_sigs, global_ctx, False)
        deploy_code.append(init_func_ir)

        # pass the amount of memory allocated for the init function
        # so that deployment does not clobber while preparing immutables
        # note: (deploy mem_ofst, code, extra_padding)
        init_mem_used = init_function._metadata[""signature""].frame_info.mem_used
        deploy_code.append([""deploy"", init_mem_used, runtime, immutables_len])

        # internal functions come after everything else
        for f in init_function._metadata[""type""].called_functions:
            deploy_code.append(internal_functions[f.name])

    else:
        if immutables_len != 0:
            raise CompilerPanic(""unreachable"")
        deploy_code.append([""deploy"", 0, runtime, 0])

    return IRnode.from_list(deploy_code), IRnode.from_list(runtime), local_sigs
",CWE-670,189.0,1
"import pytest

from vyper.compiler import compile_code
from vyper.exceptions import StorageLayoutException


def test_storage_layout_overrides():
    code = """"""
a: uint256
b: uint256""""""

    storage_layout_overrides = {
        ""a"": {""type"": ""uint256"", ""slot"": 1},
        ""b"": {""type"": ""uint256"", ""slot"": 0},
    }

    expected_output = {""storage_layout"": storage_layout_overrides, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_overrides
    )

    assert out[""layout""] == expected_output


def test_storage_layout_for_more_complex():
    code = """"""
foo: HashMap[address, uint256]

@external
@nonreentrant(""foo"")
def public_foo1():
    pass

@external
@nonreentrant(""foo"")
def public_foo2():
    pass


@internal
@nonreentrant(""bar"")
def _bar():
    pass

# mix it up a little
baz: Bytes[65]
bar: uint256

@external
@nonreentrant(""bar"")
def public_bar():
    pass

@external
@nonreentrant(""foo"")
def public_foo3():
    pass
    """"""

    storage_layout_override = {
        ""nonreentrant.foo"": {""type"": ""nonreentrant lock"", ""slot"": 8},
        ""nonreentrant.bar"": {""type"": ""nonreentrant lock"", ""slot"": 7},
        ""foo"": {""type"": ""HashMap[address, uint256]"", ""slot"": 1},
        ""baz"": {""type"": ""Bytes[65]"", ""slot"": 2},
        ""bar"": {""type"": ""uint256"", ""slot"": 6},
    }

    expected_output = {""storage_layout"": storage_layout_override, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_override
    )

    assert out[""layout""] == expected_output


def test_simple_collision():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {
        ""name"": {""slot"": 0, ""type"": ""String[64]""},
        ""symbol"": {""slot"": 1, ""type"": ""String[32]""},
    }

    with pytest.raises(
        StorageLayoutException,
        match=""Storage collision! Tried to assign 'symbol' to slot 1""
        "" but it has already been reserved by 'name'"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )


def test_incomplete_overrides():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {""name"": {""slot"": 0, ""type"": ""String[64]""}}

    with pytest.raises(
        StorageLayoutException,
        match=""Could not find storage_slot for symbol. ""
        ""Have you used the correct storage layout file?"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )
",CWE-789,113.0,1
"import pytest

from vyper.compiler import compile_code
from vyper.exceptions import StorageLayoutException


def test_storage_layout_overrides():
    code = """"""
a: uint256
b: uint256""""""

    storage_layout_overrides = {
        ""a"": {""type"": ""uint256"", ""slot"": 1},
        ""b"": {""type"": ""uint256"", ""slot"": 0},
    }

    expected_output = {""storage_layout"": storage_layout_overrides, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_overrides
    )

    assert out[""layout""] == expected_output


def test_storage_layout_for_more_complex():
    code = """"""
foo: HashMap[address, uint256]

@external
@nonreentrant(""foo"")
def public_foo1():
    pass

@external
@nonreentrant(""foo"")
def public_foo2():
    pass


@internal
@nonreentrant(""bar"")
def _bar():
    pass

# mix it up a little
baz: Bytes[65]
bar: uint256

@external
@nonreentrant(""bar"")
def public_bar():
    pass

@external
@nonreentrant(""foo"")
def public_foo3():
    pass
    """"""

    storage_layout_override = {
        ""nonreentrant.foo"": {""type"": ""nonreentrant lock"", ""slot"": 8},
        ""nonreentrant.bar"": {""type"": ""nonreentrant lock"", ""slot"": 7},
        ""foo"": {""type"": ""HashMap[address, uint256]"", ""slot"": 1},
        ""baz"": {""type"": ""Bytes[65]"", ""slot"": 2},
        ""bar"": {""type"": ""uint256"", ""slot"": 6},
    }

    expected_output = {""storage_layout"": storage_layout_override, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_override
    )

    assert out[""layout""] == expected_output


def test_simple_collision():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {
        ""name"": {""slot"": 0, ""type"": ""String[64]""},
        ""symbol"": {""slot"": 1, ""type"": ""String[32]""},
    }

    with pytest.raises(
        StorageLayoutException,
        match=""Storage collision! Tried to assign 'symbol' to slot 1""
        "" but it has already been reserved by 'name'"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )


def test_incomplete_overrides():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {""name"": {""slot"": 0, ""type"": ""String[64]""}}

    with pytest.raises(
        StorageLayoutException,
        match=""Could not find storage_slot for symbol. ""
        ""Have you used the correct storage layout file?"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )
",CWE-682,113.0,1
"import pytest

from vyper.compiler import compile_code
from vyper.exceptions import StorageLayoutException


def test_storage_layout_overrides():
    code = """"""
a: uint256
b: uint256""""""

    storage_layout_overrides = {
        ""a"": {""type"": ""uint256"", ""slot"": 1},
        ""b"": {""type"": ""uint256"", ""slot"": 0},
    }

    expected_output = {""storage_layout"": storage_layout_overrides, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_overrides
    )

    assert out[""layout""] == expected_output


def test_storage_layout_for_more_complex():
    code = """"""
foo: HashMap[address, uint256]

@external
@nonreentrant(""foo"")
def public_foo1():
    pass

@external
@nonreentrant(""foo"")
def public_foo2():
    pass


@internal
@nonreentrant(""bar"")
def _bar():
    pass

# mix it up a little
baz: Bytes[65]
bar: uint256

@external
@nonreentrant(""bar"")
def public_bar():
    pass

@external
@nonreentrant(""foo"")
def public_foo3():
    pass
    """"""

    storage_layout_override = {
        ""nonreentrant.foo"": {""type"": ""nonreentrant lock"", ""slot"": 8},
        ""nonreentrant.bar"": {""type"": ""nonreentrant lock"", ""slot"": 7},
        ""foo"": {""type"": ""HashMap[address, uint256]"", ""slot"": 1},
        ""baz"": {""type"": ""Bytes[65]"", ""slot"": 2},
        ""bar"": {""type"": ""uint256"", ""slot"": 6},
    }

    expected_output = {""storage_layout"": storage_layout_override, ""code_layout"": {}}

    out = compile_code(
        code, output_formats=[""layout""], storage_layout_override=storage_layout_override
    )

    assert out[""layout""] == expected_output


def test_simple_collision():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {
        ""name"": {""slot"": 0, ""type"": ""String[64]""},
        ""symbol"": {""slot"": 1, ""type"": ""String[32]""},
    }

    with pytest.raises(
        StorageLayoutException,
        match=""Storage collision! Tried to assign 'symbol' to slot 1""
        "" but it has already been reserved by 'name'"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )


def test_incomplete_overrides():
    code = """"""
name: public(String[64])
symbol: public(String[32])""""""

    storage_layout_override = {""name"": {""slot"": 0, ""type"": ""String[64]""}}

    with pytest.raises(
        StorageLayoutException,
        match=""Could not find storage_slot for symbol. ""
        ""Have you used the correct storage layout file?"",
    ):
        compile_code(
            code, output_formats=[""layout""], storage_layout_override=storage_layout_override
        )
",CWE-193,113.0,1
"code = """"""

struct StructOne:
    a: String[33]
    b: uint256[3]

struct StructTwo:
    a: Bytes[5]
    b: int128[2]
    c: String[64]

a: public(StructOne)
b: public(uint256[2])
c: public(Bytes[32])
d: public(int128[4])
foo: public(HashMap[uint256, uint256[3]])
dyn_array: DynArray[uint256, 3]
e: public(String[47])
f: public(int256[1])
g: public(StructTwo[2])
h: public(int256[1])


@external
def __init__():
    self.a = StructOne({a: ""ok"", b: [4,5,6]})
    self.b = [7, 8]
    self.c = b""thisisthirtytwobytesokhowdoyoudo""
    self.d = [-1, -2, -3, -4]
    self.e = ""A realllllly long string but we wont use it all""
    self.f = [33]
    self.g = [
        StructTwo({a: b""hello"", b: [-66, 420], c: ""another string""}),
        StructTwo({
            a: b""gbye"",
            b: [1337, 888],
            c: ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso""
        })
    ]
    self.dyn_array = [1, 2, 3]
    self.h =  [123456789]
    self.foo[0] = [987, 654, 321]
    self.foo[1] = [123, 456, 789]

@external
@nonreentrant('lock')
def with_lock():
    pass


@external
@nonreentrant('otherlock')
def with_other_lock():
    pass
""""""


def test_storage_slots(get_contract):
    c = get_contract(code)
    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789


def test_reentrancy_lock(get_contract):
    c = get_contract(code)

    # if re-entrancy locks are incorrectly placed within storage, these
    # calls will either revert or correupt the data that we read later
    c.with_lock()
    c.with_other_lock()

    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789
",CWE-789,100.0,1
"code = """"""

struct StructOne:
    a: String[33]
    b: uint256[3]

struct StructTwo:
    a: Bytes[5]
    b: int128[2]
    c: String[64]

a: public(StructOne)
b: public(uint256[2])
c: public(Bytes[32])
d: public(int128[4])
foo: public(HashMap[uint256, uint256[3]])
dyn_array: DynArray[uint256, 3]
e: public(String[47])
f: public(int256[1])
g: public(StructTwo[2])
h: public(int256[1])


@external
def __init__():
    self.a = StructOne({a: ""ok"", b: [4,5,6]})
    self.b = [7, 8]
    self.c = b""thisisthirtytwobytesokhowdoyoudo""
    self.d = [-1, -2, -3, -4]
    self.e = ""A realllllly long string but we wont use it all""
    self.f = [33]
    self.g = [
        StructTwo({a: b""hello"", b: [-66, 420], c: ""another string""}),
        StructTwo({
            a: b""gbye"",
            b: [1337, 888],
            c: ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso""
        })
    ]
    self.dyn_array = [1, 2, 3]
    self.h =  [123456789]
    self.foo[0] = [987, 654, 321]
    self.foo[1] = [123, 456, 789]

@external
@nonreentrant('lock')
def with_lock():
    pass


@external
@nonreentrant('otherlock')
def with_other_lock():
    pass
""""""


def test_storage_slots(get_contract):
    c = get_contract(code)
    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789


def test_reentrancy_lock(get_contract):
    c = get_contract(code)

    # if re-entrancy locks are incorrectly placed within storage, these
    # calls will either revert or correupt the data that we read later
    c.with_lock()
    c.with_other_lock()

    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789
",CWE-682,100.0,1
"code = """"""

struct StructOne:
    a: String[33]
    b: uint256[3]

struct StructTwo:
    a: Bytes[5]
    b: int128[2]
    c: String[64]

a: public(StructOne)
b: public(uint256[2])
c: public(Bytes[32])
d: public(int128[4])
foo: public(HashMap[uint256, uint256[3]])
dyn_array: DynArray[uint256, 3]
e: public(String[47])
f: public(int256[1])
g: public(StructTwo[2])
h: public(int256[1])


@external
def __init__():
    self.a = StructOne({a: ""ok"", b: [4,5,6]})
    self.b = [7, 8]
    self.c = b""thisisthirtytwobytesokhowdoyoudo""
    self.d = [-1, -2, -3, -4]
    self.e = ""A realllllly long string but we wont use it all""
    self.f = [33]
    self.g = [
        StructTwo({a: b""hello"", b: [-66, 420], c: ""another string""}),
        StructTwo({
            a: b""gbye"",
            b: [1337, 888],
            c: ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso""
        })
    ]
    self.dyn_array = [1, 2, 3]
    self.h =  [123456789]
    self.foo[0] = [987, 654, 321]
    self.foo[1] = [123, 456, 789]

@external
@nonreentrant('lock')
def with_lock():
    pass


@external
@nonreentrant('otherlock')
def with_other_lock():
    pass
""""""


def test_storage_slots(get_contract):
    c = get_contract(code)
    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789


def test_reentrancy_lock(get_contract):
    c = get_contract(code)

    # if re-entrancy locks are incorrectly placed within storage, these
    # calls will either revert or correupt the data that we read later
    c.with_lock()
    c.with_other_lock()

    assert c.a() == (""ok"", [4, 5, 6])
    assert [c.b(i) for i in range(2)] == [7, 8]
    assert c.c() == b""thisisthirtytwobytesokhowdoyoudo""
    assert [c.d(i) for i in range(4)] == [-1, -2, -3, -4]
    assert c.e() == ""A realllllly long string but we wont use it all""
    assert c.f(0) == 33
    assert c.g(0) == (b""hello"", [-66, 420], ""another string"")
    assert c.g(1) == (
        b""gbye"",
        [1337, 888],
        ""whatifthisstringtakesuptheentirelengthwouldthatbesobadidothinkso"",
    )
    assert [c.foo(0, i) for i in range(3)] == [987, 654, 321]
    assert [c.foo(1, i) for i in range(3)] == [123, 456, 789]
    assert c.h(0) == 123456789
",CWE-193,100.0,1
"import pytest

from vyper import compiler
from vyper.exceptions import InvalidType, StructureException

fail_list = [
    """"""
x[5] = 4
    """""",
    """"""
send(0x1234567890123456789012345678901234567890, 5)
    """""",
    """"""
send(0x1234567890123456789012345678901234567890, 5)
    """""",
    """"""
x: [bar, baz]
    """""",
    """"""
x: [bar(int128), baz(baffle)]
    """""",
    """"""
x: int128
@external
@view(123)
def foo() -> int128:
    pass
    """""",
    """"""
@external
def foo():
    throe
    """""",
    """"""
@external
def foo() -> int128:
    x: address = 0x1234567890123456789012345678901234567890
    return x.balance()
    """""",
    """"""
@external
def foo() -> int128:
    x: address = 0x1234567890123456789012345678901234567890
    return x.codesize()
    """""",
    """"""
@external
@nonreentrant(""B"")
@nonreentrant(""C"")
def double_nonreentrant():
    pass
    """""",
    """"""
struct X:
    int128[5]: int128[7]
    """""",
    """"""
@external
@nonreentrant(""B"")
@nonreentrant(""C"")
def double_nonreentrant():
    pass
    """""",
    """"""
@external
def foo():
    true: int128 = 3
    """""",
    """"""
n: HashMap[uint256, bool][3]
    """""",
    """"""
a: constant(uint256) = 3
n: public(HashMap[uint256, uint256][a])
    """""",
    """"""
a: immutable(uint256)
n: public(HashMap[uint256, bool][a])

@external
def __init__():
    a = 3
    """""",
    """"""
n: HashMap[uint256, bool][3][3]
    """""",
    """"""
m1: HashMap[uint8, uint8]
m2: HashMap[uint8, uint8]

@external
def __init__():
    self.m1 = self.m2
    """""",
    """"""
m1: HashMap[uint8, uint8]

@external
def __init__():
    self.m1 = 234
    """""",
]


@pytest.mark.parametrize(""bad_code"", fail_list)
def test_invalid_type_exception(bad_code):
    with pytest.raises((StructureException, InvalidType)):
        compiler.compile_code(bad_code)


del_fail_list = [
    """"""
x: int128(address)
    """""",
    """"""
x: int128(2 ** 2)
    """""",
    """"""
# invalid interface declaration (pass)
interface Bar:
    def set_lucky(arg1: int128): pass
    """""",
    """"""
interface Bar:
# invalud interface declaration (assignment)
    def set_lucky(arg1: int128):
        arg1 = 1
        arg1 = 3
    """""",
]
",CWE-667,131.0,1
"import random
import string

import hypothesis.strategies as st
import pytest
from hypothesis import given, settings

import vyper.ast as vy_ast
from vyper.compiler.phases import CompilerData
from vyper.semantics.namespace import RESERVED_KEYWORDS


def _valid_identifier(attr):
    return attr not in RESERVED_KEYWORDS


# random names for functions
@settings(max_examples=20, deadline=None)
@given(
    st.lists(
        st.tuples(
            st.sampled_from([""@pure"", ""@view"", ""@nonpayable"", ""@payable""]),
            st.text(alphabet=string.ascii_lowercase, min_size=1).filter(_valid_identifier),
        ),
        unique_by=lambda x: x[1],  # unique on function name
        min_size=1,
        max_size=10,
    )
)
@pytest.mark.fuzzing
def test_call_graph_stability_fuzz(funcs):
    def generate_func_def(mutability, func_name, i):
        return f""""""
@internal
{mutability}
def {func_name}() -> uint256:
    return {i}
        """"""

    func_defs = ""\n"".join(generate_func_def(m, s, i) for i, (m, s) in enumerate(funcs))

    for _ in range(10):
        func_names = [f for (_, f) in funcs]
        random.shuffle(func_names)

        self_calls = ""\n"".join(f""  self.{f}()"" for f in func_names)
        code = f""""""
{func_defs}

@external
def foo():
{self_calls}
        """"""
        t = CompilerData(code)

        # check the .called_functions data structure on foo() directly
        foo = t.vyper_module_folded.get_children(vy_ast.FunctionDef, filters={""name"": ""foo""})[0]
        foo_t = foo._metadata[""type""]
        assert [f.name for f in foo_t.called_functions] == func_names

        # now for sanity, ensure the order that the function definitions appear
        # in the IR is the same as the order of the calls
        sigs = t.function_signatures
        del sigs[""foo""]
        ir = t.ir_runtime
        ir_funcs = []
        # search for function labels
        for d in ir.args:  # currently: (seq ... (seq (label foo ...)) ...)
            if d.value == ""seq"" and d.args[0].value == ""label"":
                r = d.args[0].args[0].value
                if isinstance(r, str) and r.startswith(""internal""):
                    ir_funcs.append(r)
        assert ir_funcs == [
            f._ir_info.internal_function_label(is_ctor_context=False) for f in sigs.values()
        ]
",CWE-667,76.0,1
"import pytest

from vyper.ast.folding import BUILTIN_CONSTANTS
from vyper.builtins.functions import BUILTIN_FUNCTIONS
from vyper.codegen.expr import ENVIRONMENT_VARIABLES
from vyper.exceptions import NamespaceCollision, StructureException, SyntaxException
from vyper.semantics.namespace import RESERVED_KEYWORDS
from vyper.semantics.types.primitives import AddressT

BUILTIN_CONSTANTS = set(BUILTIN_CONSTANTS.keys())
ALL_RESERVED_KEYWORDS = (
    BUILTIN_CONSTANTS | BUILTIN_FUNCTIONS | RESERVED_KEYWORDS | ENVIRONMENT_VARIABLES
)


@pytest.mark.parametrize(""constant"", sorted(ALL_RESERVED_KEYWORDS))
def test_reserved_keywords_memory(constant, get_contract, assert_compile_failed):
    code = f""""""
@external
def test():
    {constant}: int128 = 31337
    """"""
    assert_compile_failed(
        lambda: get_contract(code), (SyntaxException, StructureException, NamespaceCollision)
    )


@pytest.mark.parametrize(""constant"", sorted(ALL_RESERVED_KEYWORDS))
def test_reserved_keywords_storage(constant, get_contract, assert_compile_failed):
    code = f""{constant}: int128""
    assert_compile_failed(
        lambda: get_contract(code), (SyntaxException, StructureException, NamespaceCollision)
    )


@pytest.mark.parametrize(""constant"", sorted(ALL_RESERVED_KEYWORDS))
def test_reserved_keywords_fn_args(constant, get_contract, assert_compile_failed):
    code = f""""""
@external
def test({constant}: int128):
    pass
    """"""
    assert_compile_failed(
        lambda: get_contract(code), (SyntaxException, StructureException, NamespaceCollision)
    )


SELF_NAMESPACE_MEMBERS = set(AddressT._type_members.keys())
DISALLOWED_FN_NAMES = SELF_NAMESPACE_MEMBERS | RESERVED_KEYWORDS | BUILTIN_CONSTANTS
ALLOWED_FN_NAMES = ALL_RESERVED_KEYWORDS - DISALLOWED_FN_NAMES


@pytest.mark.parametrize(""constant"", sorted(ALLOWED_FN_NAMES))
def test_reserved_keywords_fns_pass(constant, get_contract, assert_compile_failed):
    code = f""""""
@external
def {constant}(var: int128):
    pass
    """"""
    assert get_contract(code) is not None


@pytest.mark.parametrize(""constant"", sorted(DISALLOWED_FN_NAMES))
def test_reserved_keywords_fns_fail(constant, get_contract, assert_compile_failed):
    code = f""""""
@external
def {constant}(var: int128):
    pass
    """"""
    assert_compile_failed(
        lambda: get_contract(code), (SyntaxException, StructureException, NamespaceCollision)
    )
",CWE-667,73.0,1
,CWE-667,,1
"import contextlib
import re

from vyper.exceptions import (
    CompilerPanic,
    NamespaceCollision,
    StructureException,
    UndeclaredDefinition,
)
from vyper.semantics.analysis.levenshtein_utils import get_levenshtein_error_suggestions


class Namespace(dict):
    """"""
    Dictionary subclass that represents the namespace of a contract.

    Attributes
    ----------
    _scopes : List[Set]
        List of sets containing the key names for each scope
    """"""

    def __new__(cls, *args, **kwargs):
        self = super().__new__(cls, *args, **kwargs)
        self._scopes = []
        return self

    def __init__(self):
        super().__init__()
        # NOTE cyclic imports!
        # TODO: break this cycle by providing an `init_vyper_namespace` in 3rd module
        from vyper.builtins.functions import get_builtin_functions
        from vyper.semantics import environment
        from vyper.semantics.analysis.base import VarInfo
        from vyper.semantics.types import PRIMITIVE_TYPES

        self.update(PRIMITIVE_TYPES)
        self.update(environment.get_constant_vars())
        self.update({k: VarInfo(b) for (k, b) in get_builtin_functions().items()})

    def __eq__(self, other):
        return self is other

    def __setitem__(self, attr, obj):
        if self._scopes:
            self.validate_assignment(attr)
            self._scopes[-1].add(attr)
        assert isinstance(attr, str), f""not a string: {attr}""
        super().__setitem__(attr, obj)

    def __getitem__(self, key):
        if key not in self:
            suggestions_str = get_levenshtein_error_suggestions(key, self, 0.2)
            raise UndeclaredDefinition(f""'{key}' has not been declared. {suggestions_str}"")
        return super().__getitem__(key)

    def __enter__(self):
        if not self._scopes:
            raise CompilerPanic(""Context manager must be invoked via namespace.enter_scope()"")

    def __exit__(self, exc_type, exc_value, traceback):
        if not self._scopes:
            raise CompilerPanic(""Bad use of namespace as a context manager"")
        for key in self._scopes.pop():
            del self[key]

    def enter_scope(self):
        """"""
        Enter a new scope within the namespace.

        Called as a context manager, e.g. `with namespace.enter_scope():`
        All items that are added within the context are removed upon exit.
        """"""
        # NOTE cyclic imports!
        from vyper.semantics import environment

        self._scopes.append(set())

        if len(self._scopes) == 1:
            # add mutable vars (`self`) to the initial scope
            self.update(environment.get_mutable_vars())

        return self

    def update(self, other):
        for key, value in other.items():
            self.__setitem__(key, value)

    def clear(self):
        super().clear()
        self.__init__()

    def validate_assignment(self, attr):
        validate_identifier(attr)

        if attr in self:
            obj = super().__getitem__(attr)
            raise NamespaceCollision(f""'{attr}' has already been declared as a {obj}"")


def get_namespace():
    """"""
    Get the active namespace object.
    """"""
    global _namespace
    try:
        return _namespace
    except NameError:
        _namespace = Namespace()
        return _namespace


@contextlib.contextmanager
def override_global_namespace(ns):
    global _namespace
    tmp = _namespace
    try:
        # clobber global namespace
        _namespace = ns
        yield
    finally:
        # unclobber
        _namespace = tmp


def validate_identifier(attr):
    if not re.match(""^[_a-zA-Z][a-zA-Z0-9_]*$"", attr):
        raise StructureException(f""'{attr}' contains invalid character(s)"")
    if attr.lower() in RESERVED_KEYWORDS:
        raise StructureException(f""'{attr}' is a reserved keyword"")


# https://docs.python.org/3/reference/lexical_analysis.html#keywords
# note we don't technically need to block all python reserved keywords,
# but do it for hygiene
_PYTHON_RESERVED_KEYWORDS = {
    ""False"",
    ""None"",
    ""True"",
    ""and"",
    ""as"",
    ""assert"",
    ""async"",
    ""await"",
    ""break"",
    ""class"",
    ""continue"",
    ""def"",
    ""del"",
    ""elif"",
    ""else"",
    ""except"",
    ""finally"",
    ""for"",
    ""from"",
    ""global"",
    ""if"",
    ""import"",
    ""in"",
    ""is"",
    ""lambda"",
    ""nonlocal"",
    ""not"",
    ""or"",
    ""pass"",
    ""raise"",
    ""return"",
    ""try"",
    ""while"",
    ""with"",
    ""yield"",
}
_PYTHON_RESERVED_KEYWORDS = {s.lower() for s in _PYTHON_RESERVED_KEYWORDS}

# Cannot be used for variable or member naming
RESERVED_KEYWORDS = _PYTHON_RESERVED_KEYWORDS | {
    # decorators
    ""public"",
    ""external"",
    ""nonpayable"",
    ""constant"",
    ""immutable"",
    ""transient"",
    ""internal"",
    ""payable"",
    ""nonreentrant"",
    # ""class"" keywords
    ""interface"",
    ""struct"",
    ""event"",
    ""enum"",
    # EVM operations
    ""unreachable"",
    # special functions (no name mangling)
    ""init"",
    ""_init_"",
    ""___init___"",
    ""____init____"",
    ""default"",
    ""_default_"",
    ""___default___"",
    ""____default____"",
    # more control flow and special operations
    ""range"",
    # more special operations
    ""indexed"",
    # denominations
    ""ether"",
    ""wei"",
    ""finney"",
    ""szabo"",
    ""shannon"",
    ""lovelace"",
    ""ada"",
    ""babbage"",
    ""gwei"",
    ""kwei"",
    ""mwei"",
    ""twei"",
    ""pwei"",
    # sentinal constant values
    # TODO remove when these are removed from the language
    ""zero_address"",
    ""empty_bytes32"",
    ""max_int128"",
    ""min_int128"",
    ""max_decimal"",
    ""min_decimal"",
    ""max_uint256"",
    ""zero_wei"",
}
",CWE-667,232.0,1
"import re
from typing import Iterator, Union, TextIO, Optional, List, Set

from irrd.conf import PASSWORD_HASH_DUMMY_VALUE
from irrd.rpsl.passwords import PASSWORD_HASHERS_ALL

re_remove_passwords = re.compile(r'(%s)[^\n]+' % '|'.join(PASSWORD_HASHERS_ALL.keys()), flags=re.IGNORECASE)
re_remove_last_modified = re.compile(r'^last-modified: [^\n]+\n', flags=re.MULTILINE)


def remove_auth_hashes(input: Optional[str]):
    if not input:
        return input
    # If there are no hashes, skip the RE for performance.
    if not any([pw_hash in input for pw_hash in PASSWORD_HASHERS_ALL.keys()]):
        return input
    return re_remove_passwords.sub(r'\1 %s  # Filtered for security' % PASSWORD_HASH_DUMMY_VALUE, input)


def remove_last_modified(rpsl_text: str):
    """"""
    Remove all last-modified attributes from an RPSL text with less overhead
    than using the full RPSL parser.
    Assumes the last-modified value is single line. This is a safe assumption
    when the input is guaranteed to have been generated by IRRd.
    """"""
    return re_remove_last_modified.sub('', rpsl_text)


def splitline_unicodesafe(input: str) -> Iterator[str]:
    """"""
    Split an input string by newlines, and return an iterator of the lines.

    This is a replacement for Python's built-in splitlines, which also splits
    on characters such as unicode line separator (U+2028). In RPSL, that should
    not be considered a line separator.
    """"""
    if not input:
        return
    for line in input.strip('\n').split('\n'):
        yield line.strip('\r')


def split_paragraphs_rpsl(input: Union[str, TextIO], strip_comments=True) -> Iterator[str]:
    """"""
    Split an input into paragraphs, and return an iterator of the paragraphs.

    A paragraph is a block of text, separated by at least one empty line.
    Note that a line with other whitespace, e.g. a space, is not considered
    empty.

    If strip_comments=True, any line starting with % or # is entirely ignored,
    both within a paragraph and between paragraphs.
    """"""
    current_paragraph = ''
    if isinstance(input, str):
        generator = splitline_unicodesafe(input)
    else:
        generator = input

    for line in generator:
        line = line.strip('\r\n')
        if strip_comments and line.startswith('%') or line.startswith('#'):
            continue
        if line:
            current_paragraph += line + '\n'
        if not line:
            if current_paragraph:
                yield current_paragraph
            current_paragraph = ''

    if current_paragraph.strip():
        yield current_paragraph


def snake_to_camel_case(snake: Union[Set[str], List[str], str]):
    """"""
    Convert a snake case string to camel case, with lowercase first
    letter. Can also accept a list or set of strings.
    """"""
    def _str_to_camel_case(snake_str: str):
        components = snake_str.replace('_', '-').split('-')
        return components[0] + ''.join(x.title() for x in components[1:])

    if isinstance(snake, (set, list)):
        return [_str_to_camel_case(s) for s in snake]
    return _str_to_camel_case(snake)


# Turn ""IP('193.0.1.1/21') has invalid prefix length (21)"" into ""invalid prefix length (21)""
re_clean_ip_error = re.compile(r""IP\('[A-F0-9:./]+'\) has "", re.IGNORECASE)


def clean_ip_value_error(value_error):
    return re.sub(re_clean_ip_error, '', str(value_error))
",CWE-212,96.0,1
"import base64
import logging
import pathlib
import uuid

from django.conf import settings
from django.utils.functional import cached_property
from storages.utils import safe_join

from s3file.storages import storage

logger = logging.getLogger(""s3file"")


class S3FileInputMixin:
    """"""FileInput that uses JavaScript to directly upload to Amazon S3.""""""

    needs_multipart_form = False
    upload_path = str(
        getattr(settings, ""S3FILE_UPLOAD_PATH"", pathlib.PurePosixPath(""tmp"", ""s3file""))
    )
    upload_path = safe_join(str(storage.location), upload_path)
    expires = settings.SESSION_COOKIE_AGE

    @property
    def bucket_name(self):
        return storage.bucket.name

    @property
    def client(self):
        return storage.connection.meta.client

    def build_attrs(self, *args, **kwargs):
        attrs = super().build_attrs(*args, **kwargs)

        accept = attrs.get(""accept"")
        response = self.client.generate_presigned_post(
            self.bucket_name,
            str(pathlib.PurePosixPath(self.upload_folder, ""${filename}"")),
            Conditions=self.get_conditions(accept),
            ExpiresIn=self.expires,
        )

        defaults = {
            ""data-fields-%s"" % key: value for key, value in response[""fields""].items()
        }
        defaults[""data-url""] = response[""url""]
        defaults.update(attrs)

        try:
            defaults[""class""] += "" s3file""
        except KeyError:
            defaults[""class""] = ""s3file""
        return defaults

    def get_conditions(self, accept):
        conditions = [
            {""bucket"": self.bucket_name},
            [""starts-with"", ""$key"", str(self.upload_folder)],
            {""success_action_status"": ""201""},
        ]
        if accept and "","" not in accept:
            top_type, sub_type = accept.split(""/"", 1)
            if sub_type == ""*"":
                conditions.append([""starts-with"", ""$Content-Type"", ""%s/"" % top_type])
            else:
                conditions.append({""Content-Type"": accept})
        else:
            conditions.append([""starts-with"", ""$Content-Type"", """"])

        return conditions

    @cached_property
    def upload_folder(self):
        return str(
            pathlib.PurePosixPath(
                self.upload_path,
                base64.urlsafe_b64encode(uuid.uuid4().bytes)
                .decode(""utf-8"")
                .rstrip(""=\n""),
            )
        )  # S3 uses POSIX paths

    class Media:
        js = (""s3file/js/s3file.js"" if settings.DEBUG else ""s3file/js/s3file.min.js"",)
",CWE-22,86.0,1
"import logging
import pathlib

from s3file.storages import local_dev, storage

from . import views

logger = logging.getLogger(""s3file"")


class S3FileMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        file_fields = request.POST.getlist(""s3file"")
        for field_name in file_fields:
            paths = request.POST.getlist(field_name)
            request.FILES.setlist(field_name, list(self.get_files_from_storage(paths)))

        if local_dev and request.path == ""/__s3_mock__/"":
            return views.S3MockView.as_view()(request)

        return self.get_response(request)

    @staticmethod
    def get_files_from_storage(paths):
        """"""Return S3 file where the name does not include the path.""""""
        for path in paths:
            path = pathlib.PurePosixPath(path)
            try:
                location = storage.aws_location
            except AttributeError:
                location = storage.location
            try:
                f = storage.open(str(path.relative_to(location)))
                f.name = path.name
                yield f
            except (OSError, ValueError):
                logger.exception(""File not found: %s"", path)
",CWE-22,41.0,1
"import base64
import hashlib
import hmac
import logging

from django import http
from django.conf import settings
from django.core.files.storage import default_storage
from django.views import generic

logger = logging.getLogger(""s3file"")


class S3MockView(generic.View):
    def post(self, request):
        success_action_status = request.POST.get(""success_action_status"", 201)
        try:
            file = request.FILES[""file""]
            key = request.POST[""key""]
            date = request.POST[""x-amz-date""]
            signature = request.POST[""x-amz-signature""]
            policy = request.POST[""policy""]
        except KeyError:
            logger.exception(""bad request"")
            return http.HttpResponseBadRequest()

        try:
            signature = base64.b64decode(signature.encode())
            policy = base64.b64decode(policy.encode())

            calc_sign = hmac.new(
                settings.SECRET_KEY.encode(), policy + date.encode(), ""sha256""
            ).digest()
        except ValueError:
            logger.exception(""bad request"")
            return http.HttpResponseBadRequest()

        if not hmac.compare_digest(signature, calc_sign):
            logger.warning(""bad signature"")
            return http.HttpResponseForbidden()

        key = key.replace(""${filename}"", file.name)
        etag = hashlib.md5(file.read()).hexdigest()  # nosec
        file.seek(0)
        key = default_storage.save(key, file)
        return http.HttpResponse(
            '<?xml version=""1.0"" encoding=""UTF-8""?>'
            ""<PostResponse>""
            f""<Location>{settings.MEDIA_URL}{key}</Location>""
            f""<Bucket>{getattr(settings, 'AWS_STORAGE_BUCKET_NAME')}</Bucket>""
            f""<Key>{key}</Key>""
            f'<ETag>""{etag}""</ETag>'
            ""</PostResponse>"",
            status=success_action_status,
        )
",CWE-22,56.0,1
"import os
import tempfile

import pytest
from django.core.files.base import ContentFile
from django.utils.encoding import force_str
from selenium import webdriver
from selenium.common.exceptions import WebDriverException


@pytest.fixture(scope=""session"")
def driver():
    chrome_options = webdriver.ChromeOptions()
    chrome_options.headless = True
    try:
        b = webdriver.Chrome(options=chrome_options)
    except WebDriverException as e:
        pytest.skip(force_str(e))
    else:
        yield b
        b.quit()


@pytest.fixture
def upload_file(request):
    path = tempfile.mkdtemp()
    file_name = os.path.join(path, ""%s.txt"" % request.node.name)
    with open(file_name, ""w"") as f:
        f.write(request.node.name)
    return file_name


@pytest.fixture
def another_upload_file(request):
    path = tempfile.mkdtemp()
    file_name = os.path.join(path, ""another_%s.txt"" % request.node.name)
    with open(file_name, ""w"") as f:
        f.write(request.node.name)
    return file_name


@pytest.fixture
def yet_another_upload_file(request):
    path = tempfile.mkdtemp()
    file_name = os.path.join(path, ""yet_another_%s.txt"" % request.node.name)
    with open(file_name, ""w"") as f:
        f.write(request.node.name)
    return file_name


@pytest.fixture
def filemodel(request, db):
    from tests.testapp.models import FileModel

    return FileModel.objects.create(
        file=ContentFile(request.node.name, ""%s.txt"" % request.node.name)
    )
",CWE-22,58.0,1
"import os

from django.core.files.base import ContentFile
from django.core.files.uploadedfile import SimpleUploadedFile

from s3file.middleware import S3FileMiddleware
from s3file.storages import storage


class TestS3FileMiddleware:
    def test_get_files_from_storage(self):
        content = b""test_get_files_from_storage""
        name = storage.save(
            ""tmp/s3file/test_get_files_from_storage"", ContentFile(content)
        )
        files = S3FileMiddleware.get_files_from_storage(
            [os.path.join(storage.aws_location, name)]
        )
        file = next(files)
        assert file.read() == content

    def test_process_request(self, rf):
        uploaded_file = SimpleUploadedFile(""uploaded_file.txt"", b""uploaded"")
        request = rf.post(""/"", data={""file"": uploaded_file})
        S3FileMiddleware(lambda x: None)(request)
        assert request.FILES.getlist(""file"")
        assert request.FILES.get(""file"").read() == b""uploaded""

        storage.save(""tmp/s3file/s3_file.txt"", ContentFile(b""s3file""))
        request = rf.post(
            ""/"",
            data={
                ""file"": ""custom/location/tmp/s3file/s3_file.txt"",
                ""s3file"": ""file"",
            },
        )
        S3FileMiddleware(lambda x: None)(request)
        assert request.FILES.getlist(""file"")
        assert request.FILES.get(""file"").read() == b""s3file""

    def test_process_request__multiple_files(self, rf):
        storage.save(""tmp/s3file/s3_file.txt"", ContentFile(b""s3file""))
        storage.save(""tmp/s3file/s3_other_file.txt"", ContentFile(b""other s3file""))
        request = rf.post(
            ""/"",
            data={
                ""file"": [
                    ""custom/location/tmp/s3file/s3_file.txt"",
                    ""custom/location/tmp/s3file/s3_other_file.txt"",
                ],
                ""s3file"": [""file"", ""other_file""],
            },
        )
        S3FileMiddleware(lambda x: None)(request)
        files = request.FILES.getlist(""file"")
        assert files[0].read() == b""s3file""
        assert files[1].read() == b""other s3file""

    def test_process_request__no_location(self, rf, settings):
        settings.AWS_LOCATION = """"
        uploaded_file = SimpleUploadedFile(""uploaded_file.txt"", b""uploaded"")
        request = rf.post(""/"", data={""file"": uploaded_file})
        S3FileMiddleware(lambda x: None)(request)
        assert request.FILES.getlist(""file"")
        assert request.FILES.get(""file"").read() == b""uploaded""

        storage.save(""tmp/s3file/s3_file.txt"", ContentFile(b""s3file""))
        request = rf.post(
            ""/"", data={""file"": ""tmp/s3file/s3_file.txt"", ""s3file"": ""file""}
        )
        S3FileMiddleware(lambda x: None)(request)
        assert request.FILES.getlist(""file"")
        assert request.FILES.get(""file"").read() == b""s3file""

    def test_process_request__no_file(self, rf, caplog):
        request = rf.post(""/"", data={""file"": ""does_not_exist.txt"", ""s3file"": ""file""})
        S3FileMiddleware(lambda x: None)(request)
        assert not request.FILES.getlist(""file"")
        assert ""File not found: does_not_exist.txt"" in caplog.text
",CWE-22,80.0,1
"from django.contrib import admin

from .models import MFAKey


@admin.register(MFAKey)
class MFAKeyAdmin(admin.ModelAdmin):
    list_display = ['name', 'user', 'method']
",CWE-287,9.0,1
,CWE-287,,1
"from django.contrib.auth.decorators import login_required
from django.contrib.auth.views import LogoutView
from django.http import HttpResponse
from django.urls import include
from django.urls import path

from mfa.decorators import public
from mfa.views import LoginView


def dummy(request):
    return HttpResponse(status=204)


urlpatterns = [
    path('', login_required(dummy)),
    path('login/', LoginView.as_view()),
    path('logout/', public(LogoutView.as_view(next_page='/'))),
    path('mfa/', include('mfa.urls', namespace='mfa')),
]
",CWE-287,21.0,1
"""""""Template filters for Fava.

All functions in this module will be automatically added as template filters.
""""""
from __future__ import annotations

import datetime
import os
import re
import unicodedata
from typing import Any
from typing import MutableMapping
from typing import TypeVar

import flask
from beancount.core import compare
from beancount.core import realization
from beancount.core.account import ACCOUNT_RE
from beancount.core.data import Directive
from beancount.core.inventory import Inventory
from beancount.core.number import Decimal
from beancount.core.number import ZERO

from fava.context import g
from fava.core.conversion import cost
from fava.core.conversion import cost_or_value as cost_or_value_without_context
from fava.core.conversion import units
from fava.core.tree import TreeNode
from fava.util.date import Interval

MappingValue = TypeVar(""MappingValue"")


def remove_keys(
    _dict: MutableMapping[str, MappingValue] | None, keys: list[str]
) -> MutableMapping[str, MappingValue]:
    """"""Remove keys from a dictionary.""""""
    if not _dict:
        return {}
    new = dict(_dict)
    for key in keys:
        try:
            del new[key]
        except KeyError:
            pass
    return new


def cost_or_value(
    inventory: Inventory, date: datetime.date | None = None
) -> Any:
    """"""Get the cost or value of an inventory.""""""
    return cost_or_value_without_context(
        inventory, g.conversion, g.ledger.price_map, date
    )


def format_currency(
    value: Decimal,
    currency: str | None = None,
    show_if_zero: bool = False,
    invert: bool = False,
) -> str:
    """"""Format a value using the derived precision for a specified currency.""""""
    if not value and not show_if_zero:
        return """"
    if value == ZERO:
        return g.ledger.format_decimal(ZERO, currency)
    if invert:
        value = -value
    return g.ledger.format_decimal(value, currency)


def format_date(date: datetime.date) -> str:
    """"""Format a date according to the current interval.""""""
    if g.interval is Interval.YEAR:
        return date.strftime(""%Y"")
    if g.interval is Interval.QUARTER:
        return f""{date.year}Q{(date.month - 1) // 3 + 1}""
    if g.interval is Interval.WEEK:
        return date.strftime(""%YW%W"")
    if g.interval is Interval.DAY:
        return date.strftime(""%Y-%m-%d"")
    assert g.interval is Interval.MONTH
    return date.strftime(""%b %Y"")


def hash_entry(entry: Directive) -> str:
    """"""Hash an entry.""""""
    return compare.hash_entry(entry)


def balance_children(account: realization.RealAccount) -> Inventory:
    """"""Compute the total balance of an account.""""""
    return realization.compute_balance(account)


def get_or_create(
    account: realization.RealAccount, account_name: str
) -> realization.RealAccount:
    """"""Get or create a child account.""""""
    if account.account == account_name:
        return account
    return realization.get_or_create(account, account_name)


FLAGS_TO_TYPES = {""*"": ""cleared"", ""!"": ""pending""}


def flag_to_type(flag: str) -> str:
    """"""Names for entry flags.""""""
    return FLAGS_TO_TYPES.get(flag, ""other"")


def should_show(account: TreeNode) -> bool:
    """"""Determine whether the account should be shown.""""""
    if not account.balance_children.is_empty() or any(
        should_show(a) for a in account.children
    ):
        return True
    ledger = g.ledger
    filtered = g.filtered
    if account.name not in ledger.accounts:
        return False
    fava_options = ledger.fava_options
    if not fava_options.show_closed_accounts and filtered.account_is_closed(
        account.name
    ):
        return False
    if (
        not fava_options.show_accounts_with_zero_balance
        and account.balance.is_empty()
    ):
        return False
    if (
        not fava_options.show_accounts_with_zero_transactions
        and not account.has_txns
    ):
        return False
    return True


def basename(file_path: str) -> str:
    """"""Return the basename of a filepath.""""""
    return unicodedata.normalize(""NFC"", os.path.basename(file_path))


def format_errormsg(message: str) -> str:
    """"""Match account names in error messages and insert HTML links for them.""""""
    match = re.search(ACCOUNT_RE, message)
    if not match:
        return message
    account = match.group()
    url = flask.url_for(""account"", name=account)
    return (
        message.replace(account, f'<a href=""{url}"">{account}</a>')
        .replace(""for '"", ""for "")
        .replace(""': "", "": "")
    )


def collapse_account(account_name: str) -> bool:
    """"""Return true if account should be collapsed.""""""
    collapse_patterns = g.ledger.fava_options.collapse_pattern
    return any(pattern.match(account_name) for pattern in collapse_patterns)


FILTERS = [
    balance_children,
    basename,
    collapse_account,
    cost,
    cost_or_value,
    cost_or_value,
    flag_to_type,
    format_currency,
    format_date,
    format_errormsg,
    get_or_create,
    hash_entry,
    remove_keys,
    should_show,
    units,
]
",CWE-79,185.0,1
"from .api_jwk import PyJWK, PyJWKSet
from .api_jws import (
    PyJWS,
    get_unverified_header,
    register_algorithm,
    unregister_algorithm,
)
from .api_jwt import PyJWT, decode, encode
from .exceptions import (
    DecodeError,
    ExpiredSignatureError,
    ImmatureSignatureError,
    InvalidAlgorithmError,
    InvalidAudienceError,
    InvalidIssuedAtError,
    InvalidIssuerError,
    InvalidKeyError,
    InvalidSignatureError,
    InvalidTokenError,
    MissingRequiredClaimError,
    PyJWKClientError,
    PyJWKError,
    PyJWKSetError,
    PyJWTError,
)
from .jwks_client import PyJWKClient

__version__ = ""2.3.0""

__title__ = ""PyJWT""
__description__ = ""JSON Web Token implementation in Python""
__url__ = ""https://pyjwt.readthedocs.io""
__uri__ = __url__
__doc__ = f""{__description__} <{__uri__}>""

__author__ = ""Jos Padilla""
__email__ = ""hello@jpadilla.com""

__license__ = ""MIT""
__copyright__ = ""Copyright 2015-2022 Jos Padilla""


__all__ = [
    ""PyJWS"",
    ""PyJWT"",
    ""PyJWKClient"",
    ""PyJWK"",
    ""PyJWKSet"",
    ""decode"",
    ""encode"",
    ""get_unverified_header"",
    ""register_algorithm"",
    ""unregister_algorithm"",
    # Exceptions
    ""DecodeError"",
    ""ExpiredSignatureError"",
    ""ImmatureSignatureError"",
    ""InvalidAlgorithmError"",
    ""InvalidAudienceError"",
    ""InvalidIssuedAtError"",
    ""InvalidIssuerError"",
    ""InvalidKeyError"",
    ""InvalidSignatureError"",
    ""InvalidTokenError"",
    ""MissingRequiredClaimError"",
    ""PyJWKClientError"",
    ""PyJWKError"",
    ""PyJWKSetError"",
    ""PyJWTError"",
]
",CWE-327,71.0,1
"import base64
import binascii
from typing import Any, Union

try:
    from cryptography.hazmat.primitives.asymmetric.ec import EllipticCurve
    from cryptography.hazmat.primitives.asymmetric.utils import (
        decode_dss_signature,
        encode_dss_signature,
    )
except ModuleNotFoundError:
    EllipticCurve = Any  # type: ignore


def force_bytes(value: Union[str, bytes]) -> bytes:
    if isinstance(value, str):
        return value.encode(""utf-8"")
    elif isinstance(value, bytes):
        return value
    else:
        raise TypeError(""Expected a string value"")


def base64url_decode(input: Union[str, bytes]) -> bytes:
    if isinstance(input, str):
        input = input.encode(""ascii"")

    rem = len(input) % 4

    if rem > 0:
        input += b""="" * (4 - rem)

    return base64.urlsafe_b64decode(input)


def base64url_encode(input: bytes) -> bytes:
    return base64.urlsafe_b64encode(input).replace(b""="", b"""")


def to_base64url_uint(val: int) -> bytes:
    if val < 0:
        raise ValueError(""Must be a positive integer"")

    int_bytes = bytes_from_int(val)

    if len(int_bytes) == 0:
        int_bytes = b""\x00""

    return base64url_encode(int_bytes)


def from_base64url_uint(val: Union[str, bytes]) -> int:
    if isinstance(val, str):
        val = val.encode(""ascii"")

    data = base64url_decode(val)
    return int.from_bytes(data, byteorder=""big"")


def number_to_bytes(num: int, num_bytes: int) -> bytes:
    padded_hex = ""%0*x"" % (2 * num_bytes, num)
    return binascii.a2b_hex(padded_hex.encode(""ascii""))


def bytes_to_number(string: bytes) -> int:
    return int(binascii.b2a_hex(string), 16)


def bytes_from_int(val: int) -> bytes:
    remaining = val
    byte_length = 0

    while remaining != 0:
        remaining >>= 8
        byte_length += 1

    return val.to_bytes(byte_length, ""big"", signed=False)


def der_to_raw_signature(der_sig: bytes, curve: EllipticCurve) -> bytes:
    num_bits = curve.key_size
    num_bytes = (num_bits + 7) // 8

    r, s = decode_dss_signature(der_sig)

    return number_to_bytes(r, num_bytes) + number_to_bytes(s, num_bytes)


def raw_to_der_signature(raw_sig: bytes, curve: EllipticCurve) -> bytes:
    num_bits = curve.key_size
    num_bytes = (num_bits + 7) // 8

    if len(raw_sig) != 2 * num_bytes:
        raise ValueError(""Invalid signature"")

    r = bytes_to_number(raw_sig[:num_bytes])
    s = bytes_to_number(raw_sig[num_bytes:])

    return encode_dss_signature(r, s)
",CWE-327,100.0,1
,CWE-327,,1
"# -*- coding: utf-8 -*-
#
# Configuration file for the Sphinx documentation builder.
#
# This file does only contain a selection of the most common options. For a
# full list see the documentation:
# http://www.sphinx-doc.org/en/master/config

# -- Path setup --------------------------------------------------------------

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
# import os
# import sys
# sys.path.insert(0, os.path.abspath('.'))


# -- Project information -----------------------------------------------------

project = u'lsquic'
copyright = u'2021, LiteSpeed Technologies'
author = u'LiteSpeed Technologies'

# The short X.Y version
version = u'3.0'
# The full version, including alpha/beta/rc tags
release = u'3.0.4'


# -- General configuration ---------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#
# needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
# To make ours look like readthedocs.io, change theme to ""sphinx_rtd_theme"",
# pip install sphinx_rtd_theme, and uncomment extensions:
#    ""sphinx.ext.intersphinx"",
#    ""sphinx.ext.autodoc"",
#    ""sphinx.ext.mathjax"",
#    ""sphinx.ext.viewcode"",
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix(es) of source filenames.
# You can specify multiple suffix as a list of string:
#
# source_suffix = ['.rst', '.md']
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#
# This is also used if you do content translation via gettext catalogs.
# Usually you set ""language"" from the command line for these cases.
language = None

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This pattern also affects html_static_path and html_extra_path.
exclude_patterns = [u'_build', 'Thumbs.db', '.DS_Store']

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = None

default_role = 'c:func'
primary_domain = 'c'


# -- Options for HTML output -------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#
#html_theme = 'alabaster'
html_style = '/default.css'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#
# html_theme_options = {}

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named ""default.css"" will overwrite the builtin ""default.css"".
html_static_path = ['_static']

# Custom sidebar templates, must be a dictionary that maps document names
# to template names.
#
# The default sidebars (for documents that don't match any pattern) are
# defined by theme itself.  Builtin themes are using these templates by
# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',
# 'searchbox.html']``.
#
# html_sidebars = {}


# -- Options for HTMLHelp output ---------------------------------------------

# Output file base name for HTML help builder.
htmlhelp_basename = 'lsquicdoc'


# -- Options for LaTeX output ------------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #
    # 'papersize': 'letterpaper',

    # The font size ('10pt', '11pt' or '12pt').
    #
    # 'pointsize': '10pt',

    # Additional stuff for the LaTeX preamble.
    #
    # 'preamble': '',

    # Latex figure (float) alignment
    #
    # 'figure_align': 'htbp',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
    (master_doc, 'lsquic.tex', u'lsquic Documentation',
     u'LiteSpeed Technologies', 'manual'),
]


# -- Options for manual page output ------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    (master_doc, 'lsquic', u'lsquic Documentation',
     [author], 1)
]


# -- Options for Texinfo output ----------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
    (master_doc, 'lsquic', u'lsquic Documentation',
     author, 'lsquic', 'One line description of project.',
     'Miscellaneous'),
]


# -- Options for Epub output -------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = project

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#
# epub_identifier = ''

# A unique identification for the text.
#
# epub_uid = ''

# A list of files that should not be packed into the epub file.
epub_exclude_files = ['search.html']
",CWE-476,184.0,1
"import re

import modules.db.sql as sql
import modules.server.server as server_mod
from modules.common.common import checkAjaxInput
from modules.common.common import form
import modules.roxy_wi_tools as roxy_wi_tools
import modules.roxywi.common as roxywi_common

get_config_var = roxy_wi_tools.GetConfigVar()


def roxy_wi_log(**kwargs) -> list:
	log_path = get_config_var.get_config_var('main', 'log_path')

	if kwargs.get('log_id'):
		selects = roxywi_common.get_files(log_path, ""log"")
		for key, value in selects:
			log_file = f""{kwargs.get('file')}.log""
			if log_file == value:
				return key
	else:
		user_group_id = roxywi_common.get_user_group(id=1)
		if user_group_id != 1:
			user_group = roxywi_common.get_user_group()
			group_grep = f'|grep ""group: {user_group}""'
		else:
			group_grep = ''
		cmd = f""find {log_path}/roxy-wi-* -type f -exec stat --format '%Y :%y %n' '{{}}' \; | sort -nr | cut -d: -f2- "" \
				f""| head -1 |awk '{{print $4}}' |xargs tail {group_grep}|sort -r""
		try:
			output, stderr = server_mod.subprocess_execute(cmd)
			return output
		except Exception:
			return ['']


def show_log(stdout, **kwargs):
	i = 0
	out = ''
	grep = ''

	if kwargs.get('grep'):
		grep = kwargs.get('grep')
		grep = re.sub(r'[?|$|.|!|^|*|\]|\[|,| |]', r'', grep)
	for line in stdout:
		i = i + 1
		if kwargs.get('grep'):
			line = line.replace(grep, f'<span style=""color: red; font-weight: bold;"">{grep}</span>')
		line_class = ""line3"" if i % 2 == 0 else ""line""
		out += f'<div class=""{line_class}"">{line}</div>'

	return out


def show_roxy_log(
		serv, rows='10', waf='0', grep=None, hour='00',
		minut='00', hour1='24', minut1='00', service='haproxy', **kwargs
) -> str:
	exgrep = form.getvalue('exgrep')
	log_file = form.getvalue('file')
	date = checkAjaxInput(hour) + ':' + checkAjaxInput(minut)
	date1 = checkAjaxInput(hour1) + ':' + checkAjaxInput(minut1)
	rows = checkAjaxInput(rows)
	waf = checkAjaxInput(waf)
	cmd = ''
	awk_column = 3

	if grep is not None:
		grep_act = '|egrep ""%s""' % checkAjaxInput(grep)
	else:
		grep_act = ''

	if exgrep is not None:
		exgrep_act = '|egrep -v ""%s""' % checkAjaxInput(exgrep)
	else:
		exgrep_act = ''

	log_file = checkAjaxInput(log_file) if log_file is not None else log_file

	if service in ('nginx', 'haproxy', 'apache', 'keepalived'):
		syslog_server_enable = sql.get_setting('syslog_server_enable')
		if syslog_server_enable is None or syslog_server_enable == 0:
			if service == 'nginx':
				local_path_logs = sql.get_setting('nginx_path_logs')
				commands = [""sudo cat %s/%s |tail -%s %s %s"" % (local_path_logs, log_file, rows, grep_act, exgrep_act)]
			elif service == 'apache':
				local_path_logs = sql.get_setting('apache_path_logs')
				commands = [
					""sudo cat %s/%s| awk -F\""/|:\"" '$3>\""%s:00\"" && $3<\""%s:00\""' |tail -%s %s %s"" % (local_path_logs, log_file, date, date1, rows, grep_act, exgrep_act)
				]
			elif service == 'keepalived':
				local_path_logs = sql.get_setting('keepalived_path_logs')
				commands = [
					""sudo cat %s/%s| awk '$3>\""%s:00\"" && $3<\""%s:00\""' |tail -%s %s %s"" % (
						local_path_logs, log_file, date, date1, rows, grep_act, exgrep_act)
				]
			else:
				local_path_logs = sql.get_setting('haproxy_path_logs')
				commands = [""sudo cat %s/%s| awk '$3>\""%s:00\"" && $3<\""%s:00\""' |tail -%s %s %s"" % (local_path_logs, log_file, date, date1, rows, grep_act, exgrep_act)]
			syslog_server = serv
		else:
			commands = [""sudo cat /var/log/%s/syslog.log | sed '/ %s:00/,/ %s:00/! d' |tail -%s %s %s %s"" % (serv, date, date1, rows, grep_act, grep, exgrep_act)]
			syslog_server = sql.get_setting('syslog_server')

		if waf == ""1"":
			local_path_logs = '/var/log/waf.log'
			commands = [""sudo cat %s |tail -%s %s %s"" % (local_path_logs, rows, grep_act, exgrep_act)]
		if kwargs.get('html') == 0:
			a = server_mod.ssh_command(syslog_server, commands)
			return show_log(a, html=0, grep=grep)
		else:
			return server_mod.ssh_command(syslog_server, commands, show_log='1', grep=grep, timeout=10)
	elif service == 'apache_internal':
		apache_log_path = sql.get_setting('apache_log_path')

		if serv == 'roxy-wi.access.log':
			cmd = 'sudo cat {}| awk -F""/|:"" \'$3>""{}:00"" && $3<""{}:00""\' |tail -{} {} {}'.format(apache_log_path + ""/"" + serv, date, date1, rows, grep_act, exgrep_act)
		elif serv == 'roxy-wi.error.log':
			cmd = ""sudo cat {}| awk '$4>\""{}:00\"" && $4<\""{}:00\""' |tail -{} {} {}"".format(apache_log_path + ""/"" + serv, date, date1, rows, grep_act, exgrep_act)
		elif serv == 'fail2ban.log':
			cmd = 'sudo cat {}| awk -F""/|:"" \'$3>""{}:00"" && $3<""{}:00\' |tail -{} {} {}'.format(""/var/log/"" + serv, date, date1, rows, grep_act, exgrep_act)

		output, stderr = server_mod.subprocess_execute(cmd)

		return show_log(output, grep=grep)
	elif service == 'internal':
		log_path = get_config_var.get_config_var('main', 'log_path')
		logs_files = roxywi_common.get_files(log_path, ""log"")
		user_group = roxywi_common.get_user_group()
		user_grep = ''

		if user_group != '' and user_group != 'Default':
			user_grep = f""|grep 'group: {user_group}'""

		for key, value in logs_files:
			if int(serv) == key:
				serv = value
				break
		else:
			return 'Haha'

		if serv == 'backup.log':
			awk_column = 2

		cmd = f""cat {log_path}/{serv}| awk '${awk_column}>\""{date}:00\"" && ${awk_column}<\""{date1}:00\""' {user_grep} {grep_act} {exgrep_act} |tail -{rows}""

		output, stderr = server_mod.subprocess_execute(cmd)

		return show_log(output, grep=grep)
",CWE-668,151.0,1
"import os

import paramiko

import modules.db.sql as sql
import modules.common.common as common
from modules.server import ssh_connection
import modules.roxywi.common as roxywi_common
import modules.roxy_wi_tools as roxy_wi_tools

form = common.form
error_mess = common.error_mess
get_config = roxy_wi_tools.GetConfigVar()


def return_ssh_keys_path(server_ip: str, **kwargs) -> dict:
	lib_path = get_config.get_config_var('main', 'lib_path')
	ssh_settings = {}

	if kwargs.get('id'):
		sshs = sql.select_ssh(id=kwargs.get('id'))
	else:
		sshs = sql.select_ssh(serv=server_ip)

	for ssh in sshs:
		ssh_settings.setdefault('enabled', ssh.enable)
		ssh_settings.setdefault('user', ssh.username)
		ssh_settings.setdefault('password', ssh.password)
		ssh_key = f'{lib_path}/keys/{ssh.name}.pem' if ssh.enable == 1 else ''
		ssh_settings.setdefault('key', ssh_key)

	ssh_port = [str(server[10]) for server in sql.select_servers(server=server_ip)]
	ssh_settings.setdefault('port', ssh_port[0])

	return ssh_settings


def ssh_connect(server_ip):
	ssh_settings = return_ssh_keys_path(server_ip)
	ssh = ssh_connection.SshConnection(
		server_ip, ssh_settings['port'],
		ssh_settings['user'],
		ssh_settings['password'],
		ssh_settings['enabled'],
		ssh_settings['key']
	)

	return ssh


def create_ssh_cred() -> None:
	from jinja2 import Environment, FileSystemLoader

	user_group = roxywi_common.get_user_group()
	name = common.checkAjaxInput(form.getvalue('new_ssh'))
	name = f'{name}_{user_group}'
	enable = common.checkAjaxInput(form.getvalue('ssh_enable'))
	group = common.checkAjaxInput(form.getvalue('new_group'))
	username = common.checkAjaxInput(form.getvalue('ssh_user'))
	password = common.checkAjaxInput(form.getvalue('ssh_pass'))
	page = common.checkAjaxInput(form.getvalue('page'))
	page = page.split(""#"")[0]
	lang = roxywi_common.get_user_lang()

	if username is None or name is None:
		print(error_mess)
	else:
		if sql.insert_new_ssh(name, enable, group, username, password):
			env = Environment(loader=FileSystemLoader('templates/'), autoescape=True)
			template = env.get_template('ajax/new_ssh.html')
			output_from_parsed_template = template.render(groups=sql.select_groups(), sshs=sql.select_ssh(name=name), page=page, lang=lang)
			print(output_from_parsed_template)
			roxywi_common.logging('Roxy-WI server', f'New SSH credentials {name} has been created', roxywi=1, login=1)


def create_ssh_cread_api(name: str, enable: str, group: str, username: str, password: str) -> bool:
	groups = sql.select_groups(id=group)
	for group in groups:
		user_group = group.name
	name = common.checkAjaxInput(name)
	name = f'{name}_{user_group}'
	enable = common.checkAjaxInput(enable)
	username = common.checkAjaxInput(username)
	password = common.checkAjaxInput(password)

	if username is None or name is None:
		return False
	else:
		if sql.insert_new_ssh(name, enable, group, username, password):
			return True


def upload_ssh_key(name: str, user_group: str, key: str) -> bool:
	try:
		key = paramiko.pkey.load_private_key(key)
	except Exception as e:
		print(f'error: Cannot save SSH key file: {e}')
		return False

	lib_path = get_config.get_config_var('main', 'lib_path')
	full_dir = f'{lib_path}/keys/'
	ssh_keys = f'{name}.pem'

	try:
		_check_split = name.split('_')[1]
		split_name = True
	except Exception:
		split_name = False

	if not os.path.isfile(ssh_keys) and not split_name:
		name = f'{name}_{user_group}'

	if not os.path.exists(full_dir):
		os.makedirs(full_dir)

	ssh_keys = f'{full_dir}{name}.pem'

	try:
		key.write_private_key_file(ssh_keys)
	except Exception as e:
		print(f'error: Cannot save SSH key file: {e}')
		return False
	else:
		print(f'success: SSH key has been saved into: {ssh_keys}')

	try:
		os.chmod(ssh_keys, 0o600)
	except IOError as e:
		roxywi_common.logging('Roxy-WI server', e.args[0], roxywi=1)
		return False

	roxywi_common.logging(""Roxy-WI server"", f""A new SSH cert has been uploaded {ssh_keys}"", roxywi=1, login=1)
	return True


def update_ssh_key() -> None:
	ssh_id = common.checkAjaxInput(form.getvalue('id'))
	name = common.checkAjaxInput(form.getvalue('name'))
	enable = common.checkAjaxInput(form.getvalue('ssh_enable'))
	group = common.checkAjaxInput(form.getvalue('group'))
	username = common.checkAjaxInput(form.getvalue('ssh_user'))
	password = common.checkAjaxInput(form.getvalue('ssh_pass'))
	new_ssh_key_name = ''

	if username is None:
		print(error_mess)
	else:
		lib_path = get_config.get_config_var('main', 'lib_path')

		for sshs in sql.select_ssh(id=ssh_id):
			ssh_enable = sshs.enable
			ssh_key_name = f'{lib_path}/keys/{sshs.name}.pem'
			new_ssh_key_name = f'{lib_path}/keys/{name}.pem'

		if ssh_enable == 1:
			os.rename(ssh_key_name, new_ssh_key_name)
			os.chmod(new_ssh_key_name, 0o600)

		sql.update_ssh(ssh_id, name, enable, group, username, password)
		roxywi_common.logging('Roxy-WI server', f'The SSH credentials {name} has been updated ', roxywi=1, login=1)


def delete_ssh_key() -> None:
	lib_path = get_config.get_config_var('main', 'lib_path')
	sshdel = common.checkAjaxInput(form.getvalue('sshdel'))
	name = ''
	ssh_enable = 0
	ssh_key_name = ''

	for sshs in sql.select_ssh(id=sshdel):
		ssh_enable = sshs.enable
		name = sshs.name
		ssh_key_name = f'{lib_path}/keys/{sshs.name}.pem'

	if ssh_enable == 1:
		try:
			os.remove(ssh_key_name)
		except Exception:
			pass
	if sql.delete_ssh(sshdel):
		print(""Ok"")
		roxywi_common.logging('Roxy-WI server', f'The SSH credentials {name} has deleted', roxywi=1, login=1)
",CWE-668,183.0,1
"# SPDX-License-Identifier: MIT
# OpenZeppelin Contracts for Cairo v0.1.0 (account/Account.cairo)

%lang starknet

from starkware.cairo.common.cairo_builtins import HashBuiltin, SignatureBuiltin

from openzeppelin.account.library import Account, AccountCallArray

from openzeppelin.introspection.ERC165 import ERC165

#
# Constructor
#

@constructor
func constructor{
        syscall_ptr : felt*,
        pedersen_ptr : HashBuiltin*,
        range_check_ptr
    }(public_key: felt):
    Account.initializer(public_key)
    return ()
end

#
# Getters
#

@view
func get_public_key{
        syscall_ptr : felt*,
        pedersen_ptr : HashBuiltin*,
        range_check_ptr
    }() -> (res: felt):
    let (res) = Account.get_public_key()
    return (res=res)
end

@view
func get_nonce{
        syscall_ptr : felt*, 
        pedersen_ptr : HashBuiltin*,
        range_check_ptr
    }() -> (res: felt):
    let (res) = Account.get_nonce()
    return (res=res)
end

@view
func supportsInterface{
        syscall_ptr: felt*,
        pedersen_ptr: HashBuiltin*,
        range_check_ptr
    } (interfaceId: felt) -> (success: felt):
    let (success) = ERC165.supports_interface(interfaceId)
    return (success)
end

#
# Setters
#

@external
func set_public_key{
        syscall_ptr : felt*,
        pedersen_ptr : HashBuiltin*,
        range_check_ptr
    }(new_public_key: felt):
    Account.set_public_key(new_public_key)
    return ()
end

#
# Business logic
#

@view
func is_valid_signature{
        syscall_ptr : felt*,
        pedersen_ptr : HashBuiltin*,
        range_check_ptr,
        ecdsa_ptr: SignatureBuiltin*
    }(
        hash: felt,
        signature_len: felt,
        signature: felt*
    ) -> (is_valid: felt):
    let (is_valid) = Account.is_valid_signature(hash, signature_len, signature)
    return (is_valid=is_valid)
end

@external
func __execute__{
        syscall_ptr : felt*,
        pedersen_ptr : HashBuiltin*,
        range_check_ptr,
        ecdsa_ptr: SignatureBuiltin*
    }(
        call_array_len: felt,
        call_array: AccountCallArray*,
        calldata_len: felt,
        calldata: felt*,
        nonce: felt
    ) -> (response_len: felt, response: felt*):
    let (response_len, response) = Account.execute(
        call_array_len,
        call_array,
        calldata_len,
        calldata,
        nonce
    )
    return (response_len=response_len, response=response)
end
",CWE-863,115.0,1
,CWE-863,,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    MockSigner,
    ZERO_ADDRESS,
    assert_event_emitted,
    get_contract_class,
    cached_contract
)


signer = MockSigner(123456789987654321)


@pytest.fixture(scope='module')
def contract_classes():
    return (
        get_contract_class('openzeppelin/account/Account.cairo'),
        get_contract_class('tests/mocks/Ownable.cairo')
    )


@pytest.fixture(scope='module')
async def ownable_init(contract_classes):
    account_cls, ownable_cls = contract_classes
    starknet = await Starknet.empty()
    owner = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    ownable = await starknet.deploy(
        contract_class=ownable_cls,
        constructor_calldata=[owner.contract_address]
    )
    return starknet.state, ownable, owner


@pytest.fixture
def ownable_factory(contract_classes, ownable_init):
    account_cls, ownable_cls = contract_classes
    state, ownable, owner = ownable_init
    _state = state.copy()
    owner = cached_contract(_state, account_cls, owner)
    ownable = cached_contract(_state, ownable_cls, ownable)
    return ownable, owner


@pytest.mark.asyncio
async def test_constructor(ownable_factory):
    ownable, owner = ownable_factory
    expected = await ownable.owner().call()
    assert expected.result.owner == owner.contract_address


@pytest.mark.asyncio
async def test_transferOwnership(ownable_factory):
    ownable, owner = ownable_factory
    new_owner = 123
    await signer.send_transaction(owner, ownable.contract_address, 'transferOwnership', [new_owner])
    executed_info = await ownable.owner().call()
    assert executed_info.result == (new_owner,)


@pytest.mark.asyncio
async def test_transferOwnership_emits_event(ownable_factory):
    ownable, owner = ownable_factory
    new_owner = 123
    tx_exec_info = await signer.send_transaction(owner, ownable.contract_address, 'transferOwnership', [new_owner])

    assert_event_emitted(
        tx_exec_info,
        from_address=ownable.contract_address,
        name='OwnershipTransferred',
        data=[
            owner.contract_address,
            new_owner
        ]
    )


@pytest.mark.asyncio
async def test_renounceOwnership(ownable_factory):
    ownable, owner = ownable_factory
    await signer.send_transaction(owner, ownable.contract_address, 'renounceOwnership', [])
    executed_info = await ownable.owner().call()
    assert executed_info.result == (ZERO_ADDRESS,)


@pytest.mark.asyncio
async def test_renounceOwnership_emits_event(ownable_factory):
    ownable, owner = ownable_factory
    tx_exec_info = await signer.send_transaction(owner, ownable.contract_address, 'renounceOwnership', [])

    assert_event_emitted(
        tx_exec_info,
        from_address=ownable.contract_address,
        name='OwnershipTransferred',
        data=[
            owner.contract_address,
            ZERO_ADDRESS
        ]
    )
",CWE-863,103.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import MockSigner, assert_revert, get_contract_class, cached_contract, TRUE


signer = MockSigner(123456789987654321)
other = MockSigner(987654321123456789)

IACCOUNT_ID = 0xf10dbd44


@pytest.fixture(scope='module')
def contract_classes():
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')
    init_cls = get_contract_class(""tests/mocks/Initializable.cairo"")
    attacker_cls = get_contract_class(""tests/mocks/account_reentrancy.cairo"")

    return account_cls, init_cls, attacker_cls


@pytest.fixture(scope='module')
async def account_init(contract_classes):
    account_cls, init_cls, attacker_cls = contract_classes
    starknet = await Starknet.empty()

    account1 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    account2 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    initializable1 = await starknet.deploy(
        contract_class=init_cls,
        constructor_calldata=[],
    )
    initializable2 = await starknet.deploy(
        contract_class=init_cls,
        constructor_calldata=[],
    )
    attacker = await starknet.deploy(
        contract_class=attacker_cls,
        constructor_calldata=[],
    )

    return starknet.state, account1, account2, initializable1, initializable2, attacker


@pytest.fixture
def account_factory(contract_classes, account_init):
    account_cls, init_cls, attacker_cls = contract_classes
    state, account1, account2, initializable1, initializable2, attacker = account_init
    _state = state.copy()
    account1 = cached_contract(_state, account_cls, account1)
    account2 = cached_contract(_state, account_cls, account2)
    initializable1 = cached_contract(_state, init_cls, initializable1)
    initializable2 = cached_contract(_state, init_cls, initializable2)
    attacker = cached_contract(_state, attacker_cls, attacker)

    return account1, account2, initializable1, initializable2, attacker


@pytest.mark.asyncio
async def test_constructor(account_factory):
    account, *_ = account_factory

    execution_info = await account.get_public_key().call()
    assert execution_info.result == (signer.public_key,)

    execution_info = await account.supportsInterface(IACCOUNT_ID).call()
    assert execution_info.result == (TRUE,)


@pytest.mark.asyncio
async def test_execute(account_factory):
    account, _, initializable, *_ = account_factory

    execution_info = await initializable.initialized().call()
    assert execution_info.result == (0,)

    await signer.send_transactions(account, [(initializable.contract_address, 'initialize', [])])

    execution_info = await initializable.initialized().call()
    assert execution_info.result == (1,)


@pytest.mark.asyncio
async def test_multicall(account_factory):
    account, _, initializable_1, initializable_2, _ = account_factory

    execution_info = await initializable_1.initialized().call()
    assert execution_info.result == (0,)
    execution_info = await initializable_2.initialized().call()
    assert execution_info.result == (0,)

    await signer.send_transactions(
        account,
        [
            (initializable_1.contract_address, 'initialize', []),
            (initializable_2.contract_address, 'initialize', [])
        ]
    )

    execution_info = await initializable_1.initialized().call()
    assert execution_info.result == (1,)
    execution_info = await initializable_2.initialized().call()
    assert execution_info.result == (1,)


@pytest.mark.asyncio
async def test_return_value(account_factory):
    account, _, initializable, *_ = account_factory

    # initialize, set `initialized = 1`
    await signer.send_transactions(account, [(initializable.contract_address, 'initialize', [])])

    read_info = await signer.send_transactions(account, [(initializable.contract_address, 'initialized', [])])
    call_info = await initializable.initialized().call()
    (call_result, ) = call_info.result
    assert read_info.result.response == [call_result]  # 1


@ pytest.mark.asyncio
async def test_nonce(account_factory):
    account, _, initializable, *_ = account_factory

    execution_info = await account.get_nonce().call()
    current_nonce = execution_info.result.res

    # lower nonce
    await assert_revert(
        signer.send_transactions(account, [(initializable.contract_address, 'initialize', [])], current_nonce - 1),
        reverted_with=""Account: nonce is invalid""
    )

    # higher nonce
    await assert_revert(
        signer.send_transactions(account, [(initializable.contract_address, 'initialize', [])], current_nonce + 1),
        reverted_with=""Account: nonce is invalid""
    )

    # right nonce
    await signer.send_transactions(account, [(initializable.contract_address, 'initialize', [])], current_nonce)

    execution_info = await initializable.initialized().call()
    assert execution_info.result == (1,)


@pytest.mark.asyncio
async def test_public_key_setter(account_factory):
    account, *_ = account_factory

    execution_info = await account.get_public_key().call()
    assert execution_info.result == (signer.public_key,)

    # set new pubkey
    await signer.send_transactions(account, [(account.contract_address, 'set_public_key', [other.public_key])])

    execution_info = await account.get_public_key().call()
    assert execution_info.result == (other.public_key,)


@pytest.mark.asyncio
async def test_public_key_setter_different_account(account_factory):
    account, bad_account, *_ = account_factory

    # set new pubkey
    await assert_revert(
        signer.send_transactions(
            bad_account,
            [(account.contract_address, 'set_public_key', [other.public_key])]
        ),
        reverted_with=""Account: caller is not this account""
    )


@pytest.mark.asyncio
async def test_account_takeover_with_reentrant_call(account_factory):
    account, _, _, _, attacker = account_factory

    await assert_revert(
        signer.send_transaction(account, attacker.contract_address, 'account_takeover', []),
        reverted_with=""Account: no reentrant call""
    )
    
    execution_info = await account.get_public_key().call()
    assert execution_info.result == (signer.public_key,)
",CWE-863,189.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import MockSigner, get_contract_class, cached_contract


signer = MockSigner(123456789987654321)
L1_ADDRESS = 0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984
ANOTHER_ADDRESS = 0xd9e1ce17f2641f24ae83637ab66a2cca9c378b9f


@pytest.fixture(scope='module')
async def registry_factory():
    # contract classes
    registry_cls = get_contract_class(""openzeppelin/account/AddressRegistry.cairo"")
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')

    # deployments
    starknet = await Starknet.empty()
    account = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    registry = await starknet.deploy(
        contract_class=registry_cls,
        constructor_calldata=[]
    )

    # cache contracts
    state = starknet.state.copy()
    account = cached_contract(state, account_cls, account)
    registry = cached_contract(state, registry_cls, registry)

    return account, registry


@pytest.mark.asyncio
async def test_set_address(registry_factory):
    account, registry = registry_factory

    await signer.send_transaction(
        account, registry.contract_address, 'set_L1_address', [L1_ADDRESS]
    )
    execution_info = await registry.get_L1_address(account.contract_address).call()
    assert execution_info.result == (L1_ADDRESS,)


@pytest.mark.asyncio
async def test_update_address(registry_factory):
    account, registry = registry_factory

    await signer.send_transaction(
        account, registry.contract_address, 'set_L1_address', [L1_ADDRESS]
    )
    execution_info = await registry.get_L1_address(account.contract_address).call()
    assert execution_info.result == (L1_ADDRESS,)

    # set new address
    await signer.send_transaction(
        account, registry.contract_address, 'set_L1_address', [ANOTHER_ADDRESS]
    )
    execution_info = await registry.get_L1_address(account.contract_address).call()
    assert execution_info.result == (ANOTHER_ADDRESS,)
",CWE-863,63.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    TRUE, FALSE, assert_revert, assert_event_emitted, 
    get_contract_class, cached_contract, MockSigner
)

signer = MockSigner(12345678987654321)

@pytest.fixture
async def pausable_factory():
    # class
    pausable_cls = get_contract_class(""tests/mocks/Pausable.cairo"")
    account_cls = get_contract_class(""openzeppelin/account/Account.cairo"")

    starknet = await Starknet.empty()
    pausable = await starknet.deploy(
        contract_class=pausable_cls,
        constructor_calldata=[]
    )
    account = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    state = starknet.state.copy()

    pausable = cached_contract(state, pausable_cls, pausable)
    account = cached_contract(state, account_cls, account)
    return pausable, account


@pytest.mark.asyncio
async def test_pausable_when_unpaused(pausable_factory):
    contract, _ = pausable_factory

    execution_info = await contract.isPaused().call()
    assert execution_info.result.isPaused == FALSE

    execution_info = await contract.getCount().call()
    assert execution_info.result.res == 0
    
    # check that function executes when unpaused
    await contract.normalProcess().invoke()

    execution_info = await contract.getCount().call()
    assert execution_info.result.res == 1

    await assert_revert(
        contract.drasticMeasure().invoke(),
        reverted_with=""Pausable: not paused""
    )

@pytest.mark.asyncio
async def test_pausable_when_paused(pausable_factory):
    contract, _ = pausable_factory

    execution_info = await contract.isPaused().call()
    assert execution_info.result.isPaused == FALSE

    # pause
    await contract.pause().invoke()

    execution_info = await contract.isPaused().call()
    assert execution_info.result.isPaused == TRUE

    await assert_revert(
        contract.normalProcess().invoke(),
        reverted_with=""Pausable: paused""
    )

    execution_info = await contract.getDrasticMeasureTaken().call()
    assert execution_info.result.res == FALSE

    # drastic measure
    await contract.drasticMeasure().invoke()

    execution_info = await contract.getDrasticMeasureTaken().call()
    assert execution_info.result.res == TRUE

    # unpause
    await contract.unpause().invoke()

    execution_info = await contract.isPaused().call()
    assert execution_info.result.isPaused == FALSE

    # check normal process after unpausing
    await contract.normalProcess().invoke()

    execution_info = await contract.getCount().call()
    assert execution_info.result.res == 1

    await assert_revert(
        contract.drasticMeasure().invoke(),
        reverted_with=""Pausable: not paused""
    )

@pytest.mark.asyncio
async def test_pausable_pause_when_paused(pausable_factory):
    contract, _ = pausable_factory

    # pause
    await contract.pause().invoke()

    # re-pause
    await assert_revert(
        contract.pause().invoke(),
        reverted_with=""Pausable: paused""
    )

    # unpause
    await contract.unpause().invoke()

    # re-unpause
    await assert_revert(
        contract.unpause().invoke(),
        reverted_with=""Pausable: not paused""
    )

@pytest.mark.asyncio
async def test_pausable_emits_events(pausable_factory):
    contract, account = pausable_factory

    # pause
    tx_exec_info = await signer.send_transaction(
        account, contract.contract_address, 'pause', []
        )

    assert_event_emitted(
        tx_exec_info,
        from_address=contract.contract_address,
        name='Paused',
        data=[account.contract_address]
    )

    # unpause
    tx_exec_info = await signer.send_transaction(
        account, contract.contract_address, 'unpause', []
        )

    assert_event_emitted(
        tx_exec_info,
        from_address=contract.contract_address,
        name='Unpaused',
        data=[account.contract_address]
    )
",CWE-863,146.0,1
,CWE-863,,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    MockSigner, to_uint, add_uint, sub_uint, str_to_felt, ZERO_ADDRESS, INVALID_UINT256,
    get_contract_class, cached_contract, assert_revert, assert_event_emitted, 
)

signer = MockSigner(123456789987654321)

# testing vars
INIT_SUPPLY = to_uint(1000)
AMOUNT = to_uint(200)
UINT_ONE = to_uint(1)
NAME = str_to_felt(""Mintable Token"")
SYMBOL = str_to_felt(""MTKN"")
DECIMALS = 18


@pytest.fixture(scope='module')
def contract_classes():
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')
    erc20_cls = get_contract_class(
        'tests/mocks/ERC20_Burnable_mock.cairo')

    return account_cls, erc20_cls


@pytest.fixture(scope='module')
async def erc20_init(contract_classes):
    account_cls, erc20_cls = contract_classes
    starknet = await Starknet.empty()
    account1 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    erc20 = await starknet.deploy(
        contract_class=erc20_cls,
        constructor_calldata=[
            NAME,
            SYMBOL,
            DECIMALS,
            *INIT_SUPPLY,
            account1.contract_address,        # recipient
        ]
    )
    return (
        starknet.state,
        account1,
        erc20
    )


@pytest.fixture
def erc20_factory(contract_classes, erc20_init):
    account_cls, erc20_cls = contract_classes
    state, account1, erc20 = erc20_init
    _state = state.copy()
    account1 = cached_contract(_state, account_cls, account1)
    erc20 = cached_contract(_state, erc20_cls, erc20)

    return erc20, account1


@pytest.mark.asyncio
async def test_burn(erc20_factory):
    erc20, account = erc20_factory

    await signer.send_transaction(
        account, erc20.contract_address, 'burn', [
            *AMOUNT
        ])

    new_balance = sub_uint(INIT_SUPPLY, AMOUNT)

    execution_info = await erc20.balanceOf(account.contract_address).invoke()
    assert execution_info.result.balance == new_balance


@pytest.mark.asyncio
async def test_burn_emits_event(erc20_factory):
    erc20, account = erc20_factory

    tx_exec_info = await signer.send_transaction(
        account, erc20.contract_address, 'burn', [
            *AMOUNT
        ])

    assert_event_emitted(
        tx_exec_info,
        from_address=erc20.contract_address,
        name='Transfer',
        data=[
            account.contract_address,
            ZERO_ADDRESS,
            *AMOUNT
        ]
    )


@pytest.mark.asyncio
async def test_burn_not_enough_balance(erc20_factory):
    erc20, account = erc20_factory

    balance_plus_one = add_uint(INIT_SUPPLY, UINT_ONE)

    await assert_revert(signer.send_transaction(
        account, erc20.contract_address, 'burn', [
            *balance_plus_one
        ]),
        reverted_with=""ERC20: burn amount exceeds balance""
    )


@pytest.mark.asyncio
async def test_burn_from_zero_address(erc20_factory):
    erc20, _ = erc20_factory

    await assert_revert(
        erc20.burn(UINT_ONE).invoke(),
        reverted_with=""ERC20: cannot burn from the zero address""
    )


@pytest.mark.asyncio
async def test_burn_invalid_uint256(erc20_factory):
    erc20, _ = erc20_factory

    await assert_revert(
        erc20.burn(INVALID_UINT256).invoke(),
        reverted_with=""ERC20: amount is not a valid Uint256""
    )
",CWE-863,132.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    MockSigner, to_uint, add_uint, sub_uint, str_to_felt, 
    MAX_UINT256, ZERO_ADDRESS, INVALID_UINT256, get_contract_class, 
    cached_contract, assert_revert, assert_event_emitted
)

signer = MockSigner(123456789987654321)

# testing vars
RECIPIENT = 123
INIT_SUPPLY = to_uint(1000)
AMOUNT = to_uint(200)
UINT_ONE = to_uint(1)
NAME = str_to_felt(""Mintable Token"")
SYMBOL = str_to_felt(""MTKN"")
DECIMALS = 18


@pytest.fixture(scope='module')
def contract_classes():
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')
    erc20_cls = get_contract_class(
        'openzeppelin/token/erc20/ERC20_Mintable.cairo')

    return account_cls, erc20_cls


@pytest.fixture(scope='module')
async def erc20_init(contract_classes):
    account_cls, erc20_cls = contract_classes
    starknet = await Starknet.empty()
    account1 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    erc20 = await starknet.deploy(
        contract_class=erc20_cls,
        constructor_calldata=[
            NAME,
            SYMBOL,
            DECIMALS,
            *INIT_SUPPLY,
            account1.contract_address,        # recipient
            account1.contract_address         # owner
        ]
    )
    return (
        starknet.state,
        account1,
        erc20
    )


@pytest.fixture
def token_factory(contract_classes, erc20_init):
    account_cls, erc20_cls = contract_classes
    state, account1, erc20 = erc20_init
    _state = state.copy()
    account1 = cached_contract(_state, account_cls, account1)
    erc20 = cached_contract(_state, erc20_cls, erc20)

    return erc20, account1


@pytest.mark.asyncio
async def test_constructor(token_factory):
    token, owner = token_factory

    execution_info = await token.name().call()
    assert execution_info.result.name == NAME

    execution_info = await token.symbol().call()
    assert execution_info.result.symbol == SYMBOL

    execution_info = await token.decimals().call()
    assert execution_info.result.decimals == DECIMALS

    execution_info = await token.balanceOf(owner.contract_address).call()
    assert execution_info.result.balance == INIT_SUPPLY


@pytest.mark.asyncio
async def test_mint(token_factory):
    erc20, account = token_factory

    await signer.send_transaction(
        account, erc20.contract_address, 'mint', [
            account.contract_address,
            *UINT_ONE
        ])

    # check new supply
    execution_info = await erc20.totalSupply().invoke()
    new_supply = execution_info.result.totalSupply
    assert new_supply == add_uint(INIT_SUPPLY, UINT_ONE)


@pytest.mark.asyncio
async def test_mint_emits_event(token_factory):
    erc20, account = token_factory

    tx_exec_info = await signer.send_transaction(
        account, erc20.contract_address, 'mint', [
            account.contract_address,
            *UINT_ONE
        ])

    assert_event_emitted(
        tx_exec_info,
        from_address=erc20.contract_address,
        name='Transfer',
        data=[
            ZERO_ADDRESS,
            account.contract_address,
            *UINT_ONE
        ]
    )


@pytest.mark.asyncio
async def test_mint_to_zero_address(token_factory):
    erc20, account = token_factory

    await assert_revert(signer.send_transaction(
        account,
        erc20.contract_address,
        'mint',
        [ZERO_ADDRESS, *UINT_ONE]
    ),
        reverted_with=""ERC20: cannot mint to the zero address""
    )


@pytest.mark.asyncio
async def test_mint_overflow(token_factory):
    erc20, account = token_factory
    # pass_amount subtracts the already minted supply from MAX_UINT256 in order for
    # the minted supply to equal MAX_UINT256
    # (2**128 - 1, 2**128 - 1)
    pass_amount = sub_uint(MAX_UINT256, INIT_SUPPLY)

    await signer.send_transaction(
        account, erc20.contract_address, 'mint', [
            RECIPIENT,
            *pass_amount
        ])

    # totalSupply is MAX_UINT256 therefore adding (1, 0) should fail
    await assert_revert(
        signer.send_transaction(
            account, erc20.contract_address, 'mint', [
                RECIPIENT,
                *UINT_ONE
            ]),
        reverted_with=""ERC20: mint overflow""
    )


@pytest.mark.asyncio
async def test_mint_invalid_uint256(token_factory):
    erc20, account = token_factory

    await assert_revert(signer.send_transaction(
        account,
        erc20.contract_address,
        'mint',
        [RECIPIENT, *INVALID_UINT256]),
        reverted_with=""ERC20: amount is not a valid Uint256""
    )
",CWE-863,172.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    MockSigner, to_uint, sub_uint, str_to_felt, assert_revert,
    get_contract_class, cached_contract
)


signer = MockSigner(123456789987654321)

USER = 999
INIT_SUPPLY = to_uint(1000)
AMOUNT = to_uint(250)
NAME = str_to_felt('Upgradeable Token')
SYMBOL = str_to_felt('UTKN')
DECIMALS = 18


@pytest.fixture(scope='module')
def contract_classes():
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')
    token_cls = get_contract_class(
        'openzeppelin/token/erc20/ERC20_Upgradeable.cairo')
    proxy_cls = get_contract_class('openzeppelin/upgrades/Proxy.cairo')

    return account_cls, token_cls, proxy_cls


@pytest.fixture(scope='module')
async def token_init(contract_classes):
    account_cls, token_cls, proxy_cls = contract_classes
    starknet = await Starknet.empty()
    account1 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    account2 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    token_v1 = await starknet.declare(
        contract_class=token_cls,
    )
    token_v2 = await starknet.declare(
        contract_class=token_cls,
    )
    proxy = await starknet.deploy(
        contract_class=proxy_cls,
        constructor_calldata=[token_v1.class_hash]
    )
    return (
        starknet.state,
        account1,
        account2,
        token_v1,
        token_v2,
        proxy
    )


@pytest.fixture
def token_factory(contract_classes, token_init):
    account_cls, _, proxy_cls = contract_classes
    state, account1, account2, token_v1, token_v2, proxy = token_init
    _state = state.copy()
    account1 = cached_contract(_state, account_cls, account1)
    account2 = cached_contract(_state, account_cls, account2)
    proxy = cached_contract(_state, proxy_cls, proxy)

    return account1, account2, proxy, token_v1, token_v2


@pytest.fixture
async def after_initializer(token_factory):
    admin, other, proxy, token_v1, token_v2 = token_factory

    # initialize
    await signer.send_transaction(
        admin, proxy.contract_address, 'initializer', [
            NAME,                       # name
            SYMBOL,                     # symbol
            DECIMALS,                   # decimals
            *INIT_SUPPLY,               # initial supply
            admin.contract_address,     # recipient
            admin.contract_address      # admin
        ]
    )

    return admin, other, proxy, token_v1, token_v2


@pytest.mark.asyncio
async def test_constructor(token_factory):
    admin, _, proxy, *_ = token_factory

    await signer.send_transaction(
        admin, proxy.contract_address, 'initializer', [
            NAME,                       # name
            SYMBOL,                     # symbol
            DECIMALS,                   # decimals
            *INIT_SUPPLY,               # initial supply
            admin.contract_address,     # recipient
            admin.contract_address      # admin
        ])

    execution_info = await signer.send_transactions(
        admin,
        [
            (proxy.contract_address, 'name', []),
            (proxy.contract_address, 'symbol', []),
            (proxy.contract_address, 'decimals', []),
            (proxy.contract_address, 'totalSupply', [])
        ]
    )

    # check values
    expected = [NAME, SYMBOL, DECIMALS, *INIT_SUPPLY]
    assert execution_info.result.response == expected


@pytest.mark.asyncio
async def test_upgrade(after_initializer):
    admin, _, proxy, _, token_v2 = after_initializer

    # transfer
    await signer.send_transaction(
        admin, proxy.contract_address, 'transfer', [USER, *AMOUNT]
    )

    # upgrade
    await signer.send_transaction(
        admin, proxy.contract_address, 'upgrade', [token_v2.class_hash]
    )

    # fetch values
    execution_info = await signer.send_transactions(
        admin,
        [
            (proxy.contract_address, 'balanceOf', [admin.contract_address]),
            (proxy.contract_address, 'balanceOf', [USER]),
            (proxy.contract_address, 'totalSupply', [])
        ]
    )

    expected = [
        *sub_uint(INIT_SUPPLY, AMOUNT),         # balanceOf admin
        *AMOUNT,                                # balanceOf USER
        *INIT_SUPPLY                            # totalSupply
    ]

    assert execution_info.result.response == expected


@pytest.mark.asyncio
async def test_upgrade_from_nonadmin(after_initializer):
    admin, non_admin, proxy, _, token_v2 = after_initializer

    # should revert
    await assert_revert(signer.send_transaction(
        non_admin, proxy.contract_address, 'upgrade', [token_v2.class_hash]),
        reverted_with=""Proxy: caller is not admin""
    )

    # should upgrade from admin
    await signer.send_transaction(
        admin, proxy.contract_address, 'upgrade', [token_v2.class_hash]
    )
",CWE-863,168.0,1
"import pytest
from starkware.starknet.testing.starknet import Starknet
from utils import (
    MockSigner,
    assert_revert,
    get_contract_class,
    cached_contract,
    assert_event_emitted,
    assert_revert_entry_point
)

# random value
VALUE = 123

signer = MockSigner(123456789987654321)


@pytest.fixture(scope='module')
def contract_classes():
    account_cls = get_contract_class('openzeppelin/account/Account.cairo')
    implementation_cls = get_contract_class(
        'tests/mocks/proxiable_implementation.cairo'
    )
    proxy_cls = get_contract_class('openzeppelin/upgrades/Proxy.cairo')

    return account_cls, implementation_cls, proxy_cls


@pytest.fixture(scope='module')
async def proxy_init(contract_classes):
    account_cls, implementation_cls, proxy_cls = contract_classes
    starknet = await Starknet.empty()
    account1 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    account2 = await starknet.deploy(
        contract_class=account_cls,
        constructor_calldata=[signer.public_key]
    )
    implementation_decl = await starknet.declare(
        contract_class=implementation_cls
    )
    proxy = await starknet.deploy(
        contract_class=proxy_cls,
        constructor_calldata=[implementation_decl.class_hash]
    )
    return (
        starknet.state,
        account1,
        account2,
        proxy
    )


@pytest.fixture
def proxy_factory(contract_classes, proxy_init):
    account_cls, _, proxy_cls = contract_classes
    state, account1, account2, proxy = proxy_init
    _state = state.copy()
    admin = cached_contract(_state, account_cls, account1)
    other = cached_contract(_state, account_cls, account2)
    proxy = cached_contract(_state, proxy_cls, proxy)

    return admin, other, proxy


@pytest.fixture
async def after_initialized(proxy_factory):
    admin, other, proxy = proxy_factory 

    # initialize proxy
    await signer.send_transaction(
        admin, proxy.contract_address, 'initializer', [admin.contract_address]
    )

    return admin, other, proxy

#
# initializer
#

@pytest.mark.asyncio
async def test_initializer(proxy_factory):
    admin, _, proxy = proxy_factory 

    await signer.send_transaction(
        admin, proxy.contract_address, 'initializer', [admin.contract_address]
    )

    # check admin is set
    execution_info = await signer.send_transaction(
        admin, proxy.contract_address, 'getAdmin', []
    )
    assert execution_info.result.response == [admin.contract_address]


@pytest.mark.asyncio
async def test_initializer_after_initialized(after_initialized):
    admin, _, proxy = after_initialized 

    await assert_revert(signer.send_transaction(
        admin, proxy.contract_address, 'initializer', [admin.contract_address]),
        reverted_with=""Proxy: contract already initialized""
    )

#
# set_admin
#

@pytest.mark.asyncio
async def test_set_admin(after_initialized):
    admin, _, proxy = after_initialized 

    # set admin
    tx_exec_info = await signer.send_transaction(
        admin, proxy.contract_address, 'setAdmin', [VALUE]
    )

    # check event
    assert_event_emitted(
        tx_exec_info,
        from_address=proxy.contract_address,
        name='AdminChanged',
        data=[
            admin.contract_address,       # old admin
            VALUE                         # new admin
        ]
    )

    # check new admin
    execution_info = await signer.send_transaction(
        admin, proxy.contract_address, 'getAdmin', []
    )
    assert execution_info.result.response == [VALUE]


@pytest.mark.asyncio
async def test_set_admin_from_unauthorized(after_initialized):
    _, non_admin, proxy = after_initialized 

    # set admin
    await assert_revert(signer.send_transaction(
        non_admin, proxy.contract_address, 'setAdmin', [VALUE]),
        reverted_with=""Proxy: caller is not admin""
    )

#
# fallback function
#

@pytest.mark.asyncio
async def test_default_fallback(proxy_factory):
    admin, _, proxy = proxy_factory 

    # set value through proxy
    await signer.send_transaction(
        admin, proxy.contract_address, 'setValue', [VALUE]
    )

    # get value through proxy
    execution_info = execution_info = await signer.send_transaction(
        admin, proxy.contract_address, 'getValue', []
    )
    assert execution_info.result.response == [VALUE]


@pytest.mark.asyncio
async def test_fallback_when_selector_does_not_exist(proxy_factory):
    admin, _, proxy = proxy_factory 

    # should fail with entry point error
    await assert_revert_entry_point(
        signer.send_transaction(
            admin, proxy.contract_address, 'invalid_selector', []
        ),
        invalid_selector='invalid_selector'
    )
",CWE-863,179.0,1
"""""""Utilities for testing Cairo contracts.""""""

from pathlib import Path
import math
from starkware.starknet.public.abi import get_selector_from_name
from starkware.starknet.compiler.compile import compile_starknet_files
from starkware.starkware_utils.error_handling import StarkException
from starkware.starknet.testing.starknet import StarknetContract
from starkware.starknet.business_logic.execution.objects import Event
from nile.signer import Signer


MAX_UINT256 = (2**128 - 1, 2**128 - 1)
INVALID_UINT256 = (MAX_UINT256[0] + 1, MAX_UINT256[1])
ZERO_ADDRESS = 0
TRUE = 1
FALSE = 0

TRANSACTION_VERSION = 0


_root = Path(__file__).parent.parent


def contract_path(name):
    if name.startswith(""tests/""):
        return str(_root / name)
    else:
        return str(_root / ""src"" / name)


def str_to_felt(text):
    b_text = bytes(text, ""ascii"")
    return int.from_bytes(b_text, ""big"")


def felt_to_str(felt):
    b_felt = felt.to_bytes(31, ""big"")
    return b_felt.decode()


def uint(a):
    return(a, 0)


def to_uint(a):
    """"""Takes in value, returns uint256-ish tuple.""""""
    return (a & ((1 << 128) - 1), a >> 128)


def from_uint(uint):
    """"""Takes in uint256-ish tuple, returns value.""""""
    return uint[0] + (uint[1] << 128)


def add_uint(a, b):
    """"""Returns the sum of two uint256-ish tuples.""""""
    a = from_uint(a)
    b = from_uint(b)
    c = a + b
    return to_uint(c)


def sub_uint(a, b):
    """"""Returns the difference of two uint256-ish tuples.""""""
    a = from_uint(a)
    b = from_uint(b)
    c = a - b
    return to_uint(c)


def mul_uint(a, b):
    """"""Returns the product of two uint256-ish tuples.""""""
    a = from_uint(a)
    b = from_uint(b)
    c = a * b
    return to_uint(c)


def div_rem_uint(a, b):
    """"""Returns the quotient and remainder of two uint256-ish tuples.""""""
    a = from_uint(a)
    b = from_uint(b)
    c = math.trunc(a / b)
    m = a % b
    return (to_uint(c), to_uint(m))


async def assert_revert(fun, reverted_with=None):
    try:
        await fun
        assert False
    except StarkException as err:
        _, error = err.args
        if reverted_with is not None:
            assert reverted_with in error['message']


async def assert_revert_entry_point(fun, invalid_selector):
    selector_hex = hex(get_selector_from_name(invalid_selector))
    entry_point_msg = f""Entry point {selector_hex} not found in contract""
    
    await assert_revert(fun, entry_point_msg)


def assert_event_emitted(tx_exec_info, from_address, name, data):
    assert Event(
        from_address=from_address,
        keys=[get_selector_from_name(name)],
        data=data,
    ) in tx_exec_info.raw_events


def get_contract_class(path):
    """"""Return the contract class from the contract path""""""
    path = contract_path(path)
    contract_class = compile_starknet_files(
        files=[path],
        debug_info=True
    )
    return contract_class


def cached_contract(state, _class, deployed):
    """"""Return the cached contract""""""
    contract = StarknetContract(
        state=state,
        abi=_class.abi,
        contract_address=deployed.contract_address,
        deploy_execution_info=deployed.deploy_execution_info
    )
    return contract


class MockSigner():
    """"""
    Utility for sending signed transactions to an Account on Starknet.

    Parameters
    ----------

    private_key : int

    Examples
    ---------
    Constructing a MockSigner object

    >>> signer = MockSigner(1234)

    Sending a transaction

    >>> await signer.send_transaction(
            account, contract_address, 'contract_method', [arg_1]
        )

    Sending multiple transactions

    >>> await signer.send_transaction(
            account, [
                (contract_address, 'contract_method', [arg_1]),
                (contract_address, 'another_method', [arg_1, arg_2])
            ]
        )
                           
    """"""
    def __init__(self, private_key):
        self.signer = Signer(private_key)
        self.public_key = self.signer.public_key
        
    async def send_transaction(self, account, to, selector_name, calldata, nonce=None, max_fee=0):
        return await self.send_transactions(account, [(to, selector_name, calldata)], nonce, max_fee)

    async def send_transactions(self, account, calls, nonce=None, max_fee=0):
        if nonce is None:
            execution_info = await account.get_nonce().call()
            nonce, = execution_info.result

        build_calls = []
        for call in calls:
            build_call = list(call)
            build_call[0] = hex(build_call[0])
            build_calls.append(build_call)

        (call_array, calldata, sig_r, sig_s) = self.signer.sign_transaction(hex(account.contract_address), build_calls, nonce, max_fee)
        return await account.__execute__(call_array, calldata, nonce).invoke(signature=[sig_r, sig_s])
",CWE-863,186.0,1
"#
#  The OpenDiamond Platform for Interactive Search
#
#  Copyright (c) 2009-2018 Carnegie Mellon University
#  All rights reserved.
#
#  This software is distributed under the terms of the Eclipse Public
#  License, Version 1.0 which can be found in the file named LICENSE.
#  ANY USE, REPRODUCTION OR DISTRIBUTION OF THIS SOFTWARE CONSTITUTES
#  RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT
#

import os
import datetime
from xml.sax.saxutils import quoteattr

from flask import Blueprint, url_for, Response, stream_with_context, send_file, \
    jsonify
from werkzeug.datastructures import Headers

from opendiamond.dataretriever.util import ATTR_SUFFIX

BASEURL = 'collection'
STYLE = False
LOCAL_OBJ_URI = True  # if true, return local file path, otherwise http.
INDEXDIR = DATAROOT = None


def init(config):
    global INDEXDIR, DATAROOT  # pylint: disable=global-statement
    INDEXDIR = config.indexdir
    DATAROOT = config.dataroot


scope_blueprint = Blueprint('diamond_store', __name__)


@scope_blueprint.route('/<gididx>')
@scope_blueprint.route('/<gididx>/limit/<int:limit>')
def get_scope(gididx, limit=None):
    index = 'GIDIDX' + gididx.upper()
    index = _get_index_absolute_path(index)

    # Streaming response:
    # http://flask.pocoo.org/docs/0.12/patterns/streaming/
    def generate():
        num_entries = 0
        with open(index, 'r') as f:
            for _ in f.readlines():
                num_entries += 1
                if limit is not None and num_entries >= limit:
                    break

        with open(index, 'r') as f:
            yield '<?xml version=""1.0"" encoding=""UTF-8"" ?>\n'
            if STYLE:
                yield '<?xml-stylesheet type=""text/xsl"" href=""/scopelist.xsl"" ?>\n'

            yield '<objectlist count=""{:d}"">\n'.format(num_entries)
            
            count = 0
            for path in f.readlines():
                path = path.strip()
                yield _get_object_element(object_path=path) + '\n'
                count += 1
                if limit is not None and count >= limit:
                    break

            yield '</objectlist>\n'

    headers = Headers([('Content-Type', 'text/xml')])

    return Response(stream_with_context(generate()),
                    status=""200 OK"",
                    headers=headers)


@scope_blueprint.route('/id/<path:object_path>')
def get_object_id(object_path):
    headers = Headers([('Content-Type', 'text/xml')])
    return Response(_get_object_element(object_path=object_path),
                    ""200 OK"",
                    headers=headers)


@scope_blueprint.route('/meta/<path:object_path>')
def get_object_meta(object_path):
    path = _get_obj_absolute_path(object_path)
    attrs = dict()

    try:
        with DiamondTextAttr(path, 'r') as attributes:
            for key, value in attributes:
                attrs[key] = value
    except IOError:
        pass

    return jsonify(attrs)


def _get_object_element(object_path):
    path = _get_obj_absolute_path(object_path)

    if os.path.isfile(path + ATTR_SUFFIX):
        return '<object id={} src={} meta={} />' \
            .format(quoteattr(url_for('.get_object_id', object_path=object_path)),
                    quoteattr(_get_object_src_uri(object_path)),
                    quoteattr(url_for('.get_object_meta', object_path=object_path)))
    else:
        return '<object id={} src={} />' \
            .format(quoteattr(url_for('.get_object_id', object_path=object_path)),
                    quoteattr(_get_object_src_uri(object_path)))


def _get_object_src_uri(object_path):
    if LOCAL_OBJ_URI:
        return 'file://' + _get_obj_absolute_path(object_path)
    else:
        return url_for('.get_object_src_http', obj_path=object_path)


def _get_obj_absolute_path(obj_path):
    return os.path.join(DATAROOT, obj_path)


def _get_index_absolute_path(index):
    return os.path.join(INDEXDIR, index)


@scope_blueprint.route('/obj/<path:obj_path>')
def get_object_src_http(obj_path):
    path = _get_obj_absolute_path(obj_path)

    headers = Headers()
    # With add_etags=True, conditional=True
    # Flask should be smart enough to do 304 Not Modified
    response = send_file(path,
                         cache_timeout=datetime.timedelta(
                             days=365).total_seconds(),
                         add_etags=True,
                         conditional=True)
    response.headers.extend(headers)
    return response
",CWE-22,144.0,1
"#
#  The OpenDiamond Platform for Interactive Search
#
#  Copyright (c) 2018 Carnegie Mellon University
#  All rights reserved.
#
#  This software is distributed under the terms of the Eclipse Public
#  License, Version 1.0 which can be found in the file named LICENSE.
#  ANY USE, REPRODUCTION OR DISTRIBUTION OF THIS SOFTWARE CONSTITUTES
#  RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT
#
from builtins import range, str

import datetime
import json
import os
import subprocess
import sys
from math import ceil

from flask import Blueprint, Response, request, stream_with_context, url_for
from opendiamond.dataretriever.util import DiamondTextAttr
from werkzeug.datastructures import Headers

# IMPORTANT: requires ffmpeg >= 3.3. Lower versions produce incorrect clipping.

BASEURL = 'video'
STYLE = False
INDEXDIR = DATAROOT = None


def init(config):
    global INDEXDIR, DATAROOT  # pylint: disable=global-statement
    INDEXDIR = config.indexdir
    DATAROOT = config.dataroot


scope_blueprint = Blueprint('video_store', __name__)

@scope_blueprint.route('/scope/<gididx>')
@scope_blueprint.route('/scope/stride/<int:stride>/span/<int:span>/<gididx>')
def get_scope(gididx, stride=5, span=5):
    index = 'GIDIDX' + gididx.upper()

    def generate():
        yield '<?xml version=""1.0"" encoding=""UTF-8"" ?>\n'
        if STYLE:
            yield '<?xml-stylesheet type=""text/xsl"" href=""/scopelist.xsl"" ?>\n'

        yield '<objectlist>\n'

        with open(_get_index_absolute_path(index), 'rt') as f:
            for line in f:
                video = line.strip()
                video_path = str(_get_obj_absolute_path(video))
                try:
                    video_meta = _ffprobe(video_path)
                    length_sec = float(video_meta['format']['duration'])
                    num_clips = int(ceil(length_sec / stride))
                    yield '<count adjust=""{}""/>\n'.format(num_clips)
                    for clip in range(num_clips):
                        yield _get_object_element(start=clip * stride, span=span, video=video) + '\n'
                except Exception as e:
                    print(""Error parsing {}. {}. Skip."".format(video, str(e)), file=sys.stderr)
                    pass

        yield '</objectlist>\n'

    headers = Headers([('Content-Type', 'text/xml')])
    return Response(stream_with_context(generate()),
                    status=""200 OK"",
                    headers=headers)


@scope_blueprint.route('/id/start/<int:start>/span/<int:span>/<path:video>')
def get_object_id(start, span, video):
    headers = Headers([('Content-Type', 'text/xml')])
    return Response(_get_object_element(start, span, video),
                    ""200 OK"",
                    headers=headers)


@scope_blueprint.route('/obj/start/<int:start>/span/<int:span>/<path:video>')
def get_object(start, span, video):
    # Reference:
    # https://github.com/mikeboers/PyAV/blob/master/tests/test_seek.py
    video_path = str(_get_obj_absolute_path(video))
    proc = _create_ffmpeg_segment_proc(video_path,
                                       start_sec=start,
                                       duration_sec=span)

    def generate():
        while True:
            data = proc.stdout.read(4096)
            if not data:
                break
            yield data

    headers = Headers([('Content-Type', 'video/mp4')])
    response = Response(stream_with_context(generate()),
                        status=""200 OK"",
                        headers=headers)
    # Cache control
    stat = os.stat(video_path)
    last_modified = stat.st_mtime
    size = stat.st_size
    etag = ""{}_{}_{}_{}"".format(last_modified, size, start, span)
    response.last_modified = last_modified
    response.set_etag(etag=etag)
    response.cache_control.public = True
    response.cache_control.max_age = \
        datetime.timedelta(days=365).total_seconds()
    response.make_conditional(request)

    return response


def _get_object_element(start, span, video):
    return '<object id=""{}"" src=""{}"" />'.format(
        url_for('.get_object_id', start=start, span=span, video=video),
        url_for('.get_object', start=start, span=span, video=video))


def _get_obj_absolute_path(obj_path):
    return os.path.join(DATAROOT, obj_path)


def _get_index_absolute_path(index):
    return os.path.join(INDEXDIR, index)


def _ffprobe(video_path):
    cmd_l = ['ffprobe', '-v', 'quiet', '-print_format', 'json',
                '-show_format', video_path]

    proc = subprocess.Popen(cmd_l, stdout=subprocess.PIPE, bufsize=-1)
    data = json.load(proc.stdout)
    
    return data


def _create_ffmpeg_segment_proc(video_path, start_sec, duration_sec):
    """"""
    Use ffmpeg to extract a .mp4 segment of the video. Outfile is written to stdout.
    Note: requires ffmpeg >= 3.3. Lower versions produce wrong results.
    Reference: http://trac.ffmpeg.org/wiki/Seeking
    https://stackoverflow.com/questions/34123272/ffmpeg-transmux-mpegts-to-mp4-gives-error-muxer-does-not-support-non-seekable
    :param video_path:
    :param start_sec:
    :param duration_sec:
    :return: the subprocess
    """"""
    cmd_l = ['ffmpeg', '-v', 'quiet',
             '-ss', str(start_sec),
             '-t', str(duration_sec),
             '-i', str(video_path),
             '-movflags', 'frag_keyframe+empty_moov',
             '-c', 'copy',
             '-f', 'mp4',
             'pipe:1']

    proc = subprocess.Popen(cmd_l, stdout=subprocess.PIPE, bufsize=-1)
    return proc
",CWE-22,164.0,1
"#
#  The OpenDiamond Platform for Interactive Search
#
#  Copyright (c) 2018 Carnegie Mellon University
#  All rights reserved.
#
#  This software is distributed under the terms of the Eclipse Public
#  License, Version 1.0 which can be found in the file named LICENSE.
#  ANY USE, REPRODUCTION OR DISTRIBUTION OF THIS SOFTWARE CONSTITUTES
#  RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT
#
""""""
Pre-conditions:
Metadata of a data set is stored in a table <dataset> in a MySQL database.
Files (objects) belonging to a dataset are stored under DATAROOT/<dataset>/.
MySQL table stores relative path to the above directory.
Table provides keyword search to get list of objects.
Database login info is obtained from DiamondConfig.
MySQL table is indexed with:
 FULLTEXT (title, keywords, description)

Requires:
pip install mysql-connector-python==8.0.6
""""""
import datetime
import os
from flask import Blueprint, url_for, Response, \
    stream_with_context, abort, jsonify, send_file
import logging
import mysql.connector
from werkzeug.datastructures import Headers
from xml.sax.saxutils import quoteattr

BASEURL = 'yfcc100m_mysql'
STYLE = False
LOCAL_OBJ_URI = True  # if true, return local path, otherwise http.
DATAROOT = None
DB_HOST = DB_DBNAME = DB_USER = DB_PASSWORD = DB_PORT = None

_log = logging.getLogger(__name__)

yfcc100m_s3_image_prefix = 'https://multimedia-commons.s3-us-west-2.amazonaws.com/data/images/'


def init(config):
    global DATAROOT  # pylint: disable=global-statement
    DATAROOT = config.dataroot
    global DB_HOST, DB_DBNAME, DB_USER, DB_PASSWORD, DB_PORT
    DB_HOST = config.yfcc100m_db_host
    DB_DBNAME = config.yfcc100m_db_dbname
    DB_USER = config.yfcc100m_db_user
    DB_PASSWORD = config.yfcc100m_db_password
    DB_PORT = config.yfcc100m_db_port


scope_blueprint = Blueprint('mysql_store', __name__)


@scope_blueprint.route('/scope/<dataset>')
@scope_blueprint.route('/scope/<dataset>/keywords/<keywords>')
@scope_blueprint.route('/scope/<dataset>/modulo/<int:divisor>/<expression>')
@scope_blueprint.route(
    '/scope/<dataset>/keywords/<keywords>/modulo/<int:divisor>/<expression>')
def get_scope(dataset, keywords=None, divisor=None, expression=None):
    """"""

    :param expression: Can be ""<3"", ""=3"", "">3"", etc.
    :param dataset:
    :param keywords: a string of comma-separated keywords
    :param divisor: positive int
    :return:
    """"""
    # cursor.execute() can't substitute table name
    query = ""SELECT sequence_no, rel_path, download_link FROM "" + dataset
    conditions = []
    substitutes = []
    if keywords:
        conditions.append(""MATCH (title, keywords, description) AGAINST(%s)"")
        substitutes.append(keywords)

    if divisor:
        # TODO sanity check expression
        conditions.append(""(sequence_no % %s) "" + expression)
        substitutes.extend([divisor])

    if conditions:
        query += "" WHERE "" + ' AND '.join(conditions)

    _log.debug(""Query used: %s, substitutes: %s"", query, substitutes)

    def generate():
        cnx = mysql.connector.connect(user=DB_USER,
                                      password=DB_PASSWORD,
                                      host=DB_HOST,
                                      database=DB_DBNAME,
                                      port=DB_PORT)
        cursor = cnx.cursor()
        cursor.execute(query, substitutes)

        yield '<?xml version=""1.0"" encoding=""UTF-8"" ?>\n'
        if STYLE:
            yield '<?xml-stylesheet type=""text/xsl"" href=""/scopelist.xsl"" ?>\n'

        yield '<objectlist>\n'
        for seq_no, rel_path, download_link in cursor:
            yield '<count adjust=""1""/>\n'
            yield _get_object_element(dataset, seq_no, rel_path,
                                      download_link) + '\n'

        yield '</objectlist>\n'

    headers = Headers([('Content-Type', 'text/xml')])

    return Response(stream_with_context(generate()),
                    status=""200 OK"",
                    headers=headers)

@scope_blueprint.route('/id/<dataset>/<int:seq_no>')
def get_object_id(dataset, seq_no):
    headers = Headers([('Content-Type', 'text/xml')])
    return Response(_get_object_element(dataset, seq_no, None, None),
                    ""200 OK"",
                    headers=headers)

@scope_blueprint.route('/obj/<dataset>/<path:rel_path>')
def get_object_src_http(dataset, rel_path):
    path = _get_obj_abosolute_path(dataset, rel_path)
    response = send_file(path,
                         cache_timeout=datetime.timedelta(
                             days=365).total_seconds(),
                         add_etags=True,
                         conditional=True)
    return response


def _get_obj_abosolute_path(dataset, rel_path):
    return os.path.join(DATAROOT, dataset, rel_path)


def _get_object_element(dataset, seq_no, rel_path, download_link):
    """"""If rel_path and download_link are not None, we are called from scope.
    Otherwise we are called from ID and need to run SQL query to fetch these attrs.""""""

    if rel_path is None:
        query = ""SELECT rel_path, download_link FROM "" + \
        dataset + \
        "" WHERE sequence_no = %s""

        cnx = mysql.connector.connect(user=DB_USER,
                                    password=DB_PASSWORD,
                                    host=DB_HOST,
                                    database=DB_DBNAME,
                                    port=DB_PORT)
        cursor = cnx.cursor()
        cursor.execute(query, (seq_no,))

        row = cursor.fetchone()

        if not row:
            return None

        rel_path, download_link = row[0], row[1]

    if LOCAL_OBJ_URI:
        src_uri = 'file://' + os.path.join(DATAROOT, dataset, rel_path)
    else:
        src_uri = url_for('.get_object_src_http', dataset=dataset, rel_path=rel_path)

    return '<object id={} src={} hyperfind.external-link={} />' \
        .format(
        quoteattr(url_for('.get_object_id', dataset=dataset, seq_no=seq_no)),
        quoteattr(src_uri),
        quoteattr(download_link))
",CWE-22,174.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 20, 2021

@author: Patrik Dufresne
""""""
import rdiffweb.test


class CsrfTest(rdiffweb.test.WebCase):

    login = True

    def test_samesite_lax(self):
        # Given a request made to rdiffweb
        # When receiving the response
        self.getPage('/')
        # Then the header contains Set-Cookie with SameSite=Lax
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('SameSite=Lax', cookie)

    def test_samesite_lax_without_session(self):
        # Given not a client sending no cookie
        self.cookies = None
        # When a query is made to a static path (without session)
        self.getPage('/static/blue.css')
        # Then Set-Cookie is not defined.
        self.assertNoHeader('Set-Cookie')

    def test_get_with_wrong_origin(self):
        # Given a GET request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')])
        # Then the response status it 200 OK.
        self.assertStatus(200)

    def test_post_with_wrong_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')], method='POST')
        # Then the request is refused with 403 Forbiden
        self.assertStatus(403)
        self.assertInBody('Unexpected Origin header')

    def test_post_with_valid_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        self.getPage('/', headers=[('Origin', base)], method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_post_without_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
",CWE-1021,74.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import http.cookies
import logging

import cherrypy
from cherrypy._cptools import HandlerTool

# Define the logger
logger = logging.getLogger(__name__)

#
# Patch Morsel prior to 3.8
# Allow SameSite attribute to be define on the cookie.
#
if not http.cookies.Morsel().isReservedKey(""samesite""):
    http.cookies.Morsel._reserved['samesite'] = 'SameSite'


class CsrfAuth(HandlerTool):
    """"""
    This tool provide CSRF mitigation.

    First, by defining `SameSite=Lax` on the cookie
    Second by validating the `Origin` and `Referer`.

    Ref.: https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html
    """"""

    def __init__(self):
        HandlerTool.__init__(self, self.run, name='csrf')
        # Make sure to run before authform (priority 71)
        self._priority = 71

    def _setup(self):
        cherrypy.request.hooks.attach('before_finalize', self._set_same_site)
        return super()._setup()

    def _set_same_site(self):
        # Awaiting bug fix in cherrypy
        # https://github.com/cherrypy/cherrypy/issues/1767
        # Force SameSite to Lax
        cookie = cherrypy.serving.response.cookie.get('session_id', None)
        if cookie:
            cookie['samesite'] = 'Lax'

    def run(self):
        if cherrypy.request.method in ['POST', 'PUT', 'PATCH', 'DELETE']:
            # Check if Origin matches our target.
            origin = cherrypy.request.headers.get('Origin', None)
            if origin and not origin.startswith(cherrypy.request.base):
                raise cherrypy.HTTPError(403, 'Unexpected Origin header')


cherrypy.tools.csrf = CsrfAuth()
",CWE-1021,71.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 20, 2021

@author: Patrik Dufresne
""""""
import rdiffweb.test


class CsrfTest(rdiffweb.test.WebCase):

    login = True

    def test_samesite_lax(self):
        # Given a request made to rdiffweb
        # When receiving the response
        self.getPage('/')
        # Then the header contains Set-Cookie with SameSite=Lax
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('SameSite=Lax', cookie)

    def test_samesite_lax_without_session(self):
        # Given not a client sending no cookie
        self.cookies = None
        # When a query is made to a static path (without session)
        self.getPage('/static/blue.css')
        # Then Set-Cookie is not defined.
        self.assertNoHeader('Set-Cookie')

    def test_get_with_wrong_origin(self):
        # Given a GET request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')])
        # Then the response status it 200 OK.
        self.assertStatus(200)

    def test_post_with_wrong_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')], method='POST')
        # Then the request is refused with 403 Forbiden
        self.assertStatus(403)
        self.assertInBody('Unexpected Origin header')

    def test_post_with_valid_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        self.getPage('/', headers=[('Origin', base)], method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_post_without_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_clickjacking_defense(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-Frame-Options', 'DENY')
",CWE-311,82.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import http.cookies
import logging

import cherrypy
from cherrypy._cptools import HandlerTool

# Define the logger
logger = logging.getLogger(__name__)

#
# Patch Morsel prior to 3.8
# Allow SameSite attribute to be define on the cookie.
#
if not http.cookies.Morsel().isReservedKey(""samesite""):
    http.cookies.Morsel._reserved['samesite'] = 'SameSite'


class CsrfAuth(HandlerTool):
    """"""
    This tool provide CSRF mitigation.

    * Define X-Frame-Options = DENY
    * Define Cookies SameSite=Lax
    * Validate `Origin` and `Referer` on POST, PUT, PATCH, DELETE

    Ref.:
    https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html
    https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html
    """"""

    def __init__(self):
        HandlerTool.__init__(self, self.run, name='csrf')
        # Make sure to run before authform (priority 71)
        self._priority = 71

    def _setup(self):
        cherrypy.request.hooks.attach('before_finalize', self._set_headers)
        return super()._setup()

    def _set_headers(self):
        response = cherrypy.serving.response
        # Define X-Frame-Options to avoid Clickjacking
        response.headers['X-Frame-Options'] = 'DENY'
        # Awaiting bug fix in cherrypy
        # https://github.com/cherrypy/cherrypy/issues/1767
        # Force SameSite to Lax
        cookie = response.cookie.get('session_id', None)
        if cookie:
            cookie['samesite'] = 'Lax'

    def run(self):
        if cherrypy.request.method in ['POST', 'PUT', 'PATCH', 'DELETE']:
            # Check if Origin matches our target.
            origin = cherrypy.request.headers.get('Origin', None)
            if origin and not origin.startswith(cherrypy.request.base):
                raise cherrypy.HTTPError(403, 'Unexpected Origin header')


cherrypy.tools.csrf = CsrfAuth()
",CWE-311,77.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import logging
import re

import cherrypy
from wtforms.fields.html5 import EmailField
from wtforms.fields.simple import PasswordField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.cherrypy_wtf import CherryForm
from rdiffweb.tools.i18n import ugettext as _

# Define the logger
_logger = logging.getLogger(__name__)

PATTERN_EMAIL = re.compile(r'[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,4}$')


class UserProfileForm(CherryForm):
    email = EmailField(_('Email'), validators=[DataRequired(), Regexp(PATTERN_EMAIL, message=_(""Invalid email.""))])


class UserPasswordForm(CherryForm):
    current = PasswordField(_('Current password'), validators=[InputRequired(_(""Current password is missing.""))])
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )


class PrefsGeneralPanelProvider(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    panel_id = 'general'

    panel_name = _('Profile')

    def _handle_set_password(self, action, form):
        """"""
        Called when changing user password.
        """"""
        assert self.app.currentuser
        assert action == 'set_password'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update user password
        try:
            self.app.currentuser.set_password(form.new.data, old_password=form.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')

    def _handle_set_profile_info(self, action, form):
        """"""
        Called when changing user profile.
        """"""
        assert self.app.currentuser
        assert action == 'set_profile_info'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update the user's email
        username = self.app.currentuser.username
        _logger.info(""updating user [%s] email [%s]"", username, form.email.data)
        self.app.currentuser.email = form.email.data
        # Report success
        flash(_(""Profile updated successfully.""), level='success')

    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable
        # Process the parameters.
        profile_form = UserProfileForm(email=self.app.currentuser.email)
        password_form = UserPasswordForm()
        if action == ""set_profile_info"":
            self._handle_set_profile_info(action, profile_form)
        elif action == ""set_password"":
            self._handle_set_password(action, password_form)
        elif action == ""update_repos"":
            self.app.currentuser.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        elif action is None:
            pass
        else:
            _logger.warning(""unknown action: %s"", action)
            raise cherrypy.NotFound(""Unknown action"")
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
        }
        return ""prefs_general.html"", params
",CWE-755,124.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import logging
import re

import cherrypy
from wtforms.fields.html5 import EmailField
from wtforms.fields.simple import PasswordField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.cherrypy_wtf import CherryForm
from rdiffweb.tools.i18n import ugettext as _

# Define the logger
_logger = logging.getLogger(__name__)

PATTERN_EMAIL = re.compile(r'[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,4}$')


class UserProfileForm(CherryForm):
    email = EmailField(_('Email'), validators=[DataRequired(), Regexp(PATTERN_EMAIL, message=_(""Invalid email.""))])


class UserPasswordForm(CherryForm):
    current = PasswordField(_('Current password'), validators=[InputRequired(_(""Current password is missing.""))])
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )


class PrefsGeneralPanelProvider(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    panel_id = 'general'

    panel_name = _('Profile')

    def _handle_set_password(self, action, form):
        """"""
        Called when changing user password.
        """"""
        assert self.app.currentuser
        assert action == 'set_password'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update user password
        try:
            self.app.currentuser.set_password(form.new.data, old_password=form.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')

    def _handle_set_profile_info(self, action, form):
        """"""
        Called when changing user profile.
        """"""
        assert self.app.currentuser
        assert action == 'set_profile_info'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update the user's email
        username = self.app.currentuser.username
        _logger.info(""updating user [%s] email [%s]"", username, form.email.data)
        self.app.currentuser.email = form.email.data
        # Report success
        flash(_(""Profile updated successfully.""), level='success')

    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable
        # Process the parameters.
        profile_form = UserProfileForm(email=self.app.currentuser.email)
        password_form = UserPasswordForm()
        if action == ""set_profile_info"":
            self._handle_set_profile_info(action, profile_form)
        elif action == ""set_password"":
            self._handle_set_password(action, password_form)
        elif action == ""update_repos"":
            self.app.currentuser.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        elif action is None:
            pass
        else:
            _logger.warning(""unknown action: %s"", action)
            raise cherrypy.NotFound(""Unknown action"")
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
        }
        return ""prefs_general.html"", params
",CWE-521,124.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Dec 26, 2015

@author: Patrik Dufresne
""""""

from unittest.mock import MagicMock

import cherrypy

import rdiffweb.test
from rdiffweb.core.store import _REPOS


class PrefsTest(rdiffweb.test.WebCase):

    PREFS = ""/prefs/""

    login = True

    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)
        return super().tearDown()

    def _set_password(
        self,
        current,
        new_password,
        confirm,
    ):
        b = {
            'action': 'set_password',
            'current': current,
            'new': new_password,
            'confirm': confirm,
        }
        return self.getPage(self.PREFS, method='POST', body=b)

    def _set_profile_info(self, email):
        b = {
            'action': 'set_profile_info',
            'email': email,
        }
        return self.getPage(self.PREFS, method='POST', body=b)

    def test_change_email(self):
        self._set_profile_info(""test@test.com"")
        self.assertInBody(""Profile updated successfully."")

    def test_change_email_with_invalid_email(self):
        self._set_profile_info(""@test.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test@te_st.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test@test.com, test2@test.com"")
        self.assertInBody(""Invalid email"")

    def test_change_password(self):
        # When udating user's password
        self._set_password(self.PASSWORD, ""newpass"", ""newpass"")
        self.assertInBody(""Password updated successfully."")
        # Then a notification is raised
        self.listener.user_password_changed.assert_called_once()
        # Change it back
        self._set_password(""newpass"", self.PASSWORD, self.PASSWORD)
        self.assertInBody(""Password updated successfully."")

    def test_change_password_with_wrong_confirmation(self):
        self._set_password(self.PASSWORD, ""t"", ""a"")
        self.assertInBody(""The new password and its confirmation do not match."")

    def test_change_password_with_wrong_password(self):
        self._set_password(""oups"", ""t"", ""t"")
        self.assertInBody(""Wrong password"")

    def test_invalid_pref(self):
        """"""
        Check if invalid prefs url is 404 Not Found.
        """"""
        self.getPage(""/prefs/invalid/"")
        self.assertStatus(404)

    def test_update_repos(self):
        # Given a user with invalid repositories
        userobj = self.app.store.get_user(self.USERNAME)
        with self.app.store.engine.connect() as conn:
            conn.execute(_REPOS.insert().values(userid=userobj._userid, repopath='invalid'))
        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))
        # When updating the repository list
        self.getPage(self.PREFS, method='POST', body={'action': 'update_repos'})
        self.assertStatus(200)
        # Then a success message is displayed
        self.assertInBody('Repositories successfully updated')
        # Then the list is free of inexisting repos.
        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))

    def test_update_notification(self):
        self.getPage(""/prefs/notification/"", method='POST', body={'action': 'set_notification_info', 'testcases': '7'})
        self.assertStatus(200)
        # Check database update
        repo_obj = self.app.store.get_user(self.USERNAME).get_repo(self.REPO)
        self.assertEqual(7, repo_obj.maxage)

    def test_get_page(self):
        self.getPage(""/prefs/"", method='GET')
        self.assertInBody(""SSH"")


class PrefsWithSSHKeyDisabled(rdiffweb.test.WebCase):

    default_config = {
        ""disable_ssh_keys"": ""true"",
    }

    def test_get_page(self):
        self.getPage(""/prefs/"", method='GET')
        self.assertNotInBody(""SSH"")
",CWE-755,147.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Dec 26, 2015

@author: Patrik Dufresne
""""""

from unittest.mock import MagicMock

import cherrypy

import rdiffweb.test
from rdiffweb.core.store import _REPOS


class PrefsTest(rdiffweb.test.WebCase):

    PREFS = ""/prefs/""

    login = True

    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)
        return super().tearDown()

    def _set_password(
        self,
        current,
        new_password,
        confirm,
    ):
        b = {
            'action': 'set_password',
            'current': current,
            'new': new_password,
            'confirm': confirm,
        }
        return self.getPage(self.PREFS, method='POST', body=b)

    def _set_profile_info(self, email):
        b = {
            'action': 'set_profile_info',
            'email': email,
        }
        return self.getPage(self.PREFS, method='POST', body=b)

    def test_change_email(self):
        self._set_profile_info(""test@test.com"")
        self.assertInBody(""Profile updated successfully."")

    def test_change_email_with_invalid_email(self):
        self._set_profile_info(""@test.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test@te_st.com"")
        self.assertInBody(""Invalid email"")

        self._set_profile_info(""test@test.com, test2@test.com"")
        self.assertInBody(""Invalid email"")

    def test_change_password(self):
        # When udating user's password
        self._set_password(self.PASSWORD, ""newpass"", ""newpass"")
        self.assertInBody(""Password updated successfully."")
        # Then a notification is raised
        self.listener.user_password_changed.assert_called_once()
        # Change it back
        self._set_password(""newpass"", self.PASSWORD, self.PASSWORD)
        self.assertInBody(""Password updated successfully."")

    def test_change_password_with_wrong_confirmation(self):
        self._set_password(self.PASSWORD, ""t"", ""a"")
        self.assertInBody(""The new password and its confirmation do not match."")

    def test_change_password_with_wrong_password(self):
        self._set_password(""oups"", ""t"", ""t"")
        self.assertInBody(""Wrong password"")

    def test_invalid_pref(self):
        """"""
        Check if invalid prefs url is 404 Not Found.
        """"""
        self.getPage(""/prefs/invalid/"")
        self.assertStatus(404)

    def test_update_repos(self):
        # Given a user with invalid repositories
        userobj = self.app.store.get_user(self.USERNAME)
        with self.app.store.engine.connect() as conn:
            conn.execute(_REPOS.insert().values(userid=userobj._userid, repopath='invalid'))
        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))
        # When updating the repository list
        self.getPage(self.PREFS, method='POST', body={'action': 'update_repos'})
        self.assertStatus(200)
        # Then a success message is displayed
        self.assertInBody('Repositories successfully updated')
        # Then the list is free of inexisting repos.
        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))

    def test_update_notification(self):
        self.getPage(""/prefs/notification/"", method='POST', body={'action': 'set_notification_info', 'testcases': '7'})
        self.assertStatus(200)
        # Check database update
        repo_obj = self.app.store.get_user(self.USERNAME).get_repo(self.REPO)
        self.assertEqual(7, repo_obj.maxage)

    def test_get_page(self):
        self.getPage(""/prefs/"", method='GET')
        self.assertInBody(""SSH"")


class PrefsWithSSHKeyDisabled(rdiffweb.test.WebCase):

    default_config = {
        ""disable_ssh_keys"": ""true"",
    }

    def test_get_page(self):
        self.getPage(""/prefs/"", method='GET')
        self.assertNotInBody(""SSH"")
",CWE-521,147.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugins to allows users to configure the SSH keys using the web
interface. Basically it's a UI for `~/.ssh/authorized_keys`. For this
plugin to work properly, the users home directory need to match a real
user home.
""""""

import logging

from wtforms import validators
from wtforms.fields.core import StringField
from wtforms.validators import ValidationError
from wtforms.widgets.core import TextArea

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.cherrypy_wtf import CherryForm
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.core import authorizedkeys
from rdiffweb.core.store import DuplicateSSHKeyError
from rdiffweb.tools.i18n import ugettext as _

_logger = logging.getLogger(__name__)


def validate_key(unused_form, field):
    """"""Custom validator to check the SSH Key.""""""
    try:
        authorizedkeys.check_publickey(field.data)
    except ValueError:
        raise ValidationError(_(""Invalid SSH key.""))


class SshForm(CherryForm):
    title = StringField(
        _('Title'),
        description=_('The title is an optional description to identify the key. e.g.: bob@thinkpad-t530'),
        validators=[validators.data_required()],
    )
    key = StringField(
        _('Key'),
        widget=TextArea(),
        description=_(
            ""Enter a SSH public key. It should start with 'ssh-dss', 'ssh-ed25519', 'ssh-rsa', 'ecdsa-sha2-nistp256', 'ecdsa-sha2-nistp384' or 'ecdsa-sha2-nistp521'.""
        ),
        validators=[validators.data_required(), validate_key],
    )
    fingerprint = StringField('Fingerprint')


class DeleteSshForm(CherryForm):
    fingerprint = StringField('Fingerprint')


class SSHKeysPlugin(Controller):
    """"""
    Plugin to configure SSH keys.
    """"""

    panel_id = 'sshkeys'

    panel_name = _('SSH Keys')

    def _add_key(self, action, form):
        assert action == 'add'
        assert form
        if not form.validate():
            for unused, messages in form.errors.items():
                for message in messages:
                    flash(message, level='warning')
            return
        try:
            self.app.currentuser.add_authorizedkey(key=form.key.data, comment=form.title.data)
        except DuplicateSSHKeyError as e:
            flash(str(e), level='error')
        except Exception:
            flash(_(""Unknown error while adding the SSH Key""), level='error')
            _logger.warning(""error adding ssh key"", exc_info=1)

    def _delete_key(self, action, form):
        assert action == 'delete'
        assert form
        if not form.validate():
            for unused, messages in form.errors.items():
                for message in messages:
                    flash(message, level='warning')
            return
        is_maintainer()
        try:
            self.app.currentuser.delete_authorizedkey(form.fingerprint.data)
        except Exception:
            flash(_(""Unknown error while removing the SSH Key""), level='error')
            _logger.warning(""error removing ssh key"", exc_info=1)

    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable

        # Handle action
        form = SshForm()
        if action == ""add"":
            self._add_key(action, form)
        elif action == 'delete':
            self._delete_key(action, DeleteSshForm())

        # Get SSH keys if file exists.
        params = {'form': form}
        try:
            params[""sshkeys""] = [
                {'title': key.comment or (key.keytype + ' ' + key.key[:18]), 'fingerprint': key.fingerprint}
                for key in self.app.currentuser.authorizedkeys
            ]
        except IOError:
            params[""sshkeys""] = []
            flash(_(""Failed to get SSH keys""), level='error')
            _logger.warning(""error reading SSH keys"", exc_info=1)

        return ""prefs_sshkeys.html"", params
",CWE-352,132.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Jan 1, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""


import rdiffweb.test

PREFS_SSHKEYS = ""/prefs/sshkeys/""


class SSHKeysTest(rdiffweb.test.WebCase):

    login = True

    def _delete_ssh_key(self, fingerprint):
        b = {'action': 'delete', 'fingerprint': fingerprint}
        self.getPage(PREFS_SSHKEYS, method='POST', body=b)

    def _add_ssh_key(self, title, key):
        b = {'action': 'add', 'title': title, 'key': key}
        self.getPage(PREFS_SSHKEYS, method='POST', body=b)

    def test_page(self):
        self.getPage(PREFS_SSHKEYS)
        self.assertStatus('200 OK')

    def test_add(self):
        # Delete existing keys
        user = self.app.store.get_user('admin')
        for key in user.authorizedkeys:
            user.delete_authorizedkey(key.fingerprint)
        self.assertEqual(0, len(list(user.authorizedkeys)))

        # Add a new key
        self._add_ssh_key(
            ""test@mysshkey"",
            ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSEN5VTn9MLituZvdYTZMbZEaMxe0UuU7BelxHkvxzSpVWtazrIBEc3KZjtVoK9F3+0kd26P4DzSQuPUl3yZDgyZZeXrF6p2GlEA7A3tPuOEsAQ9c0oTiDYktq5/Go8vD+XAZKLd//qmCWW1Jg4datkWchMKJzbHUgBrBH015FDbGvGDWYTfVyb8I9H+LQ0GmbTHsuTu63DhPODncMtWPuS9be/flb4EEojMIx5Vce0SNO9Eih38W7jTvNWxZb75k5yfPJxBULRnS5v/fPnDVVtD3JSGybSwKoMdsMX5iImAeNhqnvd8gBu1f0IycUQexTbJXk1rPiRcF13SjKrfXz ikus060@ikus060-t530"",
        )
        self.assertStatus('200 OK')
        self.assertEqual(1, len(list(user.authorizedkeys)))

        # Show page
        self.getPage(PREFS_SSHKEYS)
        self.assertInBody(""test@mysshkey"")
        self.assertInBody(""4d:42:8b:35:e5:55:71:f7:b3:0d:58:f9:b1:2c:9e:91"")

    def test_add_duplicate(self):
        # Delete existing keys
        user = self.app.store.get_user('admin')
        for key in user.authorizedkeys:
            user.delete_authorizedkey(key.fingerprint)
        self.assertEqual(0, len(list(user.authorizedkeys)))

        # Add a new key
        self._add_ssh_key(
            ""test@mysshkey"",
            ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSEN5VTn9MLituZvdYTZMbZEaMxe0UuU7BelxHkvxzSpVWtazrIBEc3KZjtVoK9F3+0kd26P4DzSQuPUl3yZDgyZZeXrF6p2GlEA7A3tPuOEsAQ9c0oTiDYktq5/Go8vD+XAZKLd//qmCWW1Jg4datkWchMKJzbHUgBrBH015FDbGvGDWYTfVyb8I9H+LQ0GmbTHsuTu63DhPODncMtWPuS9be/flb4EEojMIx5Vce0SNO9Eih38W7jTvNWxZb75k5yfPJxBULRnS5v/fPnDVVtD3JSGybSwKoMdsMX5iImAeNhqnvd8gBu1f0IycUQexTbJXk1rPiRcF13SjKrfXz ikus060@ikus060-t530"",
        )
        self.assertStatus('200 OK')
        self.assertNotInBody(""Duplicate key."")
        self.assertEqual(1, len(list(user.authorizedkeys)))

        # Add a new key
        self._add_ssh_key(
            ""test@mysshkey"",
            ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSEN5VTn9MLituZvdYTZMbZEaMxe0UuU7BelxHkvxzSpVWtazrIBEc3KZjtVoK9F3+0kd26P4DzSQuPUl3yZDgyZZeXrF6p2GlEA7A3tPuOEsAQ9c0oTiDYktq5/Go8vD+XAZKLd//qmCWW1Jg4datkWchMKJzbHUgBrBH015FDbGvGDWYTfVyb8I9H+LQ0GmbTHsuTu63DhPODncMtWPuS9be/flb4EEojMIx5Vce0SNO9Eih38W7jTvNWxZb75k5yfPJxBULRnS5v/fPnDVVtD3JSGybSwKoMdsMX5iImAeNhqnvd8gBu1f0IycUQexTbJXk1rPiRcF13SjKrfXz ikus060@ikus060-t530"",
        )
        self.assertStatus('200 OK')
        self.assertInBody(""Duplicate key."")
        self.assertEqual(1, len(list(user.authorizedkeys)))

    def test_add_invalid(self):
        # Delete existing keys
        user = self.app.store.get_user('admin')
        for key in user.authorizedkeys:
            user.delete_authorizedkey(key.fingerprint)

        # Add key
        self._add_ssh_key(""test@mysshkey"", ""lkjasdfoiuwerlk"")
        self.assertStatus(200)
        self.assertInBody(""Invalid SSH key."")
        self.assertEqual(0, len(list(user.authorizedkeys)))

    def test_delete(self):
        # Delete existing keys
        user = self.app.store.get_user('admin')
        for key in user.authorizedkeys:
            user.delete_authorizedkey(key.fingerprint)
        self.assertEqual(0, len(list(user.authorizedkeys)))

        # Add a new key
        self._add_ssh_key(
            ""test@mysshkey"",
            ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSEN5VTn9MLituZvdYTZMbZEaMxe0UuU7BelxHkvxzSpVWtazrIBEc3KZjtVoK9F3+0kd26P4DzSQuPUl3yZDgyZZeXrF6p2GlEA7A3tPuOEsAQ9c0oTiDYktq5/Go8vD+XAZKLd//qmCWW1Jg4datkWchMKJzbHUgBrBH015FDbGvGDWYTfVyb8I9H+LQ0GmbTHsuTu63DhPODncMtWPuS9be/flb4EEojMIx5Vce0SNO9Eih38W7jTvNWxZb75k5yfPJxBULRnS5v/fPnDVVtD3JSGybSwKoMdsMX5iImAeNhqnvd8gBu1f0IycUQexTbJXk1rPiRcF13SjKrfXz ikus060@ikus060-t530"",
        )
        self.assertStatus('200 OK')
        self.assertEqual(1, len(list(user.authorizedkeys)))

        # Delete Key
        self._delete_ssh_key(""4d:42:8b:35:e5:55:71:f7:b3:0d:58:f9:b1:2c:9e:91"")
        self.assertStatus('200 OK')
        self.assertEqual(0, len(list(user.authorizedkeys)))

    def test_delete_invalid(self):
        # Delete existing keys
        user = self.app.store.get_user('admin')
        for key in user.authorizedkeys:
            user.delete_authorizedkey(key.fingerprint)
        self.assertEqual(0, len(list(user.authorizedkeys)))

        # Add a new key
        self._add_ssh_key(
            ""test@mysshkey"",
            ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSEN5VTn9MLituZvdYTZMbZEaMxe0UuU7BelxHkvxzSpVWtazrIBEc3KZjtVoK9F3+0kd26P4DzSQuPUl3yZDgyZZeXrF6p2GlEA7A3tPuOEsAQ9c0oTiDYktq5/Go8vD+XAZKLd//qmCWW1Jg4datkWchMKJzbHUgBrBH015FDbGvGDWYTfVyb8I9H+LQ0GmbTHsuTu63DhPODncMtWPuS9be/flb4EEojMIx5Vce0SNO9Eih38W7jTvNWxZb75k5yfPJxBULRnS5v/fPnDVVtD3JSGybSwKoMdsMX5iImAeNhqnvd8gBu1f0IycUQexTbJXk1rPiRcF13SjKrfXz ikus060@ikus060-t530"",
        )
        self.assertStatus('200 OK')
        self.assertEqual(1, len(list(user.authorizedkeys)))

        # Delete Key
        self._delete_ssh_key(""invalid"")
        self.assertStatus('200 OK')
        self.assertEqual(1, len(list(user.authorizedkeys)))
",CWE-352,141.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
'''
Created on Apr. 5, 2021

@author: Patrik Dufresne <patrik@ikus-soft.com>
'''
# Define the logger

import logging

import cherrypy
from wtforms import validators
from wtforms.fields.core import StringField

from rdiffweb.controller import Controller
from rdiffweb.controller.cherrypy_wtf import CherryForm
from rdiffweb.controller.dispatch import poppath
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError
from rdiffweb.tools.i18n import ugettext as _

_logger = logging.getLogger(__name__)


class DeleteRepoForm(CherryForm):
    confirm = StringField(_('Confirmation'), validators=[validators.data_required()])
    redirect = StringField(default='/')


@poppath()
class DeletePage(Controller):
    @cherrypy.expose
    @cherrypy.tools.errors(
        error_table={
            DoesNotExistError: 404,
            AccessDeniedError: 403,
        }
    )
    def default(self, path=b"""", **kwargs):
        # Check permissions on path/repo
        repo, path = self.app.store.get_repo_path(path)
        # Check if path exists with fstats
        path_obj = repo.fstat(path)
        # Check user's permissions
        is_maintainer()

        # validate form
        form = DeleteRepoForm()
        if not form.validate():
            raise cherrypy.HTTPError(400, form.error_message)

        # Validate the name
        if form.confirm.data != path_obj.display_name:
            _logger.info(""do not delete repo, bad confirmation %r != %r"", form.confirm.data, path_obj.display_name)
            raise cherrypy.HTTPError(400, 'bad confirmation')

        # Delete repository in background using a schedule task.
        scheduled = cherrypy.engine.publish('schedule_task', repo.delete, path)
        assert scheduled
        raise cherrypy.HTTPRedirect(form.redirect.data)
",CWE-352,76.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import logging
import re

import cherrypy
from wtforms.fields.html5 import EmailField
from wtforms.fields.simple import PasswordField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.cherrypy_wtf import CherryForm
from rdiffweb.tools.i18n import ugettext as _

# Define the logger
_logger = logging.getLogger(__name__)

PATTERN_EMAIL = re.compile(r'[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,4}$')


class UserProfileForm(CherryForm):
    email = EmailField(_('Email'), validators=[DataRequired(), Regexp(PATTERN_EMAIL, message=_(""Invalid email.""))])


class UserPasswordForm(CherryForm):
    current = PasswordField(_('Current password'), validators=[InputRequired(_(""Current password is missing.""))])
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.new.validators += [
            Length(
                min=self.app.cfg.password_min_length,
                max=self.app.cfg.password_max_length,
                message=_('Password must have between %(min)d and %(max)d characters.'),
            )
        ]

    @property
    def app(self):
        return cherrypy.request.app


class PrefsGeneralPanelProvider(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    panel_id = 'general'

    panel_name = _('Profile')

    def _handle_set_password(self, action, form):
        """"""
        Called when changing user password.
        """"""
        assert self.app.currentuser
        assert action == 'set_password'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update user password
        try:
            self.app.currentuser.set_password(form.new.data, old_password=form.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')

    def _handle_set_profile_info(self, action, form):
        """"""
        Called when changing user profile.
        """"""
        assert self.app.currentuser
        assert action == 'set_profile_info'
        assert form
        # Validate form
        if not form.validate():
            flash(form.error_message, level='error')
            return
        # Update the user's email
        username = self.app.currentuser.username
        _logger.info(""updating user [%s] email [%s]"", username, form.email.data)
        self.app.currentuser.email = form.email.data
        # Report success
        flash(_(""Profile updated successfully.""), level='success')

    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable
        # Process the parameters.
        profile_form = UserProfileForm(email=self.app.currentuser.email)
        password_form = UserPasswordForm()
        if action == ""set_profile_info"":
            self._handle_set_profile_info(action, profile_form)
        elif action == ""set_password"":
            self._handle_set_password(action, password_form)
        elif action == ""update_repos"":
            self.app.currentuser.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        elif action is None:
            pass
        else:
            _logger.warning(""unknown action: %s"", action)
            raise cherrypy.NotFound(""Unknown action"")
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
        }
        return ""prefs_general.html"", params
",CWE-352,138.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import logging
import re

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.tools.i18n import gettext_lazy as _

# Define the logger
_logger = logging.getLogger(__name__)

PATTERN_EMAIL = re.compile(r'[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,4}$')


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(_('Fullname'))
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Invalid email."")),
            Regexp(PATTERN_EMAIL, message=_(""Invalid email."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.new.validators += [
            Length(
                min=self.app.cfg.password_min_length,
                max=self.app.cfg.password_max_length,
                message=_('Password must have between %(min)d and %(max)d characters.'),
            )
        ]

    @property
    def app(self):
        return cherrypy.request.app

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def populate_obj(self, user):
        try:
            user.set_password(self.new.data, old_password=self.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                password_form.populate_obj(self.app.currentuser)
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-770,163.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import logging

import cherrypy
from wtforms.fields import DateField, HiddenField, StringField, SubmitField
from wtforms.validators import DataRequired, Optional

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import Token
from rdiffweb.tools.i18n import gettext_lazy as _

logger = logging.getLogger(__name__)


class TokenForm(CherryForm):
    action = HiddenField(default='add_access_token')
    name = StringField(
        _('Token name'),
        description=_(
            'Used only to identify the purpose of the token. For example, the application that uses the token.'
        ),
        validators=[DataRequired()],
    )
    expiration = DateField(
        _('Expiration date'),
        description=_(
            'Allows the creation of a temporary token by defining an expiration date. Leave empty to keep the token forever.'
        ),
        render_kw={
            ""placeholder"": _('YYYY-MM-DD'),
        },
        validators=[Optional()],
    )
    submit = SubmitField(_('Create access token'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'add_access_token'

    def populate_obj(self, userobj):
        try:
            token = userobj.add_access_token(self.name.data, self.expiration.data)
            flash(
                _(
                    ""Your new personal access token has been created.\n""
                    ""Make sure to save it - you won't be able to access it again.\n""
                    ""%s""
                )
                % token,
                level='info',
            )
        except ValueError as e:
            flash(str(e), level='warning')
        except Exception:
            logger.exception(""error adding access token: %s, %s"" % (self.name.data, self.expiration.data))
            flash(_(""Unknown error while adding the access token.""), level='error')


class DeleteTokenForm(CherryForm):
    action = HiddenField(default='delete_access_token')
    name = StringField(validators=[DataRequired()])

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'delete_access_token'

    def populate_obj(self, userobj):
        is_maintainer()
        try:
            userobj.delete_access_token(self.name.data)
            flash(_('The access token has been successfully deleted.'), level='success')
        except ValueError as e:
            flash(str(e), level='warning')
        except Exception:
            logger.exception(""error removing access token: %s"" % self.name.data)
            flash(_(""Unknown error while removing the access token.""), level='error')


class PagePrefTokens(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        form = TokenForm()
        delete_form = DeleteTokenForm()
        if form.is_submitted():
            if form.validate():
                form.populate_obj(self.app.currentuser)
            else:
                flash(form.error_message, level='error')
        elif delete_form.is_submitted():
            if delete_form.validate():
                delete_form.populate_obj(self.app.currentuser)
            else:
                flash(delete_form.error_message, level='error')
        params = {
            'form': form,
            'tokens': Token.query.filter(Token.userid == self.app.currentuser.userid),
        }
        return self._compile_template(""prefs_tokens.html"", **params)
",CWE-770,118.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import rdiffweb.test
from rdiffweb.core.model import Token, UserObject


class PagePrefTokensTest(rdiffweb.test.WebCase):

    login = True

    def test_get(self):
        # When getting the page
        self.getPage(""/prefs/tokens"")
        # Then the page is return without error
        self.assertStatus(200)

    def test_add_access_token(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': 'test-token-name', 'expiration_time': ''},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('test-token-name')
        # Then access token get created
        self.assertEqual(1, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_add_access_token_with_expiration_time(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': 'test-token-name', 'expiration_time': '1999-01-01'},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('test-token-name')
        # Then access token get created
        self.assertEqual(1, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_add_access_token_without_name(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': '', 'expiration_time': ''},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('Token name: This field is required.')
        # Then access token is not created
        self.assertEqual(0, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_delete_access_token(self):
        # Given an existing user with access_token
        userobj = UserObject.get_user(self.USERNAME)
        userobj.add_access_token('test-token-name')
        # When deleting access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'delete_access_token', 'name': 'test-token-name'},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('The access token has been successfully deleted.')
        # Then access token is not created
        self.assertEqual(0, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())
",CWE-770,97.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import logging
import re

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Optional, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.tools.i18n import gettext_lazy as _

# Define the logger
_logger = logging.getLogger(__name__)

PATTERN_EMAIL = re.compile(r'[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,4}$')


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(
        _('Fullname'),
        validators=[
            Optional(),
            Length(max=256, message=_('Fullname too long.')),
        ],
    )
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Invalid email."")),
            Regexp(PATTERN_EMAIL, message=_(""Invalid email."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def populate_obj(self, user):
        try:
            user.set_password(self.new.data, old_password=self.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                password_form.populate_obj(self.app.currentuser)
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-601,155.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging
import os
from collections import namedtuple

import cherrypy
import pkg_resources

from rdiffweb.core.config import Option
from rdiffweb.core.librdiff import RdiffTime
from rdiffweb.tools.i18n import ugettext as _

# Define the logger
logger = logging.getLogger(__name__)


def validate(value, message=None):
    """"""Raise HTTP error if value is not true.""""""
    if not value:
        raise cherrypy.HTTPError(400, message)


def validate_int(value, message=None):
    """"""Raise HTTP Error if the value is not an integer""""""
    try:
        return int(value)
    except ValueError:
        raise cherrypy.HTTPError(400, message)


def validate_isinstance(value, cls, message=None):
    """"""Raise HTTP error if value is not cls.""""""
    if not isinstance(value, cls):
        raise cherrypy.HTTPError(400, message)


def validate_date(value, message=None):
    try:
        return RdiffTime(int(value))
    except ValueError:
        logger.warning(""invalid date %s"", value)
        raise cherrypy.HTTPError(400, message or _('Invalid date.'))


FlashMessage = namedtuple('FlashMessage', ['message', 'level'])


def flash(message, level='info'):
    """"""
    Add a flashin message to the session.
    """"""
    assert message
    assert level in ['info', 'error', 'warning', 'success']
    if 'flash' not in cherrypy.session:  # @UndefinedVariable
        cherrypy.session['flash'] = []  # @UndefinedVariable
    flash_message = FlashMessage(message, level)
    cherrypy.session['flash'].append(flash_message)


def get_flashed_messages():
    if 'flash' in cherrypy.session:  # @UndefinedVariable
        messages = cherrypy.session['flash']  # @UndefinedVariable
        del cherrypy.session['flash']  # @UndefinedVariable
        return messages
    return []


class Controller(object):

    _header_name = Option(""header_name"")

    _footername = Option(""footer_name"")

    _footerurl = Option(""footer_url"")

    _default_theme = Option(""default_theme"")

    @property
    def app(self):
        return cherrypy.request.app

    def _compile_template(self, template_name, **kwargs):
        """"""
        Used to generate a standard HTML page using the given template.
        This method should be used by subclasses to provide default template
        value.
        """"""
        loc = cherrypy.response.i18n.locale
        parms = {
            ""lang"": loc.language,
            ""header_name"": self._header_name,
            ""theme"": self._default_theme,
            ""footername"": self._footername,
            ""footerurl"": self._footerurl,
            ""get_flashed_messages"": get_flashed_messages,
        }
        if self.app.currentuser:
            parms.update(
                {
                    'username': self.app.currentuser.username,
                    'fullname': self.app.currentuser.fullname,
                    'is_admin': self.app.currentuser.is_admin,
                    'is_maintainer': self.app.currentuser.is_maintainer,
                }
            )
        elif getattr(cherrypy.serving.request, 'login', None):
            parms.update(
                {
                    'username': cherrypy.serving.request.login,
                }
            )

        # Append custom branding
        if hasattr(self.app.root, ""header_logo""):
            parms[""header_logo""] = '/header_logo'

        # Check if theme exists.
        default_theme_css = pkg_resources.resource_filename('rdiffweb', 'static/%s.css' % self._default_theme)
        if not os.access(default_theme_css, os.F_OK):
            logger.warning(""invalid DefaultTheme value, %s doesn't exists"" % default_theme_css)

        # Append template parameters.
        parms.update(kwargs)

        return self.app.templates.compile_template(template_name, **parms)
",CWE-326,142.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Optional, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(
        _('Fullname'),
        validators=[
            Optional(),
            Length(max=256, message=_('Fullname too long.')),
            Regexp(UserObject.PATTERN_FULLNAME, message=_('Must not contain any special characters.')),
        ],
    )
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Email too long."")),
            Regexp(UserObject.PATTERN_EMAIL, message=_(""Must be a valid email address."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def populate_obj(self, user):
        try:
            user.set_password(self.new.data, old_password=self.current.data)
            flash(_(""Password updated successfully.""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                password_form.populate_obj(self.app.currentuser)
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-326,149.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging

import cherrypy
from cherrypy.process.plugins import SimplePlugin

from rdiffweb.core.model import UserObject
from rdiffweb.core.passwd import check_password

logger = logging.getLogger(__name__)


class LoginPlugin(SimplePlugin):
    """"""
    This plugins register an ""authenticate"" listener to validate
    username and password of users. In addition, it provide a ""login""
    listener to authenticate and possibly create the user in database.
    """"""

    add_missing_user = False
    add_user_default_role = UserObject.USER_ROLE
    add_user_default_userroot = None

    def start(self):
        self.bus.log('Start Login plugin')
        self.bus.subscribe(""authenticate"", self.authenticate)
        self.bus.subscribe(""login"", self.login)

    def stop(self):
        self.bus.log('Stop Login plugin')
        self.bus.unsubscribe(""authenticate"", self.authenticate)
        self.bus.unsubscribe(""login"", self.login)

    def authenticate(self, username, password):
        """"""
        Only verify the user's credentials using the database store.
        """"""
        user = UserObject.query.filter_by(username=username).first()
        if user and check_password(password, user.hash_password):
            return username, {}
        return False

    def login(self, username, password):
        """"""
        Validate username password using database and LDAP.
        """"""
        # Validate credentials.
        authenticates = self.bus.publish('authenticate', username, password)
        authenticates = [a for a in authenticates if a]
        if not authenticates:
            return None
        real_username = authenticates[0][0]
        extra_attrs = authenticates[0][1]
        fullname = extra_attrs.get('_fullname', None)
        email = extra_attrs.get('_email', None)
        # When enabled, create missing userobj in database.
        userobj = UserObject.query.filter_by(username=username).first()
        if userobj is None and self.add_missing_user:
            try:
                # At this point, we need to create a new user in database.
                # In case default values are invalid, let evaluate them
                # before creating the user in database.
                default_user_root = self.add_user_default_userroot and self.add_user_default_userroot.format(
                    **extra_attrs
                )
                default_role = UserObject.ROLES.get(self.add_user_default_role)
                userobj = UserObject.add_user(
                    username=real_username,
                    fullname=fullname,
                    email=email,
                    role=default_role,
                    user_root=default_user_root,
                ).add()
            except Exception:
                logger.error('fail to create new user', exc_info=1)
        if userobj is None:
            # User doesn't exists in database
            return None

        # Update user attributes
        dirty = False
        if fullname:
            userobj.fullname = fullname
            dirty = True
        if email:
            userobj.email = email
            dirty = True
        if dirty:
            userobj.add()
        self.bus.publish('user_login', userobj)
        return userobj


cherrypy.login = LoginPlugin(cherrypy.engine)
cherrypy.login.subscribe()

cherrypy.config.namespaces['login'] = lambda key, value: setattr(cherrypy.login, key, value)
",CWE-326,114.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Optional, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _

# Maximum number of password change attempt before logout
CHANGE_PASSWORD_MAX_ATTEMPT = 5
CHANGE_PASSWORD_ATTEMPTS = 'change_password_attempts'


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(
        _('Fullname'),
        validators=[
            Optional(),
            Length(max=256, message=_('Fullname too long.')),
            Regexp(UserObject.PATTERN_FULLNAME, message=_('Must not contain any special characters.')),
        ],
    )
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Email too long."")),
            Regexp(UserObject.PATTERN_EMAIL, message=_(""Must be a valid email address."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def populate_obj(self, user):
        # Check if current password is ""valid"" if Not, rate limit the
        # number of attempts and logout user after too many invalid attempts.
        if not user.validate_password(self.current.data):
            cherrypy.session[CHANGE_PASSWORD_ATTEMPTS] = cherrypy.session.get(CHANGE_PASSWORD_ATTEMPTS, 0) + 1
            attempts = cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]
            if attempts >= CHANGE_PASSWORD_MAX_ATTEMPT:
                cherrypy.session.clear()
                cherrypy.session.regenerate()
                flash(
                    _(""You were logged out because you entered the wrong password too many times.""),
                    level='warning',
                )
                raise cherrypy.HTTPRedirect('/login/')
            flash(_(""Wrong current password.""), level='warning')
        else:
            # Clear number of attempts
            if CHANGE_PASSWORD_ATTEMPTS in cherrypy.session:
                del cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]
            # If Valid, update password
            try:
                user.set_password(self.new.data)
                flash(_(""Password updated successfully.""), level='success')
            except ValueError as e:
                flash(str(e), level='warning')


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                password_form.populate_obj(self.app.currentuser)
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-521,172.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Nov 16, 2017

@author: Patrik Dufresne
""""""
# Define the logger


import logging

import cherrypy

from rdiffweb.controller import Controller
from rdiffweb.core.librdiff import RdiffTime
from rdiffweb.core.model import UserObject

try:
    import simplejson as json
except ImportError:
    import json

logger = logging.getLogger(__name__)


def json_handler(*args, **kwargs):
    """"""Custom json handle to convert RdiffDate to str.""""""
    value = cherrypy.serving.request._json_inner_handler(*args, **kwargs)

    def default(o):
        if isinstance(o, RdiffTime):
            return str(o)
        raise TypeError(repr(o) + "" is not JSON serializable"")

    encode = json.JSONEncoder(default=default, ensure_ascii=False).iterencode
    for chunk in encode(value):
        yield chunk.encode('utf-8')


def _checkpassword(realm, username, password):
    """"""
    Check basic authentication.
    """"""
    # Validate username
    userobj = UserObject.get_user(username)
    if userobj is not None:
        # Verify if the password matches a token.
        if userobj.validate_access_token(password):
            return True
        # Disable password authentication for MFA
        if userobj.mfa == UserObject.ENABLED_MFA:
            return False
    # Otherwise validate username password
    return any(cherrypy.engine.publish('login', username, password))


class ApiCurrentUser(Controller):
    @cherrypy.expose
    def default(self):
        u = self.app.currentuser
        u.refresh_repos()
        return {
            ""email"": u.email,
            ""username"": u.username,
            ""repos"": [
                {
                    # Database fields.
                    ""name"": repo_obj.name,
                    ""maxage"": repo_obj.maxage,
                    ""keepdays"": repo_obj.keepdays,
                    # Repository fields.
                    ""display_name"": repo_obj.display_name,
                    ""last_backup_date"": repo_obj.last_backup_date,
                    ""status"": repo_obj.status[0],
                    ""encoding"": repo_obj.encoding,
                }
                for repo_obj in u.repo_objs
            ],
        }


@cherrypy.tools.json_out(handler=json_handler)
@cherrypy.config(**{'error_page.default': False})
@cherrypy.tools.auth_basic(realm='rdiffweb', checkpassword=_checkpassword, priority=70)
@cherrypy.tools.auth_form(on=False)
@cherrypy.tools.auth_mfa(on=False)
@cherrypy.tools.sessions(on=False)
@cherrypy.tools.i18n(on=False)
@cherrypy.tools.ratelimit()
class ApiPage(Controller):
    """"""
    This class provide a restful API to access some of the rdiffweb resources.
    """"""

    currentuser = ApiCurrentUser()

    @cherrypy.expose
    def index(self):
        return {
            ""version"": self.app.version,
        }
",CWE-770,117.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import cherrypy
from markupsafe import Markup
from wtforms.form import Form

SUBMIT_METHODS = {'POST', 'PUT', 'PATCH', 'DELETE'}


class _ProxyFormdata:
    """"""
    Custom class to proxy default form data into WTForm from cherrypy variables.
    """"""

    def __contains__(self, key):
        return key in cherrypy.request.params

    def getlist(self, key):
        # Default to use cherrypy params.
        params = cherrypy.request.params
        if key in params:
            if isinstance(params[key], list):
                return params[key]
            else:
                return [params[key]]
        # Return default empty list.
        return []


_AUTO = _ProxyFormdata()


class CherryForm(Form):
    """"""
    Custom implementation of WTForm for cherrypy to support kwargs parms.

    If ``formdata`` is not specified, this will use cherrypy.request.params
    Explicitly pass ``formdata=None`` to prevent this.
    """"""

    def __init__(self, **kwargs):
        if 'formdata' in kwargs:
            formdata = kwargs.pop('formdata')
        else:
            formdata = _AUTO if CherryForm.is_submitted(self) else None
        super().__init__(formdata=formdata, **kwargs)

    def is_submitted(self):
        """"""
        Consider the form submitted if there is an active request and
        the method is ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        """"""
        return cherrypy.request.method in SUBMIT_METHODS

    def validate_on_submit(self):
        """"""
        Call `validate` only if the form is submitted.
        This is a shortcut for ``form.is_submitted() and form.validate()``.
        """"""
        return self.is_submitted() and self.validate()

    @property
    def error_message(self):
        if self.errors:
            msg = Markup("""")
            for field, messages in self.errors.items():
                if msg:
                    msg += Markup('<br/>')
                # Field name
                if field in self:
                    msg += ""%s: "" % self[field].label.text
                else:
                    msg += ""%s: "" % field
                for m in messages:
                    msg += m
            return msg

    def __html__(self):
        """"""
        Return a HTML representation of the form. For more powerful rendering, see the __call__() method.
        """"""
        return self()

    def __call__(self, **kwargs):
        env = cherrypy.tree.apps[''].templates.jinja_env
        tmpl = env.get_template('components/form.html')
        return Markup(tmpl.render(form=self, **kwargs))
",CWE-770,103.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms import validators
from wtforms.fields import IntegerField, StringField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import SessionObject
from rdiffweb.tools.i18n import ugettext as _


class RevokeSessionForm(CherryForm):
    action = StringField(validators=[validators.regexp('delete')])
    number = IntegerField(validators=[validators.data_required()])

    @property
    def app(self):
        return cherrypy.request.app


@cherrypy.tools.is_admin()
class AdminSessionPage(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        # Delete session on form submit
        form = RevokeSessionForm()
        if form.is_submitted():
            if form.validate():
                session = SessionObject.query.filter(SessionObject.number == form.number.data).first()
                if not session:
                    flash(_('The given session cannot be removed because it cannot be found.'), level='warning')
                elif session.id == cherrypy.session.id:
                    flash(_('You cannot revoke your current session.'), level='warning')
                else:
                    session.delete()
                    flash(_('The session was successfully revoked.'), level='success')
            else:
                flash(form.error_message, level='error')
        # Get list of current user's session
        obj_list = SessionObject.query.filter().all()
        active_sessions = [
            {
                'number': obj.number,
                'access_time': obj.data.get('access_time', None),
                'current': cherrypy.session.id == obj.id,
                'expiration_time': obj.expiration_time,
                'ip_address': obj.data.get('ip_address', None),
                'login_time': obj.data.get('login_time', None),
                'user_agent': obj.data.get('user_agent', None),
                'username': obj.username,
            }
            for obj in obj_list
        ]
        return self._compile_template(""admin_session.html"", active_sessions=active_sessions)
",CWE-770,72.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import logging

import cherrypy
from wtforms.fields import BooleanField, PasswordField, StringField, SubmitField
from wtforms.validators import InputRequired, Length

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.tools.auth_form import LOGIN_PERSISTENT, SESSION_KEY
from rdiffweb.tools.i18n import gettext_lazy as _

# Define the logger
logger = logging.getLogger(__name__)


class LoginForm(CherryForm):
    # Sanitize the redirect URL to avoid Open Redirect
    # redirect = HiddenField(default='/', filters=[lambda v: v if v.startswith('/') else '/'])
    login = StringField(
        _('Username'),
        default=lambda: cherrypy.session.get(SESSION_KEY, None),
        validators=[InputRequired(), Length(max=256, message=_('Username too long.'))],
        render_kw={
            ""placeholder"": _('Username'),
            ""autocorrect"": ""off"",
            ""autocapitalize"": ""none"",
            ""autocomplete"": ""off"",
            ""autofocus"": ""autofocus"",
        },
    )
    password = PasswordField(_('Password'), validators=[InputRequired()], render_kw={""placeholder"": _('Password')})
    persistent = BooleanField(
        _('Remember me'),
        default=lambda: cherrypy.session.get(LOGIN_PERSISTENT, False),
    )
    submit = SubmitField(
        _('Sign in'),
        render_kw={""class"": ""btn-primary btn-lg btn-block""},
    )


class LoginPage(Controller):
    """"""
    This page is used by the authentication to enter a user/pass.
    """"""

    @cherrypy.expose()
    @cherrypy.tools.auth_mfa(on=False)
    @cherrypy.tools.ratelimit()
    def index(self, **kwargs):
        """"""
        Called by auth_form to generate the /login/ page.
        """"""
        form = LoginForm()

        # Validate user's credentials
        if form.validate_on_submit():
            try:
                results = [r for r in cherrypy.engine.publish('login', form.login.data, form.password.data) if r]
            except Exception:
                logger.exception('fail to validate user [%s] credentials', form.login.data)
                flash(_(""Failed to validate user credentials.""), level='error')
            else:
                if len(results) > 0 and results[0]:
                    cherrypy.tools.auth_form.login(username=results[0].username, persistent=form.persistent.data)
                    cherrypy.tools.auth_form.redirect_to_original_url()
                else:
                    flash(_(""Invalid username or password.""))
        params = {
            'form': form,
        }
        # Add welcome message to params. Try to load translated message.
        welcome_msg = self.app.cfg.welcome_msg
        if welcome_msg:
            params[""welcome_msg""] = welcome_msg.get('')
            if hasattr(cherrypy.response, 'i18n'):
                locale = cherrypy.response.i18n.locale.language
                params[""welcome_msg""] = welcome_msg.get(locale, params[""welcome_msg""])

        return self._compile_template(""login.html"", **params)
",CWE-770,97.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import logging

import cherrypy
from wtforms.fields import BooleanField, StringField, SubmitField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.tools.auth_form import LOGIN_PERSISTENT
from rdiffweb.tools.i18n import gettext_lazy as _

# Define the logger
logger = logging.getLogger(__name__)


class MfaForm(CherryForm):
    code = StringField(
        _('Verification code'),
        description=_('Enter the code to verify your identity.'),
        render_kw={
            ""class"": ""form-control-lg"",
            ""placeholder"": _('Enter verification code here'),
            ""autocomplete"": ""off"",
            ""autocorrect"": ""off"",
            ""autofocus"": ""autofocus"",
        },
    )
    persistent = BooleanField(
        _('Remember me'),
        default=lambda: cherrypy.session.get(LOGIN_PERSISTENT, False),
    )
    submit = SubmitField(
        _('Sign in'),
        render_kw={""class"": ""btn-primary btn-lg btn-block""},
    )
    resend_code = SubmitField(
        _('Resend code to my email'),
        render_kw={""class"": ""btn-link btn-sm btn-block""},
    )

    def validate_code(self, field):
        # Code is required when submit.
        if self.submit.data:
            if not self.code.data:
                raise ValueError(_('Invalid verification code.'))
            # Validate verification code.
            if not cherrypy.tools.auth_mfa.verify_code(code=self.code.data, persistent=self.persistent.data):
                raise ValueError(_('Invalid verification code.'))

    def validate(self, extra_validators=None):
        if not (self.submit.data or self.resend_code.data):
            raise ValueError(_('Invalid operation'))
        return super().validate()


class MfaPage(Controller):
    @cherrypy.expose()
    @cherrypy.tools.ratelimit()
    def index(self, **kwargs):
        form = MfaForm()

        # Validate MFA
        if form.is_submitted():
            if form.validate():
                if form.submit.data:
                    cherrypy.tools.auth_mfa.redirect_to_original_url()
                elif form.resend_code.data:
                    self.send_code()
        if cherrypy.tools.auth_mfa.is_code_expired():
            # Send verification code if previous code expired.
            self.send_code()
        params = {
            'form': form,
        }
        # Add welcome message to params. Try to load translated message.
        welcome_msg = self.app.cfg.welcome_msg
        if welcome_msg:
            params[""welcome_msg""] = welcome_msg.get('')
            if hasattr(cherrypy.response, 'i18n'):
                locale = cherrypy.response.i18n.locale.language
                params[""welcome_msg""] = welcome_msg.get(locale, params[""welcome_msg""])
        return self._compile_template(""mfa.html"", **params)

    def send_code(self):
        # Send verification code by email
        userobj = cherrypy.serving.request.currentuser
        if not userobj.email:
            flash(
                _(
                    ""Multi-factor authentication is enabled for your account, but your account does not have a valid email address to send the verification code to. Check your account settings with your administrator.""
                )
            )
        else:
            code = cherrypy.tools.auth_mfa.generate_code()
            body = self.app.templates.compile_template(
                ""email_mfa.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj, 'code': code}
            )
            cherrypy.engine.publish('queue_mail', to=userobj.email, subject=_(""Your verification code""), message=body)
            flash(_(""A new verification code has been sent to your email.""))
",CWE-770,115.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Optional, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _

# Maximum number of password change attempt before logout
CHANGE_PASSWORD_MAX_ATTEMPT = 5
CHANGE_PASSWORD_ATTEMPTS = 'change_password_attempts'


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(
        _('Fullname'),
        validators=[
            Optional(),
            Length(max=256, message=_('Fullname too long.')),
            Regexp(UserObject.PATTERN_FULLNAME, message=_('Must not contain any special characters.')),
        ],
    )
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Email too long."")),
            Regexp(UserObject.PATTERN_EMAIL, message=_(""Must be a valid email address."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def validate_new(self, field):
        """"""
        Make sure new password if not equals to old password.
        """"""
        if self.new.data and self.new.data == self.current.data:
            raise ValueError(_('The new password must be different from the current password.'))

    def populate_obj(self, user):
        # Check if current password is ""valid"" if Not, rate limit the
        # number of attempts and logout user after too many invalid attempts.
        if not user.validate_password(self.current.data):
            cherrypy.session[CHANGE_PASSWORD_ATTEMPTS] = cherrypy.session.get(CHANGE_PASSWORD_ATTEMPTS, 0) + 1
            attempts = cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]
            if attempts >= CHANGE_PASSWORD_MAX_ATTEMPT:
                cherrypy.session.clear()
                cherrypy.session.regenerate()
                flash(
                    _(""You were logged out because you entered the wrong password too many times.""),
                    level='warning',
                )
                raise cherrypy.HTTPRedirect('/login/')
            self.current.errors = [_(""Wrong current password."")]
            return False

        # Clear number of attempts
        if CHANGE_PASSWORD_ATTEMPTS in cherrypy.session:
            del cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]

        try:
            user.set_password(self.new.data)
            return True
        except ValueError as e:
            self.new.errors = [str(e)]
            return False


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
                raise cherrypy.HTTPRedirect("""")
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                if password_form.populate_obj(self.app.currentuser):
                    flash(_(""Password updated successfully.""), level='success')
                    raise cherrypy.HTTPRedirect("""")
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-770,184.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms import validators
from wtforms.fields import IntegerField, StringField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import SessionObject
from rdiffweb.tools.i18n import ugettext as _


class RevokeSessionForm(CherryForm):
    action = StringField(validators=[validators.regexp('delete')])
    number = IntegerField(validators=[validators.data_required()])

    @property
    def app(self):
        return cherrypy.request.app


class PagePrefSession(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        # Delete session on form submit
        form = RevokeSessionForm()
        if form.is_submitted():
            if form.validate():
                session = SessionObject.query.filter(
                    SessionObject.username == self.app.currentuser.username, SessionObject.number == form.number.data
                ).first()
                if not session:
                    flash(_('The given session cannot be removed because it cannot be found.'), level='warning')
                elif session.id == cherrypy.session.id:
                    flash(_('You cannot revoke your current session.'), level='warning')
                else:
                    session.delete()
                    flash(_('The session was successfully revoked.'), level='success')
            else:
                flash(form.error_message, level='error')
        # Get list of current user's session
        obj_list = SessionObject.query.filter(SessionObject.username == self.app.currentuser.username).all()
        active_sessions = [
            {
                'number': obj.number,
                'access_time': obj.data.get('access_time', None),
                'current': cherrypy.session.id == obj.id,
                'expiration_time': obj.expiration_time,
                'ip_address': obj.data.get('ip_address', None),
                'login_time': obj.data.get('login_time', None),
                'user_agent': obj.data.get('user_agent', None),
                'username': obj.username,
            }
            for obj in obj_list
        ]
        return self._compile_template(""prefs_session.html"", active_sessions=active_sessions)
",CWE-770,73.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Nov 16, 2017

@author: Patrik Dufresne
""""""


from base64 import b64encode

import rdiffweb.test
from rdiffweb.core.model import UserObject


class APITest(rdiffweb.test.WebCase):

    headers = [(""Authorization"", ""Basic "" + b64encode(b""admin:admin123"").decode('ascii'))]

    def test_get_index(self):
        data = self.getJson('/api/', headers=self.headers)
        self.assertIsNotNone(data.get('version'))

    def test_get_currentuser(self):
        data = self.getJson('/api/currentuser/', headers=self.headers)
        self.assertEqual(data.get('username'), 'admin')
        self.assertEqual(data.get('email'), '')
        # This value change on every execution.
        self.assertEqual(2, len(data.get('repos')))
        repo = data.get('repos')[1]
        self.assertEqual(repo.get('keepdays'), -1)
        self.assertEqual(repo.get('last_backup_date'), '2016-02-02T16:30:40-05:00')
        self.assertEqual(repo.get('status'), 'ok')
        self.assertEqual(repo.get('display_name'), 'testcases')
        self.assertEqual(repo.get('encoding'), 'utf-8')
        self.assertEqual(repo.get('name'), 'testcases')
        self.assertEqual(repo.get('maxage'), 0)

    def test_getapi_without_authorization(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/')
        self.assertStatus('401 Unauthorized')

    def test_getapi_without_username(self):
        """"""
        Check if error 401 is raised when requesting /login without a username.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b"":admin123"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_empty_password(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_invalid_password(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:invalid"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_authorization(self):
        """"""
        Check if 200 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:admin123"").decode('ascii'))])
        self.assertStatus('200 OK')

    def test_getapi_with_session(self):
        # Given an authenticate user
        b = {'login': self.USERNAME, 'password': self.PASSWORD}
        self.getPage('/login/', method='POST', body=b)
        self.assertStatus('303 See Other')
        self.getPage('/')
        self.assertStatus('200 OK')
        # When querying the API
        self.getPage('/api/')
        # Then access is refused
        self.assertStatus('401 Unauthorized')

    def test_auth_with_access_token(self):
        # Given a user with an access token
        userobj = UserObject.get_user(self.USERNAME)
        token = userobj.add_access_token('test').encode('ascii')
        # When using this token to authenticated with /api
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:"" + token).decode('ascii'))])
        # Then authentication is successful
        self.assertStatus('200 OK')

    def test_auth_failed_with_mfa_enabled(self):
        # Given a user with MFA enabled
        userobj = UserObject.get_user(self.USERNAME)
        userobj.mfa = UserObject.ENABLED_MFA
        userobj.add()
        # When authenticating with /api/
        self.getPage('/api/', headers=self.headers)
        # Then access is refused
        self.assertStatus('401 Unauthorized')


class APIRatelimitTest(rdiffweb.test.WebCase):

    default_config = {
        'rate-limit': 5,
    }

    def test_login_ratelimit(self):
        for i in range(0, 6):
            self.getPage('/api/')
        self.assertStatus(429)
",CWE-770,130.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import os
import pickle
import threading
import time
from collections import namedtuple

import cherrypy

Tracker = namedtuple('Tracker', ['token', 'hits', 'timeout'])


class _DataStore:
    """"""
    Base class for rate limit data store
    """"""

    def __init__(self, **kwargs):
        self._locks = {}

    def get_and_increment(self, token, delay):
        lock = self._locks.setdefault(token, threading.RLock())
        with lock:
            tracker = self._load(token)
            if tracker is None or tracker.timeout < time.time():
                tracker = Tracker(token=token, hits=0, timeout=int(time.time() + delay))
            tracker = tracker._replace(hits=tracker.hits + 1)
            self._save(tracker)
        return tracker.hits

    def _save(self, tracker):
        raise NotImplementedError

    def _load(self, token):
        raise NotImplementedError


class RamRateLimit(_DataStore):
    """"""
    Store rate limit information in memory.
    """"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._data = {}

    def _load(self, token):
        return self._data.get(token, None)

    def _save(self, tracker):
        self._data[tracker.token] = tracker


class FileRateLimit(_DataStore):
    """"""
    Store rate limit information in files.
    """"""

    PREFIX = 'ratelimit-'
    pickle_protocol = pickle.HIGHEST_PROTOCOL

    def __init__(self, storage_path, **kwargs):
        super().__init__(**kwargs)
        # The 'storage_path' arg is required for file-based datastore.
        assert (
            storage_path
        ), 'FileRateLimit required a storage_path `tools.ratelimit.storage_path = ""/home/site/ratelimit""`'
        self.storage_path = os.path.abspath(storage_path)

    def _path(self, token):
        assert token
        f = os.path.join(self.storage_path, self.PREFIX + token.strip('/').replace('/', '-'))
        if not os.path.abspath(f).startswith(self.storage_path):
            raise ValueError('invalid token')
        return f

    def _load(self, token):
        path = self._path(token)
        try:
            f = open(path, 'rb')
            try:
                return pickle.load(f)
            finally:
                f.close()
        except (IOError, EOFError):
            # Drop session data if invalid
            pass
        return None

    def _save(self, tracker):
        path = self._path(tracker.token)
        f = open(path, 'wb')
        try:
            pickle.dump(tracker, f, self.pickle_protocol)
        finally:
            f.close()


def check_ratelimit(delay=60, anonymous_limit=0, registered_limit=0, rate_exceed_status=429, debug=False, **conf):
    """"""
    Verify the ratelimit. By default return a 429 HTTP error code (Too Many Request).

    Usage:

    @cherrypy.tools.ratelimit(on=True, anonymous_limit=5, registered_limit=50, storage_class=FileRateLimit, storage_path='/tmp')
    def index(self):
        pass
    """"""

    # If datastore is not pass as configuration, create it for the first time.
    datastore = getattr(cherrypy, '_ratelimit_datastore', None)
    if datastore is None:
        # Create storage using storage class
        storage_class = conf.get('storage_class', RamRateLimit)
        datastore = storage_class(**conf)
        cherrypy._ratelimit_datastore = datastore

    # If user is authenticated, use the username else use the ip address
    token = cherrypy.request.login or cherrypy.request.remote.ip

    # Get the real limit depending of user login.
    limit = registered_limit if cherrypy.request.login else anonymous_limit
    if limit is None or limit <= 0:
        return

    # Get hits count using datastore.
    hits = datastore.get_and_increment(token, delay)
    if debug:
        cherrypy.log(
            'check and increase rate limit for token %s, limit %s, hits %s' % (token, limit, hits), 'TOOLS.RATELIMIT'
        )

    # Verify user has not exceeded rate limit
    if limit <= hits:
        raise cherrypy.HTTPError(rate_exceed_status)


cherrypy.tools.ratelimit = cherrypy.Tool('before_handler', check_ratelimit, priority=60)
",CWE-770,154.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 20, 2021

@author: Patrik Dufresne
""""""
from parameterized import parameterized

import rdiffweb.test


class SecureHeadersTest(rdiffweb.test.WebCase):

    login = True

    def test_cookie_samesite_lax(self):
        # Given a request made to rdiffweb
        # When receiving the response
        self.getPage('/')
        # Then the header contains Set-Cookie with SameSite=Lax
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('SameSite=Lax', cookie)

    def test_cookie_samesite_lax_without_session(self):
        # Given not a client sending no cookie
        self.cookies = None
        # When a query is made to a static path (without session)
        self.getPage('/static/blue.css')
        # Then Set-Cookie is not defined.
        self.assertNoHeader('Set-Cookie')

    def test_cookie_with_https(self):
        # Given an https request made to rdiffweb
        self.getPage('/', headers=[('X-Forwarded-Proto', 'https')])
        # When receiving the response
        self.assertStatus(200)
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('Secure', cookie)

    @parameterized.expand(
        [
            ('/invalid', 404),
            ('/browse/invalid', 404),
            ('/login', 301),
            ('/logout', 303),
        ]
    )
    def test_cookie_with_https_http_error(self, url, expected_error_code):
        # Given an https request made to rdiffweb
        self.getPage(url, headers=[('X-Forwarded-Proto', 'https')])
        # When receiving the response
        self.assertStatus(expected_error_code)
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('Secure', cookie)

    def test_cookie_with_http(self):
        # Given an https request made to rdiffweb
        self.getPage('/')
        # When receiving the response
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertNotIn('Secure', cookie)

    def test_get_with_wrong_origin(self):
        # Given a GET request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')])
        # Then the response status it 200 OK.
        self.assertStatus(200)

    def test_post_with_wrong_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')], method='POST')
        # Then the request is refused with 403 Forbiden
        self.assertStatus(403)
        self.assertInBody('Unexpected Origin header')

    def test_post_with_valid_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        self.getPage('/', headers=[('Origin', base)], method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_post_without_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_clickjacking_defense(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-Frame-Options', 'DENY')

    def test_no_cache(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Cache-control', 'no-cache')
        self.assertHeaderItemValue('Cache-control', 'no-store')
        self.assertHeaderItemValue('Cache-control', 'must-revalidate')
        self.assertHeaderItemValue('Cache-control', 'max-age=0')
        self.assertHeaderItemValue('Pragma', 'no-cache')
        self.assertHeaderItemValue('Expires', '0')

    def test_no_cache_with_static(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/static/default.css')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertNoHeader('Cache-control')
        self.assertNoHeader('Pragma')
        self.assertNoHeader('Expires')

    def test_referrer_policy(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Referrer-Policy', 'same-origin')

    def test_nosniff(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-Content-Type-Options', 'nosniff')

    def test_xss_protection(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-XSS-Protection', '1; mode=block')

    def test_content_security_policy(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue(
            'Content-Security-Policy',
            ""default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'"",
        )

    def test_strict_transport_security(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', headers=[('X-Forwarded-Proto', 'https')])
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Strict-Transport-Security', 'max-age=31536000; includeSubDomains')
",CWE-346,184.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import http.cookies
import logging

import cherrypy

# Define the logger
logger = logging.getLogger(__name__)

#
# Patch Morsel prior to 3.8
# Allow SameSite attribute to be define on the cookie.
#
if not http.cookies.Morsel().isReservedKey(""samesite""):
    http.cookies.Morsel._reserved['samesite'] = 'SameSite'


def set_headers(
    xfo='DENY',
    no_cache=True,
    referrer='same-origin',
    nosniff=True,
    xxp='1; mode=block',
    csp=""default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'"",
):
    """"""
    This tool provide CSRF mitigation.

    * Define X-Frame-Options = DENY
    * Define Cookies SameSite=Lax
    * Define Cookies Secure when https is detected
    * Validate `Origin` and `Referer` on POST, PUT, PATCH, DELETE
    * Define Cache-Control by default
    * Define Referrer-Policy to 'same-origin'

    Ref.:
    https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html
    https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html
    """"""
    request = cherrypy.request
    response = cherrypy.serving.response

    # Check if Origin matches our target.
    if request.method in ['POST', 'PUT', 'PATCH', 'DELETE']:
        origin = request.headers.get('Origin', None)
        if origin and not origin.startswith(request.base):
            raise cherrypy.HTTPError(403, 'Unexpected Origin header')

    # Check if https is enabled
    https = request.base.startswith('https')

    # Define X-Frame-Options to avoid Clickjacking
    if xfo:
        response.headers['X-Frame-Options'] = xfo

    # Enforce security on cookies
    cookie = response.cookie.get('session_id', None)
    if cookie:
        # Awaiting bug fix in cherrypy
        # https://github.com/cherrypy/cherrypy/issues/1767
        # Force SameSite to Lax
        cookie['samesite'] = 'Lax'
        if https:
            cookie['secure'] = 1

    # Add Cache-Control to avoid storing sensible information in Browser cache.
    if no_cache:
        response.headers['Cache-control'] = 'no-cache, no-store, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'

    # Add Referrer-Policy
    if referrer:
        response.headers['Referrer-Policy'] = referrer

    # Add X-Content-Type-Options to avoid browser to ""sniff"" to content-type
    if nosniff:
        response.headers['X-Content-Type-Options'] = 'nosniff'

    # Add X-XSS-Protection to enabled XSS protection
    if xxp:
        response.headers['X-XSS-Protection'] = xxp

    # Add Content-Security-Policy
    if csp:
        response.headers['Content-Security-Policy'] = csp

    # Add Strict-Transport-Security to force https use.
    if https:
        response.headers['Strict-Transport-Security'] = ""max-age=31536000; includeSubDomains""


cherrypy.tools.secure_headers = cherrypy.Tool('before_request_body', set_headers, priority=71)
",CWE-346,110.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import datetime
import time
import urllib.parse

import cherrypy
from cherrypy.lib import httputil

SESSION_KEY = '_cp_username'
LOGIN_TIME = 'login_time'
LOGIN_REDIRECT_URL = '_auth_form_redirect_url'
LOGIN_PERSISTENT = 'login_persistent'


class CheckAuthForm(cherrypy.Tool):
    def __init__(self, priority=73):
        super().__init__(point='before_handler', callable=self.run, priority=priority)

    def _is_login(self):
        """"""
        Verify if the login expired and we need to prompt the user to authenticated again using either credentials and/or MFA.
        """"""
        # Verify if current user exists
        request = cherrypy.serving.request
        if not getattr(request, 'currentuser', None):
            return False

        # Verify if session is enabled
        sessions_on = request.config.get('tools.sessions.on', False)
        if not sessions_on:
            return False

        # Verify session
        session = cherrypy.session
        return (
            session.get(SESSION_KEY) is not None
            and session.get(LOGIN_TIME) is not None
            and session[LOGIN_TIME] + datetime.timedelta(minutes=session.timeout) > session.now()
        )

    def _get_redirect_url(self):
        """"""
        Return the original URL the user browser before getting redirect to login.
        """"""
        return cherrypy.session.get(LOGIN_REDIRECT_URL) or '/'

    def _set_redirect_url(self):
        # Keep reference to the current URL
        request = cherrypy.serving.request
        uri_encoding = getattr(request, 'uri_encoding', 'utf-8')
        original_url = urllib.parse.quote(request.path_info, encoding=uri_encoding)
        qs = request.query_string
        new_url = cherrypy.url(original_url, qs=qs, base='')
        cherrypy.session[LOGIN_REDIRECT_URL] = new_url

    def redirect_to_original_url(self):
        # Redirect user to original URL
        raise cherrypy.HTTPRedirect(self._get_redirect_url())

    def run(self, login_url='/login/', logout_url='/logout', timeout=43200):
        """"""
        A tool that verify if the session is associated to a user by tracking
        a session key. If session is not authenticated, redirect user to login page.
        """"""
        request = cherrypy.serving.request
        # Skip execution of this tools when browsing the login page.
        if request.path_info == login_url:
            if self._is_login():
                raise cherrypy.HTTPRedirect('/')
            return

        # Clear session when browsing /logout
        if request.path_info == logout_url or request.path_info.startswith(logout_url):
            self.logout()
            raise cherrypy.HTTPRedirect('/')

        # Check if login
        if not self._is_login():
            # Store original URL
            self._set_redirect_url()
            # And redirect to login page
            raise cherrypy.HTTPRedirect(login_url)

        # If login is persistent, update the cookie max-age/expires
        if cherrypy.session.get(LOGIN_PERSISTENT, False):
            cherrypy.session.timeout = timeout
            cookie = cherrypy.serving.response.cookie
            cookie['session_id']['max-age'] = timeout * 60
            cookie['session_id']['expires'] = httputil.HTTPDate(time.time() + timeout * 60)
        else:
            session_timeout = cherrypy.request.config.get('tools.sessions.timeout', 60)
            cherrypy.session.timeout = session_timeout

    def login(self, username, persistent=False):
        """"""
        Must be called by the page hanlder when the authentication is successful.
        """"""
        # Store session data
        cherrypy.session[LOGIN_PERSISTENT] = persistent
        cherrypy.session[SESSION_KEY] = username
        cherrypy.session[LOGIN_TIME] = cherrypy.session.now()
        # Generate a new session id
        cherrypy.session.regenerate()

    def logout(self):
        # Clear session date and generate a new session id
        cherrypy.session.clear()
        cherrypy.session.regenerate()


cherrypy.tools.auth_form = CheckAuthForm()
",CWE-306,127.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Nov 16, 2017

@author: Patrik Dufresne
""""""
# Define the logger


import logging

import cherrypy

from rdiffweb.controller import Controller
from rdiffweb.core.librdiff import RdiffTime
from rdiffweb.core.model import UserObject

try:
    import simplejson as json
except ImportError:
    import json

logger = logging.getLogger(__name__)


def json_handler(*args, **kwargs):
    """"""Custom json handle to convert RdiffDate to str.""""""
    value = cherrypy.serving.request._json_inner_handler(*args, **kwargs)

    def default(o):
        if isinstance(o, RdiffTime):
            return str(o)
        raise TypeError(repr(o) + "" is not JSON serializable"")

    encode = json.JSONEncoder(default=default, ensure_ascii=False).iterencode
    for chunk in encode(value):
        yield chunk.encode('utf-8')


def _checkpassword(realm, username, password):
    """"""
    Check basic authentication.
    """"""
    # Validate username
    userobj = UserObject.get_user(username)
    if userobj is not None:
        # Verify if the password matches a token.
        if userobj.validate_access_token(password):
            return True
        # Disable password authentication for MFA
        if userobj.mfa == UserObject.ENABLED_MFA:
            cherrypy.tools.ratelimit.hit()
            return False
    # Otherwise validate username password
    valid = any(cherrypy.engine.publish('login', username, password))
    if not valid:
        # When invalid, we need to increase the rate limit.
        cherrypy.tools.ratelimit.hit()
    return valid


class ApiCurrentUser(Controller):
    @cherrypy.expose
    def default(self):
        u = self.app.currentuser
        u.refresh_repos()
        return {
            ""email"": u.email,
            ""username"": u.username,
            ""repos"": [
                {
                    # Database fields.
                    ""name"": repo_obj.name,
                    ""maxage"": repo_obj.maxage,
                    ""keepdays"": repo_obj.keepdays,
                    # Repository fields.
                    ""display_name"": repo_obj.display_name,
                    ""last_backup_date"": repo_obj.last_backup_date,
                    ""status"": repo_obj.status[0],
                    ""encoding"": repo_obj.encoding,
                }
                for repo_obj in u.repo_objs
            ],
        }


@cherrypy.tools.json_out(handler=json_handler)
@cherrypy.config(**{'error_page.default': False})
@cherrypy.tools.auth_basic(realm='rdiffweb', checkpassword=_checkpassword, priority=70)
@cherrypy.tools.auth_form(on=False)
@cherrypy.tools.auth_mfa(on=False)
@cherrypy.tools.i18n(on=False)
@cherrypy.tools.ratelimit(scope='rdiffweb-api', hit=0, priority=69)
@cherrypy.tools.sessions(on=False)
class ApiPage(Controller):
    """"""
    This class provide a restful API to access some of the rdiffweb resources.
    """"""

    currentuser = ApiCurrentUser()

    @cherrypy.expose
    def index(self):
        return {
            ""version"": self.app.version,
        }
",CWE-613,122.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms import validators
from wtforms.fields import IntegerField, StringField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import SessionObject
from rdiffweb.tools.i18n import ugettext as _


class RevokeSessionForm(CherryForm):
    action = StringField(validators=[validators.regexp('delete')])
    number = IntegerField(validators=[validators.data_required()])


@cherrypy.tools.is_admin()
class AdminSessionPage(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        # Delete session on form submit
        form = RevokeSessionForm()
        if form.is_submitted():
            if form.validate():
                session = SessionObject.query.filter(SessionObject.number == form.number.data).first()
                if not session:
                    flash(_('The given session cannot be removed because it cannot be found.'), level='warning')
                elif session.id == cherrypy.session.id:
                    flash(_('You cannot revoke your current session.'), level='warning')
                else:
                    session.delete()
                    flash(_('The session was successfully revoked.'), level='success')
            else:
                flash(form.error_message, level='error')
        # Get list of current user's session
        obj_list = SessionObject.query.filter().all()
        active_sessions = [
            {
                'number': obj.number,
                'access_time': obj.data.get('access_time', None),
                'current': cherrypy.session.id == obj.id,
                'expiration_time': obj.expiration_time,
                'ip_address': obj.data.get('ip_address', None),
                'login_time': obj.data.get('login_time', None),
                'user_agent': obj.data.get('user_agent', None),
                'username': obj.username,
            }
            for obj in obj_list
        ]
        return self._compile_template(""admin_session.html"", active_sessions=active_sessions)
",CWE-613,68.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
'''
Created on Apr. 5, 2021

@author: Patrik Dufresne <patrik@ikus-soft.com>
'''
# Define the logger

import logging
import os

import cherrypy
from wtforms.fields.core import StringField
from wtforms.validators import DataRequired, ValidationError

from rdiffweb.controller import Controller
from rdiffweb.controller.dispatch import poppath
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError
from rdiffweb.core.model import RepoObject
from rdiffweb.core.rdw_templating import url_for
from rdiffweb.tools.i18n import gettext_lazy as _

_logger = logging.getLogger(__name__)


class DeleteRepoForm(CherryForm):
    confirm = StringField(_('Confirmation'), validators=[DataRequired()])

    def validate_confirm(self, field):
        if self.confirm.data != self.expected_confirm:
            raise ValidationError(_('Invalid value, must be: %s') % self.expected_confirm)


@poppath()
class DeletePage(Controller):
    @cherrypy.expose
    @cherrypy.tools.errors(
        error_table={
            DoesNotExistError: 404,
            AccessDeniedError: 403,
        }
    )
    def default(self, path=b"""", **kwargs):
        # Check permissions on path/repo
        repo, path = RepoObject.get_repo_path(path)
        # Check if path exists with fstats
        path_obj = repo.fstat(path)
        # Check user's permissions
        is_maintainer()

        # validate form
        form = DeleteRepoForm()

        form.expected_confirm = path_obj.display_name
        if form.is_submitted():
            if form.validate():
                RepoObject.session.expunge(repo)
                cherrypy.engine.publish('schedule_task', repo.delete, path)
                # Redirect to parent folder or to root if repo get deleted
                if path_obj.isroot:
                    raise cherrypy.HTTPRedirect(url_for('/'))
                else:
                    parent_path = repo.fstat(os.path.dirname(path_obj.path))
                    raise cherrypy.HTTPRedirect(url_for('browse', repo, parent_path))
            else:
                raise cherrypy.HTTPError(400, form.error_message)
        else:
            raise cherrypy.HTTPError(405)
",CWE-613,86.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging

import cherrypy

from rdiffweb.controller import Controller

# Define the logger
logger = logging.getLogger(__name__)


class LocationsPage(Controller):
    """"""
    Shows the repository page. Will show all available destination
    backup directories. This is the root (/) page.
    """"""

    @cherrypy.expose
    def index(self):
        # Get page params
        self.app.currentuser.refresh_repos()
        params = {
            ""repos"": self.app.currentuser.repo_objs,
            ""disk_usage"": self.app.currentuser.disk_usage,
            ""disk_quota"": self.app.currentuser.disk_quota,
        }
        # Render the page.
        return self._compile_template(""locations.html"", **params)
",CWE-613,45.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Default preference page to show general user information. It allows user
to change password ans refresh it's repository view.
""""""

import cherrypy
from wtforms.fields import HiddenField, PasswordField, StringField, SubmitField
from wtforms.fields.html5 import EmailField
from wtforms.validators import DataRequired, EqualTo, InputRequired, Length, Optional, Regexp

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _


class UserProfileForm(CherryForm):
    action = HiddenField(default='set_profile_info')
    username = StringField(_('Username'), render_kw={'readonly': True})
    fullname = StringField(
        _('Fullname'),
        validators=[
            Optional(),
            Length(max=256, message=_('Fullname too long.')),
            Regexp(UserObject.PATTERN_FULLNAME, message=_('Must not contain any special characters.')),
        ],
    )
    email = EmailField(
        _('Email'),
        validators=[
            DataRequired(),
            Length(max=256, message=_(""Email too long."")),
            Regexp(UserObject.PATTERN_EMAIL, message=_(""Must be a valid email address."")),
        ],
    )
    set_profile_info = SubmitField(_('Save changes'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_profile_info'

    def populate_obj(self, user):
        user.fullname = self.fullname.data
        user.email = self.email.data
        user.add()


class UserPasswordForm(CherryForm):
    action = HiddenField(default='set_password')
    current = PasswordField(
        _('Current password'),
        validators=[InputRequired(_(""Current password is missing.""))],
        description=_(""You must provide your current password in order to change it.""),
    )
    new = PasswordField(
        _('New password'),
        validators=[
            InputRequired(_(""New password is missing."")),
            EqualTo('confirm', message=_(""The new password and its confirmation do not match."")),
        ],
    )
    confirm = PasswordField(
        _('Confirm new password'), validators=[InputRequired(_(""Confirmation password is missing.""))]
    )
    set_password = SubmitField(_('Update password'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'set_password'

    def validate_new(self, field):
        """"""
        Make sure new password if not equals to old password.
        """"""
        if self.new.data and self.new.data == self.current.data:
            raise ValueError(_('The new password must be different from the current password.'))

    def populate_obj(self, user):
        # Check if current password is ""valid"" if Not, rate limit the
        # number of attempts and logout user after too many invalid attempts.
        if not user.validate_password(self.current.data):
            self.current.errors = [_(""Wrong current password."")]
            return False
        try:
            user.set_password(self.new.data)
            return True
        except ValueError as e:
            self.new.errors = [str(e)]
            return False


class RefreshForm(CherryForm):
    action = HiddenField(default='update_repos')
    update_repos = SubmitField(
        _('Refresh repositories'),
        description=_(
            ""Refresh the list of repositories associated to your account. If you recently add a new repository and it doesn't show, you may try to refresh the list.""
        ),
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'update_repos'

    def populate_obj(self, user):
        try:
            user.refresh_repos(delete=True)
            flash(_(""Repositories successfully updated""), level='success')
        except ValueError as e:
            flash(str(e), level='warning')


class PagePrefsGeneral(Controller):
    """"""
    Plugin to change user profile and password.
    """"""

    @cherrypy.expose
    @cherrypy.tools.ratelimit(methods=['POST'], logout=True)
    def default(self, **kwargs):
        # Process the parameters.
        profile_form = UserProfileForm(obj=self.app.currentuser)
        password_form = UserPasswordForm()
        refresh_form = RefreshForm()
        if profile_form.is_submitted():
            if profile_form.validate():
                profile_form.populate_obj(self.app.currentuser)
                flash(_(""Profile updated successfully.""), level='success')
                raise cherrypy.HTTPRedirect("""")
            else:
                flash(profile_form.error_message, level='error')
        elif password_form.is_submitted():
            if password_form.validate():
                if password_form.populate_obj(self.app.currentuser):
                    flash(_(""Password updated successfully.""), level='success')
                    raise cherrypy.HTTPRedirect("""")
            else:
                flash(password_form.error_message, level='error')
        elif refresh_form.is_submitted():
            if refresh_form.validate():
                refresh_form.populate_obj(self.app.currentuser)
            else:
                flash(refresh_form.error_message, level='error')
        params = {
            'profile_form': profile_form,
            'password_form': password_form,
            'refresh_form': refresh_form,
        }
        return self._compile_template(""prefs_general.html"", **params)
",CWE-613,166.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms.fields import SelectField, StringField, SubmitField
from wtforms.widgets import HiddenInput

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _


class AbstractMfaForm(CherryForm):
    def __init__(self, obj, **kwargs):
        assert obj
        super().__init__(obj=obj, **kwargs)
        # Keep only one of the enable or disable button
        if obj.mfa:
            self.enable_mfa.widget = HiddenInput()
            self.enable_mfa.data = ''
        else:
            self.disable_mfa.widget = HiddenInput()
            self.disable_mfa.data = ''


class MfaStatusForm(AbstractMfaForm):
    mfa = SelectField(
        _('Two-Factor Authentication (2FA) Status'),
        coerce=int,
        choices=[
            (UserObject.DISABLED_MFA, _(""Disabled"")),
            (UserObject.ENABLED_MFA, _(""Enabled"")),
        ],
        render_kw={'readonly': True, 'disabled': True, 'data-beta': '1'},
    )
    enable_mfa = SubmitField(_('Enable Two-Factor Authentication'), render_kw={""class"": ""btn-success""})
    disable_mfa = SubmitField(_('Disable Two-Factor Authentication'), render_kw={""class"": ""btn-warning""})


class MfaToggleForm(AbstractMfaForm):
    code = StringField(
        _('Verification code'),
        render_kw={
            ""placeholder"": _('Enter verification code here'),
            ""autocomplete"": ""off"",
            ""autocorrect"": ""off"",
            ""autofocus"": ""autofocus"",
        },
    )
    enable_mfa = SubmitField(_('Enable Two-Factor Authentication'), render_kw={""class"": ""btn-success""})
    disable_mfa = SubmitField(_('Disable Two-Factor Authentication'), render_kw={""class"": ""btn-warning""})
    resend_code = SubmitField(
        _('Resend code to my email'),
        render_kw={""class"": ""btn-link""},
    )

    @property
    def app(self):
        return cherrypy.request.app

    def populate_obj(self, userobj):
        # Enable or disable MFA only when a code is provided.
        if self.enable_mfa.data:
            userobj.mfa = UserObject.ENABLED_MFA
            flash(_(""Two-Factor authentication enabled successfully.""), level='success')
        elif self.disable_mfa.data:
            userobj.mfa = UserObject.DISABLED_MFA
            flash(_(""Two-Factor authentication disabled successfully.""), level='success')

    def validate_code(self, field):
        # Code is required for enable_mfa and disable_mfa
        if self.enable_mfa.data or self.disable_mfa.data:
            if not self.code.data:
                raise ValueError(_(""Enter the verification code to continue.""))
            # Validate code
            if not cherrypy.tools.auth_mfa.verify_code(self.code.data, False):
                raise ValueError(_(""Invalid verification code.""))

    def validate(self, extra_validators=None):
        if not (self.enable_mfa.data or self.disable_mfa.data or self.resend_code.data):
            raise ValueError(_('Invalid operation'))
        return super().validate()


class PagePrefMfa(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        form = MfaToggleForm(obj=self.app.currentuser)
        if form.is_submitted():
            if form.validate():
                if form.resend_code.data:
                    self.send_code()
                elif form.enable_mfa.data or form.disable_mfa.data:
                    form.populate_obj(self.app.currentuser)
                    form = MfaStatusForm(obj=self.app.currentuser)
            # Send verification code if previous code expired.
            elif cherrypy.tools.auth_mfa.is_code_expired():
                self.send_code()
        else:
            form = MfaStatusForm(obj=self.app.currentuser)
        params = {
            'form': form,
        }
        return self._compile_template(""prefs_mfa.html"", **params)

    def send_code(self):
        userobj = self.app.currentuser
        if not userobj.email:
            flash(_(""To continue, you must set up an email address for your account.""), level='warning')
            return
        code = cherrypy.tools.auth_mfa.generate_code()
        body = self.app.templates.compile_template(
            ""email_verification_code.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj, 'code': code}
        )
        cherrypy.engine.publish('queue_mail', to=userobj.email, subject=_(""Your verification code""), message=body)
        flash(_(""A new verification code has been sent to your email.""))
",CWE-613,133.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugin used to send email to users when their repository is getting too old.
User can control the notification period.
""""""


import cherrypy
from wtforms.fields import HiddenField, SelectField, SubmitField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.tools.i18n import ugettext as _


class MaxAgeField(SelectField):
    def __init__(self, *args, **kwargs):
        super().__init__(
            *args,
            choices=[
                (0, _('disabled')),
                (1, _('1 day')),
                (2, _('2 days')),
                (3, _('3 days')),
                (4, _('4 days')),
                (5, _('5 days')),
                (6, _('6 days')),
                (7, _('1 week')),
                (14, _('2 weeks')),
                (21, _('3 weeks')),
                (28, _('4 weeks')),
                (31, _('1 month')),
            ],
            coerce=int,
            **kwargs
        )


class NotificationForm(CherryForm):
    action = HiddenField(default=""set_notification_info"")

    @classmethod
    def create_form(cls, userobj):
        # Create dynamic list of fields
        data = {}
        extends = {}
        for repo in userobj.repo_objs:
            extends[repo.display_name] = MaxAgeField(label=repo.display_name)
            data[repo.display_name] = repo.maxage
        extends['submit'] = SubmitField(label=_('Save changes'))
        # Create class
        sub_form = type('SubForm', (cls,), extends)
        return sub_form(data=data)

    def is_submitted(self):
        return self.action.data == 'set_notification_info' and super().is_submitted()

    def populate_obj(self, userobj):
        # Loop trough user repo and update max age.
        for repo in userobj.repo_objs:
            if repo.display_name in self:
                # Update the maxage
                repo.maxage = self[repo.display_name].data


class PagePrefNotification(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        # Process the parameters.
        form = NotificationForm.create_form(self.app.currentuser)
        if form.validate_on_submit():
            form.populate_obj(self.app.currentuser)
            flash(_('Notification settings updated successfully.'), level='success')

        params = {
            'email': self.app.currentuser.email,
            'form': form,
        }
        return self._compile_template(""prefs_notification.html"", **params)
",CWE-613,95.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms import validators
from wtforms.fields import IntegerField, StringField

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import SessionObject
from rdiffweb.tools.i18n import ugettext as _


class RevokeSessionForm(CherryForm):
    action = StringField(validators=[validators.regexp('delete')])
    number = IntegerField(validators=[validators.data_required()])


class PagePrefSession(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        # Delete session on form submit
        form = RevokeSessionForm()
        if form.is_submitted():
            if form.validate():
                session = SessionObject.query.filter(
                    SessionObject.username == self.app.currentuser.username, SessionObject.number == form.number.data
                ).first()
                if not session:
                    flash(_('The given session cannot be removed because it cannot be found.'), level='warning')
                elif session.id == cherrypy.session.id:
                    flash(_('You cannot revoke your current session.'), level='warning')
                else:
                    session.delete()
                    flash(_('The session was successfully revoked.'), level='success')
            else:
                flash(form.error_message, level='error')
        # Get list of current user's session
        obj_list = SessionObject.query.filter(SessionObject.username == self.app.currentuser.username).all()
        active_sessions = [
            {
                'number': obj.number,
                'access_time': obj.data.get('access_time', None),
                'current': cherrypy.session.id == obj.id,
                'expiration_time': obj.expiration_time,
                'ip_address': obj.data.get('ip_address', None),
                'login_time': obj.data.get('login_time', None),
                'user_agent': obj.data.get('user_agent', None),
                'username': obj.username,
            }
            for obj in obj_list
        ]
        return self._compile_template(""prefs_session.html"", active_sessions=active_sessions)
",CWE-613,69.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugins to allows users to configure the SSH keys using the web
interface. Basically it's a UI for `~/.ssh/authorized_keys`. For this
plugin to work properly, the users home directory need to match a real
user home.
""""""

import logging

import cherrypy
from wtforms import validators
from wtforms.fields.core import StringField
from wtforms.validators import ValidationError
from wtforms.widgets.core import TextArea

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.dispatch import restapi
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core import authorizedkeys
from rdiffweb.core.model import DuplicateSSHKeyError
from rdiffweb.tools.i18n import gettext_lazy as _

_logger = logging.getLogger(__name__)


def validate_key(unused_form, field):
    """"""Custom validator to check the SSH Key.""""""
    try:
        authorizedkeys.check_publickey(field.data)
    except ValueError:
        raise ValidationError(_(""Invalid SSH key.""))


class SshForm(CherryForm):
    title = StringField(
        _('Title'),
        description=_('The title is an optional description to identify the key. e.g.: bob@thinkpad-t530'),
        validators=[
            validators.data_required(),
            validators.length(
                max=256,
                message=_('Title too long.'),
            ),
        ],
    )
    key = StringField(
        _('Key'),
        widget=TextArea(),
        description=_(
            ""Enter a SSH public key. It should start with 'ssh-dss', 'ssh-ed25519', 'ssh-rsa', 'ecdsa-sha2-nistp256', 'ecdsa-sha2-nistp384' or 'ecdsa-sha2-nistp521'.""
        ),
        validators=[validators.data_required(), validate_key],
    )

    def populate_obj(self, userobj):
        try:
            userobj.add_authorizedkey(key=self.key.data, comment=self.title.data)
        except DuplicateSSHKeyError as e:
            flash(str(e), level='error')
        except Exception:
            flash(_(""Unknown error while adding the SSH Key""), level='error')
            _logger.warning(""error adding ssh key"", exc_info=1)


class DeleteSshForm(CherryForm):
    fingerprint = StringField('Fingerprint', validators=[validators.data_required()])

    def populate_obj(self, userobj):
        is_maintainer()
        try:
            userobj.delete_authorizedkey(self.fingerprint.data)
        except Exception:
            flash(_(""Unknown error while removing the SSH Key""), level='error')
            _logger.warning(""error removing ssh key"", exc_info=1)


class PagePrefSshKeys(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):

        # Handle action
        form = SshForm()
        delete_form = DeleteSshForm()
        if not self.app.cfg.disable_ssh_keys:
            if action == 'add' and form.is_submitted():
                if form.validate():
                    form.populate_obj(self.app.currentuser)
                else:
                    flash(form.error_message, level='warning')
            elif action == 'delete' and delete_form.is_submitted():
                if delete_form.validate():
                    delete_form.populate_obj(self.app.currentuser)
                else:
                    flash(delete_form.error_message, level='warning')

        # Get SSH keys if file exists.
        params = {
            'disable_ssh_keys': self.app.cfg.disable_ssh_keys,
            'form': form,
        }
        try:
            params[""sshkeys""] = [
                {'title': key.comment, 'fingerprint': key.fingerprint} for key in self.app.currentuser.authorizedkeys
            ]
        except IOError:
            params[""sshkeys""] = []
            flash(_(""Failed to get SSH keys""), level='error')
            _logger.warning(""error reading SSH keys"", exc_info=1)

        return self._compile_template(""prefs_sshkeys.html"", **params)


@restapi()
@cherrypy.tools.json_out()
class ApiSshKeys(Controller):
    @cherrypy.expose
    def list(self):
        return [{'title': key.comment, 'fingerprint': key.fingerprint} for key in self.app.currentuser.authorizedkeys]

    @cherrypy.expose
    def get(self, fingerprint):
        for key in self.app.currentuser.authorizedkeys:
            if key.fingerprint == fingerprint:
                return {'title': key.comment, 'fingerprint': key.fingerprint}
        raise cherrypy.HTTPError(404)

    @cherrypy.expose
    def delete(self, fingerprint):
        form = DeleteSshForm(fingerprint=fingerprint)
        if form.validate():
            form.populate_obj(self.app.currentuser)
            return {}
        else:
            raise cherrypy.HTTPError(400, form.error_message)

    @cherrypy.expose
    def post(self, **kwargs):
        form = SshForm()
        if form.validate():
            form.populate_obj(self.app.currentuser)
            return kwargs
        else:
            raise cherrypy.HTTPError(400, form.error_message)
",CWE-613,161.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import logging

import cherrypy
from wtforms.fields import DateField, HiddenField, StringField, SubmitField
from wtforms.validators import DataRequired, Length, Optional

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import Token
from rdiffweb.tools.i18n import gettext_lazy as _

logger = logging.getLogger(__name__)


class TokenForm(CherryForm):
    action = HiddenField(default='add_access_token')
    name = StringField(
        _('Token name'),
        description=_(
            'Used only to identify the purpose of the token. For example, the application that uses the token.'
        ),
        validators=[
            DataRequired(),
            Length(max=256, message=_('Token name too long')),
        ],
    )
    expiration = DateField(
        _('Expiration date'),
        description=_(
            'Allows the creation of a temporary token by defining an expiration date. Leave empty to keep the token forever.'
        ),
        render_kw={
            ""placeholder"": _('YYYY-MM-DD'),
        },
        validators=[Optional()],
    )
    submit = SubmitField(_('Create access token'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'add_access_token'

    def populate_obj(self, userobj):
        try:
            token = userobj.add_access_token(self.name.data, self.expiration.data)
            flash(
                _(
                    ""Your new personal access token has been created.\n""
                    ""Make sure to save it - you won't be able to access it again.\n""
                    ""%s""
                )
                % token,
                level='info',
            )
        except ValueError as e:
            flash(str(e), level='warning')
        except Exception:
            logger.exception(""error adding access token: %s, %s"" % (self.name.data, self.expiration.data))
            flash(_(""Unknown error while adding the access token.""), level='error')


class DeleteTokenForm(CherryForm):
    action = HiddenField(default='delete_access_token')
    name = StringField(validators=[DataRequired()])

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'delete_access_token'

    def populate_obj(self, userobj):
        is_maintainer()
        try:
            userobj.delete_access_token(self.name.data)
            flash(_('The access token has been successfully deleted.'), level='success')
        except ValueError as e:
            flash(str(e), level='warning')
        except Exception:
            logger.exception(""error removing access token: %s"" % self.name.data)
            flash(_(""Unknown error while removing the access token.""), level='error')


class PagePrefTokens(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        form = TokenForm()
        delete_form = DeleteTokenForm()
        if form.is_submitted():
            if form.validate():
                form.populate_obj(self.app.currentuser)
            else:
                flash(form.error_message, level='error')
        elif delete_form.is_submitted():
            if delete_form.validate():
                delete_form.populate_obj(self.app.currentuser)
            else:
                flash(delete_form.error_message, level='error')
        params = {
            'form': form,
            'tokens': Token.query.filter(Token.userid == self.app.currentuser.userid),
        }
        return self._compile_template(""prefs_tokens.html"", **params)
",CWE-613,121.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Nov 16, 2017

@author: Patrik Dufresne
""""""


from base64 import b64encode

import rdiffweb.test
from rdiffweb.core.model import UserObject


class APITest(rdiffweb.test.WebCase):

    headers = [(""Authorization"", ""Basic "" + b64encode(b""admin:admin123"").decode('ascii'))]

    def test_get_index(self):
        data = self.getJson('/api/', headers=self.headers)
        self.assertIsNotNone(data.get('version'))

    def test_get_currentuser(self):
        data = self.getJson('/api/currentuser/', headers=self.headers)
        self.assertEqual(data.get('username'), 'admin')
        self.assertEqual(data.get('email'), '')
        # This value change on every execution.
        self.assertEqual(2, len(data.get('repos')))
        repo = data.get('repos')[1]
        self.assertEqual(repo.get('keepdays'), -1)
        self.assertEqual(repo.get('last_backup_date'), '2016-02-02T16:30:40-05:00')
        self.assertEqual(repo.get('status'), 'ok')
        self.assertEqual(repo.get('display_name'), 'testcases')
        self.assertEqual(repo.get('encoding'), 'utf-8')
        self.assertEqual(repo.get('name'), 'testcases')
        self.assertEqual(repo.get('maxage'), 0)

    def test_getapi_without_authorization(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/')
        self.assertStatus('401 Unauthorized')

    def test_getapi_without_username(self):
        """"""
        Check if error 401 is raised when requesting /login without a username.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b"":admin123"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_empty_password(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_invalid_password(self):
        """"""
        Check if 401 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:invalid"").decode('ascii'))])
        self.assertStatus('401 Unauthorized')

    def test_getapi_with_authorization(self):
        """"""
        Check if 200 is return when authorization is not provided.
        """"""
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:admin123"").decode('ascii'))])
        self.assertStatus('200 OK')

    def test_getapi_with_session(self):
        # Given an authenticate user
        b = {'login': self.USERNAME, 'password': self.PASSWORD}
        self.getPage('/login/', method='POST', body=b)
        self.assertStatus('303 See Other')
        self.getPage('/')
        self.assertStatus('200 OK')
        # When querying the API
        self.getPage('/api/')
        # Then access is refused
        self.assertStatus('401 Unauthorized')

    def test_auth_with_access_token(self):
        # Given a user with an access token
        userobj = UserObject.get_user(self.USERNAME)
        token = userobj.add_access_token('test').encode('ascii')
        # When using this token to authenticated with /api
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:"" + token).decode('ascii'))])
        # Then authentication is successful
        self.assertStatus('200 OK')

    def test_auth_failed_with_mfa_enabled(self):
        # Given a user with MFA enabled
        userobj = UserObject.get_user(self.USERNAME)
        userobj.mfa = UserObject.ENABLED_MFA
        userobj.add()
        # When authenticating with /api/
        self.getPage('/api/', headers=self.headers)
        # Then access is refused
        self.assertStatus('401 Unauthorized')


class APIRatelimitTest(rdiffweb.test.WebCase):

    default_config = {
        'rate-limit': 5,
    }

    def test_login_ratelimit(self):
        # Given invalid credentials sent to API
        headers = [(""Authorization"", ""Basic "" + b64encode(b""admin:invalid"").decode('ascii'))]
        for i in range(1, 5):
            self.getPage('/api/', headers=headers)
            self.assertStatus(401)
        # Then the 6th request is refused
        self.getPage('/api/', headers=headers)
        self.assertStatus(429)
        # Next request is also refused event if credentials are valid.
        self.getPage('/api/', headers=[(""Authorization"", ""Basic "" + b64encode(b""admin:admin123"").decode('ascii'))])
        self.assertStatus(429)
",CWE-613,138.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Mar 13, 2019

@author: Patrik Dufresne
""""""

import datetime

from parameterized import parameterized

import rdiffweb.test
from rdiffweb.core.model import DbSession, SessionObject


class ControllerTest(rdiffweb.test.WebCase):

    login = True

    default_config = {'HeaderName': 'MyTest'}

    def test_headername(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"")
        self.assertStatus('200 OK')
        self.assertInBody('MyTest')

    def test_proxy(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"", headers=[('Host', 'this.is.a.test.com')])
        self.assertStatus('200 OK')
        self.assertInBody('http://this.is.a.test.com/favicon.ico')

    def test_proxy_https(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"", headers=[('Host', 'this.is.a.test.com'), ('X-Forwarded-Proto', 'https')])
        self.assertStatus('200 OK')
        self.assertInBody('https://this.is.a.test.com/favicon.ico')

    @parameterized.expand(
        [
            '/favicon.ico',
            '/static/blue.css',
            '/static/css/bootstrap.min.css',
            '/static/css/font-awesome.min.css',
            '/static/css/jquery.dataTables.min.css',
            '/static/default.css',
            '/static/js/bootstrap.bundle.min.js',
            '/static/js/jquery.dataTables.min.js',
            '/static/js/jquery.min.js',
            '/static/js/rdiffweb.js',
            '/static/orange.css',
        ]
    )
    def test_static_files(self, path):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage('/logout')
        self.getPage(path)
        self.assertStatus(200)

    def test_static_invalid_method(self):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage(""/static/default.css"", method=""POST"")
        self.assertStatus(400)

    def test_static_invalid_file(self):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage(""/static/invalid.css"")
        self.assertStatus(400)

    def test_path_traversal(self):
        self.getPage('/static//../../test.txt')
        self.assertStatus(403)


class ControllerOrangeThemeTest(rdiffweb.test.WebCase):

    login = True

    default_config = {'DefaultTheme': 'orange'}

    def test_static(self):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage(""/"")
        self.assertStatus('200 OK')
        self.assertInBody('/static/orange.css')


class ControllerBlueThemeTest(rdiffweb.test.WebCase):

    login = True

    default_config = {'DefaultTheme': 'blue'}

    def test_theme(self):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage(""/"")
        self.assertInBody('/static/blue.css')


class ControllerSession(rdiffweb.test.WebCase):
    def test_enrich_session_anonymous(self):
        # When making a query to a page while unauthenticated
        self.getPage('/', headers=[('User-Agent', 'test')])
        # Then a session object is enriched
        self.assertEqual(1, SessionObject.query.filter(SessionObject.id == self.session_id).count())
        SessionObject.query.filter(SessionObject.id == self.session_id).first()
        session = DbSession(id=self.session_id)
        session.load()
        self.assertIsNotNone(session.get('ip_address'))
        self.assertIsNotNone(session.get('user_agent'))
        self.assertIsNotNone(session.get('access_time'))

    def test_enrich_session_authenticated(self):
        # When making a query to a page while unauthenticated
        self.getPage(
            '/login/',
            method='POST',
            headers=[('User-Agent', 'test')],
            body={'login': self.USERNAME, 'password': self.PASSWORD},
        )
        # Then a session object is enriched
        self.assertEqual(1, SessionObject.query.filter(SessionObject.id == self.session_id).count())
        SessionObject.query.filter(SessionObject.id == self.session_id).first()
        session = DbSession(id=self.session_id)
        session.load()
        self.assertIsNotNone(session.get('ip_address'))
        self.assertIsNotNone(session.get('user_agent'))
        self.assertIsNotNone(session.get('access_time'))

    def test_create_session(self):
        # Given a server with no session.
        self.assertEqual(0, len(SessionObject.query.all()))
        # When querying a new page
        self.getPage('/')
        self.assertStatus(303)
        # Then a new session get created
        self.assertEqual(1, len(SessionObject.query.all()))
        session = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        self.assertIsNotNone(session)

    def test_clean_up_session(self):
        # Given a server with a session
        self.getPage('/')
        self.assertStatus(303)
        self.assertEqual(1, len(SessionObject.query.all()))
        # When this session get old
        data = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        data.expiration_time = datetime.datetime.now() - datetime.timedelta(seconds=1)
        data.add()
        session = DbSession(id=self.session_id)
        # Then the session get deleted by clean_up process
        session.clean_up()
        # Then session is deleted
        data = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        self.assertIsNone(data)
",CWE-613,188.0,1
"# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
from parameterized import parameterized

import rdiffweb.test
from rdiffweb.core.model import UserObject


class AdminPagesAsUser(rdiffweb.test.WebCase):
    def setUp(self):
        super().setUp()
        # Add test user
        UserObject.add_user('test', 'test123')
        self._login('test', 'test123')

    @parameterized.expand(
        [
            ""/admin"",
            ""/admin/users"",
            ""/admin/repos"",
            ""/admin/session"",
            ""/admin/sysinfo"",
            ""/admin/logs"",
        ]
    )
    def test_forbidden_access(self, value):
        self.getPage(value)
        self.assertStatus(403)
",CWE-613,42.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

""""""
Created on Jan 1, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""

import rdiffweb.test
from rdiffweb.core.model import UserObject


class SettingsTest(rdiffweb.test.WebCase):

    login = True

    def test_activities(self):
        self.getPage(""/graphs/activities/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        self.assertStatus('200 OK')

    def test_errors(self):
        self.getPage(""/graphs/errors/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        self.assertStatus('200 OK')

    def test_files(self):
        self.getPage(""/graphs/files/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        self.assertStatus('200 OK')

    def test_sizes(self):
        self.getPage(""/graphs/sizes/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        self.assertStatus('200 OK')

    def test_times(self):
        self.getPage(""/graphs/times/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        self.assertStatus('200 OK')

    def test_as_another_user(self):
        # Create another user with admin right
        user_obj = UserObject.add_user('anotheruser', 'password')
        user_obj.user_root = self.testcases
        user_obj.refresh_repos()

        self.getPage(""/graphs/activities/anotheruser/testcases"")
        self.assertStatus('200 OK')
        self.assertInBody(""Activities"")

        # Remove admin role
        admin = UserObject.get_user('admin')
        admin.role = UserObject.USER_ROLE
        admin.add()

        # Browse admin's repos
        self.getPage(""/graphs/activities/anotheruser/testcases"")
        self.assertStatus('403 Forbidden')

    def test_chartkick_js(self):
        self.getPage(""/static/js/chart.min.js"")
        self.assertStatus('200 OK')
        self.assertInBody(""Chart"")

    def test_chart_js(self):
        self.getPage(""/static/js/chartkick.min.js"")
        self.assertStatus('200 OK')
        self.assertInBody(""Chartkick"")

    def test_does_not_exists(self):
        # Given an invalid repo
        repo = 'invalid'
        # When trying to get graphs of it
        self.getPage(""/graphs/activities/"" + self.USERNAME + ""/"" + repo + ""/"")
        # Then a 404 error is return
        self.assertStatus(404)

    def test_browser_with_failed_repo(self):
        # Given a failed repo
        admin = UserObject.get_user('admin')
        admin.user_root = 'invalid'
        admin.add()
        # When querying the logs
        self.getPage(""/graphs/activities/"" + self.USERNAME + ""/"" + self.REPO + ""/"")
        # Then the page is return with an error message
        self.assertStatus(200)
        self.assertInBody('The repository cannot be found or is badly damaged.')
",CWE-613,99.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

""""""
Created on Dec 29, 2015

@author: Patrik Dufresne
""""""


import rdiffweb.test
from rdiffweb.core.model import UserObject


class HistoryPageTest(rdiffweb.test.WebCase):

    login = True

    def _history(self, user, path, limit=None):
        url = ""/history/"" + user + ""/"" + path + ""/""
        if limit:
            url += ""?limit=%s"" % limit
        self.getPage(url)
        self.assertStatus('200 OK')

    def test_history_with_root(self):
        self._history(self.USERNAME, self.REPO)
        # Check revisions
        self.assertInBody(""2016-02-02T16:30:40-05:00"")
        self.assertInBody(""2014-11-02T09:50:53-05:00"")
        # Check show more button get displayed
        self.assertInBody(""Show more"")
        # Check download buttont
        self.assertInBody(""Download"")
        self.assertInBody(""/restore/"" + self.USERNAME + ""/"" + self.REPO + ""?date=1415221507"")

    def test_history_with_path(self):
        self._history(self.USERNAME, 'testcases/Subdirectory')
        self.assertInBody(""2016-02-02T16:30:40-05:00"")
        self.assertInBody(""2016-01-20T10:42:21-05:00"")
        self.assertNotInBody(""Show more"")

    def test_history_with_deleted_path(self):
        self._history(self.USERNAME, ""testcases/R%C3%A9pertoire%20Supprim%C3%A9/"")
        self.assertInBody(""Download"")
        self.assertInBody(""ZIP"")
        self.assertInBody(""TAR.GZ"")
        self.assertInBody(""2014-11-01T15:51:15-04:00"")
        self.assertInBody(
            ""/restore/"" + self.USERNAME + ""/"" + self.REPO + ""/R%C3%A9pertoire%20Supprim%C3%A9?date=1414871475""
        )

    def test_history_with_limit(self):
        self._history(self.USERNAME, self.REPO, 10)
        self.assertInBody(""Show more"")
        self._history(self.USERNAME, self.REPO, 50)
        self.assertNotInBody(""Show more"")

    def test_as_another_user(self):
        # Create a nother user with admin right
        user_obj = UserObject.add_user('anotheruser', 'password')
        user_obj.user_root = self.testcases
        user_obj.refresh_repos()
        self.getPage(""/history/anotheruser/testcases"")
        self.assertStatus('200 OK')

        # Remove admin right
        admin = UserObject.get_user('admin')
        admin.role = UserObject.USER_ROLE
        admin.add()

        # Browse admin's repos
        self.getPage(""/history/anotheruser/testcases"")
        self.assertStatus('403 Forbidden')

    def test_history_does_not_exists(self):
        # Given an invalid repo
        repo = 'invalid'
        # When trying to browse the history
        self.getPage(""/history/"" + self.USERNAME + ""/"" + repo)
        # Then a 404 error is return to the user
        self.assertStatus(404)

    def test_browser_with_failed_repo(self):
        # Given a failed repo
        admin = UserObject.get_user('admin')
        admin.user_root = 'invalid'
        admin.add()
        # When querying the logs
        self.getPage(""/history/"" + self.USERNAME + ""/"" + self.REPO)
        # Then the page is return with an error message
        self.assertStatus(200)
        self.assertInBody('The repository cannot be found or is badly damaged.')
",CWE-613,108.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Apr 26, 2021

@author: Patrik Dufresne
""""""

import os

import rdiffweb.test
from rdiffweb.core.model import UserObject
from rdiffweb.core.rdw_templating import url_for


class LogsPageTest(rdiffweb.test.WebCase):

    login = True

    def _log(self, user, repo, limit=None, date=None, file=None, raw=None):
        url = url_for('logs', user, repo, limit=limit, date=date, file=file, raw=raw)
        return self.getPage(url)

    def test_logs(self):
        self._log(self.USERNAME, self.REPO)
        # Check revisions
        self.assertInBody(""Backup Log"")
        self.assertInBody(""Restore Log"")
        # Check show more button get displayed
        self.assertInBody(""Show more"")

    def test_logs_with_date_notfound(self):
        self._log(self.USERNAME, self.REPO, date=1)
        self.assertStatus(404)

    def test_logs_with_date_invalid(self):
        self._log(self.USERNAME, self.REPO, date='invalid')
        self.assertStatus(400)

    def test_logs_with_file_backup(self):
        self._log(self.USERNAME, self.REPO, file='backup.log')
        self.assertStatus(200)

    def test_logs_with_file_backup_missing(self):
        os.unlink(os.path.join(self.testcases, self.REPO, 'rdiff-backup-data', 'backup.log'))
        self._log(self.USERNAME, self.REPO, file='backup.log')
        self.assertStatus(200)
        self.assertInBody(""This log file is empty"")

    def test_logs_with_file_restore(self):
        self._log(self.USERNAME, self.REPO, file='restore.log')
        self.assertStatus(200)
        self.assertInBody(""Starting restore of"")

    def test_logs_with_file_restore_missing(self):
        os.unlink(os.path.join(self.testcases, self.REPO, 'rdiff-backup-data', 'restore.log'))
        self._log(self.USERNAME, self.REPO, file='restore.log')
        self.assertStatus(200)
        self.assertInBody(""This log file is empty"")

    def test_logs_with_date_valid(self):
        self._log(self.USERNAME, self.REPO, date='1454448640')
        self.assertStatus(200)

    def test_logs_with_limit(self):
        self._log(self.USERNAME, self.REPO, limit=50)
        self.assertStatus(200)
        self.assertNotInBody(""Show more"")

    def test_logs_with_raw(self):
        self._log(self.USERNAME, self.REPO, file='restore.log', raw=1)
        self.assertStatus(200)
        self.assertHeaderItemValue('Content-Type', 'text/plain;charset=utf-8')
        self.assertInBody(""Starting restore of"")
        self.assertNotInBody(""<html"")

    def test_logs_does_not_exists(self):
        # Given an invalid repo
        repo = 'invalid'
        # When trying to get logs from it
        self._log(self.USERNAME, repo)
        # Then a 4040 error is return
        self.assertStatus(404)

    def test_browser_with_failed_repo(self):
        # Given a failed repo
        admin = UserObject.get_user('admin')
        admin.user_root = 'invalid'
        admin.add()
        # When querying the logs
        self._log(self.USERNAME, self.REPO)
        # Then the page is return with an error message
        self.assertStatus(200)
        self.assertInBody('The repository cannot be found or is badly damaged.')
",CWE-613,109.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from unittest.mock import ANY, MagicMock

import cherrypy
from parameterized import parameterized

import rdiffweb.test
from rdiffweb.core.model import UserObject


class PagePrefMfaTest(rdiffweb.test.WebCase):

    login = True

    def setUp(self):
        super().setUp()
        # Define email for all test
        userobj = UserObject.get_user(self.USERNAME)
        userobj.email = 'admin@example.com'
        userobj.add()
        # Register a listener on email
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def _set_mfa(self, mfa):
        # Define mfa for user
        userobj = UserObject.get_user(self.USERNAME)
        userobj.mfa = mfa
        userobj.add()
        # Reset mock.
        self.listener.queue_email.reset_mock()
        # Leave to disable mfa
        if mfa == UserObject.DISABLED_MFA:
            return
        # Generate a code for login if required
        self.getPage(""/mfa/"")
        self.assertStatus(200)
        self.assertInBody(""A new verification code has been sent to your email."")
        # Extract code from email between <strong> and </strong>
        self.listener.queue_email.assert_called_once()
        message = self.listener.queue_email.call_args[1]['message']
        code = message.split('<strong>', 1)[1].split('</strong>')[0]
        # Login to MFA
        self.getPage(""/mfa/"", method='POST', body={'code': code, 'submit': '1'})
        self.assertStatus(303)
        # Clear mock.
        self.listener.queue_email.reset_mock()

    def _get_code(self, action):
        assert action in ['enable_mfa', 'disable_mfa', 'resend_code']
        # Query MFA page to generate a code
        self.getPage(""/prefs/mfa"", method='POST', body={action: '1'})
        self.assertStatus(200)
        self.assertInBody(""A new verification code has been sent to your email."")
        # Extract code from email between <strong> and </strong>
        self.listener.queue_email.assert_called_once()
        message = self.listener.queue_email.call_args[1]['message']
        self.listener.queue_email.reset_mock()
        return message.split('<strong>', 1)[1].split('</strong>')[0]

    def test_get(self):
        # When getting the page
        self.getPage(""/prefs/mfa"")
        # Then the page is return without error
        self.assertStatus(200)

    @parameterized.expand(
        [
            ('enable_mfa', UserObject.DISABLED_MFA, UserObject.ENABLED_MFA, ""Two-Factor Authentication turned on""),
            ('disable_mfa', UserObject.ENABLED_MFA, UserObject.DISABLED_MFA, ""Two-Factor Authentication turned off""),
        ]
    )
    def test_with_valid_code(self, action, initial_mfa, expected_mfa, expected_subject):
        # Define mfa for user
        self._set_mfa(initial_mfa)
        # Given a user with email requesting a code
        code = self._get_code(action=action)
        # When sending a valid code
        self.getPage(""/prefs/mfa"", method='POST', body={action: '1', 'code': code})
        # Then mfa get enabled or disable accordingly
        self.assertStatus(200)
        userobj = UserObject.get_user(self.USERNAME)
        self.assertEqual(userobj.mfa, expected_mfa)
        # Then no verification code get sent
        self.assertNotInBody(""A new verification code has been sent to your email."")
        # Then an email confirmation get send
        self.listener.queue_email.assert_called_once_with(to=ANY, subject=expected_subject, message=ANY)
        # Then next page request is still working.
        self.getPage('/')
        self.assertStatus(200)

    @parameterized.expand(
        [
            ('enable_mfa', UserObject.DISABLED_MFA, UserObject.DISABLED_MFA),
            ('disable_mfa', UserObject.ENABLED_MFA, UserObject.ENABLED_MFA),
        ]
    )
    def test_with_invalid_code(self, action, initial_mfa, expected_mfa):
        # Define mfa for user
        self._set_mfa(initial_mfa)
        # Given a user with email requesting a code
        self._get_code(action=action)
        # When sending an invalid code
        self.getPage(""/prefs/mfa"", method='POST', body={action: '1', 'code': '1234567'})
        # Then mfa get enabled or disable accordingly
        self.assertStatus(200)
        userobj = UserObject.get_user(self.USERNAME)
        self.assertEqual(userobj.mfa, expected_mfa)
        # Then next page request is still working.
        self.getPage('/')
        self.assertStatus(200)

    @parameterized.expand(
        [
            ('enable_mfa', UserObject.DISABLED_MFA),
            ('disable_mfa', UserObject.ENABLED_MFA),
        ]
    )
    def test_without_email(self, action, initial_mfa):
        # Define mfa for user
        self._set_mfa(initial_mfa)
        # Given a user without email requesting a code
        userobj = UserObject.get_user(self.USERNAME)
        userobj.email = ''
        userobj.add()
        # When trying to enable or disable mfa
        self.getPage(""/prefs/mfa"", method='POST', body={action: '1'})
        # Then an error is return to the user
        self.assertStatus(200)
        self.assertInBody(""To continue, you must set up an email address for your account."")

    @parameterized.expand(
        [
            (UserObject.DISABLED_MFA,),
            (UserObject.ENABLED_MFA,),
        ]
    )
    def test_resend_code(self, initial_mfa):
        # Define mfa for user
        self._set_mfa(initial_mfa)
        # When requesting a new code.
        self.getPage(""/prefs/mfa"", method='POST', body={'resend_code': '1'})
        # Then a new code get sent.
        self.assertInBody(""A new verification code has been sent to your email."")
",CWE-613,165.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import rdiffweb.test
from rdiffweb.core.model import Token, UserObject


class PagePrefTokensTest(rdiffweb.test.WebCase):

    login = True

    def test_get(self):
        # When getting the page
        self.getPage(""/prefs/tokens"")
        # Then the page is return without error
        self.assertStatus(200)

    def test_add_access_token(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': 'test-token-name', 'expiration_time': ''},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('test-token-name')
        # Then access token get created
        self.assertEqual(1, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_add_access_token_with_expiration_time(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': 'test-token-name', 'expiration_time': '1999-01-01'},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('test-token-name')
        # Then access token get created
        self.assertEqual(1, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_add_access_token_without_name(self):
        # Given an existing user
        userobj = UserObject.get_user(self.USERNAME)
        # When adding a new access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': '', 'expiration_time': ''},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('Token name: This field is required.')
        # Then access token is not created
        self.assertEqual(0, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())

    def test_add_access_token_with_name_too_long(self):
        # Given an existing user
        # When adding a new access token with name too long.
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'add_access_token', 'name': 'token' * 52, 'expiration_time': ''},
        )
        # Then page return with error message
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('Token name too long')

    def test_delete_access_token(self):
        # Given an existing user with access_token
        userobj = UserObject.get_user(self.USERNAME)
        userobj.add_access_token('test-token-name')
        # When deleting access token
        self.getPage(
            ""/prefs/tokens"",
            method='POST',
            body={'action': 'delete_access_token', 'name': 'test-token-name'},
        )
        # Then page return without error
        self.assertStatus(200)
        # Then token name get displayed in the view
        self.assertInBody('The access token has been successfully deleted.')
        # Then access token is not created
        self.assertEqual(0, Token.query.filter(Token.userid == userobj.userid, Token.name == 'test-token-name').count())
",CWE-613,110.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

""""""
Created on Jan 1, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""


import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class SettingsTest(rdiffweb.test.WebCase):

    login = True

    def test_page(self):
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + self.REPO)
        self.assertInBody(""Character encoding"")
        self.assertStatus(200)

    def test_as_another_user(self):
        # Create a nother user with admin right
        user_obj = UserObject.add_user('anotheruser', 'password')
        user_obj.user_root = self.testcases
        user_obj.refresh_repos()
        self.getPage(""/settings/anotheruser/testcases"")
        self.assertInBody(""Character encoding"")
        self.assertStatus('200 OK')

        # Remove admin right
        admin = UserObject.get_user('admin')
        admin.role = UserObject.USER_ROLE
        admin.add()

        # Browse admin's repos
        self.getPage(""/settings/anotheruser/testcases"")
        self.assertStatus('403 Forbidden')

    def test_set_maxage(self):
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + self.REPO + ""/"", method=""POST"", body={'maxage': '4'})
        self.assertStatus(200)
        # Check database update
        repo_obj = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        self.assertEqual(4, repo_obj.maxage)

    def test_set_maxage_method_get(self):
        # When trying to update maxage with GET method
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + self.REPO + ""/?maxage=4"")
        # Then page return without error
        self.assertStatus(200)
        # Then database is not updated
        repo_obj = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        self.assertEqual(0, repo_obj.maxage)

    def test_does_not_exists(self):
        # Given an invalid repo
        repo = 'invalid'
        # When trying to get settings from it
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + repo)
        # Then a 404 error is return
        self.assertStatus(404)

    def test_browser_with_failed_repo(self):
        # Given a failed repo
        admin = UserObject.get_user('admin')
        admin.user_root = '/invalid/'
        admin.add()
        # When querying the logs
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + self.REPO)
        # Then the page is return with an error message
        self.assertStatus(200)
        self.assertInBody('The repository cannot be found or is badly damaged.')
",CWE-613,90.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on May 2, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""


import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class RemoveOlderTest(rdiffweb.test.WebCase):

    login = True

    def _settings(self, user, repo):
        self.getPage(""/settings/"" + user + ""/"" + repo + ""/"")

    def _remove_older(self, user, repo, value):
        self.getPage(""/settings/"" + user + ""/"" + repo + ""/"", method=""POST"", body={'keepdays': value})

    def test_page_set_keepdays(self):
        self._remove_older(self.USERNAME, self.REPO, '1')
        self.assertStatus(200)
        # Make sure the right value is selected.
        self._settings(self.USERNAME, self.REPO)
        self.assertStatus(200)
        self.assertInBody('<option selected value=""1"">')
        # Also check if the value is updated in database
        repo = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        keepdays = repo.keepdays
        self.assertEqual(1, keepdays)

    def test_as_another_user(self):
        # Create another user with admin right
        user_obj = UserObject.add_user('anotheruser', 'password')
        user_obj.user_root = self.testcases
        user_obj.refresh_repos()
        self._remove_older('anotheruser', 'testcases', '1')
        self.assertStatus('200 OK')
        repo = RepoObject.query.filter(RepoObject.user == user_obj, RepoObject.repopath == self.REPO).first()
        self.assertEqual(1, repo.keepdays)

        # Remove admin right
        admin = UserObject.get_user('admin')
        admin.role = UserObject.USER_ROLE
        admin.add()

        # Browse admin's repos
        self._remove_older('anotheruser', 'testcases', '2')
        self.assertStatus('403 Forbidden')

    def test_set_keepdays_method_get(self):
        # When trying update keepdays with method GET
        self.getPage(""/settings/"" + self.USERNAME + ""/"" + self.REPO + ""/?keepdays=4"")
        # Then pge return without error
        self.assertStatus(200)
        # Then database is not updated
        user_obj = UserObject.get_user(self.USERNAME)
        repo = RepoObject.query.filter(RepoObject.user == user_obj, RepoObject.repopath == self.REPO).first()
        self.assertEqual(-1, repo.keepdays)
",CWE-613,78.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Jan 1, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""


import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class SetEncodingTest(rdiffweb.test.WebCase):

    login = True

    def _settings(self, user, repo):
        self.getPage(""/settings/"" + user + ""/"" + repo + ""/"")

    def _set_encoding(self, user, repo, encoding):
        self.getPage(""/settings/"" + user + ""/"" + repo + ""/"", method=""POST"", body={'new_encoding': encoding})

    def test_check_default_encoding(self):
        # Default encoding for broker-repo is the default system encoding.
        self._settings('admin', 'broker-repo')
        self.assertInBody(""Character encoding"")
        self.assertInBody('selected value=""%s""' % RepoObject.DEFAULT_REPO_ENCODING)

    def test_set_encoding(self):
        """"""
        Check to update the encoding with cp1252.
        """"""
        self._set_encoding('admin', 'testcases', 'cp1252')
        self.assertStatus(200)
        self.assertInBody(""Updated"")
        repo = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        self.assertEqual('cp1252', repo.encoding)
        # Get back encoding.
        self._settings('admin', 'testcases')
        self.assertInBody('selected value=""cp1252""')

    def test_set_encoding_capital_case(self):
        """"""
        Check to update the encoding with US-ASCII.
        """"""
        self._set_encoding('admin', 'testcases', 'US-ASCII')
        self.assertStatus(200)
        self.assertInBody(""Updated"")
        repo = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        self.assertEqual('ascii', repo.encoding)
        # Get back encoding.
        self._settings('admin', 'testcases')
        self.assertInBody('selected value=""ascii""')

    def test_set_encoding_invalid(self):
        """"""
        Check to update the encoding with invalid value.
        """"""
        self._set_encoding('admin', 'testcases', 'invalid')
        self.assertStatus(400)
        self.assertInBody(""invalid encoding value"")

    def test_set_encoding_windows_1252(self):
        """"""
        Check to update the encoding with windows 1252.
        """"""
        # Update encoding
        self._set_encoding('admin', 'testcases', 'windows_1252')
        self.assertStatus(200)
        self.assertInBody(""Updated"")
        # Get back encoding.
        self._settings('admin', 'testcases')
        self.assertInBody('selected value=""cp1252""')
        repo = RepoObject.query.filter(RepoObject.repopath == self.REPO).first()
        self.assertEqual('cp1252', repo.encoding)

    def test_as_another_user(self):
        # Create another user with admin right
        user_obj = UserObject.add_user('anotheruser', 'password')
        user_obj.user_root = self.testcases
        user_obj.refresh_repos()
        self._set_encoding('anotheruser', 'testcases', 'cp1252')
        self.assertStatus('200 OK')
        repo = RepoObject.query.filter(RepoObject.user == user_obj, RepoObject.repopath == self.REPO).first()
        self.assertEqual('cp1252', repo.encoding)

        # Remove admin right
        admin = UserObject.get_user('admin')
        admin.role = UserObject.USER_ROLE
        admin.add()

        # Browse admin's repos
        self._set_encoding('anotheruser', 'testcases', 'utf-8')
        self.assertStatus('403 Forbidden')

    def test_set_encoding_method_get(self):
        # When trying to update encoding with method GET
        self.getPage(""/settings/admin/testcases/?new_encoding=cp1252"")
        # Then page return without error
        self.assertStatus(200)
        # Then database is not updated
        user_obj = UserObject.get_user(self.USERNAME)
        repo = RepoObject.query.filter(RepoObject.user == user_obj, RepoObject.repopath == self.REPO).first()
        self.assertEqual('utf-8', repo.encoding)
",CWE-613,120.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Aug 30, 2019

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""

import rdiffweb.test
from rdiffweb.core.model import UserObject


class StatusTest(rdiffweb.test.WebCase):

    login = True

    def test_page(self):
        # When browsing the status page
        self.getPage(""/status/"")
        # Then no error are raised
        self.assertStatus(200)
        self.assertInBody('Backup Status')

    def test_page_with_broken_repo(self):
        # Given a user's with broken repo
        userobj = UserObject.get_user('admin')
        userobj.user_root = '/invalid/'
        userobj.add()
        # When browsing the status page
        self.getPage(""/status/"")
        # Then not error should be raised
        self.assertStatus(200)
        self.assertInBody('Backup Status')
",CWE-613,48.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging

import cherrypy
from cherrypy.process.plugins import SimplePlugin

from rdiffweb.core.model import UserObject

logger = logging.getLogger(__name__)


class LoginPlugin(SimplePlugin):
    """"""
    This plugins register an ""authenticate"" listener to validate
    username and password of users. In addition, it provide a ""login""
    listener to authenticate and possibly create the user in database.
    """"""

    add_missing_user = False
    add_user_default_role = UserObject.USER_ROLE
    add_user_default_userroot = None

    def start(self):
        self.bus.log('Start Login plugin')
        self.bus.subscribe(""authenticate"", self.authenticate)
        self.bus.subscribe(""login"", self.login)

    def stop(self):
        self.bus.log('Stop Login plugin')
        self.bus.unsubscribe(""authenticate"", self.authenticate)
        self.bus.unsubscribe(""login"", self.login)

    def authenticate(self, username, password):
        """"""
        Only verify the user's credentials using the database store.
        """"""
        user = UserObject.query.filter_by(username=username).first()
        if user and user.validate_password(password):
            return username, {}
        return False

    def login(self, username, password):
        """"""
        Validate username password using database and LDAP.
        """"""
        # Validate credentials.
        authenticates = self.bus.publish('authenticate', username, password)
        authenticates = [a for a in authenticates if a]
        if not authenticates:
            return None
        real_username = authenticates[0][0]
        extra_attrs = authenticates[0][1]
        fullname = extra_attrs.get('_fullname', None)
        email = extra_attrs.get('_email', None)
        # When enabled, create missing userobj in database.
        userobj = UserObject.query.filter_by(username=username).first()
        if userobj is None and self.add_missing_user:
            try:
                # At this point, we need to create a new user in database.
                # In case default values are invalid, let evaluate them
                # before creating the user in database.
                default_user_root = self.add_user_default_userroot and self.add_user_default_userroot.format(
                    **extra_attrs
                )
                default_role = UserObject.ROLES.get(self.add_user_default_role)
                userobj = UserObject.add_user(
                    username=real_username,
                    fullname=fullname,
                    email=email,
                    role=default_role,
                    user_root=default_user_root,
                ).add()
            except Exception:
                logger.error('fail to create new user', exc_info=1)
        if userobj is None:
            # User doesn't exists in database
            return None

        # Update user attributes
        dirty = False
        if fullname:
            userobj.fullname = fullname
            dirty = True
        if email:
            userobj.email = email
            dirty = True
        if dirty:
            userobj.add()
        self.bus.publish('user_login', userobj)
        return userobj


cherrypy.login = LoginPlugin(cherrypy.engine)
cherrypy.login.subscribe()

cherrypy.config.namespaces['login'] = lambda key, value: setattr(cherrypy.login, key, value)
",CWE-613,113.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import cherrypy
from sqlalchemy import event

from ._repo import RepoObject  # noqa
from ._session import DbSession, SessionObject  # noqa
from ._sshkey import SshKey  # noqa
from ._token import Token  # noqa
from ._user import DuplicateSSHKeyError, UserObject  # noqa

Base = cherrypy.tools.db.get_base()


@event.listens_for(Base.metadata, 'after_create')
def db_after_create(target, connection, **kw):
    """"""
    Called on database creation to update database schema.
    """"""

    def exists(column):
        table_name = column.table.fullname
        column_name = column.name
        if 'SQLite' in connection.engine.dialect.__class__.__name__:
            sql = ""SELECT COUNT(*) FROM pragma_table_info('%s') WHERE LOWER(name)=LOWER('%s')"" % (
                table_name,
                column_name,
            )
        else:
            sql = ""SELECT COUNT(*) FROM information_schema.columns WHERE table_name='%s' and column_name='%s'"" % (
                table_name,
                column_name,
            )
        data = connection.engine.execute(sql).first()
        return data[0] >= 1

    def add_column(column):
        if exists(column):
            return
        table_name = column.table.fullname
        column_name = column.name
        column_type = column.type.compile(connection.engine.dialect)
        connection.engine.execute('ALTER TABLE %s ADD COLUMN %s %s' % (table_name, column_name, column_type))

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()

    # Add repo's Encoding
    add_column(RepoObject.__table__.c.Encoding)
    add_column(RepoObject.__table__.c.keepdays)

    # Create column for roles using ""isadmin"" column. Keep the
    # original column in case we need to revert to previous version.
    if not exists(UserObject.__table__.c.role):
        add_column(UserObject.__table__.c.role)
        UserObject.query.filter(UserObject._is_admin == 1).update({UserObject.role: UserObject.ADMIN_ROLE})

    # Add user's fullname column
    add_column(UserObject.__table__.c.fullname)

    # Add user's mfa column
    add_column(UserObject.__table__.c.mfa)

    # Re-create session table if Number column is missing
    if not exists(SessionObject.__table__.c.Number):
        SessionObject.__table__.drop()
        SessionObject.__table__.create()

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()
    # Remove preceding and leading slash (/) generated by previous
    # versions. Also rename '.' to ''
    result = RepoObject.query.all()
    for row in result:
        if row.repopath.startswith('/') or row.repopath.endswith('/'):
            row.repopath = row.repopath.strip('/')
            row.add()
        if row.repopath == '.':
            row.repopath = ''
            row.add()
    # Remove duplicates and nested repositories.
    result = RepoObject.query.order_by(RepoObject.userid, RepoObject.repopath).all()
    prev_repo = (None, None)
    for row in result:
        if prev_repo[0] == row.userid and (prev_repo[1] == row.repopath or row.repopath.startswith(prev_repo[1] + '/')):
            row.delete()
        else:
            prev_repo = (row.userid, row.repopath)
",CWE-613,104.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging
import threading

import cherrypy
from cherrypy.lib.sessions import Session
from sqlalchemy import Column, DateTime, Integer, PickleType, String
from sqlalchemy.orm import validates

SESSION_KEY = '_cp_username'

Base = cherrypy.tools.db.get_base()

logger = logging.getLogger(__name__)


class SessionObject(Base):
    __tablename__ = 'sessions'
    __table_args__ = {'sqlite_autoincrement': True}
    number = Column('Number', Integer, unique=True, primary_key=True)
    id = Column('SessionID', String, unique=True, nullable=False)
    username = Column('Username', String)
    data = Column('Data', PickleType)
    expiration_time = Column('ExpirationTime', DateTime, nullable=False)
    access_time = Column('AccessTime', DateTime)

    @validates('data')
    def validate_data(self, key, value):
        # Extract specific fields from data into column to speed up SQL query.
        if value:
            self.access_time = value.get('access_time')
            self.username = value.get(SESSION_KEY)
        return value


class DbSession(Session):
    def _exists(self):
        return SessionObject.query.filter(SessionObject.id == self.id).first() is not None

    def _load(self):
        session = SessionObject.query.filter(SessionObject.id == self.id).first()
        if not session:
            return None
        try:
            self.timeout = session.data.pop('_timeout', self.timeout)
            return (session.data, session.expiration_time)
        except TypeError:
            logger.error('fail to read session data', exc_info=1)
        return None

    def _save(self, expiration_time):
        session = SessionObject.query.filter(SessionObject.id == self.id).first()
        if not session:
            session = SessionObject(id=self.id)
        session.data = self._data
        session.data['_timeout'] = self.timeout
        session.expiration_time = expiration_time
        session.add()

    def _delete(self):
        SessionObject.query.filter(SessionObject.id == self.id).delete()

    def clean_up(self):
        """"""Clean up expired sessions.""""""
        try:
            now = self.now()
            SessionObject.query.filter(SessionObject.expiration_time < now).delete()
        except Exception:
            logger.error('fail to clean-up sessions', exc_info=1)
        finally:
            cherrypy.tools.db.on_end_resource()

    def __len__(self):
        """"""Return the number of active sessions.""""""
        return SessionObject.query.count()

    # http://docs.cherrypy.org/dev/refman/lib/sessions.html?highlight=session#locking-sessions
    # session id locks as done in RamSession

    locks = {}

    def acquire_lock(self):
        """"""Acquire an exclusive lock on the currently-loaded session data.""""""
        self.locked = True
        self.locks.setdefault(self.id, threading.RLock()).acquire()

    def release_lock(self):
        """"""Release the lock on the currently-loaded session data.""""""
        self.locks[self.id].release()
        self.locked = False
",CWE-613,107.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import datetime

import cherrypy
from sqlalchemy import Column, DateTime, Integer, String
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

Base = cherrypy.tools.db.get_base()


class Token(Base):
    __tablename__ = 'tokens'
    name = Column('Name', String, nullable=False, default="""", primary_key=True)
    userid = Column('UserID', Integer, nullable=False, primary_key=True)
    user = relationship(
        'UserObject',
        foreign_keys=[userid],
        primaryjoin='UserObject.userid == Token.userid',
        uselist=False,
        lazy=True,
    )
    hash_token = Column('Token', String, nullable=False, default="""")
    access_time = Column('AccessTime', DateTime, nullable=True)
    creation_time = Column('CreationTime', DateTime, nullable=False, server_default=func.now())
    expiration_time = Column('ExpirationTime', DateTime, nullable=True)

    @property
    def is_expired(self):
        return self.expiration_time is not None and self.expiration_time <= datetime.datetime.now()
",CWE-613,46.0,1
,CWE-613,,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
from unittest.mock import MagicMock

import cherrypy

import rdiffweb.test
from rdiffweb.core.model import UserObject


class LoginAbstractTest(rdiffweb.test.WebCase):
    def setUp(self):
        super().setUp()
        self.listener = MagicMock()
        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)
        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)
        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)
        cherrypy.engine.subscribe('user_login', self.listener.user_login, priority=50)
        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)

    def tearDown(self):
        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)
        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)
        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)
        cherrypy.engine.unsubscribe('user_login', self.listener.user_login)
        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)
        return super().tearDown()


class LoginTest(LoginAbstractTest):
    def test_login(self):
        # Given a valid user in database with a password
        userobj = UserObject.add_user('tom', 'password')
        # When trying to login with valid password
        login = cherrypy.engine.publish('login', 'tom', 'password')
        # Then login is successful
        self.assertEqual(login, [userobj])
        # Check if listener called
        self.listener.user_login.assert_called_once_with(userobj)

    def test_login_with_invalid_password(self):
        UserObject.add_user('jeff', 'password')
        self.assertFalse(any(cherrypy.engine.publish('login', 'jeff', 'invalid')))
        # password is case sensitive
        self.assertFalse(any(cherrypy.engine.publish('login', 'jeff', 'Password')))
        # Match entire password
        self.assertFalse(any(cherrypy.engine.publish('login', 'jeff', 'pass')))
        self.assertFalse(any(cherrypy.engine.publish('login', 'jeff', '')))
        # Check if listener called
        self.listener.user_login.assert_not_called()

    def test_login_with_invalid_user(self):
        # Given a database without users
        # When trying to login with an invalid user
        login = cherrypy.engine.publish('login', 'josh', 'password')
        # Then login is not successful
        self.assertEqual(login, [None])
        # Check if listener called
        self.listener.user_login.assert_not_called()


class LoginWithAddMissing(LoginAbstractTest):

    default_config = {'ldap-uri': '__default__', 'ldap-base-dn': 'dc=nodomain', 'ldap-add-missing-user': 'true'}

    def setUp(self):
        super().setUp()
        cherrypy.engine.subscribe('authenticate', self.listener.authenticate, priority=50)

    def tearDown(self):
        cherrypy.engine.unsubscribe('authenticate', self.listener.authenticate)
        super().tearDown()

    def test_login_with_create_user(self):
        # Given an external authentication
        self.listener.authenticate.return_value = ('tony', {})
        # Given a user doesn't exists in database
        self.assertIsNone(UserObject.get_user('tony'))
        # When login successfully with that user
        login = cherrypy.engine.publish('login', 'tony', 'password')
        self.assertIsNotNone(login)
        userobj = login[0]
        # Then user is created in database
        self.assertIsNotNone(UserObject.get_user('tony'))
        self.assertFalse(userobj.is_admin)
        self.assertEqual(UserObject.USER_ROLE, userobj.role)
        self.assertEqual('', userobj.user_root)
        self.assertEqual('', userobj.email)
        # Check listener
        self.listener.authenticate.assert_called_once_with('tony', 'password')
        self.listener.user_added.assert_called_once_with(userobj)
        self.listener.user_login.assert_called_once_with(userobj)

    def test_login_with_create_user_with_email(self):
        # Given an external authentication with email attribute
        self.listener.authenticate.return_value = ('userwithemail', {'_email': 'user@example.com'})
        # Given a user doesn't exists in database
        self.assertIsNone(UserObject.get_user('userwithemail'))
        # When login successfully with that user
        login = cherrypy.engine.publish('login', 'userwithemail', 'password')
        self.assertIsNotNone(login)
        userobj = login[0]
        # Then user is created in database
        self.assertIsNotNone(UserObject.get_user('userwithemail'))
        self.assertFalse(userobj.is_admin)
        self.assertEqual(UserObject.USER_ROLE, userobj.role)
        self.assertEqual('', userobj.user_root)
        self.assertEqual('user@example.com', userobj.email)


class LoginWithAddMissingWithDefaults(LoginAbstractTest):

    default_config = {
        'ldap-uri': '__default__',
        'ldap-base-dn': 'dc=nodomain',
        'ldap-add-missing-user': 'true',
        'ldap-add-user-default-role': 'maintainer',
        'ldap-add-user-default-userroot': '/backups/users/{uid[0]}',
    }

    def setUp(self):
        super().setUp()
        cherrypy.engine.subscribe('authenticate', self.listener.authenticate, priority=50)

    def tearDown(self):
        cherrypy.engine.unsubscribe('authenticate', self.listener.authenticate)
        super().tearDown()

    def test_login_with_create_user(self):
        # Given an external authentication with email attribute
        self.listener.authenticate.return_value = ('tony', {'uid': ['tony']})
        # Given a user doesn't exists in database
        self.assertIsNone(UserObject.get_user('tony'))
        # When login successfully with that user
        login = cherrypy.engine.publish('login', 'tony', 'password')
        self.assertIsNotNone(login)
        userobj = login[0]
        # Then user is create in database
        self.assertIsNotNone(UserObject.get_user('tony'))
        self.assertFalse(userobj.is_admin)
        self.assertEqual(UserObject.MAINTAINER_ROLE, userobj.role)
        self.assertEqual('/backups/users/tony', userobj.user_root)
        # Check listener
        self.listener.user_added.assert_called_once_with(userobj)
        self.listener.user_login.assert_called_once_with(userobj)


class LoginWithAddMissingWithComplexUserroot(LoginAbstractTest):

    default_config = {
        'ldap-uri': '__default__',
        'ldap-base-dn': 'dc=nodomain',
        'ldap-add-missing-user': 'true',
        'ldap-add-user-default-role': 'maintainer',
        'ldap-add-user-default-userroot': '/home/{sAMAccountName[0]}/backups',
    }

    def setUp(self):
        super().setUp()
        cherrypy.engine.subscribe('authenticate', self.listener.authenticate, priority=50)

    def tearDown(self):
        cherrypy.engine.unsubscribe('authenticate', self.listener.authenticate)
        super().tearDown()

    def test_login_with_create_user(self):
        # Given an external authentication with email attribute
        self.listener.authenticate.return_value = ('tony', {'sAMAccountName': ['tony']})
        # Given a user doesn't exists in database
        self.assertIsNone(UserObject.get_user('tony'))
        # When login successfully with that user
        login = cherrypy.engine.publish('login', 'tony', 'password')
        self.assertIsNotNone(login)
        userobj = login[0]
        # Then user is created in database
        self.assertIsNotNone(UserObject.get_user('tony'))
        self.assertFalse(userobj.is_admin)
        self.assertEqual(UserObject.MAINTAINER_ROLE, userobj.role)
        self.assertEqual('/home/tony/backups', userobj.user_root)
        # Check listener
        self.listener.user_added.assert_called_once_with(userobj)
        self.listener.user_login.assert_called_once_with(userobj)
",CWE-613,197.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


""""""
Created on Feb 13, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""
from unittest.mock import MagicMock

import cherrypy

import rdiffweb.core.notification
import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class NotificationJobTest(rdiffweb.test.WebCase):
    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_check_schedule(self):
        # Given the application is started
        # Then remove_older job should be schedule
        self.assertEqual(1, len([job for job in cherrypy.scheduler.list_jobs() if job.name == 'notification_job']))

    def test_notification_job(self):
        """"""
        Run the notification and check if mails are sent
        """"""
        # Given a user with an email address and a repository with a maxage
        # Set user config
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = 1
        repo.add()
        # When running notification_job
        cherrypy.notification.notification_job()

        # Then an email is queue for this user
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>testcases</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_undefined_last_backup_date(self):
        # Given a valid user with a repository configured for notification
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add()
        # Given a repo with last_backup_date None
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == 'broker-repo').first()
        repo.maxage = 1
        repo.add()
        self.assertIsNone(repo.last_backup_date)

        # When Notification job is running
        cherrypy.notification.notification_job()

        # Then a notification is sent to the user.
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>broker-repo</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_without_notification(self):
        # Given a valid user with a repository configured without notification (-1)
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = -1
        repo.add()

        # Call notification.
        cherrypy.notification.notification_job()

        # Expect it to be called.
        self.listener.queue_email.assert_not_called()


class NotificationPluginTest(rdiffweb.test.WebCase):

    default_config = {
        'email-send-changed-notification': True,
    }

    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_email_changed(self):
        # Given a user with an email address
        user = UserObject.get_user(self.USERNAME)
        user.email = 'original_email@test.com'
        user.add()
        self.listener.queue_email.reset_mock()

        # When updating the user's email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        user.add()

        # Then a email is queue to notify the user.
        self.listener.queue_email.assert_called_once_with(
            to='original_email@test.com',
            subject='Email address changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the email address associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_email_updated_with_same_value(self):
        # Given a user with an email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        self.listener.queue_email.reset_mock()

        # When updating the user's email with the same value
        user.email = 'email_changed@test.com'

        # Then no email are sent to the user
        self.listener.queue_email.assert_not_called()

    def test_password_change_notification(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        self.listener.queue_email.reset_mock()

        # When updating the user password
        user.set_password('new_password')

        # Then a email is send to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_password_change_with_same_value(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        user.set_password('new_password')
        self.listener.queue_email.reset_mock()

        # When updating the user password with the same value
        user.set_password('new_password')

        # Then an email is sent to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )
",CWE-613,185.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Dec 10, 2020

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""

from unittest import mock
from unittest.mock import MagicMock

import cherrypy

from rdiffweb import test
from rdiffweb.core.model import UserObject


class QuotaPluginTest(test.WebCase):

    default_config = {
        'quota-get-cmd': 'echo 123456',
        'quota-used-cmd': 'echo 21474836',
        'quota-set-cmd': 'echo $RDIFFWEB_QUOTA',
    }

    def test_get_disk_usage(self):
        # Given a user
        userobj = UserObject.add_user('bob')
        # When querying quota for a userobj
        result = cherrypy.engine.publish('get_disk_usage', userobj)
        # Then quota return a value
        self.assertEqual(21474836, result[0])

    def test_get_disk_quota(self):
        # Given a user
        userobj = UserObject.add_user('bob')
        # When querying quota for a userobj
        result = cherrypy.engine.publish('get_disk_quota', userobj)
        # Then quota return a value
        self.assertEqual(123456, result[0])

    def test_set_disk_quota(self):
        # Given a used cmd
        userobj = UserObject.add_user('bob')
        # When querying quota for a userobj
        results = cherrypy.engine.publish('set_disk_quota', userobj, 98765)
        # Then quota return a value
        self.assertEqual([98765], results)


class QuotaPluginTestWithFailure(test.WebCase):

    default_config = {
        'quota-get-cmd': 'exit 1',
        'quota-used-cmd': 'exit 2',
        'quota-set-cmd': 'exit 3',
    }

    def test_set_disk_quota_with_failure(self):
        # Given a user object
        userobj = UserObject.add_user('bob')
        # When settings the quota
        results = cherrypy.engine.publish('set_disk_quota', userobj, 98765)
        # Then False is returned
        self.assertEqual([False], results)


class QuotaPluginTestWithUndefinedCmd(test.WebCase):
    def test_get_disk_usage_unsupported(self):
        # Given a user object with a valid user_root
        userobj = UserObject.get_user(self.USERNAME)
        # When getting disk usage
        results = cherrypy.engine.publish('get_disk_usage', userobj)
        # Then default disk usage is return
        self.assertEqual([mock.ANY], results)

    def test_get_disk_quota_unsupported(self):
        # Given a user object
        userobj = UserObject.get_user(self.USERNAME)
        # When gettings the quota
        results = cherrypy.engine.publish('get_disk_quota', userobj)
        # Then default disk usage is return
        self.assertEqual([mock.ANY], results)

    def test_set_disk_quota_unsupported(self):
        # Given a user object
        userobj = UserObject.get_user(self.USERNAME)
        # When settings the quota
        results = cherrypy.engine.publish('set_disk_quota', userobj, 98765)
        # Then no response is returned
        self.assertEqual([], results)

    def test_get_disk_usage_with_empty_user_root(self):
        # Given a user with an empty user_root.
        userobj = UserObject.add_user('bob')
        userobj.user_root = ''
        # When getting disk usage
        results = cherrypy.engine.publish('get_disk_usage', userobj)
        # Then default disk usage is return
        self.assertEqual([0], results)

    def test_get_disk_usage_with_invalid_user_root(self):
        # Given a user with an invalid user_root.
        userobj = UserObject.add_user('bob')
        userobj.user_root = 'invalid'
        # When getting disk usage
        results = cherrypy.engine.publish('get_disk_usage', userobj)
        # Then default disk usage is return
        self.assertEqual([0], results)


class UserObjectQuotaTest(test.WebCase):
    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe(""set_disk_quota"", self.listener.set_disk_quota, priority=40)
        cherrypy.engine.subscribe(""get_disk_quota"", self.listener.get_disk_quota, priority=40)
        cherrypy.engine.subscribe(""get_disk_usage"", self.listener.get_disk_usage, priority=40)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe(""set_disk_quota"", self.listener.set_disk_quota)
        cherrypy.engine.unsubscribe(""get_disk_quota"", self.listener.get_disk_quota)
        cherrypy.engine.unsubscribe(""get_disk_usage"", self.listener.get_disk_usage)
        return super().tearDown()

    def test_get_disk_usage(self):
        # Given a mock quota
        self.listener.get_disk_usage.return_value = 12345
        # Given a user object
        userobj = UserObject.get_user(self.USERNAME)
        # When getting disk usage
        value = userobj.disk_usage
        # Then disk usage value is return
        self.assertEqual(12345, value)
        # Then listener was called
        self.listener.get_disk_usage.assert_called_once_with(userobj)

    def test_get_disk_quota(self):
        # Given a mock quota
        self.listener.get_disk_quota.return_value = 23456
        # Given a user object
        userobj = UserObject.get_user(self.USERNAME)
        # When getting disk quota
        value = userobj.disk_quota
        # Then disk quota value is return
        self.assertEqual(23456, value)
        # Then listener was called
        self.listener.get_disk_quota.assert_called_once_with(userobj)

    def test_set_disk_quota(self):
        # Given a user object
        userobj = UserObject.get_user(self.USERNAME)
        # When setting disk quota
        userobj.disk_quota = 345678
        # Then listener was called
        self.listener.set_disk_quota.assert_called_once_with(userobj, 345678)
",CWE-613,171.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import unittest

import cherrypy

from rdiffweb.core.librdiff import RdiffTime
from rdiffweb.core.model import RepoObject, UserObject
from rdiffweb.core.rdw_templating import _ParentEntry, attrib, do_format_lastupdated, list_parents, url_for
from rdiffweb.test import AppTestCase, WebCase


class TemplateManagerTest(unittest.TestCase):
    def test_attrib(self):
        # Single value
        self.assertEqual('id=""row""', attrib(id='row'))
        # Single value with quote
        self.assertEqual('id=""val&lt;ue&quot;with&quot;qu&gt;ot&amp;e""', attrib(id='val<ue""with""qu>ot&e'))
        # Multi attribute
        self.assertEqual('id=""row"" type=""table""', attrib(type='table', id='row'))
        # Attribute with list
        self.assertEqual('type=""table container""', attrib(type=['table', 'container']))
        # Attribute with class
        self.assertEqual('class=""table container""', attrib(**{'class': ['table', 'container']}))
        # Boolean expressions
        self.assertEqual('id=""active""', attrib(id=[False, 'active', False]))
        self.assertEqual('data=""coucou"" id=""active""', attrib(type=False, id=[False, 'active', False], data='coucou'))
        active = True
        self.assertEqual('id=""active""', attrib(id=[active and 'active']))
        active = False
        self.assertEqual('', attrib(id=[active and 'active']))

        # With True
        self.assertEqual('selected', attrib(selected=True))

        # Bytes
        self.assertEqual('selected=""text""', attrib(selected=b'text'))

        # Newstr
        self.assertEqual('selected=""text""', attrib(selected=str('text')))

        self.assertEqual('value=""0""', attrib(value=0))

    def test_url_for(self):
        # Check backward compatibility
        self.assertEqual(cherrypy.server.base() + '/', url_for('/'))
        self.assertEqual(cherrypy.server.base() + '/browse', url_for('browse'))
        self.assertEqual(cherrypy.server.base() + '/browse/testcases', url_for('browse', b'testcases'))
        self.assertEqual(
            cherrypy.server.base() + '/browse/testcases/Revisions', url_for('browse', b'testcases', b'Revisions')
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/testcases/Revisions?date=1454448640',
            url_for('restore', b'testcases', b'Revisions', date=1454448640),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/testcases/Revisions?date=1454448640&kind=tar.gz',
            url_for('restore', b'testcases', b'Revisions', date=1454448640, kind='tar.gz'),
        )
        self.assertEqual(
            cherrypy.server.base() + '/browse/testcases/R%C3%A9pertoire',
            url_for('browse', b'testcases', b'R\xc3\xa9pertoire'),
        )
        # Check if multi path is supported.
        self.assertEqual(cherrypy.server.base() + '/admin/logs', url_for('admin/logs'))
        self.assertEqual(cherrypy.server.base() + '/admin/logs/backup.log', url_for('admin/logs', 'backup.log'))

    def test_do_format_lastupdated(self):
        self.assertEqual('23 seconds ago', do_format_lastupdated(1591978823, now=1591978846))
        self.assertEqual('23 seconds ago', do_format_lastupdated(RdiffTime(value=1591978823), now=1591978846))
        self.assertEqual('8 minutes ago', do_format_lastupdated(RdiffTime(value=1591978324), now=1591978846))
        self.assertEqual('2 hours ago', do_format_lastupdated(RdiffTime(value=1591971646), now=1591978846))
        self.assertEqual('2 days ago', do_format_lastupdated(RdiffTime(value=1591805524), now=1591978846))
        self.assertEqual('4 weeks ago', do_format_lastupdated(RdiffTime(value=1589127124), now=1591978846))
        self.assertEqual('5 months ago', do_format_lastupdated(RdiffTime(value=1578672724), now=1591978846))
        self.assertEqual('4 years ago', do_format_lastupdated(RdiffTime(value=1452442324), now=1591978846))


class ListParentsTest(AppTestCase):
    def test_list_parents_with_root_dir(self):
        repo, path = RepoObject.get_repo_path(b'admin/testcases', as_user=UserObject.get_user('admin'))
        self.assertEqual(list_parents(repo, path), [_ParentEntry(path=b'', display_name='testcases')])

    def test_list_parents_with_root_subdir(self):
        repo, path = RepoObject.get_repo_path(b'admin/testcases/Revisions', as_user=UserObject.get_user('admin'))
        self.assertEqual(
            list_parents(repo, path),
            [
                _ParentEntry(path=b'', display_name='testcases'),
                _ParentEntry(path=b'Revisions', display_name='Revisions'),
            ],
        )


class UrlForTest(WebCase):
    @property
    def repo_obj(self):
        user = UserObject.query.filter(UserObject.username == 'admin').first()
        return RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()

    def test_url_for_absolute_path(self):
        self.assertEqual(cherrypy.server.base() + '/static/js/jquery.min.js', url_for('/static/js/jquery.min.js'))

    def test_url_for_browse(self):
        """"""Check creation of url""""""
        self.assertEqual(cherrypy.server.base() + '/browse/admin/testcases', url_for('browse', self.repo_obj))
        self.assertEqual(
            cherrypy.server.base() + '/browse/admin/testcases/Revisions', url_for('browse', self.repo_obj, b'Revisions')
        )
        self.assertEqual(
            cherrypy.server.base() + '/browse/admin/testcases/Revisions?restore=True',
            url_for('browse', self.repo_obj, b'Revisions', restore=True),
        )
        self.assertEqual(
            cherrypy.server.base()
            + '/browse/admin/testcases/R%C3%A9pertoire%20%28%40vec%29%20%7Bc%C3%A0ra%C3%A7t%23%C3%A8r%C3%AB%7D%20%24%C3%A9p%C3%AAcial',
            url_for(
                'browse',
                self.repo_obj,
                b'R\xc3\xa9pertoire (@vec) {c\xc3\xa0ra\xc3\xa7t#\xc3\xa8r\xc3\xab} $\xc3\xa9p\xc3\xaacial',
            ),
        )

    def test_url_for_graphs(self):
        self.assertEqual(
            cherrypy.server.base() + '/graphs/files/admin/testcases', url_for('graphs', 'files', self.repo_obj)
        )

    def test_url_for_history(self):
        """"""Check creation of url""""""
        self.assertEqual(cherrypy.server.base() + '/history/admin/testcases', url_for('history', self.repo_obj))

    def test_url_for_restore(self):
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021',
            url_for('restore', self.repo_obj, date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021',
            url_for('restore', self.repo_obj, b'', date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021&kind=tar.gz',
            url_for('restore', self.repo_obj, b'', date=RdiffTime(1414967021), kind='tar.gz'),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases/Revisions?date=1414967021',
            url_for('restore', self.repo_obj, b'Revisions', date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base()
            + '/restore/admin/testcases/R%C3%A9pertoire%20%28%40vec%29%20%7Bc%C3%A0ra%C3%A7t%23%C3%A8r%C3%AB%7D%20%24%C3%A9p%C3%AAcial?date=1414967021',
            url_for(
                'restore',
                self.repo_obj,
                b'R\xc3\xa9pertoire (@vec) {c\xc3\xa0ra\xc3\xa7t#\xc3\xa8r\xc3\xab} $\xc3\xa9p\xc3\xaacial',
                date=RdiffTime(1414967021),
            ),
        )

    def test_url_for_status(self):
        self.assertEqual(
            cherrypy.server.base() + '/status?date=1414967021', url_for('status', date=RdiffTime(1414967021))
        )
        self.assertEqual(
            cherrypy.server.base() + '/status/admin/testcases?date=1414967021',
            url_for('status', self.repo_obj, date=RdiffTime(1414967021)),
        )

    def test_url_for_with_none(self):
        self.assertEqual(cherrypy.server.base() + '/logs', url_for('logs', date=None))
",CWE-613,187.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 14, 2015

Mock class for testing.

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""
import json
import os
import shutil
import subprocess
import tempfile
import unittest
import unittest.mock
from threading import Thread
from urllib.parse import urlencode

import cherrypy
import pkg_resources
from cherrypy.test import helper

from rdiffweb.core.model import UserObject
from rdiffweb.rdw_app import RdiffwebApp

# For cherrypy8, we need to monkey patch Thread.isAlive
Thread.isAlive = Thread.is_alive


def create_testcases_repo(app):
    """"""Extract testcases.""""""
    # Extract 'testcases.tar.gz'
    testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable
    new = str(tempfile.mkdtemp(prefix='rdiffweb_tests_'))
    subprocess.check_call(['tar', '-zxf', testcases], cwd=new)
    return new


class AppTestCase(unittest.TestCase):

    REPO = 'testcases'

    USERNAME = 'admin'

    PASSWORD = 'admin123'

    default_config = {}

    app_class = RdiffwebApp

    @classmethod
    def setup_class(cls):
        if cls is AppTestCase:
            raise unittest.SkipTest(""%s is an abstract base class"" % cls.__name__)

    @classmethod
    def teardown_class(cls):
        pass

    def setUp(self):
        # Allow defining a custom database uri for testing.
        self.database_dir = tempfile.mkdtemp(prefix='rdiffweb_tests_db_')
        uri = os.path.join(self.database_dir, 'rdiffweb.tmp.db')
        uri = os.environ.get('RDIFFWEB_TEST_DATABASE_URI', uri)
        self.default_config['database-uri'] = uri
        cfg = self.app_class.parse_args(
            args=[], config_file_contents='\n'.join('%s=%s' % (k, v) for k, v in self.default_config.items())
        )
        # Create Application
        self.app = self.app_class(cfg)
        # Create repositories
        self.testcases = create_testcases_repo(self.app)
        # Register repository
        admin_user = UserObject.get_user(self.USERNAME)
        if admin_user:
            admin_user.user_root = self.testcases
            admin_user.refresh_repos()

    def tearDown(self):
        if hasattr(self, 'database_dir'):
            shutil.rmtree(self.database_dir)
            delattr(self, 'database_dir')
        if hasattr(self, 'testcases'):
            shutil.rmtree(self.testcases)
            delattr(self, 'testcases')


class WebCase(helper.CPWebCase):
    """"""
    Helper class for the rdiffweb test suite.
    """"""

    REPO = 'testcases'

    USERNAME = 'admin'

    PASSWORD = 'admin123'

    interactive = False

    login = False

    default_config = {}

    app_class = RdiffwebApp

    @classmethod
    def setup_class(cls):
        if cls is WebCase:
            raise unittest.SkipTest(""%s is an abstract base class"" % cls.__name__)
        super().setup_class()
        cls.do_gc_test = False

    @classmethod
    def teardown_class(cls):
        super().teardown_class()

    @classmethod
    def setup_server(cls):
        # Allow defining a custom database uri for testing.
        uri = os.environ.get(
            'RDIFFWEB_TEST_DATABASE_URI', 'sqlite:///' + tempfile.gettempdir() + '/test_rdiffweb_data.db'
        )
        cls.default_config['database-uri'] = uri
        # Disable rate-limit for testing.
        if 'rate-limit' not in cls.default_config:
            cls.default_config['rate-limit'] = -1
        cfg = cls.app_class.parse_args(
            args=[], config_file_contents='\n'.join('%s=%s' % (k, v) for k, v in cls.default_config.items())
        )
        # Create Application
        app = cls.app_class(cfg)
        cherrypy.tree.mount(app)

    def setUp(self):
        helper.CPWebCase.setUp(self)
        cherrypy.tools.db.drop_all()
        cherrypy.tools.db.create_all()
        # Create default admin
        UserObject.create_admin_user(self.USERNAME, self.PASSWORD)
        # Create testcases repo
        self.testcases = create_testcases_repo(self.app)
        admin_user = UserObject.get_user(self.USERNAME)
        if admin_user:
            admin_user.user_root = self.testcases
            admin_user.refresh_repos()
        # Login to web application.
        if self.login:
            self._login()

    def tearDown(self):
        if hasattr(self, 'testcases'):
            shutil.rmtree(self.testcases)
            delattr(self, 'testcases')

    @property
    def app(self):
        """"""
        Return reference to Rdiffweb application.
        """"""
        return cherrypy.tree.apps['']

    @property
    def session(self):
        return cherrypy.tools.db.get_session()

    @property
    def session_id(self):
        if hasattr(self, 'cookies') and self.cookies:
            for unused, value in self.cookies:
                for part in value.split(';'):
                    key, unused, value = part.partition('=')
                    if key == 'session_id':
                        return value

    @property
    def baseurl(self):
        return 'http://%s:%s' % (self.HOST, self.PORT)

    def getPage(self, url, headers=None, method=""GET"", body=None, protocol=None):
        if headers is None:
            headers = []
        # When body is a dict, send the data as form data.
        if isinstance(body, dict) and method in ['POST', 'PUT']:
            data = [(k.encode(encoding='latin1'), v.encode(encoding='utf-8')) for k, v in body.items()]
            body = urlencode(data)
        # Send back cookies if any
        if hasattr(self, 'cookies') and self.cookies:
            headers.extend(self.cookies)
        # CherryPy ~8.9.1 is not handling absolute URL properly and web browser
        # are usually not sending absolute URL either. So trim the base.
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        if url.startswith(base):
            url = url[len(base) :]
        helper.CPWebCase.getPage(self, url, headers, method, body, protocol)

    def getJson(self, *args, **kwargs):
        self.getPage(*args, **kwargs)
        self.assertStatus(200)
        return json.loads(self.body.decode('utf8'))

    def _login(self, username=USERNAME, password=PASSWORD):
        self.getPage(""/logout"")
        self.getPage(""/login/"", method='POST', body={'login': username, 'password': password})
        self.assertStatus('303 See Other')
",CWE-613,221.0,1
"# -*- coding: utf-8 -*-
# udb, A web interface to manage IT network
# Copyright (C) 2022 IKUS Software inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
'''
SQLAlchemy Tool for CherryPy.
'''
import logging

import cherrypy
from sqlalchemy import create_engine, event
from sqlalchemy.engine import Engine
from sqlalchemy.ext.declarative import DeclarativeMeta, declarative_base
from sqlalchemy.orm import scoped_session, sessionmaker

logger = logging.getLogger(__name__)


@event.listens_for(Engine, 'connect')
def _set_sqlite_journal_mode_wal(connection, connection_record):
    """"""
    Enable WAL journaling for concurrent read and write operation.
    """"""
    if 'sqlite3' in str(connection.__class__):
        cursor = connection.cursor()
        cursor.execute('PRAGMA journal_mode=WAL;')
        cursor.close()


class Base:
    '''
    Extends declarative base to provide convenience methods to models similar to
    functionality found in Elixir. Works in python3.

    For example, given the model User:
    # no need to write init methods for models, simply pass keyword arguments or
    # override if needed.
    User(name=""daniel"", email=""daniel@dasa.cc"").add()
    User.query # returns session.query(User)
    User.query.all() # instead of session.query(User).all()
    changed = User.from_dict({}) # update record based on dict argument passed in and returns any keys changed
    '''

    def add(self, commit=True):
        """"""
        Add current object to session.
        """"""
        self.__class__.session.add(self)
        if commit:
            self.__class__.session.commit()
        return self

    def delete(self, commit=True):
        """"""
        Delete current object to session.
        """"""
        self.__class__.session.delete(self)
        if commit:
            self.__class__.session.commit()
        return self

    def merge(self, commit=True):
        """"""
        Merge current object to session.
        """"""
        self.__class__.session.merge(self)
        if commit:
            self.__class__.session.commit()
        return self

    def expire(self):
        self.__class__.session.expire(self)


class BaseExtensions(DeclarativeMeta):
    @property
    def query(self):
        return self.session.query(self)

    @property
    def session(self):
        return cherrypy.tools.db.get_session()


class SQLA(cherrypy.Tool):
    _name = 'sqla'
    _base = None
    _session = None

    def __init__(self, **kw):
        cherrypy.Tool.__init__(self, None, None, priority=20)

    def _setup(self):
        cherrypy.request.hooks.attach('on_end_resource', self.on_end_resource)

    def create_all(self):
        # Release opened sessions.
        self.on_end_resource()
        # Create new metadata binding
        base = self.get_base()
        if base.metadata.bind is None:
            dburi = cherrypy.config.get('tools.db.uri')
            debug = cherrypy.config.get('tools.db.debug')
            base.metadata.bind = create_engine(dburi)
            if debug:
                logging.getLogger('sqlalchemy.engine').setLevel(logging.DEBUG)
        base.metadata.create_all()

    def drop_all(self):
        # Release opened sessions.
        self.on_end_resource()
        # Drop all
        base = self.get_base()
        base.metadata.drop_all()

    def get_base(self):
        if self._base is None:
            self._base = declarative_base(metaclass=BaseExtensions, cls=Base)
        return self._base

    def get_session(self):
        if self._session is None:
            self._session = scoped_session(sessionmaker(autoflush=False, autocommit=False))
            self._session.bind = self.get_base().metadata.bind
        return self._session

    def on_end_resource(self):
        if self._session is None:
            return
        try:
            self._session.flush()
            self._session.commit()
        except Exception:
            logger.exception('error trying to flush and commit session')
            self._session.rollback()
            self._session.expunge_all()
        finally:
            self._session.remove()


cherrypy.tools.db = SQLA()
",CWE-613,154.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Mar 13, 2019

@author: Patrik Dufresne
""""""

import datetime

from parameterized import parameterized, parameterized_class

import rdiffweb.test
from rdiffweb.core.model import DbSession, SessionObject


class ControllerTest(rdiffweb.test.WebCase):

    login = True

    default_config = {'HeaderName': 'MyTest'}

    def test_headername(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"")
        self.assertStatus('200 OK')
        self.assertInBody('MyTest')

    def test_proxy(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"", headers=[('Host', 'this.is.a.test.com')])
        self.assertStatus('200 OK')
        self.assertInBody('http://this.is.a.test.com/favicon.ico')

    def test_proxy_https(self):
        """"""
        Check if the headername is used in the page.
        """"""
        self.getPage(""/"", headers=[('Host', 'this.is.a.test.com'), ('X-Forwarded-Proto', 'https')])
        self.assertStatus('200 OK')
        self.assertInBody('https://this.is.a.test.com/favicon.ico')

    @parameterized.expand(
        [
            '/favicon.ico',
            '/default.css',
            '/logo',
            '/header_logo',
            '/static/css/bootstrap.min.css',
            '/static/css/font-awesome.min.css',
            '/static/css/jquery.dataTables.min.css',
            '/static/js/bootstrap.bundle.min.js',
            '/static/js/jquery.dataTables.min.js',
            '/static/js/jquery.min.js',
            '/static/js/rdiffweb.js',
        ]
    )
    def test_static_files(self, path):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage('/logout')
        self.getPage(path)
        self.assertStatus(200)
        # Test with invalid method.
        self.getPage(path, method=""POST"")
        self.assertStatus(400)

    def test_static_invalid_file(self):
        """"""
        Check if the theme is properly configure.
        """"""
        self.getPage(""/static/invalid.css"")
        self.assertStatus(400)

    def test_path_traversal(self):
        self.getPage('/static//../../test.txt')
        self.assertStatus(403)


@parameterized_class(
    [
        {""default_config"": {'DefaultTheme': 'default'}, ""expect_color"": '#35979c'},
        {""default_config"": {'DefaultTheme': 'orange'}, ""expect_color"": '#dd4814'},
        {""default_config"": {'DefaultTheme': 'blue'}, ""expect_color"": '#153a58'},
        {""default_config"": {'link-color': '111'}, ""expect_color"": '#111'},
        {""default_config"": {'navbar-color': '222'}, ""expect_color"": '#222'},
        {""default_config"": {'font-family': 'Sans'}, ""expect_color"": 'Sans'},
    ]
)
class ControllerThemeTest(rdiffweb.test.WebCase):

    default_config = {}

    expect_color = ''

    def test_static(self):
        # Query css with uniq value to avoid caching.
        self.getPage(""/default.css"")
        self.assertStatus('200 OK')
        self.assertInBody(self.expect_color)


class ControllerSession(rdiffweb.test.WebCase):
    def test_enrich_session_anonymous(self):
        # When making a query to a page while unauthenticated
        self.getPage('/', headers=[('User-Agent', 'test')])
        # Then a session object is enriched
        self.assertEqual(1, SessionObject.query.filter(SessionObject.id == self.session_id).count())
        SessionObject.query.filter(SessionObject.id == self.session_id).first()
        session = DbSession(id=self.session_id)
        session.load()
        self.assertIsNotNone(session.get('ip_address'))
        self.assertIsNotNone(session.get('user_agent'))
        self.assertIsNotNone(session.get('access_time'))

    def test_enrich_session_authenticated(self):
        # When making a query to a page while unauthenticated
        self.getPage(
            '/login/',
            method='POST',
            headers=[('User-Agent', 'test')],
            body={'login': self.USERNAME, 'password': self.PASSWORD},
        )
        # Then a session object is enriched
        self.assertEqual(1, SessionObject.query.filter(SessionObject.id == self.session_id).count())
        SessionObject.query.filter(SessionObject.id == self.session_id).first()
        session = DbSession(id=self.session_id)
        session.load()
        self.assertIsNotNone(session.get('ip_address'))
        self.assertIsNotNone(session.get('user_agent'))
        self.assertIsNotNone(session.get('access_time'))

    def test_create_session(self):
        # Given a server with no session.
        self.assertEqual(0, len(SessionObject.query.all()))
        # When querying a new page
        self.getPage('/')
        self.assertStatus(303)
        # Then a new session get created
        self.assertEqual(1, len(SessionObject.query.all()))
        session = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        self.assertIsNotNone(session)

    def test_clean_up_session(self):
        # Given a server with a session
        self.getPage('/')
        self.assertStatus(303)
        self.assertEqual(1, len(SessionObject.query.all()))
        # When this session get old
        data = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        data.expiration_time = datetime.datetime.now() - datetime.timedelta(seconds=1)
        data.commit()
        session = DbSession(id=self.session_id)
        # Then the session get deleted by clean_up process
        session.clean_up()
        # Then session is deleted
        data = SessionObject.query.filter(SessionObject.id == self.session_id).first()
        self.assertIsNone(data)
",CWE-352,178.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 20, 2021

@author: Patrik Dufresne
""""""
from parameterized import parameterized

import rdiffweb.test


class SecureHeadersTest(rdiffweb.test.WebCase):

    login = True

    def test_cookie_samesite_lax(self):
        # Given a request made to rdiffweb
        # When receiving the response
        self.getPage('/')
        # Then the header contains Set-Cookie with SameSite=Lax
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('SameSite=Lax', cookie)

    def test_cookie_samesite_lax_without_session(self):
        # Given not a client sending no cookie
        self.cookies = None
        # When a query is made to a static path (without session)
        self.getPage('/static/blue.css')
        # Then Set-Cookie is not defined.
        self.assertNoHeader('Set-Cookie')

    def test_cookie_with_https(self):
        # Given an https request made to rdiffweb
        self.getPage('/', headers=[('X-Forwarded-Proto', 'https')])
        # When receiving the response
        self.assertStatus(200)
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('Secure', cookie)

    @parameterized.expand(
        [
            ('/invalid', 404),
            ('/browse/invalid', 404),
            ('/login', 301),
            ('/logout', 303),
        ]
    )
    def test_cookie_with_https_http_error(self, url, expected_error_code):
        # Given an https request made to rdiffweb
        self.getPage(url, headers=[('X-Forwarded-Proto', 'https')])
        # When receiving the response
        self.assertStatus(expected_error_code)
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertIn('Secure', cookie)

    def test_cookie_with_http(self):
        # Given an https request made to rdiffweb
        self.getPage('/')
        # When receiving the response
        # Then the header contains Set-Cookie with Secure
        cookie = self.assertHeader('Set-Cookie')
        self.assertNotIn('Secure', cookie)

    def test_get_with_wrong_origin(self):
        # Given a GET request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')])
        # Then the response status it 200 OK.
        self.assertStatus(200)

    def test_post_with_wrong_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        self.getPage('/', headers=[('Origin', 'http://www.examples.com')], method='POST')
        # Then the request is refused with 403 Forbiden
        self.assertStatus(403)
        self.assertInBody('Unexpected Origin header')

    def test_post_with_prefixed_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        base = 'http://%s:%s' % (self.HOST + 'anything.com', self.PORT)
        self.getPage('/dashboard/', headers=[('Origin', base)], method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(403)
        self.assertInBody('Unexpected Origin header')

    def test_post_with_valid_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made using a different origin
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        self.getPage('/', headers=[('Origin', base)], method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_post_without_origin(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', method='POST')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)

    def test_clickjacking_defense(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-Frame-Options', 'DENY')

    def test_no_cache(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Cache-control', 'no-cache')
        self.assertHeaderItemValue('Cache-control', 'no-store')
        self.assertHeaderItemValue('Cache-control', 'must-revalidate')
        self.assertHeaderItemValue('Cache-control', 'max-age=0')
        self.assertHeaderItemValue('Pragma', 'no-cache')
        self.assertHeaderItemValue('Expires', '0')

    def test_no_cache_with_static(self):
        self.getPage('/static/js/rdiffweb.js')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertNoHeader('Cache-control')
        self.assertNoHeader('Pragma')
        self.assertNoHeader('Expires')

    def test_referrer_policy(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Referrer-Policy', 'same-origin')

    def test_nosniff(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-Content-Type-Options', 'nosniff')

    def test_xss_protection(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('X-XSS-Protection', '1; mode=block')

    def test_content_security_policy(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/')
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue(
            'Content-Security-Policy',
            ""default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'"",
        )

    def test_strict_transport_security(self):
        # Given a POST request made to rdiffweb
        # When the request is made without an origin
        self.getPage('/', headers=[('X-Forwarded-Proto', 'https')])
        # Then the request is accepted with 200 OK
        self.assertStatus(200)
        self.assertHeaderItemValue('Strict-Transport-Security', 'max-age=31536000; includeSubDomains')
",CWE-352,191.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Created on Oct 14, 2015

Mock class for testing.

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""
import json
import os
import shutil
import subprocess
import tempfile
import time
import unittest
import unittest.mock
from threading import Thread
from urllib.parse import urlencode

import cherrypy
import pkg_resources
from cherrypy.test import helper

from rdiffweb.core.model import UserObject
from rdiffweb.rdw_app import RdiffwebApp

# For cherrypy8, we need to monkey patch Thread.isAlive
Thread.isAlive = Thread.is_alive


def create_testcases_repo(app):
    """"""Extract testcases.""""""
    # Extract 'testcases.tar.gz'
    testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable
    new = str(tempfile.mkdtemp(prefix='rdiffweb_tests_'))
    subprocess.check_call(['tar', '-zxf', testcases], cwd=new)
    return new


class WebCase(helper.CPWebCase):
    """"""
    Helper class for the rdiffweb test suite.
    """"""

    REPO = 'testcases'

    USERNAME = 'admin'

    PASSWORD = 'admin123'

    interactive = False

    login = False

    default_config = {}

    app_class = RdiffwebApp

    @classmethod
    def setup_class(cls):
        if cls is WebCase:
            raise unittest.SkipTest(""%s is an abstract base class"" % cls.__name__)
        super().setup_class()
        cls.do_gc_test = False

    @classmethod
    def teardown_class(cls):
        super().teardown_class()
        cherrypy.tools.db.drop_all()
        if hasattr(cherrypy, '_cache'):
            cherrypy._cache.clear()

    @classmethod
    def setup_server(cls):
        # Allow defining a custom database uri for testing.
        uri = os.environ.get(
            'RDIFFWEB_TEST_DATABASE_URI', 'sqlite:///' + tempfile.gettempdir() + '/test_rdiffweb_data.db'
        )
        cls.default_config['database-uri'] = uri
        # Disable rate-limit for testing.
        if 'rate-limit' not in cls.default_config:
            cls.default_config['rate-limit'] = -1
        cfg = cls.app_class.parse_args(
            args=[], config_file_contents='\n'.join('%s=%s' % (k, v) for k, v in cls.default_config.items())
        )
        # Create Application
        app = cls.app_class(cfg)
        cherrypy.tree.mount(app)

    def setUp(self):
        helper.CPWebCase.setUp(self)
        if hasattr(cherrypy, '_cache'):
            cherrypy._cache.clear()
        cherrypy.tools.db.drop_all()
        cherrypy.tools.db.create_all()
        # Create default admin
        admin_user = UserObject.create_admin_user(self.USERNAME, self.PASSWORD)
        admin_user.commit()
        # Create testcases repo
        self.testcases = create_testcases_repo(self.app)
        if admin_user:
            admin_user.user_root = self.testcases
            admin_user.refresh_repos()
            admin_user.commit()
        # Login to web application.
        if self.login:
            self._login()

    def tearDown(self):
        if hasattr(self, 'testcases'):
            shutil.rmtree(self.testcases)
            delattr(self, 'testcases')
        cherrypy.tools.db.drop_all()
        if hasattr(cherrypy, '_cache'):
            cherrypy._cache.clear()

    @property
    def app(self):
        """"""
        Return reference to Rdiffweb application.
        """"""
        return cherrypy.tree.apps['']

    @property
    def session(self):
        return cherrypy.tools.db.get_session()

    @property
    def session_id(self):
        if hasattr(self, 'cookies') and self.cookies:
            for unused, value in self.cookies:
                for part in value.split(';'):
                    key, unused, value = part.partition('=')
                    if key == 'session_id':
                        return value

    @property
    def baseurl(self):
        return 'http://%s:%s' % (self.HOST, self.PORT)

    def getPage(self, url, headers=None, method=""GET"", body=None, protocol=None):
        if headers is None:
            headers = []
        # When body is a dict, send the data as form data.
        if isinstance(body, dict) and method in ['POST', 'PUT']:
            data = [(k.encode(encoding='latin1'), v.encode(encoding='utf-8')) for k, v in body.items()]
            body = urlencode(data)
        # Send back cookies if any
        if hasattr(self, 'cookies') and self.cookies:
            headers.extend(self.cookies)
        # CherryPy ~8.9.1 is not handling absolute URL properly and web browser
        # are usually not sending absolute URL either. So trim the base.
        base = 'http://%s:%s' % (self.HOST, self.PORT)
        if url.startswith(base):
            url = url[len(base) :]
        helper.CPWebCase.getPage(self, url, headers, method, body, protocol)

    def getJson(self, *args, **kwargs):
        self.getPage(*args, **kwargs)
        self.assertStatus(200)
        return json.loads(self.body.decode('utf8'))

    def _login(self, username=USERNAME, password=PASSWORD):
        self.getPage(""/logout"")
        self.getPage(""/login/"", method='POST', body={'login': username, 'password': password})
        self.assertStatus('303 See Other')

    def wait_for_tasks(self):
        time.sleep(1)
        while len(cherrypy.scheduler.list_tasks()) or cherrypy.scheduler.is_job_running():
            time.sleep(1)
",CWE-352,187.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import datetime
import time
import urllib.parse

import cherrypy
from cherrypy.lib import httputil

SESSION_KEY = '_cp_username'
LOGIN_TIME = 'login_time'
LOGIN_REDIRECT_URL = '_auth_form_redirect_url'
LOGIN_PERSISTENT = 'login_persistent'


class CheckAuthForm(cherrypy.Tool):
    def __init__(self, priority=73):
        super().__init__(point='before_handler', callable=self.run, priority=priority)

    def _is_login(self):
        """"""
        Verify if the login expired and we need to prompt the user to authenticated again using either credentials and/or MFA.
        """"""
        # Verify if current user exists
        request = cherrypy.serving.request
        if not getattr(request, 'currentuser', None):
            return False

        # Verify if session is enabled
        sessions_on = request.config.get('tools.sessions.on', False)
        if not sessions_on:
            return False

        # Verify session
        # We don't need to verify the timeout value since expired session get deleted automatically.
        session = cherrypy.session
        return session.get(SESSION_KEY) is not None and session.get(LOGIN_TIME) is not None

    def _get_redirect_url(self):
        """"""
        Return the original URL the user browser before getting redirect to login.
        """"""
        return cherrypy.session.get(LOGIN_REDIRECT_URL) or '/'

    def _set_redirect_url(self):
        # Keep reference to the current URL
        request = cherrypy.serving.request
        uri_encoding = getattr(request, 'uri_encoding', 'utf-8')
        original_url = urllib.parse.quote(request.path_info, encoding=uri_encoding)
        qs = request.query_string
        new_url = cherrypy.url(original_url, qs=qs, base='')
        cherrypy.session[LOGIN_REDIRECT_URL] = new_url

    def _update_session_timeout(self, persistent_timeout=43200, absolute_timeout=30):
        """"""
        Since we have multiple timeout value (idle, absolute and persistent) We need to update the session timeout and possibly the cookie timeout.
        """"""
        persistent_timeout = cherrypy.request.config.get('tools.auth_form.persistent_timeout', 43200)
        absolute_timeout = cherrypy.request.config.get('tools.auth_form.absolute_timeout', 30)
        # If login is persistent, update the cookie max-age/expires
        session = cherrypy.session
        if session.get(LOGIN_PERSISTENT, False):
            expiration = session[LOGIN_TIME] + datetime.timedelta(minutes=persistent_timeout)
            session.timeout = int((expiration - session.now()).total_seconds() / 60)
            cookie = cherrypy.serving.response.cookie
            cookie['session_id']['max-age'] = session.timeout * 60
            cookie['session_id']['expires'] = httputil.HTTPDate(time.time() + session.timeout * 60)
        else:
            session_idle_timeout = cherrypy.request.config.get('tools.sessions.timeout', 60)
            expiration1 = session.now() + datetime.timedelta(minutes=session_idle_timeout)
            expiration2 = session[LOGIN_TIME] + datetime.timedelta(minutes=absolute_timeout)
            expiration = min(expiration1, expiration2)
            session.timeout = int((expiration - session.now()).total_seconds() / 60)

    def redirect_to_original_url(self):
        # Redirect user to original URL
        raise cherrypy.HTTPRedirect(self._get_redirect_url())

    def run(self, login_url='/login/', logout_url='/logout', persistent_timeout=43200, absolute_timeout=30):
        """"""
        A tool that verify if the session is associated to a user by tracking
        a session key. If session is not authenticated, redirect user to login page.
        """"""
        request = cherrypy.serving.request
        # Skip execution of this tools when browsing the login page.
        if request.path_info == login_url:
            if self._is_login():
                raise cherrypy.HTTPRedirect('/')
            return

        # Clear session when browsing /logout
        if request.path_info == logout_url or request.path_info.startswith(logout_url):
            self.logout()
            raise cherrypy.HTTPRedirect('/')

        # Check if login
        if not self._is_login():
            # Store original URL
            self._set_redirect_url()
            # And redirect to login page
            raise cherrypy.HTTPRedirect(login_url)

        self._update_session_timeout()

    def login(self, username, persistent=False):
        """"""
        Must be called by the page hanlder when the authentication is successful.
        """"""
        # Store session data
        cherrypy.session[LOGIN_PERSISTENT] = persistent
        cherrypy.session[SESSION_KEY] = username
        cherrypy.session[LOGIN_TIME] = cherrypy.session.now()
        # Generate a new session id
        cherrypy.session.regenerate()
        # Update the session timeout
        self._update_session_timeout()

    def logout(self):
        # Clear session date and generate a new session id
        cherrypy.session.clear()
        cherrypy.session.regenerate()


cherrypy.tools.auth_form = CheckAuthForm()
",CWE-352,139.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugin used to send email to users when their repository is getting too old.
User can control the notification period.
""""""

import datetime
import logging

import cherrypy
from cherrypy.process.plugins import SimplePlugin

from rdiffweb.core import librdiff
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import ugettext as _

logger = logging.getLogger(__name__)


class NotificationPlugin(SimplePlugin):
    """"""
    Send email notification when a repository get too old (without a backup).
    """"""

    execution_time = '23:00'

    send_changed = False

    def start(self):
        self.bus.log('Start Notification plugin')
        self.bus.publish('schedule_job', self.execution_time, self.notification_job)
        self.bus.subscribe('access_token_added', self.access_token_added)
        self.bus.subscribe('user_attr_changed', self.user_attr_changed)
        self.bus.subscribe('user_password_changed', self.user_password_changed)

    start.priority = 55

    def stop(self):
        self.bus.log('Stop Notification plugin')
        self.bus.publish('unschedule_job', self.notification_job)
        self.bus.unsubscribe('access_token_added', self.access_token_added)
        self.bus.unsubscribe('user_attr_changed', self.user_attr_changed)
        self.bus.unsubscribe('user_password_changed', self.user_password_changed)

    stop.priority = 45

    @property
    def app(self):
        return cherrypy.tree.apps['']

    def access_token_added(self, userobj, name):
        if not self.send_changed:
            return

        if not userobj.email:
            logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
            return

        # Send a mail notification
        body = self.app.templates.compile_template(
            ""access_token_added.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj, 'name': name}
        )
        self.bus.publish('queue_mail', to=userobj.email, subject=_(""A new access token has been created""), message=body)

    def user_attr_changed(self, userobj, attrs={}):
        if not self.send_changed:
            return

        # Leave if the mail was not changed.
        if 'email' in attrs:
            old_email = attrs['email'][0]
            if not old_email:
                logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
                return
            # If the email attributes was changed, send a mail notification.
            subject = _(""Email address changed"")
            body = self.app.templates.compile_template(
                ""email_changed.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
            )
            self.bus.publish('queue_mail', to=old_email, subject=str(subject), message=body)

        if 'mfa' in attrs:
            if not userobj.email:
                logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
                return
            subject = (
                _(""Two-Factor Authentication turned off"")
                if userobj.mfa == UserObject.DISABLED_MFA
                else _(""Two-Factor Authentication turned on"")
            )
            body = self.app.templates.compile_template(
                ""email_mfa.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
            )
            self.bus.publish('queue_mail', to=userobj.email, subject=str(subject), message=body)

    def user_password_changed(self, userobj):
        if not self.send_changed:
            return

        if not userobj.email:
            logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
            return

        # If the email attributes was changed, send a mail notification.
        body = self.app.templates.compile_template(
            ""password_changed.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
        )
        self.bus.publish('queue_mail', to=userobj.email, subject=_(""Password changed""), message=body)

    def notification_job(self):
        """"""
        Loop trough all the user repository and send notifications.
        """"""

        now = librdiff.RdiffTime()

        def _user_repos():
            """"""Return a generator trought user repos to be notified.""""""
            for user in UserObject.query.all():
                # Check if user has email.
                if not user.email:
                    continue
                # Identify old repo for current user.
                old_repos = []
                for repo in user.repo_objs:
                    # Check if repo has age configured (in days)
                    maxage = repo.maxage
                    if not maxage or maxage <= 0:
                        continue
                    # Check repo age.
                    if repo.last_backup_date is None or repo.last_backup_date < (now - datetime.timedelta(days=maxage)):
                        old_repos.append(repo)
                # Return an item only if user had old repo
                if old_repos:
                    yield user, old_repos

        # For each candidate, send mail.
        for user, repos in _user_repos():
            parms = {'user': user, 'repos': repos}
            body = self.app.templates.compile_template(""email_notification.html"", **parms)
            cherrypy.engine.publish('queue_mail', to=user.email, subject=_(""Notification""), message=body)


cherrypy.notification = NotificationPlugin(cherrypy.engine)
cherrypy.notification.subscribe()

cherrypy.config.namespaces['notification'] = lambda key, value: setattr(cherrypy.notification, key, value)
",CWE-601,163.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugin used to send email to users when their repository is getting too old.
User can control the notification period.
""""""

import datetime
import logging

import cherrypy
from cherrypy.process.plugins import SimplePlugin

from rdiffweb.core import librdiff
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import ugettext as _

logger = logging.getLogger(__name__)


class NotificationPlugin(SimplePlugin):
    """"""
    Send email notification when a repository get too old (without a backup).
    """"""

    execution_time = '23:00'

    send_changed = False

    def start(self):
        self.bus.log('Start Notification plugin')
        self.bus.publish('schedule_job', self.execution_time, self.notification_job)
        self.bus.subscribe('access_token_added', self.access_token_added)
        self.bus.subscribe('user_attr_changed', self.user_attr_changed)
        self.bus.subscribe('user_password_changed', self.user_password_changed)

    start.priority = 55

    def stop(self):
        self.bus.log('Stop Notification plugin')
        self.bus.publish('unschedule_job', self.notification_job)
        self.bus.unsubscribe('access_token_added', self.access_token_added)
        self.bus.unsubscribe('user_attr_changed', self.user_attr_changed)
        self.bus.unsubscribe('user_password_changed', self.user_password_changed)

    stop.priority = 45

    @property
    def app(self):
        return cherrypy.tree.apps['']

    def access_token_added(self, userobj, name):
        if not self.send_changed:
            return

        if not userobj.email:
            logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
            return

        # Send a mail notification
        body = self.app.templates.compile_template(
            ""access_token_added.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj, 'name': name}
        )
        self.bus.publish('queue_mail', to=userobj.email, subject=_(""A new access token has been created""), message=body)

    def user_attr_changed(self, userobj, attrs={}):
        if not self.send_changed:
            return

        # Leave if the mail was not changed.
        if 'email' in attrs:
            old_email = attrs['email'][0]
            if not old_email:
                logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
                return
            # If the email attributes was changed, send a mail notification.
            subject = _(""Email address changed"")
            body = self.app.templates.compile_template(
                ""email_changed.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
            )
            self.bus.publish('queue_mail', to=old_email, subject=str(subject), message=body)

        if 'mfa' in attrs:
            if not userobj.email:
                logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
                return
            subject = (
                _(""Two-Factor Authentication turned off"")
                if userobj.mfa == UserObject.DISABLED_MFA
                else _(""Two-Factor Authentication turned on"")
            )
            body = self.app.templates.compile_template(
                ""email_mfa.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
            )
            self.bus.publish('queue_mail', to=userobj.email, subject=str(subject), message=body)

    def user_password_changed(self, userobj):
        if not self.send_changed:
            return

        if not userobj.email:
            logger.info(""can't sent mail to user [%s] without an email"", userobj.username)
            return

        # If the email attributes was changed, send a mail notification.
        body = self.app.templates.compile_template(
            ""password_changed.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj}
        )
        self.bus.publish('queue_mail', to=userobj.email, subject=_(""Password changed""), message=body)

    def notification_job(self):
        """"""
        Loop trough all the user repository and send notifications.
        """"""

        now = librdiff.RdiffTime()

        def _user_repos():
            """"""Return a generator trought user repos to be notified.""""""
            for user in UserObject.query.all():
                # Check if user has email.
                if not user.email:
                    continue
                # Identify old repo for current user.
                old_repos = []
                for repo in user.repo_objs:
                    # Check if repo has age configured (in days)
                    maxage = repo.maxage
                    if not maxage or maxage <= 0:
                        continue
                    # Check repo age.
                    if repo.last_backup_date is None or repo.last_backup_date < (now - datetime.timedelta(days=maxage)):
                        old_repos.append(repo)
                # Return an item only if user had old repo
                if old_repos:
                    yield user, old_repos

        # For each candidate, send mail.
        for user, repos in _user_repos():
            parms = {'user': user, 'repos': repos}
            body = self.app.templates.compile_template(""email_notification.html"", **parms)
            cherrypy.engine.publish('queue_mail', to=user.email, subject=_(""Notification""), message=body)


cherrypy.notification = NotificationPlugin(cherrypy.engine)
cherrypy.notification.subscribe()

cherrypy.config.namespaces['notification'] = lambda key, value: setattr(cherrypy.notification, key, value)
",CWE-75,163.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


""""""
Created on Feb 13, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""
from unittest.mock import MagicMock

import cherrypy

import rdiffweb.core.notification
import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class NotificationJobTest(rdiffweb.test.WebCase):
    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_check_schedule(self):
        # Given the application is started
        # Then remove_older job should be schedule
        self.assertEqual(1, len([job for job in cherrypy.scheduler.list_jobs() if job.name == 'notification_job']))

    def test_notification_job(self):
        """"""
        Run the notification and check if mails are sent
        """"""
        # Given a user with an email address and a repository with a maxage
        # Set user config
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.commit()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = 1
        repo.commit()
        # When running notification_job
        cherrypy.notification.notification_job()

        # Then an email is queue for this user
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>testcases</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_undefined_last_backup_date(self):
        # Given a valid user with a repository configured for notification
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add().commit()
        # Given a repo with last_backup_date None
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == 'broker-repo').first()
        repo.maxage = 1
        repo.add().commit()
        self.assertIsNone(repo.last_backup_date)

        # When Notification job is running
        cherrypy.notification.notification_job()

        # Then a notification is sent to the user.
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>broker-repo</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_without_notification(self):
        # Given a valid user with a repository configured without notification (-1)
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add().commit()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = -1
        repo.add().commit()

        # Call notification.
        cherrypy.notification.notification_job()

        # Expect it to be called.
        self.listener.queue_email.assert_not_called()


class NotificationPluginTest(rdiffweb.test.WebCase):

    default_config = {
        'email-send-changed-notification': True,
    }

    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_email_changed(self):
        # Given a user with an email address
        user = UserObject.get_user(self.USERNAME)
        user.email = 'original_email@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user's email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        user.add().commit()

        # Then a email is queue to notify the user.
        self.listener.queue_email.assert_called_once_with(
            to='original_email@test.com',
            subject='Email address changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the email address associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_email_updated_with_same_value(self):
        # Given a user with an email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user's email with the same value
        user.email = 'email_changed@test.com'
        user.add().commit()

        # Then no email are sent to the user
        self.listener.queue_email.assert_not_called()

    def test_password_change_notification(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user password
        user.set_password('new_password')
        user.add().commit()

        # Then a email is send to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_password_change_with_same_value(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        user.set_password('new_password')
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user password with the same value
        user.set_password('new_password')
        user.add().commit()

        # Then an email is sent to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )
",CWE-601,191.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


""""""
Created on Feb 13, 2016

@author: Patrik Dufresne <patrik@ikus-soft.com>
""""""
from unittest.mock import MagicMock

import cherrypy

import rdiffweb.core.notification
import rdiffweb.test
from rdiffweb.core.model import RepoObject, UserObject


class NotificationJobTest(rdiffweb.test.WebCase):
    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_check_schedule(self):
        # Given the application is started
        # Then remove_older job should be schedule
        self.assertEqual(1, len([job for job in cherrypy.scheduler.list_jobs() if job.name == 'notification_job']))

    def test_notification_job(self):
        """"""
        Run the notification and check if mails are sent
        """"""
        # Given a user with an email address and a repository with a maxage
        # Set user config
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.commit()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = 1
        repo.commit()
        # When running notification_job
        cherrypy.notification.notification_job()

        # Then an email is queue for this user
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>testcases</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_undefined_last_backup_date(self):
        # Given a valid user with a repository configured for notification
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add().commit()
        # Given a repo with last_backup_date None
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == 'broker-repo').first()
        repo.maxage = 1
        repo.add().commit()
        self.assertIsNone(repo.last_backup_date)

        # When Notification job is running
        cherrypy.notification.notification_job()

        # Then a notification is sent to the user.
        self.listener.queue_email.assert_called_once_with(
            to='test@test.com',
            subject='Notification',
            message=""<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>\n      You are receiving this email to notify you about your backups. The\n      following repositories are inactive for some time. We invite you to have a look\n      at your last backup schedule.\n    </p>\n    <ul>\n      <li>broker-repo</li>\n    </ul>\n    <p>\n      If you don't want to be notify about this. You need to review your\n      user preferences.\n    </p>\n  </body>\n</html>"",
        )

    def test_notification_job_without_notification(self):
        # Given a valid user with a repository configured without notification (-1)
        user = UserObject.get_user(self.USERNAME)
        user.email = 'test@test.com'
        user.add().commit()
        repo = RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()
        repo.maxage = -1
        repo.add().commit()

        # Call notification.
        cherrypy.notification.notification_job()

        # Expect it to be called.
        self.listener.queue_email.assert_not_called()


class NotificationPluginTest(rdiffweb.test.WebCase):

    default_config = {
        'email-send-changed-notification': True,
    }

    def setUp(self):
        self.listener = MagicMock()
        cherrypy.engine.subscribe('queue_mail', self.listener.queue_email, priority=50)
        return super().setUp()

    def tearDown(self):
        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_email)
        return super().tearDown()

    def test_email_changed(self):
        # Given a user with an email address
        user = UserObject.get_user(self.USERNAME)
        user.email = 'original_email@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user's email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        user.add().commit()

        # Then a email is queue to notify the user.
        self.listener.queue_email.assert_called_once_with(
            to='original_email@test.com',
            subject='Email address changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the email address associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_email_updated_with_same_value(self):
        # Given a user with an email
        user = UserObject.get_user(self.USERNAME)
        user.email = 'email_changed@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user's email with the same value
        user.email = 'email_changed@test.com'
        user.add().commit()

        # Then no email are sent to the user
        self.listener.queue_email.assert_not_called()

    def test_password_change_notification(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user password
        user.set_password('new_password')
        user.add().commit()

        # Then a email is send to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )

    def test_password_change_with_same_value(self):
        # Given a user with a email.
        user = UserObject.get_user(self.USERNAME)
        user.email = 'password_change@test.com'
        user.set_password('new_password')
        user.add().commit()
        self.listener.queue_email.reset_mock()

        # When updating the user password with the same value
        user.set_password('new_password')
        user.add().commit()

        # Then an email is sent to the user
        self.listener.queue_email.assert_called_once_with(
            to='password_change@test.com',
            subject='Password changed',
            message='<html>\n  <head></head>\n  <body>\n    Hey admin,\n    <p>You recently changed the password associated with your Rdiffweb account.</p>\n    <p>\n      If you did not make this change and believe your account has been compromised, please contact your administrator.\n    </p>\n  </body>\n</html>',
        )
",CWE-75,191.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import cherrypy
from wtforms.fields import SelectField, StringField, SubmitField
from wtforms.validators import ValidationError
from wtforms.widgets import HiddenInput

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import UserObject
from rdiffweb.tools.i18n import gettext_lazy as _


class AbstractMfaForm(CherryForm):
    def __init__(self, obj, **kwargs):
        assert obj
        super().__init__(obj=obj, **kwargs)
        # Keep only one of the enable or disable button
        if obj.mfa:
            self.enable_mfa.widget = HiddenInput()
            self.enable_mfa.data = ''
        else:
            self.disable_mfa.widget = HiddenInput()
            self.disable_mfa.data = ''


class MfaStatusForm(AbstractMfaForm):
    mfa = SelectField(
        _('Two-Factor Authentication (2FA) Status'),
        coerce=int,
        choices=[
            (UserObject.DISABLED_MFA, _(""Disabled"")),
            (UserObject.ENABLED_MFA, _(""Enabled"")),
        ],
        render_kw={'readonly': True, 'disabled': True, 'data-beta': '1'},
    )
    enable_mfa = SubmitField(_('Enable Two-Factor Authentication'), render_kw={""class"": ""btn-success""})
    disable_mfa = SubmitField(_('Disable Two-Factor Authentication'), render_kw={""class"": ""btn-warning""})


class MfaToggleForm(AbstractMfaForm):
    code = StringField(
        _('Verification code'),
        render_kw={
            ""placeholder"": _('Enter verification code here'),
            ""autocomplete"": ""off"",
            ""autocorrect"": ""off"",
            ""autofocus"": ""autofocus"",
        },
    )
    enable_mfa = SubmitField(_('Enable Two-Factor Authentication'), render_kw={""class"": ""btn-success""})
    disable_mfa = SubmitField(_('Disable Two-Factor Authentication'), render_kw={""class"": ""btn-warning""})
    resend_code = SubmitField(
        _('Resend code to my email'),
        render_kw={""class"": ""btn-link""},
    )

    @property
    def app(self):
        return cherrypy.request.app

    def populate_obj(self, userobj):
        # Enable or disable MFA only when a code is provided.
        try:
            if self.enable_mfa.data:
                userobj.mfa = UserObject.ENABLED_MFA
                userobj.commit()
                flash(_(""Two-Factor authentication enabled successfully.""), level='success')
            elif self.disable_mfa.data:
                userobj.mfa = UserObject.DISABLED_MFA
                userobj.commit()
                flash(_(""Two-Factor authentication disabled successfully.""), level='success')
        except Exception as e:
            userobj.rollback()
            flash(str(e), level='warning')

    def validate_code(self, field):
        # Code is required for enable_mfa and disable_mfa
        if self.enable_mfa.data or self.disable_mfa.data:
            if not self.code.data:
                raise ValidationError(_(""Enter the verification code to continue.""))
            # Validate code
            if not cherrypy.tools.auth_mfa.verify_code(self.code.data, False):
                raise ValidationError(_(""Invalid verification code.""))

    def validate(self, extra_validators=None):
        if not (self.enable_mfa.data or self.disable_mfa.data or self.resend_code.data):
            raise ValidationError(_('Invalid operation'))
        return super().validate()


class PagePrefMfa(Controller):
    @cherrypy.expose
    def default(self, action=None, **kwargs):
        form = MfaToggleForm(obj=self.app.currentuser)
        if form.is_submitted():
            if form.validate():
                if form.resend_code.data:
                    self.send_code()
                elif form.enable_mfa.data or form.disable_mfa.data:
                    form.populate_obj(self.app.currentuser)
                    form = MfaStatusForm(obj=self.app.currentuser)
            # Send verification code if previous code expired.
            elif cherrypy.tools.auth_mfa.is_code_expired():
                self.send_code()
        else:
            form = MfaStatusForm(obj=self.app.currentuser)
        params = {
            'form': form,
        }
        return self._compile_template(""prefs_mfa.html"", **params)

    def send_code(self):
        userobj = self.app.currentuser
        if not userobj.email:
            flash(_(""To continue, you must set up an email address for your account.""), level='warning')
            return
        code = cherrypy.tools.auth_mfa.generate_code()
        body = self.app.templates.compile_template(
            ""email_verification_code.html"", **{""header_name"": self.app.cfg.header_name, 'user': userobj, 'code': code}
        )
        cherrypy.engine.publish('queue_mail', to=userobj.email, subject=_(""Your verification code""), message=body)
        flash(_(""A new verification code has been sent to your email.""))
",CWE-770,140.0,1
"# -*- coding: utf-8 -*-
# udb, A web interface to manage IT network
# Copyright (C) 2022 IKUS Software inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import os
import pickle
import threading
import time
from collections import namedtuple

import cherrypy

Tracker = namedtuple('Tracker', ['token', 'hits', 'timeout'])


class _DataStore:
    """"""
    Base class for rate limit data store
    """"""

    def __init__(self, **kwargs):
        self._locks = {}

    def get_and_increment(self, token, delay, hit=1):
        lock = self._locks.setdefault(token, threading.RLock())
        with lock:
            tracker = self._load(token)
            if tracker is None or tracker.timeout < time.time():
                tracker = Tracker(token=token, hits=0, timeout=int(time.time() + delay))
            tracker = tracker._replace(hits=tracker.hits + hit)
            self._save(tracker)
        return tracker.hits

    def _save(self, tracker):
        raise NotImplementedError

    def _load(self, token):
        raise NotImplementedError


class RamRateLimit(_DataStore):
    """"""
    Store rate limit information in memory.
    """"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._data = {}

    def _load(self, token):
        return self._data.get(token, None)

    def _save(self, tracker):
        self._data[tracker.token] = tracker


class FileRateLimit(_DataStore):
    """"""
    Store rate limit information in files.
    """"""

    PREFIX = 'ratelimit-'
    pickle_protocol = pickle.HIGHEST_PROTOCOL

    def __init__(self, storage_path, **kwargs):
        super().__init__(**kwargs)
        # The 'storage_path' arg is required for file-based datastore.
        assert (
            storage_path
        ), 'FileRateLimit required a storage_path `tools.ratelimit.storage_path = ""/home/site/ratelimit""`'
        self.storage_path = os.path.abspath(storage_path)

    def _path(self, token):
        assert token
        f = os.path.join(self.storage_path, self.PREFIX + token.strip('/').replace('/', '-'))
        if not os.path.abspath(f).startswith(self.storage_path):
            raise ValueError('invalid token')
        return f

    def _load(self, token):
        path = self._path(token)
        try:
            f = open(path, 'rb')
            try:
                return pickle.load(f)
            finally:
                f.close()
        except Exception:
            # Drop session data if invalid
            pass
        return None

    def _save(self, tracker):
        path = self._path(tracker.token)
        f = open(path, 'wb')
        try:
            pickle.dump(tracker, f, self.pickle_protocol)
        finally:
            f.close()


def check_ratelimit(
    delay=3600, limit=25, return_status=429, logout=False, scope=None, methods=None, debug=False, hit=1, **conf
):
    """"""
    Verify the ratelimit. By default return a 429 HTTP error code (Too Many Request). After 25 request within the same hour.

    Arguments:
        delay:         Time window for analysis in seconds. Default per hour (3600 seconds)
        limit:         Number of request allowed for an entry point. Default 25
        return_status: HTTP Error code to return.
        logout:        True to logout user when limit is reached
        scope:         if specify, define the scope of rate limit. Default to path_info.
        methods:       if specify, only the methods in the list will be rate limited.
    """"""
    assert delay > 0, 'invalid delay'

    # Check if limit is enabled
    if limit <= 0:
        return

    # Check if this 'method' should be rate limited
    request = cherrypy.request
    if methods is not None and request.method not in methods:
        if debug:
            cherrypy.log(
                'skip rate limit for HTTP method %s' % (request.method,),
                'TOOLS.RATELIMIT',
            )
        return

    # If datastore is not pass as configuration, create it for the first time.
    datastore = getattr(cherrypy.request.app, '_ratelimit_datastore', None)
    if datastore is None:
        # Create storage using storage class
        storage_class = conf.get('storage_class', RamRateLimit)
        datastore = storage_class(**conf)
        cherrypy.request.app._ratelimit_datastore = datastore

    # If user is authenticated, use the username else use the ip address
    token = (request.login or request.remote.ip) + '.' + (scope or request.path_info)

    # Get hits count using datastore.
    hits = datastore.get_and_increment(token, delay, hit)
    if debug:
        cherrypy.log(
            'check and increase rate limit for scope %s, limit %s, hits %s' % (token, limit, hits), 'TOOLS.RATELIMIT'
        )

    # Verify user has not exceeded rate limit
    if limit <= hits:
        if logout:
            if hasattr(cherrypy.serving, 'session'):
                cherrypy.serving.session.clear()
            raise cherrypy.HTTPRedirect(""/"")

        raise cherrypy.HTTPError(return_status)


def hit(hit=1):
    """"""
    May be called directly by handlers to add a hit for the given request.
    """"""
    conf = cherrypy.tools.ratelimit._merged_args()
    conf['hit'] = hit
    cherrypy.tools.ratelimit.callable(**conf)


cherrypy.tools.ratelimit = cherrypy.Tool('before_handler', check_ratelimit, priority=60)


cherrypy.tools.ratelimit.hit = hit
",CWE-770,185.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging

import cherrypy
from cherrypy.process.plugins import SimplePlugin

from rdiffweb.core.model import UserObject

logger = logging.getLogger(__name__)


class LoginPlugin(SimplePlugin):
    """"""
    This plugins register an ""authenticate"" listener to validate
    username and password of users. In addition, it provide a ""login""
    listener to authenticate and possibly create the user in database.
    """"""

    add_missing_user = False
    add_user_default_role = UserObject.USER_ROLE
    add_user_default_userroot = None

    def start(self):
        self.bus.log('Start Login plugin')
        self.bus.subscribe(""authenticate"", self.authenticate)
        self.bus.subscribe(""login"", self.login)

    def stop(self):
        self.bus.log('Stop Login plugin')
        self.bus.unsubscribe(""authenticate"", self.authenticate)
        self.bus.unsubscribe(""login"", self.login)

    def authenticate(self, username, password):
        """"""
        Only verify the user's credentials using the database store.
        """"""
        user = UserObject.query.filter_by(username=username).first()
        if user and user.validate_password(password):
            return username, {}
        return False

    def login(self, username, password):
        """"""
        Validate username password using database and LDAP.
        """"""
        # Validate credentials.
        authenticates = self.bus.publish('authenticate', username, password)
        authenticates = [a for a in authenticates if a]
        if not authenticates:
            return None
        real_username = authenticates[0][0]
        extra_attrs = authenticates[0][1]
        fullname = extra_attrs.get('_fullname', None)
        email = extra_attrs.get('_email', None)
        # When enabled, create missing userobj in database.
        userobj = UserObject.query.filter_by(username=username).first()
        if userobj is None and self.add_missing_user:
            try:
                # At this point, we need to create a new user in database.
                # In case default values are invalid, let evaluate them
                # before creating the user in database.
                default_user_root = self.add_user_default_userroot and self.add_user_default_userroot.format(
                    **extra_attrs
                )
                default_role = UserObject.ROLES.get(self.add_user_default_role)
                userobj = UserObject.add_user(
                    username=real_username,
                    fullname=fullname,
                    email=email,
                    role=default_role,
                    user_root=default_user_root,
                ).commit()
            except Exception:
                logger.error('fail to create new user', exc_info=1)
        if userobj is None:
            # User doesn't exists in database
            return None

        # Update user attributes
        dirty = False
        if fullname:
            userobj.fullname = fullname
            dirty = True
        if email:
            userobj.email = email
            dirty = True
        if dirty:
            userobj.commit()
        self.bus.publish('user_login', userobj)
        return userobj


cherrypy.login = LoginPlugin(cherrypy.engine)
cherrypy.login.subscribe()

cherrypy.config.namespaces['login'] = lambda key, value: setattr(cherrypy.login, key, value)
",CWE-287,113.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import cherrypy
from sqlalchemy import event

from ._repo import RepoObject  # noqa
from ._session import DbSession, SessionObject  # noqa
from ._sshkey import SshKey  # noqa
from ._token import Token  # noqa
from ._user import DuplicateSSHKeyError, UserObject  # noqa

Base = cherrypy.tools.db.get_base()


@event.listens_for(Base.metadata, 'after_create')
def db_after_create(target, connection, **kw):
    """"""
    Called on database creation to update database schema.
    """"""

    def exists(column):
        table_name = column.table.fullname
        column_name = column.name
        if 'SQLite' in connection.engine.dialect.__class__.__name__:
            sql = ""SELECT COUNT(*) FROM pragma_table_info('%s') WHERE LOWER(name)=LOWER('%s')"" % (
                table_name,
                column_name,
            )
        else:
            sql = ""SELECT COUNT(*) FROM information_schema.columns WHERE table_name='%s' and column_name='%s'"" % (
                table_name,
                column_name,
            )
        data = connection.engine.execute(sql).first()
        return data[0] >= 1

    def add_column(column):
        if exists(column):
            return
        table_name = column.table.fullname
        column_name = column.name
        column_type = column.type.compile(connection.engine.dialect)
        connection.engine.execute('ALTER TABLE %s ADD COLUMN %s %s' % (table_name, column_name, column_type))

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()

    # Add repo's Encoding
    add_column(RepoObject.__table__.c.Encoding)
    add_column(RepoObject.__table__.c.keepdays)

    # Create column for roles using ""isadmin"" column. Keep the
    # original column in case we need to revert to previous version.
    if not exists(UserObject.__table__.c.role):
        add_column(UserObject.__table__.c.role)
        UserObject.query.filter(UserObject._is_admin == 1).update({UserObject.role: UserObject.ADMIN_ROLE})

    # Add user's fullname column
    add_column(UserObject.__table__.c.fullname)

    # Add user's mfa column
    add_column(UserObject.__table__.c.mfa)

    # Re-create session table if Number column is missing
    if not exists(SessionObject.__table__.c.Number):
        SessionObject.__table__.drop()
        SessionObject.__table__.create()

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()
    # Remove preceding and leading slash (/) generated by previous
    # versions. Also rename '.' to ''
    result = RepoObject.query.all()
    for row in result:
        if row.repopath.startswith('/') or row.repopath.endswith('/'):
            row.repopath = row.repopath.strip('/')
            row.commit()
        if row.repopath == '.':
            row.repopath = ''
            row.commit()
    # Remove duplicates and nested repositories.
    result = RepoObject.query.order_by(RepoObject.userid, RepoObject.repopath).all()
    prev_repo = (None, None)
    for row in result:
        if prev_repo[0] == row.userid and (prev_repo[1] == row.repopath or row.repopath.startswith(prev_repo[1] + '/')):
            row.delete()
        else:
            prev_repo = (row.userid, row.repopath)
",CWE-287,104.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import unittest

import cherrypy

from rdiffweb.core.librdiff import RdiffTime
from rdiffweb.core.model import RepoObject, UserObject
from rdiffweb.core.rdw_templating import _ParentEntry, attrib, do_format_lastupdated, list_parents, url_for
from rdiffweb.test import WebCase


class TemplateManagerTest(unittest.TestCase):
    def test_attrib(self):
        # Single value
        self.assertEqual('id=""row""', attrib(id='row'))
        # Single value with quote
        self.assertEqual('id=""val&lt;ue&quot;with&quot;qu&gt;ot&amp;e""', attrib(id='val<ue""with""qu>ot&e'))
        # Multi attribute
        self.assertEqual('id=""row"" type=""table""', attrib(type='table', id='row'))
        # Attribute with list
        self.assertEqual('type=""table container""', attrib(type=['table', 'container']))
        # Attribute with class
        self.assertEqual('class=""table container""', attrib(**{'class': ['table', 'container']}))
        # Boolean expressions
        self.assertEqual('id=""active""', attrib(id=[False, 'active', False]))
        self.assertEqual('data=""coucou"" id=""active""', attrib(type=False, id=[False, 'active', False], data='coucou'))
        active = True
        self.assertEqual('id=""active""', attrib(id=[active and 'active']))
        active = False
        self.assertEqual('', attrib(id=[active and 'active']))

        # With True
        self.assertEqual('selected', attrib(selected=True))

        # Bytes
        self.assertEqual('selected=""text""', attrib(selected=b'text'))

        # Newstr
        self.assertEqual('selected=""text""', attrib(selected=str('text')))

        self.assertEqual('value=""0""', attrib(value=0))

    def test_url_for(self):
        # Check backward compatibility
        self.assertEqual(cherrypy.server.base() + '/', url_for('/'))
        self.assertEqual(cherrypy.server.base() + '/browse', url_for('browse'))
        self.assertEqual(cherrypy.server.base() + '/browse/testcases', url_for('browse', b'testcases'))
        self.assertEqual(
            cherrypy.server.base() + '/browse/testcases/Revisions', url_for('browse', b'testcases', b'Revisions')
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/testcases/Revisions?date=1454448640',
            url_for('restore', b'testcases', b'Revisions', date=1454448640),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/testcases/Revisions?date=1454448640&kind=tar.gz',
            url_for('restore', b'testcases', b'Revisions', date=1454448640, kind='tar.gz'),
        )
        self.assertEqual(
            cherrypy.server.base() + '/browse/testcases/R%C3%A9pertoire',
            url_for('browse', b'testcases', b'R\xc3\xa9pertoire'),
        )
        # Check if multi path is supported.
        self.assertEqual(cherrypy.server.base() + '/admin/logs', url_for('admin/logs'))
        self.assertEqual(cherrypy.server.base() + '/admin/logs/backup.log', url_for('admin/logs', 'backup.log'))

    def test_do_format_lastupdated(self):
        self.assertEqual('23 seconds ago', do_format_lastupdated(1591978823, now=1591978846))
        self.assertEqual('23 seconds ago', do_format_lastupdated(RdiffTime(value=1591978823), now=1591978846))
        self.assertEqual('8 minutes ago', do_format_lastupdated(RdiffTime(value=1591978324), now=1591978846))
        self.assertEqual('2 hours ago', do_format_lastupdated(RdiffTime(value=1591971646), now=1591978846))
        self.assertEqual('2 days ago', do_format_lastupdated(RdiffTime(value=1591805524), now=1591978846))
        self.assertEqual('4 weeks ago', do_format_lastupdated(RdiffTime(value=1589127124), now=1591978846))
        self.assertEqual('5 months ago', do_format_lastupdated(RdiffTime(value=1578672724), now=1591978846))
        self.assertEqual('4 years ago', do_format_lastupdated(RdiffTime(value=1452442324), now=1591978846))


class ListParentsTest(WebCase):
    def test_list_parents_with_root_dir(self):
        repo, path = RepoObject.get_repo_path(b'admin/testcases', as_user=UserObject.get_user('admin'))
        self.assertEqual(list_parents(repo, path), [_ParentEntry(path=b'', display_name='testcases')])

    def test_list_parents_with_root_subdir(self):
        repo, path = RepoObject.get_repo_path(b'admin/testcases/Revisions', as_user=UserObject.get_user('admin'))
        self.assertEqual(
            list_parents(repo, path),
            [
                _ParentEntry(path=b'', display_name='testcases'),
                _ParentEntry(path=b'Revisions', display_name='Revisions'),
            ],
        )


class UrlForTest(WebCase):
    @property
    def repo_obj(self):
        user = UserObject.query.filter(UserObject.username == 'admin').first()
        return RepoObject.query.filter(RepoObject.user == user, RepoObject.repopath == self.REPO).first()

    def test_url_for_absolute_path(self):
        self.assertEqual(cherrypy.server.base() + '/static/js/jquery.min.js', url_for('/static/js/jquery.min.js'))

    def test_url_for_browse(self):
        """"""Check creation of url""""""
        self.assertEqual(cherrypy.server.base() + '/browse/admin/testcases', url_for('browse', self.repo_obj))
        self.assertEqual(
            cherrypy.server.base() + '/browse/admin/testcases/Revisions', url_for('browse', self.repo_obj, b'Revisions')
        )
        self.assertEqual(
            cherrypy.server.base() + '/browse/admin/testcases/Revisions?restore=True',
            url_for('browse', self.repo_obj, b'Revisions', restore=True),
        )
        self.assertEqual(
            cherrypy.server.base()
            + '/browse/admin/testcases/R%C3%A9pertoire%20%28%40vec%29%20%7Bc%C3%A0ra%C3%A7t%23%C3%A8r%C3%AB%7D%20%24%C3%A9p%C3%AAcial',
            url_for(
                'browse',
                self.repo_obj,
                b'R\xc3\xa9pertoire (@vec) {c\xc3\xa0ra\xc3\xa7t#\xc3\xa8r\xc3\xab} $\xc3\xa9p\xc3\xaacial',
            ),
        )

    def test_url_for_graphs(self):
        self.assertEqual(
            cherrypy.server.base() + '/graphs/files/admin/testcases', url_for('graphs', 'files', self.repo_obj)
        )

    def test_url_for_history(self):
        """"""Check creation of url""""""
        self.assertEqual(cherrypy.server.base() + '/history/admin/testcases', url_for('history', self.repo_obj))

    def test_url_for_restore(self):
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021',
            url_for('restore', self.repo_obj, date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021',
            url_for('restore', self.repo_obj, b'', date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases?date=1414967021&kind=tar.gz',
            url_for('restore', self.repo_obj, b'', date=RdiffTime(1414967021), kind='tar.gz'),
        )
        self.assertEqual(
            cherrypy.server.base() + '/restore/admin/testcases/Revisions?date=1414967021',
            url_for('restore', self.repo_obj, b'Revisions', date=RdiffTime(1414967021)),
        )
        self.assertEqual(
            cherrypy.server.base()
            + '/restore/admin/testcases/R%C3%A9pertoire%20%28%40vec%29%20%7Bc%C3%A0ra%C3%A7t%23%C3%A8r%C3%AB%7D%20%24%C3%A9p%C3%AAcial?date=1414967021',
            url_for(
                'restore',
                self.repo_obj,
                b'R\xc3\xa9pertoire (@vec) {c\xc3\xa0ra\xc3\xa7t#\xc3\xa8r\xc3\xab} $\xc3\xa9p\xc3\xaacial',
                date=RdiffTime(1414967021),
            ),
        )

    def test_url_for_status(self):
        self.assertEqual(
            cherrypy.server.base() + '/status?date=1414967021', url_for('status', date=RdiffTime(1414967021))
        )
        self.assertEqual(
            cherrypy.server.base() + '/status/admin/testcases?date=1414967021',
            url_for('status', self.repo_obj, date=RdiffTime(1414967021)),
        )

    def test_url_for_with_none(self):
        self.assertEqual(cherrypy.server.base() + '/logs', url_for('logs', date=None))
",CWE-287,187.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import logging
import sys

import cherrypy
from sqlalchemy import event
from sqlalchemy.exc import IntegrityError

from ._repo import RepoObject  # noqa
from ._session import DbSession, SessionObject  # noqa
from ._sshkey import SshKey  # noqa
from ._token import Token  # noqa
from ._user import DuplicateSSHKeyError, UserObject, user_username_index  # noqa

Base = cherrypy.tools.db.get_base()

logger = logging.getLogger(__name__)


def _column_add(connection, column):
    if _column_exists(connection, column):
        return
    table_name = column.table.fullname
    column_name = column.name
    column_type = column.type.compile(connection.engine.dialect)
    connection.engine.execute('ALTER TABLE %s ADD COLUMN %s %s' % (table_name, column_name, column_type))


def _column_exists(connection, column):
    table_name = column.table.fullname
    column_name = column.name
    if 'SQLite' in connection.engine.dialect.__class__.__name__:
        sql = ""SELECT COUNT(*) FROM pragma_table_info('%s') WHERE LOWER(name)=LOWER('%s')"" % (
            table_name,
            column_name,
        )
    else:
        sql = ""SELECT COUNT(*) FROM information_schema.columns WHERE table_name='%s' and column_name='%s'"" % (
            table_name,
            column_name,
        )
    data = connection.engine.execute(sql).first()
    return data[0] >= 1


def _index_exists(connection, index_name):
    if 'SQLite' in connection.engine.dialect.__class__.__name__:
        sql = ""SELECT name FROM sqlite_master WHERE type = 'index' AND name = '%s';"" % (index_name)
    else:
        sql = ""SELECT * FROM pg_indexes WHERE indexname = '%s'"" % (index_name)
    return connection.engine.execute(sql).first() is not None


@event.listens_for(Base.metadata, 'after_create')
def db_after_create(target, connection, **kw):
    """"""
    Called on database creation to update database schema.
    """"""

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()

    # Add repo's Encoding
    _column_add(connection, RepoObject.__table__.c.Encoding)
    _column_add(connection, RepoObject.__table__.c.keepdays)

    # Create column for roles using ""isadmin"" column. Keep the
    # original column in case we need to revert to previous version.
    if not _column_exists(connection, UserObject.__table__.c.role):
        _column_add(connection, UserObject.__table__.c.role)
        UserObject.query.filter(UserObject._is_admin == 1).update({UserObject.role: UserObject.ADMIN_ROLE})

    # Add user's fullname column
    _column_add(connection, UserObject.__table__.c.fullname)

    # Add user's mfa column
    _column_add(connection, UserObject.__table__.c.mfa)

    # Re-create session table if Number column is missing
    if not _column_exists(connection, SessionObject.__table__.c.Number):
        SessionObject.__table__.drop()
        SessionObject.__table__.create()

    if getattr(connection, '_transaction', None):
        connection._transaction.commit()

    # Remove preceding and leading slash (/) generated by previous
    # versions. Also rename '.' to ''
    result = RepoObject.query.all()
    for row in result:
        if row.repopath.startswith('/') or row.repopath.endswith('/'):
            row.repopath = row.repopath.strip('/')
            row.commit()
        if row.repopath == '.':
            row.repopath = ''
            row.commit()
    # Remove duplicates and nested repositories.
    result = RepoObject.query.order_by(RepoObject.userid, RepoObject.repopath).all()
    prev_repo = (None, None)
    for row in result:
        if prev_repo[0] == row.userid and (prev_repo[1] == row.repopath or row.repopath.startswith(prev_repo[1] + '/')):
            row.delete()
        else:
            prev_repo = (row.userid, row.repopath)

    # Fix username case insensitive unique
    if not _index_exists(connection, 'user_username_index'):
        duplicate_users = (
            UserObject.query.with_entities(func.lower(UserObject.username))
            .group_by(func.lower(UserObject.username))
            .having(func.count(UserObject.username) > 1)
        ).all()
        try:
            user_username_index.create()
        except IntegrityError:
            msg = (
                'Failure to upgrade your database to make Username case insensitive. '
                'You must downgrade and deleted duplicate Username. '
                '%s' % '\n'.join([str(k) for k in duplicate_users]),
            )
            logger.error(msg)
            print(msg, file=sys.stderr)
            raise SystemExit(12)
",CWE-284,140.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2021 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import cherrypy
from sqlalchemy import Column, Integer, Text

Base = cherrypy.tools.db.get_base()


class SshKey(Base):
    __tablename__ = 'sshkeys'
    __table_args__ = {'sqlite_autoincrement': True}
    fingerprint = Column('Fingerprint', Text)
    key = Column('Key', Text, unique=True, primary_key=True)
    userid = Column('UserID', Integer, nullable=False)
",CWE-284,30.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2023 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
""""""
Plugins to allows users to configure the SSH keys using the web
interface. Basically it's a UI for `~/.ssh/authorized_keys`. For this
plugin to work properly, the users home directory need to match a real
user home.
""""""

import logging

import cherrypy
from wtforms import validators
from wtforms.fields import HiddenField, StringField
from wtforms.validators import ValidationError
from wtforms.widgets.core import TextArea

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.dispatch import restapi
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core import authorizedkeys
from rdiffweb.core.model import DuplicateSSHKeyError
from rdiffweb.tools.i18n import gettext_lazy as _

_logger = logging.getLogger(__name__)


def validate_key(unused_form, field):
    """"""Custom validator to check the SSH Key.""""""
    try:
        authorizedkeys.check_publickey(field.data)
    except ValueError:
        raise ValidationError(_(""Invalid SSH key.""))


class SshForm(CherryForm):
    action = HiddenField(default=""add"")
    title = StringField(
        _('Title'),
        description=_('The title is an optional description to identify the key. e.g.: bob@thinkpad-t530'),
        validators=[
            validators.data_required(),
            validators.length(
                max=256,
                message=_('Title too long.'),
            ),
        ],
    )
    key = StringField(
        _('Key'),
        widget=TextArea(),
        description=_(
            ""Enter a SSH public key. It should start with 'ssh-dss', 'ssh-ed25519', 'ssh-rsa', 'ecdsa-sha2-nistp256', 'ecdsa-sha2-nistp384' or 'ecdsa-sha2-nistp521'.""
        ),
        validators=[validators.data_required(), validate_key],
    )

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'add'

    def populate_obj(self, userobj):
        try:
            userobj.add_authorizedkey(key=self.key.data, comment=self.title.data)
            userobj.commit()
            return True
        except DuplicateSSHKeyError as e:
            userobj.rollback()
            flash(str(e), level='error')
            _logger.warning(""trying to add duplicate ssh key"")
            return False
        except Exception:
            userobj.rollback()
            flash(_(""Unknown error while adding the SSH Key""), level='error')
            _logger.warning(""error adding ssh key"", exc_info=1)
            return False


class DeleteSshForm(CherryForm):
    action = HiddenField(default=""delete"")
    fingerprint = StringField('Fingerprint', validators=[validators.data_required()])

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.action.data == 'delete'

    def populate_obj(self, userobj):
        is_maintainer()
        try:
            userobj.delete_authorizedkey(self.fingerprint.data)
            userobj.commit()
            return True
        except Exception:
            userobj.rollback()
            if hasattr(cherrypy.serving, 'session'):
                flash(_(""Unknown error while removing the SSH Key""), level='error')
            _logger.warning(""error removing ssh key"", exc_info=1)
            return False


class PagePrefSshKeys(Controller):
    @cherrypy.expose
    def default(self, **kwargs):
        # Handle action
        add_form = SshForm()
        delete_form = DeleteSshForm()
        if not self.app.cfg.disable_ssh_keys:
            if add_form.is_submitted():
                if add_form.validate():
                    if add_form.populate_obj(self.app.currentuser):
                        raise cherrypy.HTTPRedirect("""")
                else:
                    flash(add_form.error_message, level='warning')
            elif delete_form.is_submitted():
                if delete_form.validate():
                    if delete_form.populate_obj(self.app.currentuser):
                        raise cherrypy.HTTPRedirect("""")
                else:
                    flash(delete_form.error_message, level='warning')

        # Get SSH keys if file exists.
        params = {
            'disable_ssh_keys': self.app.cfg.disable_ssh_keys,
            'form': add_form,
        }
        try:
            params[""sshkeys""] = [
                {'title': key.comment, 'fingerprint': key.fingerprint} for key in self.app.currentuser.authorizedkeys
            ]
        except IOError:
            params[""sshkeys""] = []
            flash(_(""Failed to get SSH keys""), level='error')
            _logger.warning(""error reading SSH keys"", exc_info=1)

        return self._compile_template(""prefs_sshkeys.html"", **params)


@restapi()
@cherrypy.tools.json_out()
class ApiSshKeys(Controller):
    @cherrypy.expose
    def list(self):
        return [{'title': key.comment, 'fingerprint': key.fingerprint} for key in self.app.currentuser.authorizedkeys]

    @cherrypy.expose
    def get(self, fingerprint):
        for key in self.app.currentuser.authorizedkeys:
            if key.fingerprint == fingerprint:
                return {'title': key.comment, 'fingerprint': key.fingerprint}
        raise cherrypy.HTTPError(404)

    @cherrypy.expose
    def delete(self, fingerprint):
        form = DeleteSshForm(fingerprint=fingerprint)
        if form.validate():
            form.populate_obj(self.app.currentuser)
            return {}
        else:
            raise cherrypy.HTTPError(400, form.error_message)

    @cherrypy.expose
    def post(self, **kwargs):
        form = SshForm()
        if form.validate():
            # Create the SSH Key
            userobj = self.app.currentuser
            try:
                userobj.add_authorizedkey(key=form.key.data, comment=form.title.data)
                userobj.commit()
            except DuplicateSSHKeyError as e:
                userobj.rollback()
                raise cherrypy.HTTPError(400, str(e))
            return kwargs
        else:
            raise cherrypy.HTTPError(400, form.error_message)
",CWE-770,191.0,1
"# -*- coding: utf-8 -*-
# rdiffweb, A web interface to rdiff-backup repositories
# Copyright (C) 2012-2023 rdiffweb contributors
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


import logging

import cherrypy
from wtforms.fields import DateTimeField, StringField, SubmitField
from wtforms.validators import DataRequired, Length, Optional

from rdiffweb.controller import Controller, flash
from rdiffweb.controller.filter_authorization import is_maintainer
from rdiffweb.controller.form import CherryForm
from rdiffweb.core.model import Token
from rdiffweb.tools.i18n import gettext_lazy as _

try:
    # wtform>=3
    from wtforms.widgets import DateInput
except ImportError:
    # wtform<3
    from wtforms.widgets.html5 import DateInput

logger = logging.getLogger(__name__)


class TokenForm(CherryForm):
    name = StringField(
        _('Token name'),
        description=_(
            'Used only to identify the purpose of the token. For example, the application that uses the token.'
        ),
        validators=[
            DataRequired(),
            Length(max=256, message=_('Token name too long')),
        ],
    )
    expiration = DateTimeField(
        _('Expiration date'),
        description=_(
            'Allows the creation of a temporary token by defining an expiration date. Leave empty to keep the token forever.'
        ),
        render_kw={
            ""placeholder"": _('YYYY-MM-DD'),
        },
        format=""%Y-%m-%d"",
        widget=DateInput(),
        validators=[Optional()],
    )
    add_access_token = SubmitField(_('Create access token'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.add_access_token.data

    def populate_obj(self, userobj):
        try:
            token = userobj.add_access_token(self.name.data, self.expiration.data)
            userobj.commit()
            flash(
                _(
                    ""Your new personal access token has been created.\n""
                    ""Make sure to save it - you won't be able to access it again.\n""
                    ""%s""
                )
                % token,
                level='info',
            )
            return True
        except ValueError as e:
            userobj.rollback()
            flash(str(e), level='warning')
            return False
        except Exception:
            userobj.rollback()
            logger.exception(""error adding access token: %s, %s"" % (self.name.data, self.expiration.data))
            flash(_(""Unknown error while adding the access token.""), level='error')
            return False


class DeleteTokenForm(CherryForm):
    name = StringField(validators=[DataRequired()])
    revoke = SubmitField(_('Revoke'))

    def is_submitted(self):
        # Validate only if action is set_profile_info
        return super().is_submitted() and self.revoke.data

    def populate_obj(self, userobj):
        is_maintainer()
        try:
            userobj.delete_access_token(self.name.data)
            flash(_('The access token has been successfully deleted.'), level='success')
            return True
        except ValueError as e:
            userobj.rollback()
            flash(str(e), level='warning')
            return False
        except Exception:
            userobj.rollback()
            logger.exception(""error removing access token: %s"" % self.name.data)
            flash(_(""Unknown error while removing the access token.""), level='error')
            return False


class PagePrefTokens(Controller):
    @cherrypy.expose
    def default(self, **kwargs):
        form = TokenForm()
        delete_form = DeleteTokenForm()
        if form.is_submitted():
            if form.validate():
                if form.populate_obj(self.app.currentuser):
                    raise cherrypy.HTTPRedirect("""")
            else:
                flash(form.error_message, level='error')
        elif delete_form.is_submitted():
            if delete_form.validate():
                if delete_form.populate_obj(self.app.currentuser):
                    raise cherrypy.HTTPRedirect("""")
            else:
                flash(delete_form.error_message, level='error')
        params = {
            'form': form,
            'tokens': Token.query.filter(Token.userid == self.app.currentuser.userid),
        }
        return self._compile_template(""prefs_tokens.html"", **params)
",CWE-770,142.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Minarca Server
#
# Copyright (C) 2020 IKUS Software inc. All rights reserved.
# IKUS Software inc. PROPRIETARY/CONFIDENTIAL.
# Use is subject to license terms.


import setuptools

setuptools.setup(
    name=""minarca_server"",
    use_scm_version={""root"": "".."", ""relative_to"": __file__},
    description=""Minarca Web Server"",
    long_description=""Minarca is a self-hosted open source data backup software that allows you to manage your computer and server backups for free from a direct online accessible centralized view of your data with easy retrieval in case of displacement, loss or breakage."",
    author=""IKUS Software inc."",
    author_email=""support@ikus-soft.com"",
    maintainer=""IKUS Software inc."",
    maintainer_email=""support@ikus-soft.com"",
    url=""https://www.ikus-soft.com/en/minarca/"",
    include_package_data=True,
    python_requires="">=3.5"",
    packages=[""minarca_server"", ""minarca_server.plugins"", ""minarca_server.core""],
    setup_requires=[
        ""setuptools_scm>=5.0.1"",
    ],
    install_requires=[
        ""rdiffweb==2.4.0"",
        ""cherrypy>=18.0.0"",
        ""requests"",
        ""tzlocal~=2.0"",
    ],
    # required packages for build process
    extras_require={
        ""test"": [
            ""responses"",
            ""pytest"",
        ]
    },
    # Declare entry point
    entry_points={
        ""console_scripts"": [
            ""minarca-server = minarca_server.main:main"",
            ""minarca-shell = minarca_server.shell:main"",
        ]
    },
)
",CWE-311,50.0,1
"#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Minarca Server
#
# Copyright (C) 2020 IKUS Software inc. All rights reserved.
# IKUS Software inc. PROPRIETARY/CONFIDENTIAL.
# Use is subject to license terms.


import setuptools

setuptools.setup(
    name=""minarca_server"",
    use_scm_version={""root"": "".."", ""relative_to"": __file__},
    description=""Minarca Web Server"",
    long_description=""Minarca is a self-hosted open source data backup software that allows you to manage your computer and server backups for free from a direct online accessible centralized view of your data with easy retrieval in case of displacement, loss or breakage."",
    author=""IKUS Software inc."",
    author_email=""support@ikus-soft.com"",
    maintainer=""IKUS Software inc."",
    maintainer_email=""support@ikus-soft.com"",
    url=""https://www.ikus-soft.com/en/minarca/"",
    include_package_data=True,
    python_requires="">=3.5"",
    packages=[""minarca_server"", ""minarca_server.plugins"", ""minarca_server.core""],
    setup_requires=[
        ""setuptools_scm>=5.0.1"",
    ],
    install_requires=[
        ""rdiffweb==2.4.0"",
        ""cherrypy>=18.0.0"",
        ""requests"",
        ""tzlocal~=2.0"",
    ],
    # required packages for build process
    extras_require={
        ""test"": [
            ""responses"",
            ""pytest"",
        ]
    },
    # Declare entry point
    entry_points={
        ""console_scripts"": [
            ""minarca-server = minarca_server.main:main"",
            ""minarca-shell = minarca_server.shell:main"",
        ]
    },
)
",CWE-521,50.0,1
"import json
import pickle
import typing
from abc import ABCMeta, abstractmethod

try:
    import msgpack
except ImportError:  # pragma: no cover
    msgpack = None  # type: ignore

try:
    import cbor2 as cbor
except ImportError:  # pragma: no cover
    cbor = None  # type: ignore

from rpcpy.exceptions import SerializerNotFound


class BaseSerializer(metaclass=ABCMeta):
    """"""
    Base Serializer
    """"""

    name: str
    content_type: str

    @abstractmethod
    def encode(self, data: typing.Any) -> bytes:
        raise NotImplementedError()

    @abstractmethod
    def decode(self, raw_data: bytes) -> typing.Any:
        raise NotImplementedError()


class JSONSerializer(BaseSerializer):
    name = ""json""
    content_type = ""application/json""

    def __init__(
        self,
        default_encode: typing.Callable = None,
        default_decode: typing.Callable = None,
    ) -> None:
        self.default_encode = default_encode
        self.default_decode = default_decode

    def encode(self, data: typing.Any) -> bytes:
        return json.dumps(
            data,
            ensure_ascii=False,
            default=self.default_encode,
        ).encode(""utf8"")

    def decode(self, data: bytes) -> typing.Any:
        return json.loads(
            data.decode(""utf8""),
            object_hook=self.default_decode,
        )


class PickleSerializer(BaseSerializer):
    name = ""pickle""
    content_type = ""application/x-pickle""

    def encode(self, data: typing.Any) -> bytes:
        return pickle.dumps(data)

    def decode(self, data: bytes) -> typing.Any:
        return pickle.loads(data)


class MsgpackSerializer(BaseSerializer):
    """"""
    Msgpack: https://github.com/msgpack/msgpack-python
    """"""

    name = ""msgpack""
    content_type = ""application/x-msgpack""

    def __init__(
        self,
        default_encode: typing.Callable = None,
        default_decode: typing.Callable = None,
    ) -> None:
        self.default_encode = default_encode
        self.default_decode = default_decode

    def encode(self, data: typing.Any) -> bytes:
        return msgpack.packb(data, default=self.default_encode)

    def decode(self, data: bytes) -> typing.Any:
        return msgpack.unpackb(data, object_hook=self.default_decode)


class CBORSerializer(BaseSerializer):
    """"""
    CBOR: https://tools.ietf.org/html/rfc7049
    """"""

    name = ""cbor""
    content_type = ""application/x-cbor""

    def encode(self, data: typing.Any) -> bytes:
        return cbor.dumps(data)

    def decode(self, data: bytes) -> typing.Any:
        return cbor.loads(data)


SERIALIZER_NAMES = {
    JSONSerializer.name: JSONSerializer(),
    PickleSerializer.name: PickleSerializer(),
    MsgpackSerializer.name: MsgpackSerializer(),
    CBORSerializer.name: CBORSerializer(),
}

SERIALIZER_TYPES = {
    JSONSerializer.content_type: JSONSerializer(),
    PickleSerializer.content_type: PickleSerializer(),
    MsgpackSerializer.content_type: MsgpackSerializer(),
    CBORSerializer.content_type: CBORSerializer(),
}


def get_serializer(headers: typing.Mapping) -> BaseSerializer:
    """"""
    parse header and try find serializer
    """"""
    serializer_name = headers.get(""serializer"", None)
    if serializer_name:
        if serializer_name not in SERIALIZER_NAMES:
            raise SerializerNotFound(f""Serializer `{serializer_name}` not found"")
        return SERIALIZER_NAMES[serializer_name]

    serializer_type = headers.get(""content-type"", None)
    if serializer_type:
        if serializer_type not in SERIALIZER_TYPES:
            raise SerializerNotFound(f""Serializer for `{serializer_type}` not found"")
        return SERIALIZER_TYPES[serializer_type]

    raise SerializerNotFound(
        ""You must set a value for header `serializer` or `content-type`""
    )
",CWE-522,145.0,1
"import unittest

from vncap.vnc.protocol import VNCServerAuthenticator

class DummyTransport(object):

    buf = """"
    lost = False

    def write(self, data):
        self.buf += data

    def loseConnection(self):
        self.lost = True

class TestVNCServerAuthenticator(unittest.TestCase):

    def setUp(self):
        self.p = VNCServerAuthenticator(""password"", {})
        self.t = DummyTransport()
        self.p.makeConnection(self.t)

    def test_trivial(self):
        pass

    def test_connectionMade(self):
        self.assertEqual(self.t.buf, ""RFB 003.008\n"")

    def test_check_version(self):
        self.t.buf = """"
        self.p.check_version(""RFB 003.008\n"")
        self.assertEqual(self.t.buf, ""\x02\x01\x02"")

    def test_check_invalid_version(self):
        self.t.buf = """"
        self.p.check_version(""RFB 002.000\n"")
        self.assertTrue(self.t.lost)
",CWE-287,38.0,1
"from os import urandom

from twisted.internet import reactor
from twisted.internet.defer import Deferred
from twisted.protocols.stateful import StatefulProtocol
from twisted.python import log

from vncap.vnc.d3des import generate_response

def check_password(challenge, response, password):
    password = password.ljust(8, ""\x00"")[:8]
    return generate_response(password, challenge) == response

(
    STATE_VERSION,
    STATE_SECURITY_TYPES,
    STATE_AUTHENTICATION,
    STATE_RESULT,
    STATE_CONNECTED
) = range(5)

class VNCAuthenticator(StatefulProtocol):
    """"""
    Base class for VNC protocols.

    This protocol isn't interesting on its own; subclass it to make a server
    or client.
    """"""

    VERSION = ""RFB 003.008\n""

    def __init__(self, password):
        self.password = password
        self.authentication_d = Deferred()

    def authenticated(self):
        """"""
        Switch to proxy mode.
        """"""

        log.msg(""Successfully authenticated %s!"" % self)
        self.transport.pauseProducing()
        reactor.callLater(0, self.authentication_d.callback, self)

class VNCServerAuthenticator(VNCAuthenticator):
    """"""
    Trivial server protocol which can authenticate VNC clients.

    This protocol is lacking lots of things, like support for older VNC
    protocols.
    """"""

    def __init__(self, password, options):
        VNCAuthenticator.__init__(self, password)
        self.options = options

        if 'password' in options:
            self.password = options['password']

    def connectionMade(self):
        log.msg(""Received incoming connection"")
        self.transport.write(self.VERSION)

    def getInitialState(self):
        self.verify_ip()
        return self.check_version, 12

    def check_version(self, version):
        """"""
        Determine the client's version and decide whether to continue the
        handshake.
        """"""

        if version == self.VERSION:
            log.msg(""Client version %s is valid"" % version.strip())
            # Hardcoded: 2 security types: None and VNC Auth.
            self.transport.write(""\x02\x01\x02"")
            return self.select_security_type, 1
        else:
            log.err(""Can't handle VNC version %r"" % version)
            self.transport.loseConnection()

    def select_security_type(self, security_type):
        """"""
        Choose the security type that the client wants.
        """"""

        security_type = ord(security_type)

        if security_type == 2:
            # VNC authentication. Issue our challenge.
            self.challenge = urandom(16)
            self.transport.write(self.challenge)

            return self.vnc_authentication_result, 16
        elif security_type == 1:
            # No authentication. Just move to the SecurityResult.
            self.authenticated()
        else:
            log.err(""Couldn't agree on an authentication scheme!"")
            self.transport.loseConnection()

    def vnc_authentication_result(self, response):
        log.msg(""Doing VNC auth, buf %r"" % response)

        if check_password(self.challenge, response, self.password):
            self.authenticated()
        else:
            log.err(""Failed VNC auth!"")
            self.transport.loseConnection()

    def verify_ip(self):
        if 'ip' in self.options:
            if self.options['ip'] != self.transport.getPeer().host:
                log.err(""Failed to verify client IP"")
                self.transport.loseConnection()
            else:
                log.msg(""Verified client IP"")

    def authenticated(self):
        log.msg(""Successfully authenticated a client!"")
        # Send a u32 0, for success.
        self.transport.write(""\x00\x00\x00\x00"")
        VNCAuthenticator.authenticated(self)

class VNCClientAuthenticator(VNCAuthenticator):
    """"""
    Trivial client protocol which can authenticate itself to a VNC server.

    This protocol is lacking lots of things, like support for older VNC
    protocols.
    """"""

    def getInitialState(self):
        return self.check_version, 12

    def check_version(self, version):
        if version == self.VERSION:
            log.msg(""Server version %s is valid"" % version.strip())
            self.transport.write(self.VERSION)
            return self.count_security_types, 1
        else:
            log.err(""Can't handle VNC version %r"" % version)
            self.transport.loseConnection()

    def count_security_types(self, data):
        count = ord(data)

        if not count:
            log.err(""Server wouldn't give us any security types!"")
            self.transport.loseConnection()

        return self.pick_security_type, count

    def pick_security_type(self, data):
        """"""
        Ascertain whether the server supports any security types we might
        want.
        """"""

        security_types = set(ord(i) for i in data)
        log.msg(""Available authentication methods: %s""
            % "", "".join(hex(i) for i in security_types))

        if 2 in security_types:
            log.msg(""Choosing VNC authentication..."")
            self.transport.write(""\x02"")
            return self.vnc_authentication, 16
        elif 1 in security_types:
            log.msg(""Choosing no authentication..."")
            self.transport.write(""\x01"")
            return self.security_result, 4
        else:
            log.err(""Couldn't agree on an authentication scheme!"")
            self.transport.loseConnection()

    def vnc_authentication(self, challenge):
        # Take in 16 bytes, encrypt with 3DES using the password as the key,
        # and send the response.

        response = generate_response(self.password, challenge)
        self.transport.write(response)

        return self.security_result, 4

    def security_result(self, data):
        if data == ""\x00\x00\x00\x00"":
            # Success!
            log.msg(""Successfully authenticated to the server!"")
            self.authenticated()
        else:
            log.err(""Failed security result!"")
            self.transport.loseConnection()
",CWE-287,194.0,1
"#!/usr/bin/env python
""""""
Creates an HTTP server with basic auth and websocket communication.
""""""
import argparse
import base64
import hashlib
import os
import time
import threading
import webbrowser

try:
    import cStringIO as io
except ImportError:
    import io

import tornado.web
import tornado.websocket
from tornado.ioloop import PeriodicCallback

# Hashed password for comparison and a cookie for login cache
ROOT = os.path.normpath(os.path.dirname(__file__))
with open(os.path.join(ROOT, ""password.txt"")) as in_file:
    PASSWORD = in_file.read().strip()
COOKIE_NAME = ""camp""


class IndexHandler(tornado.web.RequestHandler):

    def get(self):
        if args.require_login and not self.get_secure_cookie(COOKIE_NAME):
            self.redirect(""/login"")
        else:
            self.render(""index.html"", port=args.port)


class LoginHandler(tornado.web.RequestHandler):

    def get(self):
        self.render(""login.html"")

    def post(self):
        password = self.get_argument(""password"", """")
        if hashlib.sha512(password).hexdigest() == PASSWORD:
            self.set_secure_cookie(COOKIE_NAME, str(time.time()))
            self.redirect(""/"")
        else:
            time.sleep(1)
            self.redirect(u""/login?error"")


class ErrorHandler(tornado.web.RequestHandler):
    def get(self):
        self.send_error(status_code=403)


class WebSocket(tornado.websocket.WebSocketHandler):

    def on_message(self, message):
        """"""Evaluates the function pointed to by json-rpc.""""""

        # Start an infinite loop when this is called
        if message == ""read_camera"":
            if not args.require_login or self.get_secure_cookie(COOKIE_NAME):
                self.camera_loop = PeriodicCallback(self.loop, 10)
                self.camera_loop.start()
            else:
                print(""Unauthenticated websocket request"")

        # Extensibility for other methods
        else:
            print(""Unsupported function: "" + message)

    def loop(self):
        """"""Sends camera images in an infinite loop.""""""
        try:
            sio = io.BytesIO() # for Python3
        except AttributeError:
            sio = io.StringIO()  # for Python2

        if args.use_usb:
            _, frame = camera.read()
            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            img.save(sio, ""JPEG"")
        else:
            camera.capture(sio, ""jpeg"", use_video_port=True)

        try:
            self.write_message(base64.b64encode(sio.getvalue()))
        except tornado.websocket.WebSocketClosedError:
            self.camera_loop.stop()


parser = argparse.ArgumentParser(description=""Starts a webserver that ""
                                 ""connects to a webcam."")
parser.add_argument(""--port"", type=int, default=8000, help=""The ""
                    ""port on which to serve the website."")
parser.add_argument(""--resolution"", type=str, default=""low"", help=""The ""
                    ""video resolution. Can be high, medium, or low."")
parser.add_argument(""--require-login"", action=""store_true"", help=""Require ""
                    ""a password to log in to webserver."")
parser.add_argument(""--use-usb"", action=""store_true"", help=""Use a USB ""
                    ""webcam instead of the standard Pi camera."")
parser.add_argument(""--usb-id"", type=int, default=0, help=""The ""
                     ""usb camera number to display"")
args = parser.parse_args()

if args.use_usb:
    import cv2
    from PIL import Image
    camera = cv2.VideoCapture(args.usb_id)
else:
    import picamera
    camera = picamera.PiCamera()
    camera.start_preview()

resolutions = {""high"": (1280, 720), ""medium"": (640, 480), ""low"": (320, 240)}
if args.resolution in resolutions:
    if args.use_usb:
        w, h = resolutions[args.resolution]
        camera.set(3, w)
        camera.set(4, h)
    else:
        camera.resolution = resolutions[args.resolution]
else:
    raise Exception(""%s not in resolution options."" % args.resolution)

handlers = [(r""/"", IndexHandler), (r""/login"", LoginHandler),
            (r""/websocket"", WebSocket),
            (r""/static/password.txt"", ErrorHandler),
            (r'/static/(.*)', tornado.web.StaticFileHandler, {'path': ROOT})]
application = tornado.web.Application(handlers, cookie_secret=PASSWORD)
application.listen(args.port)

webbrowser.open(""http://localhost:%d/"" % args.port, new=2)

tornado.ioloop.IOLoop.instance().start()
",CWE-522,139.0,1
"# -*- coding: utf-8 -*-

# Copyright (C) 2009-2014:
#     Gabes Jean, naparuba@gmail.com
#     Gerhard Lausser, Gerhard.Lausser@consol.de
#     Gregory Starck, g.starck@gmail.com
#     Hartmut Goebel, h.goebel@goebel-consult.de
#
# This file is part of Shinken.
#
# Shinken is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Shinken is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with Shinken.  If not, see <http://www.gnu.org/licenses/>.

import sys
import cPickle
from cStringIO import StringIO



# Unpickle but strip and remove all __reduce__ things
# so we don't allow external code to be executed
# Code from Graphite::carbon project
class SafeUnpickler(object):
    PICKLE_SAFE = {
        'copy_reg': set(['_reconstructor']),
        '__builtin__': set(['object', 'set']),
    }


    @classmethod
    def find_class(cls, module, name):
        if module not in cls.PICKLE_SAFE and not module.startswith('shinken.'):
            raise ValueError('Attempting to unpickle unsafe module %s' % module)
        __import__(module)
        mod = sys.modules[module]
        if not module.startswith('shinken.') and name not in cls.PICKLE_SAFE[module]:
            raise ValueError('Attempting to unpickle unsafe class %s/%s' %
                             (module, name))
        return getattr(mod, name)


    @classmethod
    def loads(cls, pickle_string):
        pickle_obj = cPickle.Unpickler(StringIO(pickle_string))
        pickle_obj.find_global = cls.find_class
        return pickle_obj.load()
",CWE-287,57.0,1
"#!/usr/bin/env python
# Copyright (C) 2009-2014:
#    Gabes Jean, naparuba@gmail.com
#    Gerhard Lausser, Gerhard.Lausser@consol.de
#
# This file is part of Shinken.
#
# Shinken is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Shinken is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with Shinken.  If not, see <http://www.gnu.org/licenses/>.

#
# This file is used to test reading and processing of config files
#


import cPickle as pickle
from shinken_test import *

from shinken.safepickle import SafeUnpickler


should_not_change = False
def fff(b):
    global should_not_change
    should_not_change = b


class SadPanda(object):
    def __reduce__(self):
        return (fff, (True,))


class TestSafePickle(ShinkenTest):

    def setUp(self):
        pass


    def launch_safe_pickle(self, buf):
        SafeUnpickler.loads(buf)
        
        
    def test_safe_pickle(self):
        global should_not_change

        print ""Creating payload""
        buf = pickle.dumps(SadPanda(), 0)
        should_not_change = False
        print ""Payload"", buf
        #self.assertEqual('HARD', host.state_type)
        print ""Now loading payload""
        pickle.loads(buf)
        print should_not_change
        self.assertTrue(should_not_change)
        
        # reset and try our fix
        should_not_change = False
        #SafeUnpickler.loads(buf)
        def launch_safe_pickle():
            SafeUnpickler.loads(buf)
        self.assertRaises(ValueError, launch_safe_pickle)
        print should_not_change
        self.assertFalse(should_not_change)
        
        
if __name__ == '__main__':
    unittest.main()
",CWE-287,78.0,1
"import os
from setuptools import setup

def read(name):
    return open(os.path.join(os.path.dirname(__file__), name)).read()

setup(
    name='python_jwt',
    version='3.3.3',
    description=""Module for generating and verifying JSON Web Tokens"",
    long_description=read('README.md'),
    long_description_content_type='text/markdown',
    keywords='',
    author='David Halls',
    author_email='dave@davedoesdev.com',
    url='https://github.com/davedoesdev/python-jwt',
    license='MIT',
    packages=['python_jwt'],
    install_requires=[""jwcrypto>=0.4.2,<1.0.0; python_version < '3.0'"",
                      ""jwcrypto>=1.0.0; python_version >= '3.0'""],
    python_requires='>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*',
    classifiers=[
        'Programming Language :: Python :: 2',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: Implementation :: CPython',
    ],
)
",CWE-290,28.0,1
,CWE-290,,1
"# -*- coding: utf-8 -*-
from __future__ import absolute_import, print_function, unicode_literals

import re
# see https://gist.github.com/dperini/729294
URL_REGEX = re.compile(
    # protocol identifier
    ""(?:(?:https?|ftp)://)""
    # user:pass authentication
    ""(?:\S+(?::\S*)?@)?""
    ""(?:""
    # IP address exclusion
    # private & local networks
    ""(?!(?:10|127)(?:\.\d{1,3}){3})""
    ""(?!(?:169\.254|192\.168)(?:\.\d{1,3}){2})""
    ""(?!172\.(?:1[6-9]|2\d|3[0-1])(?:\.\d{1,3}){2})""
    # IP address dotted notation octets
    # excludes loopback network 0.0.0.0
    # excludes reserved space >= 224.0.0.0
    # excludes network & broadcast addresses
    # (first & last IP address of each class)
    ""(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])""
    ""(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5])){2}""
    ""(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))""
    ""|""
    # host name
    ""(?:(?:[a-z\u00a1-\uffff0-9]-?)*[a-z\u00a1-\uffff0-9]+)""
    # domain name
    ""(?:\.(?:[a-z\u00a1-\uffff0-9]-?)*[a-z\u00a1-\uffff0-9]+)*""
    # TLD identifier
    ""(?:\.(?:[a-z\u00a1-\uffff]{2,}))""
    "")""
    # port number
    ""(?::\d{2,5})?""
    # resource path
    ""(?:/\S*)?"",
    re.UNICODE)

HASH_REGEX = r""--hash[=| ][\w]+:[\w]+""
",CWE-1333,40.0,1
"import os
import shutil
from tempfile import mkdtemp
from unittest.mock import patch

import pytest
from traitlets import Integer

from jupyter_core.application import JupyterApp, NoStart

pjoin = os.path.join


def test_basic():
    JupyterApp()


def test_default_traits():
    app = JupyterApp()
    for trait_name in app.traits():
        getattr(app, trait_name)


class DummyApp(JupyterApp):
    name = ""dummy-app""
    m = Integer(0, config=True)
    n = Integer(0, config=True)


_dummy_config = """"""
c.DummyApp.n = 10
""""""


def test_custom_config():
    app = DummyApp()
    td = mkdtemp()
    fname = pjoin(td, ""config.py"")
    with open(fname, ""w"", encoding=""utf-8"") as f:
        f.write(_dummy_config)
    app.initialize([""--config"", fname])
    shutil.rmtree(td)
    assert app.config_file == fname
    assert app.n == 10


def test_cli_override():
    app = DummyApp()
    td = mkdtemp()
    fname = pjoin(td, ""config.py"")
    with open(fname, ""w"", encoding=""utf-8"") as f:
        f.write(_dummy_config)
    app.initialize([""--config"", fname, ""--DummyApp.n=20""])
    shutil.rmtree(td)
    assert app.n == 20


def test_generate_config():
    td = mkdtemp()
    app = DummyApp(config_dir=td)
    app.initialize([""--generate-config""])
    assert app.generate_config

    with pytest.raises(NoStart):
        app.start()

    assert os.path.exists(os.path.join(td, ""dummy_app_config.py""))


def test_load_config():
    config_dir = mkdtemp()
    wd = mkdtemp()
    with open(pjoin(config_dir, ""dummy_app_config.py""), ""w"", encoding=""utf-8"") as f:
        f.write(""c.DummyApp.m = 1\n"")
        f.write(""c.DummyApp.n = 1"")
    with patch.object(os, ""getcwd"", lambda: wd):
        app = DummyApp(config_dir=config_dir)
        app.initialize([])

    assert app.n == 1, ""Loaded config from config dir""

    with open(pjoin(wd, ""dummy_app_config.py""), ""w"", encoding=""utf-8"") as f:
        f.write(""c.DummyApp.n = 2"")

    with patch.object(os, ""getcwd"", lambda: wd):
        app = DummyApp(config_dir=config_dir)
        app.initialize([])

    assert app.m == 1, ""Loaded config from config dir""
    assert app.n == 2, ""Loaded config from CWD""

    shutil.rmtree(config_dir)
    shutil.rmtree(wd)


def test_load_bad_config():
    config_dir = mkdtemp()
    wd = mkdtemp()
    with open(pjoin(config_dir, ""dummy_app_config.py""), ""w"", encoding=""utf-8"") as f:
        f.write('c.DummyApp.m = ""a\n')  # Syntax error
    with patch.object(os, ""getcwd"", lambda: wd):
        with pytest.raises(SyntaxError):
            app = DummyApp(config_dir=config_dir)
            app.raise_config_file_errors = True
            app.initialize([])

    shutil.rmtree(config_dir)
    shutil.rmtree(wd)


def test_runtime_dir_changed():
    app = DummyApp()
    td = mkdtemp()
    shutil.rmtree(td)
    app.runtime_dir = td
    assert os.path.isdir(td)
    shutil.rmtree(td)
",CWE-427,118.0,1
"# pylint: disable=unused-argument, no-self-use, avoid-list-comprehension
import difflib

from django.db.models import signals
from django.http import HttpResponseRedirect
from django.template.defaultfilters import safe
from django.utils.translation import gettext_lazy as _
from simple_history.admin import SimpleHistoryAdmin
from simple_history.models import HistoricalRecords


def diff_objects(old_instance, new_instance, fields):
    """"""
    Diff two objects by examining the given fields and
    return a string.
    """"""
    full_diff = []

    for field in fields:
        field_diff = []
        old_value = getattr(old_instance, field.attname)
        new_value = getattr(new_instance, field.attname)
        for line in difflib.unified_diff(
            str(old_value).split(""\n""),
            str(new_value).split(""\n""),
            fromfile=field.attname,
            tofile=field.attname,
            lineterm="""",
        ):
            field_diff.append(line)
        full_diff.extend(field_diff)

    return ""\n"".join(full_diff)


def history_email_for(instance, title):
    """"""
    Generate the subject and email body that is sent via
    email notifications post update!
    """"""
    history = instance.history.latest()

    subject = _(""UPDATE: %(model_name)s #%(pk)d - %(title)s"") % {
        ""model_name"": instance.__class__.__name__,
        ""pk"": instance.pk,
        ""title"": title,
    }

    body = (
        _(
            """"""Updated on %(history_date)s
Updated by %(username)s

%(diff)s

For more information:
%(instance_url)s""""""
        )
        % {
            ""history_date"": history.history_date.strftime(""%c""),
            ""username"": getattr(history.history_user, ""username"", """"),
            ""diff"": history.history_change_reason,
            ""instance_url"": instance.get_full_url(),
        }
    )
    return subject, body


class KiwiHistoricalRecords(HistoricalRecords):
    """"""
    This class will keep track of what fields were changed
    inside of the ``history_change_reason`` field. This gives us
    a crude changelog until upstream introduces their new interface.
    """"""

    def pre_save(self, instance, **kwargs):
        """"""
        Signal handlers don't have access to the previous version of
        an object so we have to load it from the database!
        """"""
        if kwargs.get(""raw"", False):
            return

        if instance.pk and hasattr(instance, ""history""):
            instance.previous = instance.__class__.objects.filter(
                pk=instance.pk
            ).first()

    def post_save(self, instance, created, using=None, **kwargs):
        """"""
        Calculate the changelog and call the inherited method to
        write the data into the database.
        """"""
        if kwargs.get(""raw"", False):
            return

        if hasattr(instance, ""previous"") and instance.previous:
            # note: simple_history.utils.update_change_reason() performs an extra
            # DB query so it is better to use the private field instead!
            # In older simple_history version this field wasn't private but was renamed
            # in 2.10.0 hence the pylint disable!
            instance._change_reason = diff_objects(  # pylint: disable=protected-access
                instance.previous, instance, self.fields_included(instance)
            )
        super().post_save(instance, created, using, **kwargs)

    def finalize(self, sender, **kwargs):
        """"""
        Connect the pre_save signal handler after calling the inherited method.
        """"""
        super().finalize(sender, **kwargs)
        signals.pre_save.connect(self.pre_save, sender=sender, weak=False)


class ReadOnlyHistoryAdmin(SimpleHistoryAdmin):
    """"""
    Custom history admin which shows all fields
    as read-only.
    """"""

    history_list_display = [""Diff""]

    def Diff(self, obj):  # pylint: disable=invalid-name
        return safe(f""<pre>{obj.history_change_reason}</pre>"")

    def get_readonly_fields(self, request, obj=None):
        # make all fields readonly
        readonly_fields = list(
            set(
                [field.name for field in self.opts.local_fields]
                + [field.name for field in self.opts.local_many_to_many]
            )
        )
        return readonly_fields

    def response_change(self, request, obj):
        super().response_change(request, obj)
        return HttpResponseRedirect(obj.get_absolute_url())
",CWE-79,139.0,1
,CWE-22,,1
"#! -*- coding: utf8 -*-
from setuptools import setup, find_packages

version = '1.7.dev0'

long_description = (
    open('README.rst').read()
    + '\n' +
    'Contributors\n'
    '============\n'
    + '\n' +
    open('CONTRIBUTORS.rst').read()
    + '\n' +
    open('CHANGES.rst').read()
    + '\n')

setup(
    name='collective.dms.basecontent',
    version=version,
    description=""Base content types for document management system"",
    long_description=long_description,
    # Get more strings from
    # http://pypi.python.org/pypi?%3Aaction=list_classifiers
    classifiers=[
        ""Development Status :: 5 - Production/Stable"",
        ""Environment :: Web Environment"",
        ""Framework :: Plone"",
        ""Framework :: Plone :: 4.2"",
        ""Framework :: Plone :: 4.3"",
        ""License :: OSI Approved :: GNU General Public License v2 (GPLv2)"",
        ""Operating System :: OS Independent"",
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 2.7"",
        ""Topic :: Software Development :: Libraries :: Python Modules"",
    ],
    keywords='document management system dms viewer',
    author='Ecreall, Entrouvert, IMIO',
    author_email='cedricmessiant@ecreall.com',
    url='https://github.com/collective/collective.dms.basecontent',
    download_url='https://pypi.org/project/collective.dms.basecontent',
    license='gpl',
    packages=find_packages('src'),
    package_dir={'': 'src'},
    namespace_packages=['collective', 'collective.dms'],
    include_package_data=True,
    zip_safe=False,
    install_requires=[
        'setuptools',
        'five.grok',
        'collective.documentviewer',
        'dexterity.localrolesfield',
        'plone.api',
        'plone.app.dexterity',
        'plone.directives.form',
        'plone.namedfile',
        'z3c.blobfile',
        'plone.app.contenttypes',
        'plone.app.relationfield',
        'plone.formwidget.contenttree',
        'plone.principalsource',
        'collective.z3cform.chosen',
        'z3c.table',
    ],
    extras_require={
        'test': ['plone.app.testing',
                 'ecreall.helpers.testing',
                 'plone.app.vocabularies'
                 ],
    },
    entry_points=""""""
    # -*- Entry points: -*-
    [z3c.autoinclude.plugin]
    target = plone
    """""",
)
",CWE-79,76.0,1
"from django.test import TestCase, override_settings

from ..models import Photo
from .factories import PhotoFactory


@override_settings(ROOT_URLCONF='photologue.tests.test_urls')
class RequestPhotoTest(TestCase):

    def setUp(self):
        super().setUp()
        self.photo = PhotoFactory(slug='fake-photo')

    def tearDown(self):
        super().tearDown()
        self.photo.delete()

    def test_archive_photo_url_works(self):
        response = self.client.get('/ptests/photo/')
        self.assertEqual(response.status_code, 200)

    def test_archive_photo_empty(self):
        """"""If there are no photo to show, tell the visitor - don't show a
        404.""""""

        Photo.objects.all().update(is_public=False)

        response = self.client.get('/ptests/photo/')
        self.assertEqual(response.status_code, 200)

        self.assertEqual(response.context['latest'].count(),
                         0)

    def test_paginated_photo_url_works(self):
        response = self.client.get('/ptests/photolist/')
        self.assertEqual(response.status_code, 200)

    def test_photo_works(self):
        response = self.client.get('/ptests/photo/fake-photo/')
        self.assertEqual(response.status_code, 200)

    def test_archive_year_photo_works(self):
        response = self.client.get('/ptests/photo/2011/')
        self.assertEqual(response.status_code, 200)

    def test_archive_month_photo_works(self):
        response = self.client.get('/ptests/photo/2011/12/')
        self.assertEqual(response.status_code, 200)

    def test_archive_day_photo_works(self):
        response = self.client.get('/ptests/photo/2011/12/23/')
        self.assertEqual(response.status_code, 200)

    def test_detail_photo_works(self):
        response = self.client.get('/ptests/photo/2011/12/23/fake-photo/')
        self.assertEqual(response.status_code, 200)
",CWE-79,57.0,1
"# -*- coding: utf-8 -*-
""""""Installer for the collective.task package.""""""

from setuptools import find_packages
from setuptools import setup


long_description = (
    open('README.rst').read()
    + '\n' +
    'Contributors\n'
    '============\n'
    + '\n' +
    open('CONTRIBUTORS.rst').read()
    + '\n' +
    open('CHANGES.rst').read()
    + '\n')


setup(
    name='collective.task',
    version='3.0.9.dev0',
    description=""Tasks management for Plone."",
    long_description=long_description,
    # Get more from http://pypi.python.org/pypi?%3Aaction=list_classifiers
    classifiers=[
        ""Environment :: Web Environment"",
        ""Framework :: Plone"",
        ""Framework :: Plone :: 4.3"",
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 2.7"",
    ],
    keywords='Plone Python',
    author='Cdric Messiant',
    author_email='cedricmessiant@ecreall.com',
    url='http://pypi.python.org/pypi/collective.task',
    license='GPL',
    packages=find_packages('src', exclude=['ez_setup']),
    namespace_packages=['collective'],
    package_dir={'': 'src'},
    include_package_data=True,
    zip_safe=False,
    install_requires=[
        'dexterity.localrolesfield',
        'plone.api',
        'plone.app.lockingbehavior',
        'plone.directives.form',
        'plone.formwidget.masterselect',
        'plone.principalsource',
        'imio.helpers',
        'imio.migrator',
        'setuptools',
        'z3c.table',
    ],
    extras_require={
        'test': [
            'collective.eeafaceted.batchactions',
            'imio.prettylink',
            'plone.app.testing',
            'plone.app.contenttypes',
            'plone.app.robotframework[debug]',
        ],
    },
    entry_points=""""""
    [z3c.autoinclude.plugin]
    target = plone
    """""",
)
",CWE-79,69.0,1
"# -*- coding: utf-8 -*-
""""""Define tables and columns.""""""

from collective.task import _
from collective.task import PMF
from collective.task.adapters import EMPTY_STRING
from plone import api
from Products.CMFPlone.utils import normalizeString
from Products.CMFPlone.utils import safe_unicode
from z3c.table.column import Column
from z3c.table.column import LinkColumn
from z3c.table.table import Table
from zope.cachedescriptors.property import CachedProperty
from zope.i18n import translate

try:
    from imio.prettylink.interfaces import IPrettyLink
except ImportError:
    pass


class TasksTable(Table):

    """"""Table that displays tasks info.""""""

    cssClassEven = u'even'
    cssClassOdd = u'odd'
    cssClasses = {'table': 'listing taskContainerListing icons-on'}

    batchSize = 20
    startBatchingAt = 30
    results = []

    @CachedProperty
    def translation_service(self):
        return api.portal.get_tool('translation_service')

    @CachedProperty
    def wtool(self):
        return api.portal.get_tool('portal_workflow')

    @CachedProperty
    def portal_url(self):
        return api.portal.get().absolute_url()

    @CachedProperty
    def values(self):
        return self.results


class UserColumn(Column):

    """"""Base user column.""""""

    field = NotImplemented

    def renderCell(self, value):
        username = getattr(value, self.field, '')
        if username and username != EMPTY_STRING:
            member = api.user.get(username)
            return member.getUser().getProperty('fullname').decode('utf-8')

        return """"


class TitleColumn(LinkColumn):

    """"""Column that displays title.""""""

    header = PMF(""Title"")
    weight = 10

    def getLinkCSS(self, item):
        return ' class=""state-%s contenttype-%s""' % (api.content.get_state(obj=item),
                                                     normalizeString(item.portal_type))

    def getLinkContent(self, item):
        return safe_unicode(item.title)


class PrettyLinkTitleColumn(TitleColumn):

    """"""Column that displays prettylink title.""""""

    header = PMF(""Title"")
    weight = 10

    params = {}

    def getPrettyLink(self, obj):
        pl = IPrettyLink(obj)
        for k, v in self.params.items():
            setattr(pl, k, v)
        return pl.getLink()

    def renderCell(self, item):
        """""" """"""
        return self.getPrettyLink(item)


class EnquirerColumn(UserColumn):

    """"""Column that displays enquirer.""""""

    header = _(""Enquirer"")
    weight = 20
    field = 'enquirer'


class AssignedGroupColumn(Column):

    """"""Column that displays assigned group.""""""

    header = _(""Assigned group"")
    weight = 30

    def renderCell(self, value):
        if value.assigned_group:
            group = api.group.get(value.assigned_group).getGroup()
            return group.getProperty('title').decode('utf-8')

        return """"


class AssignedUserColumn(UserColumn):

    """"""Column that displays assigned user.""""""

    header = _(""Assigned user"")
    weight = 40
    field = 'assigned_user'


class DueDateColumn(Column):

    """"""Column that displays due date.""""""

    header = _(""Due date"")
    weight = 50
    long_format = False
    time_only = False

    def renderCell(self, value):
        if value.due_date:
            return api.portal.get_localized_time(datetime=value.due_date, long_format=self.long_format,
                                                 time_only=self.time_only)

        return """"


class ReviewStateColumn(Column):

    """"""Column that displays value's review state.""""""

    header = PMF(""Review state"")
    weight = 60

    def renderCell(self, value):
        state = api.content.get_state(value)
        if state:
            wtool = api.portal.get_tool('portal_workflow')
            state_title = wtool.getTitleForStateOnType(state, value.portal_type)
            return translate(PMF(state_title), context=self.request)

        return ''
",CWE-79,166.0,1
"import certifi
import requests


from flask import request, session as flask_session, redirect
import flask_login
from requests_oauthlib import OAuth2Session

from app.db import with_session, DBSession
from env import QuerybookSettings
from lib.logger import get_logger
from logic.user import (
    get_user_by_name,
    create_user,
)
from .utils import (
    AuthenticationError,
    AuthUser,
    abort_unauthorized,
    QuerybookLoginManager,
)

LOG = get_logger(__file__)

OAUTH_CALLBACK_PATH = ""/oauth2callback""


class OAuthLoginManager(object):
    def __init__(self):
        self.login_manager = QuerybookLoginManager()
        self.flask_app = None

    @property
    def oauth_session(self):
        oauth_config = self.oauth_config
        return OAuth2Session(
            oauth_config[""client_id""],
            scope=oauth_config[""scope""],
            redirect_uri=oauth_config[""callback_url""],
        )

    @property
    def oauth_config(self):
        return {
            ""callback_url"": ""{}{}"".format(
                QuerybookSettings.PUBLIC_URL, OAUTH_CALLBACK_PATH
            ),
            ""client_id"": QuerybookSettings.OAUTH_CLIENT_ID,
            ""client_secret"": QuerybookSettings.OAUTH_CLIENT_SECRET,
            ""authorization_url"": QuerybookSettings.OAUTH_AUTHORIZATION_URL,
            ""token_url"": QuerybookSettings.OAUTH_TOKEN_URL,
            ""profile_url"": QuerybookSettings.OAUTH_USER_PROFILE,
            ""scope"": ""user"",
        }

    def init_app(self, flask_app):
        self.flask_app = flask_app

        self.login_manager.init_app(self.flask_app)
        self.flask_app.add_url_rule(
            OAUTH_CALLBACK_PATH, ""oauth_callback"", self.oauth_callback
        )

    def login(self, request):
        oauth_url, _ = self._get_authn_url()
        flask_session[""next""] = request.path
        return redirect(oauth_url)

    def _get_authn_url(self):
        return self.oauth_session.authorization_url(
            self.oauth_config[""authorization_url""]
        )

    def oauth_callback(self):
        LOG.debug(""Handling Oauth callback..."")

        if request.args.get(""error""):
            return f""<h1>Error: {request.args.get('error')}</h1>""

        code = request.args.get(""code"")
        try:
            access_token = self._fetch_access_token(code)
            username, email = self._get_user_profile(access_token)
            with DBSession() as session:
                flask_login.login_user(
                    AuthUser(self.login_user(username, email, session=session))
                )
        except AuthenticationError as e:
            LOG.error(""Failed authenticate oauth user"", e)
            abort_unauthorized()

        next_url = QuerybookSettings.PUBLIC_URL
        if ""next"" in flask_session:
            next_url = flask_session[""next""]
            del flask_session[""next""]

        return redirect(next_url)

    def _fetch_access_token(self, code):
        resp = self.oauth_session.fetch_token(
            token_url=self.oauth_config[""token_url""],
            client_id=self.oauth_config[""client_id""],
            code=code,
            client_secret=self.oauth_config[""client_secret""],
            cert=certifi.where(),
        )
        if resp is None:
            raise AuthenticationError(""Null response, denying access."")
        return resp[""access_token""]

    def _get_user_profile(self, access_token):
        resp = requests.get(
            self.oauth_config[""profile_url""],
            headers={""Authorization"": ""Bearer {}"".format(access_token)},
        )
        if not resp or resp.status_code != 200:
            raise AuthenticationError(
                ""Failed to fetch user profile, status ({0})"".format(
                    resp.status if resp else ""None""
                )
            )
        return self._parse_user_profile(resp)

    def _parse_user_profile(self, profile_response):
        user = profile_response.json()[""user""]
        return user[""username""], user[""email""]

    @with_session
    def login_user(self, username, email, session=None):
        if not username:
            raise AuthenticationError(""Username must not be empty!"")

        user = get_user_by_name(username, session=session)
        if not user:
            user = create_user(
                username=username, fullname=username, email=email, session=session
            )
        return user


login_manager = OAuthLoginManager()

ignore_paths = [OAUTH_CALLBACK_PATH]


def init_app(app):
    login_manager.init_app(app)


def login(request):
    return login_manager.login(request)


def oauth_authorization_url():
    return login_manager._get_authn_url()
",CWE-79,156.0,1
"import certifi
import requests
import flask_login

from app.auth.oauth_auth import OAuthLoginManager, OAUTH_CALLBACK_PATH
from app.db import with_session, DBSession
from env import QuerybookSettings, get_env_config
from flask import request, session as flask_session, redirect
from lib.logger import get_logger
from lib.utils.decorators import in_mem_memoized
from logic.user import (
    get_user_by_name,
    create_user,
)
from .utils import AuthenticationError, abort_unauthorized, AuthUser

LOG = get_logger(__file__)


class NoopAuth(requests.auth.AuthBase):
    """"""
    This auth doesn't do anything.
    It only used to override oauthlib's behavior.
    """"""

    def __call__(self, r):
        return r


class OktaLoginManager(OAuthLoginManager):
    def get_okta_urls(self):
        okta_base_url = get_env_config(""OKTA_BASE_URL"")
        authorization_url = f""{okta_base_url}/v1/authorize""
        token_url = f""{okta_base_url}/v1/token""
        profile_url = f""{okta_base_url}/v1/userinfo""
        return authorization_url, token_url, profile_url

    @property
    @in_mem_memoized()
    def oauth_config(self):
        authorization_url, token_url, profile_url = self.get_okta_urls()

        return {
            ""callback_url"": ""{}{}"".format(
                QuerybookSettings.PUBLIC_URL, OAUTH_CALLBACK_PATH
            ),
            ""client_id"": QuerybookSettings.OAUTH_CLIENT_ID,
            ""client_secret"": QuerybookSettings.OAUTH_CLIENT_SECRET,
            ""authorization_url"": authorization_url,
            ""token_url"": token_url,
            ""profile_url"": profile_url,
            ""scope"": [""openid"", ""email"", ""profile""],
        }

    def _fetch_access_token(self, code):
        resp = self.oauth_session.fetch_token(
            token_url=self.oauth_config[""token_url""],
            client_id=self.oauth_config[""client_id""],
            code=code,
            client_secret=self.oauth_config[""client_secret""],
            cert=certifi.where(),
            # This Authentication is needed because Okta would throw error
            # about passing client_secret and client_id in request.header
            # which is the default behavior of oauthlib
            auth=NoopAuth(),
        )
        if resp is None:
            raise AuthenticationError(""Null response, denying access."")
        return resp[""access_token""]

    def _get_user_profile(self, access_token):
        resp = requests.get(
            self.oauth_config[""profile_url""],
            headers={""Authorization"": ""Bearer {}"".format(access_token)},
        )
        if not resp or resp.status_code != 200:
            raise AuthenticationError(
                ""Failed to fetch user profile, status ({0})"".format(
                    resp.status if resp else ""None""
                )
            )
        return self._parse_user_profile(resp)

    def oauth_callback(self):
        LOG.debug(""Handling Oauth callback..."")

        if request.args.get(""error""):
            return f""<h1>Error: {request.args.get('error')}</h1>""

        code = request.args.get(""code"")
        try:
            access_token = self._fetch_access_token(code)
            username, email, fullname = self._get_user_profile(access_token)
            with DBSession() as session:
                flask_login.login_user(
                    AuthUser(
                        self.login_user(username, email, fullname, session=session)
                    )
                )
        except AuthenticationError as e:
            LOG.error(""Failed authenticate oauth user"", e)
            abort_unauthorized()

        next_url = QuerybookSettings.PUBLIC_URL
        if ""next"" in flask_session:
            next_url = flask_session[""next""]
            del flask_session[""next""]

        return redirect(next_url)

    def _parse_user_profile(self, resp):
        user = resp.json()
        username = user[""email""].split(""@"")[0]
        return username, user[""email""], user[""name""]

    @with_session
    def login_user(self, username, email, fullname, session=None):
        if not username:
            raise AuthenticationError(""Username must not be empty!"")

        user = get_user_by_name(username, session=session)
        if not user:
            user = create_user(
                username=username, fullname=fullname, email=email, session=session
            )
        return user


login_manager = OktaLoginManager()

ignore_paths = [OAUTH_CALLBACK_PATH]


def init_app(app):
    login_manager.init_app(app)


def login(request):
    return login_manager.login(request)
",CWE-79,140.0,1
"# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.
#
# Licensed under the MIT License. See the LICENSE accompanying this file
# for the specific language governing permissions and limitations under
# the License.

import random
import socket
from unittest.mock import MagicMock

import pytest

import mount_efs

from .. import utils

try:
    import ConfigParser
except ImportError:
    from configparser import ConfigParser

DEFAULT_TLS_PORT_RANGE_LOW = 20049
DEFAULT_TLS_PORT_RANGE_HIGH = 21049
DEFAULT_TLS_PORT = random.randrange(
    DEFAULT_TLS_PORT_RANGE_LOW, DEFAULT_TLS_PORT_RANGE_HIGH
)


def _get_config():
    try:
        config = ConfigParser.SafeConfigParser()
    except AttributeError:
        config = ConfigParser()
    config.add_section(mount_efs.CONFIG_SECTION)
    config.set(
        mount_efs.CONFIG_SECTION,
        ""port_range_lower_bound"",
        str(DEFAULT_TLS_PORT_RANGE_LOW),
    )
    config.set(
        mount_efs.CONFIG_SECTION,
        ""port_range_upper_bound"",
        str(DEFAULT_TLS_PORT_RANGE_HIGH),
    )
    return config


def test_choose_tls_port_first_try(mocker):
    sock_mock = MagicMock()
    sock_mock.getsockname.return_value = (""local_host"", DEFAULT_TLS_PORT)
    mocker.patch(""socket.socket"", return_value=sock_mock)
    options = {}

    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)
    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)
    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH


def test_choose_tls_port_second_try(mocker):
    bad_sock = MagicMock()
    bad_sock.bind.side_effect = [socket.error, None]
    bad_sock.getsockname.return_value = (""local_host"", DEFAULT_TLS_PORT)
    options = {}

    mocker.patch(""socket.socket"", return_value=bad_sock)

    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)
    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)

    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH
    assert 2 == bad_sock.bind.call_count
    assert 1 == bad_sock.getsockname.call_count


def test_choose_tls_port_never_succeeds(mocker, capsys):
    bad_sock = MagicMock()
    bad_sock.bind.side_effect = socket.error()
    options = {}

    mocker.patch(""socket.socket"", return_value=bad_sock)

    with pytest.raises(SystemExit) as ex:
        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)

    assert 0 != ex.value.code

    out, err = capsys.readouterr()
    assert ""Failed to locate an available port"" in err

    assert (
        DEFAULT_TLS_PORT_RANGE_HIGH - DEFAULT_TLS_PORT_RANGE_LOW
        == bad_sock.bind.call_count
    )


def test_choose_tls_port_option_specified(mocker):
    sock_mock = MagicMock()
    sock_mock.getsockname.return_value = (""local_host"", DEFAULT_TLS_PORT)
    mocker.patch(""socket.socket"", return_value=sock_mock)
    options = {""tlsport"": DEFAULT_TLS_PORT}

    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)
    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)

    assert DEFAULT_TLS_PORT == tls_port


def test_choose_tls_port_option_specified_unavailable(mocker, capsys):
    bad_sock = MagicMock()
    bad_sock.bind.side_effect = socket.error()
    options = {""tlsport"": 1000}

    mocker.patch(""socket.socket"", return_value=bad_sock)

    with pytest.raises(SystemExit) as ex:
        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)

    assert 0 != ex.value.code

    out, err = capsys.readouterr()
    assert ""Specified port [1000] is unavailable"" in err

    assert 1 == bad_sock.bind.call_count


def test_choose_tls_port_under_netns(mocker, capsys):
    mocker.patch(""builtins.open"")
    setns_mock = mocker.patch(""mount_efs.setns"", return_value=(None, None))
    mocker.patch(""socket.socket"", return_value=MagicMock())
    options = {""netns"": ""/proc/1000/ns/net""}

    mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)
    utils.assert_called(setns_mock)


def test_verify_tls_port(mocker):
    sock = MagicMock()
    sock.connect.side_effect = [ConnectionRefusedError, None]
    mocker.patch(""socket.socket"", return_value=sock)
    result = mount_efs.verify_tlsport_can_be_connected(1000)
    assert result is False
    result = mount_efs.verify_tlsport_can_be_connected(1000)
    assert result is True
    assert 2 == sock.connect.call_count
",CWE-362,145.0,1
"# import stuff
import logging
FORMAT = '%(levelname)s | TIME - %(asctime)s | PROCESS - %(processName)s %(process)d | MSG - %(message)s'
logging.basicConfig(filename='LiuOS.log', encoding='utf-8', level=logging.DEBUG, format=FORMAT)
logging.debug(""Created logging config"")
import api
logging.debug(f""Loaded LiuOS API {api.VerAPI}"")
import hashlib
logging.debug(""Imported hashlib"")
import getpass
logging.debug(""Imported getpass"")
import lang
logging.debug(f""Loaded LiuOS {lang.CURRENT_LANG}"")
import cred
logging.debug(""Imported cred.py"")
import os
logging.debug(""Imported os"")
import sys
logging.debug(""Imported sys"")
import cmd
logging.debug(""Imported cmd"")
import runpy
logging.debug(""Imported runpy"")

class LiuShell(cmd.Cmd):
    intro = lang.SHELL_INTRO
    prompt = 'LiuOS: '
    file = None

    # ----- LiuOS Shell commands -----
    def do_runcmd(self, arg):
        'Runs the host shell command specified. Ex: runcmd echo'
        logging.info(""Running command using runcmd in shell"")
        os.system(arg)
    def do_runline(self, arg):
        'Runs the Python line specified. Ex: runline print(""hello"")'
        logging.info(""Running Python code using runline in shell"")
        exec(arg)
    def do_run(self, arg):
        'Runs the script specified, it must be in the programs dir in the same dir as LiuOS and exist, or Python will crash. Ex: run eteled.py'
        logging.info(f""Running Python file using run in shell"")
        runpy.run_path(path_name=""programs/{arg}"")
    def do_clear(self, arg):
        'Clears the terminal'
        os.system('cls' if os.name == 'nt' else 'clear')
    def do_logout(self, arg):
        'Closes the shell. Ex: logout'
        logging.warning(""Logging out shell session"")
        print('Logging out...')
        self.close()
        return True
    def do_shutdown(self, arg):
        'Closes the shell, and quits the script. Ex: shutdown'
        print('Logging out...')
        logging.info(""Shut down using shell command"")
        exit()
        return True

    # ----- record and playback -----
    def do_savecmd(self, arg):
        'Save future commands to filename:  RECORD rose.cmd'
        self.file = open(arg, 'w')
    def do_opencmd(self, arg):
        'Playback commands from a file:  PLAYBACK rose.cmd'
        self.close()
        with open(arg) as f:
            self.cmdqueue.extend(f.read().splitlines())
    def precmd(self, line):
        line = line.lower()
        if self.file and 'playback' not in line:
            print(line, file=self.file)
        return line
    def close(self):
        if self.file:
            self.file.close()
            self.file = None

def parse(arg):
    'Convert a series of zero or more numbers to an argument tuple'
    return tuple(map(int, arg.split()))
# Counter
attemps = 0
def actualsys() :
        logging.debug(""Launched main system"")
        os.system('cls' if os.name == 'nt' else 'clear')
        logging.debug(""Loaded LiuOS Shell"")
        LiuShell().cmdloop()
logging.debug(""Assigned main system function"")
if os.environ.get('GITHUB_ACTIONS') == ""true"":
        logging.info('Running on GitHub Actions, not using the LiuOS Shell')
        print(lang.ENTER_USERNAME_LOGIN)
        print(lang.ENTER_PASSWD_LOGIN)
        print(lang.FAKE_SUCCESSFUL_LOGIN)
        logging.warning(""Fake login completed"")
        print(lang.SHELL_INTRO)
        print(lang.SAMPLE_ABC)
        print(lang.SAMPLE_STRING)
        TestProg = ""programs/helloworld.py""
        runpy.run_path(path_name=TestProg)
        print(""Code completed"")
else:
 # Authentication system

       while attemps < 7:
        username = input(lang.ENTER_USERNAME_LOGIN)
        logging.debug('Entered username')
        password = getpass.getpass(lang.ENTER_PASSWD_LOGIN)
        logging.debug('Entered password')
        bytehash = hashlib.sha512(password.encode())
        pwdreshash = bytehash.hexdigest()
        logging.debug('Generated hash of password')
        if attemps == 6:
        ## Brute force protection
           raise Exception(""Too many password attempts. Because of the risk of a brute force attack, after 6 attempts, you will need to rerun LiuOS to try 6 more times."")
        if os.environ.get('GITHUB_ACTIONS') != """":
            logging.warning(""Running on Github Actions"")
            actualsys()
        elif username == cred.loginname and pwdreshash == cred.loginpass:
            print(lang.SUCCESSFUL_LOGIN)
            logging.debug('Correct login credentials, logged in')
            actualsys()
        else:
            print(lang.INCORRECT_LOGIN)
            logging.error(""Incorrect login credentials"")
            attemps += 1
            continue
        
",CWE-639,128.0,1
"from django.http import HttpResponseBadRequest
from graphite.logger import log


class NormalizeEmptyResultError(Exception):
    # throw error for normalize() when empty
    pass


class InputParameterError(ValueError):

    def __init__(self, *args, **kwargs):
        super(InputParameterError, self).__init__(*args, **kwargs)
        self.context = {}

    def setSourceIdHeaders(self, newHeaders):
        headers = self.context.get('sourceIdHeaders', {})
        headers.update(newHeaders)
        self.context['sourceIdHeaders'] = headers

    @property
    def sourceIdHeaders(self):
        sourceIdHeaders = self.context.get('sourceIdHeaders', {})
        headers = list(sourceIdHeaders.keys())
        headers.sort()
        source = ''

        for name in headers:
            if source:
                source += ', '
            source += '{name}: {value}'.format(
                name=name,
                value=sourceIdHeaders[name])

        return source

    def setTargets(self, targets):
        self.context['targets'] = targets

    @property
    def targets(self):
        return ', '.join(self.context.get('targets', []))

    def setFunction(self, name, args, kwargs):
        self.context['function'] = {
            'name': name,
            'args': args,
            'kwargs': kwargs,
        }

    @property
    def function(self):
        func = self.context.get('function', None)
        if not func:
            return ''

        funcName = func.get('name', '')
        if not funcName:
            return ''

        kwargs = func.get('kwargs', {})
        kwargKeys = list(kwargs.keys())

        # keep kwargs sorted in message, for consistency and testability
        kwargKeys.sort()

        # generate string of args and kwargs
        args = ', '.join(
            argList
            for argList in [
                ', '.join(repr(arg) for arg in func.get('args', [])),
                ', '.join('{k}={v}'.format(k=str(k), v=repr(kwargs[k])) for k in kwargKeys),
            ] if argList
        )

        return '{func}({args})'.format(func=funcName, args=args)

    def __str__(self):
        msg = 'Invalid parameters ({msg})'.format(msg=str(super(InputParameterError, self).__str__()))
        targets = self.targets
        if targets:
            msg += '; targets: ""{targets}""'.format(targets=targets)

        source = self.sourceIdHeaders
        if source:
            msg += '; source: ""{source}""'.format(source=source)

        # needs to be last because the string ""args"" may potentially be thousands
        # of chars long after expanding the globbing patterns
        func = self.function
        if func:
            msg += '; func: ""{func}""'.format(func=func)

        return msg


# Replace special characters ""&"", ""<"" and "">"" to HTML-safe sequences.
def escape(s):
    s = s.replace(""&"", ""&amp;"")  # Must be done first!
    s = s.replace(""<"", ""&lt;"")
    s = s.replace("">"", ""&gt;"")

    return s


# decorator which turns InputParameterExceptions into Django's HttpResponseBadRequest
def handleInputParameterError(f):
    def new_f(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except InputParameterError as e:
            msgStr = str(e)
            log.warning('%s', msgStr)
            return HttpResponseBadRequest(escape(msgStr))

    return new_f
",CWE-79,117.0,1
"from django.test import TestCase as OriginalTestCase
from graphite.worker_pool.pool import stop_pools


class TestCase(OriginalTestCase):
    def tearDown(self):
        stop_pools()

    # Assert that a response is unsanitized (for check XSS issues)
    def assertXSS(self, response, status_code=200, msg_prefix=''):
        if status_code is not None:
            self.assertEqual(
                response.status_code, status_code,
                msg_prefix + ""Couldn't retrieve content: Response code was %d""
                "" (expected %d)"" % (response.status_code, status_code)
            )

        xss = response.content.find(b""<"") != -1 or response.content.find(b"">"") != -1
        self.assertFalse(xss, msg=msg_prefix+str(response.content))
",CWE-79,20.0,1
"import sshpubkeys
from sqlalchemy.exc import IntegrityError

from grouper.models.counter import Counter
from grouper.models.public_key import PublicKey
from grouper.plugin import get_plugin_proxy
from grouper.plugin.exceptions import PluginRejectedPublicKey


class DuplicateKey(Exception):
    pass


class PublicKeyParseError(Exception):
    pass


class BadPublicKey(Exception):
    pass


class KeyNotFound(Exception):
    """"""Particular user's specific key was not found.""""""

    def __init__(self, key_id, user_id):
        # type: (int, int) -> None
        self.key_id = key_id
        self.user_id = user_id


def get_public_key(session, user_id, key_id):
    """"""Retrieve specific public key for user.

    Args:
        session(models.base.session.Session): database session
        user_id(int): id of user in question
        key_id(int): id of the user's key we want to delete

    Throws:
        KeyNotFound if specified key wasn't found

    Returns:
        PublicKey model object representing the key
    """"""
    pkey = session.query(PublicKey).filter_by(id=key_id, user_id=user_id).scalar()
    if not pkey:
        raise KeyNotFound(key_id=key_id, user_id=user_id)

    return pkey


def add_public_key(session, user, public_key_str):
    """"""Add a public key for a particular user.

    Args:
        session: db session
        user: User model of user in question
        public_key_str: public key to add

    Throws:
        DuplicateKey if key is already in use
        PublicKeyParseError if key can't be parsed
        BadPublicKey if a plugin rejects the key

    Returns:
        PublicKey model object representing the key
    """"""
    pubkey = sshpubkeys.SSHKey(public_key_str, strict=True)

    try:
        pubkey.parse()
    except sshpubkeys.InvalidKeyException as e:
        raise PublicKeyParseError(str(e))

    try:
        get_plugin_proxy().will_add_public_key(pubkey)
    except PluginRejectedPublicKey as e:
        raise BadPublicKey(str(e))

    db_pubkey = PublicKey(
        user=user,
        public_key=pubkey.keydata.strip(),
        fingerprint=pubkey.hash_md5().replace(""MD5:"", """"),
        fingerprint_sha256=pubkey.hash_sha256().replace(""SHA256:"", """"),
        key_size=pubkey.bits,
        key_type=pubkey.key_type,
        comment=pubkey.comment,
    )

    try:
        db_pubkey.add(session)
        Counter.incr(session, ""updates"")
    except IntegrityError:
        session.rollback()
        raise DuplicateKey()

    session.commit()

    return db_pubkey


def delete_public_key(session, user_id, key_id):
    """"""Delete a particular user's public key.

    Args:
        session(models.base.session.Session): database session
        user_id(int): id of user in question
        key_id(int): id of the user's key we want to delete

    Throws:
        KeyNotFound if specified key wasn't found
    """"""
    pkey = get_public_key(session, user_id, key_id)
    pkey.delete(session)
    Counter.incr(session, ""updates"")
    session.commit()


def get_public_keys_of_user(session, user_id):
    """"""Retrieve all public keys for user.

    Args:
        session(models.base.session.Session): database session
        user_id(int): id of user in question

    Returns:
        List of PublicKey model object representing the keys
    """"""
    pkey = session.query(PublicKey).filter_by(user_id=user_id).all()
    return pkey
",CWE-74,131.0,1
"import pytest
from mock import patch

from grouper.plugin.base import BasePlugin
from grouper.plugin.exceptions import PluginRejectedPublicKey
from grouper.plugin.proxy import PluginProxy
from grouper.public_key import (
    add_public_key,
    BadPublicKey,
    DuplicateKey,
    get_public_keys_of_user,
    PublicKeyParseError,
)
from tests.constants import SSH_KEY_1, SSH_KEY_BAD
from tests.fixtures import session, users  # noqa: F401


class PublicKeyPlugin(BasePlugin):
    def will_add_public_key(self, key):
        raise PluginRejectedPublicKey()


def test_duplicate_key(session, users):  # noqa: F811
    user = users[""cbguder@a.co""]

    add_public_key(session, user, SSH_KEY_1)
    assert len(get_public_keys_of_user(session, user.id)) == 1

    with pytest.raises(DuplicateKey):
        add_public_key(session, user, SSH_KEY_1)

    assert len(get_public_keys_of_user(session, user.id)) == 1


def test_bad_key(session, users):  # noqa: F811
    user = users[""cbguder@a.co""]

    with pytest.raises(PublicKeyParseError):
        add_public_key(session, user, SSH_KEY_BAD)

    assert get_public_keys_of_user(session, user.id) == []


@patch(""grouper.public_key.get_plugin_proxy"")
def test_rejected_key(get_plugin_proxy, session, users):  # noqa: F811
    get_plugin_proxy.return_value = PluginProxy([PublicKeyPlugin()])

    user = users[""cbguder@a.co""]

    with pytest.raises(BadPublicKey):
        add_public_key(session, user, SSH_KEY_1)

    assert get_public_keys_of_user(session, user.id) == []
",CWE-74,54.0,1
"# -*- coding: utf-8 -*-

import random
import socket
import string

import js2py

from .check import is_mapping


def random_string(length):
    seq = string.ascii_letters + string.digits + string.punctuation
    return """".join(random.choice(seq) for _ in range(length))


def is_plural(value):
    try:
        n = abs(float(value))
        return n == 0 or n > 1
    except ValueError:
        return value.endswith(""s"")  # TODO: detect uncommon plurals


def eval_js(script, es6=False):
    # return requests_html.HTML().render(script=script, reload=False)
    return (js2py.eval_js6 if es6 else js2py.eval_js)(script)


def accumulate(iterable, to_map=None):
    """"""
    Accumulate (key, value) data to {value : [key]} dictionary.
    """"""
    if to_map is None:
        to_map = {}
    for key, value in iterable:
        to_map.setdefault(value, []).append(key)
    return to_map


def reversemap(obj):
    """"""
    Invert mapping object preserving type and ordering.
    """"""
    return obj.__class__(reversed(item) for item in obj.items())


# def get_translation(domain, localedir=None, languages=None, class_=None,
# fallback=False, codeset=None):
# try:
# trans = gettext.translation(
# domain, localedir, languages, class_, False, codeset)
# except (IOError, OSError):
# if not fallback:
# raise
# trans = gettext.translation(
# domain, localedir, None, class_, fallback, codeset)
# return trans


# def install_translation(domain, localedir=None, languages=None,
# class_=None, fallback=False, codeset=None):
# trans = get_translation(
# domain, localedir, languages, class_, fallback, codeset)
# try:
# trans.install(str=True)
# except TypeError:
# trans.install()
",CWE-94,69.0,1
"# -*- coding: utf-8 -*-
#       ____________
#   ___/       |    \_____________ _                 _ ___
#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \
# /    \___/  ______/   | '_ \ || | |__/ _ \/ _` / _` |    \
# \             |      | .__/\_, |____\___/\__,_\__,_|    /
#  \_______\    /_______|_|   |__/________________________/
#           \  /
#            \/

import os

import flask
import jinja2
from werkzeug.serving import WSGIRequestHandler

from .blueprints import BLUEPRINTS
from .config import get_default_config
from .extensions import EXTENSIONS, THEMES
from .filters import TEMPLATE_FILTERS
from .globals import TEMPLATE_GLOBALS
from .handlers import ERROR_HANDLERS
from .helpers import JSONEncoder
from .processors import CONTEXT_PROCESSORS


#: flask app singleton?
class App:

    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS
    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS
    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS
    FLASK_ERROR_HANDLERS = ERROR_HANDLERS
    FLASK_BLUEPRINTS = BLUEPRINTS
    FLASK_EXTENSIONS = EXTENSIONS
    FLASK_THEMES = THEMES


    @classmethod
    def _configure_config(cls, app, develop):
        conf_obj = get_default_config(develop)
        app.config.from_object(conf_obj)

    @classmethod
    def _configure_blueprints(cls, app, path_prefix):
        for blueprint in cls.FLASK_BLUEPRINTS:
            url_prefix = path_prefix if not blueprint.url_prefix else None
            app.register_blueprint(blueprint, url_prefix=url_prefix)

    @classmethod
    def _configure_extensions(cls, app):
        for extension in cls.FLASK_EXTENSIONS:
            extension.init_app(app)

    @classmethod
    def _configure_themes(cls, app, path_prefix=""""):
        for theme in cls.FLASK_THEMES:
            theme.init_app(app, path_prefix)

    @classmethod
    def _configure_handlers(cls, app):
        """"""
        Register error handlers.
        """"""
        for exc, fn in cls.FLASK_ERROR_HANDLERS:
            app.register_error_handler(exc, fn)

    @classmethod
    def _configure_json_encoding(cls, app):
        app.json_encoder = JSONEncoder

    @classmethod
    def _configure_templating(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""jinja"")

        os.makedirs(cache_path, exist_ok=True)

        app.create_jinja_environment()

        # NOTE: enable autoescape for all file extensions (included .js)
        #       maybe this will break .txt rendering, but we don't render this kind of files actually
        #       that does not change 'default_for_string=False' (by default)
        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)
        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)

        for fn in cls.JINJA_TEMPLATE_FILTERS:
            app.add_template_filter(fn)

        for fn in cls.JINJA_TEMPLATE_GLOBALS:
            app.add_template_global(fn)

        for fn in cls.JINJA_CONTEXT_PROCESSORS:
            app.context_processor(fn)

    @classmethod
    def _configure_session(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""flask"")
        os.makedirs(cache_path, exist_ok=True)

        app.config[""SESSION_FILE_DIR""] = cache_path
        app.config[""SESSION_TYPE""] = ""filesystem""
        app.config[""SESSION_COOKIE_NAME""] = ""pyload_session""
        app.config[""SESSION_PERMANENT""] = False

        session_lifetime = max(app.config[""PYLOAD_API""].get_config_value(""webui"", ""session_lifetime""), 1) * 60
        app.config[""PERMANENT_SESSION_LIFETIME""] = session_lifetime

    @classmethod
    def _configure_api(cls, app, pycore):
        app.config[""PYLOAD_API""] = pycore.api

    @classmethod
    def _configure_logging(cls, app, pycore):
        # Inject our custom logger
        app.logger = pycore.log.getChild(""webui"")

    def __new__(cls, pycore, develop=False, path_prefix=None):
        app = flask.Flask(__name__)

        cls._configure_logging(app, pycore)
        cls._configure_api(app, pycore)
        cls._configure_config(app, develop)
        cls._configure_templating(app)
        cls._configure_json_encoding(app)
        cls._configure_session(app)
        cls._configure_blueprints(app, path_prefix)
        cls._configure_extensions(app)
        cls._configure_themes(app, path_prefix or """")
        cls._configure_handlers(app)

        WSGIRequestHandler.protocol_version = ""HTTP/1.1""

        return app
",CWE-319,136.0,1
"# -*- coding: utf-8 -*-
#       ____________
#   ___/       |    \_____________ _                 _ ___
#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \
# /    \___/  ______/   | '_ \ || | |__/ _ \/ _` / _` |    \
# \             |      | .__/\_, |____\___/\__,_\__,_|    /
#  \_______\    /_______|_|   |__/________________________/
#           \  /
#            \/

import os

import flask
import jinja2
from werkzeug.serving import WSGIRequestHandler

from .blueprints import BLUEPRINTS
from .config import get_default_config
from .extensions import EXTENSIONS, THEMES
from .filters import TEMPLATE_FILTERS
from .globals import TEMPLATE_GLOBALS
from .handlers import ERROR_HANDLERS
from .helpers import JSONEncoder
from .processors import CONTEXT_PROCESSORS


#: flask app singleton?
class App:

    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS
    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS
    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS
    FLASK_ERROR_HANDLERS = ERROR_HANDLERS
    FLASK_BLUEPRINTS = BLUEPRINTS
    FLASK_EXTENSIONS = EXTENSIONS
    FLASK_THEMES = THEMES


    @classmethod
    def _configure_config(cls, app, develop):
        conf_obj = get_default_config(develop)
        app.config.from_object(conf_obj)

    @classmethod
    def _configure_blueprints(cls, app, path_prefix):
        for blueprint in cls.FLASK_BLUEPRINTS:
            url_prefix = path_prefix if not blueprint.url_prefix else None
            app.register_blueprint(blueprint, url_prefix=url_prefix)

    @classmethod
    def _configure_extensions(cls, app):
        for extension in cls.FLASK_EXTENSIONS:
            extension.init_app(app)

    @classmethod
    def _configure_themes(cls, app, path_prefix=""""):
        for theme in cls.FLASK_THEMES:
            theme.init_app(app, path_prefix)

    @classmethod
    def _configure_handlers(cls, app):
        """"""
        Register error handlers.
        """"""
        for exc, fn in cls.FLASK_ERROR_HANDLERS:
            app.register_error_handler(exc, fn)

    @classmethod
    def _configure_json_encoding(cls, app):
        app.json_encoder = JSONEncoder

    @classmethod
    def _configure_templating(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""jinja"")

        os.makedirs(cache_path, exist_ok=True)

        app.create_jinja_environment()

        # NOTE: enable auto escape for all file extensions (including .js)
        #       maybe this will break .txt rendering, but we don't render this kind of files actually
        #       that does not change 'default_for_string=False' (by default)
        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)
        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)

        for fn in cls.JINJA_TEMPLATE_FILTERS:
            app.add_template_filter(fn)

        for fn in cls.JINJA_TEMPLATE_GLOBALS:
            app.add_template_global(fn)

        for fn in cls.JINJA_CONTEXT_PROCESSORS:
            app.context_processor(fn)

    @classmethod
    def _configure_session(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""flask"")
        os.makedirs(cache_path, exist_ok=True)

        app.config[""SESSION_FILE_DIR""] = cache_path
        app.config[""SESSION_TYPE""] = ""filesystem""
        app.config[""SESSION_COOKIE_NAME""] = ""pyload_session""
        app.config[""SESSION_COOKIE_SECURE""] = app.config[""PYLOAD_API""].get_config_value(""webui"", ""use_ssl"")
        app.config[""SESSION_PERMANENT""] = False

        session_lifetime = max(app.config[""PYLOAD_API""].get_config_value(""webui"", ""session_lifetime""), 1) * 60
        app.config[""PERMANENT_SESSION_LIFETIME""] = session_lifetime

    @classmethod
    def _configure_api(cls, app, pycore):
        app.config[""PYLOAD_API""] = pycore.api

    @classmethod
    def _configure_logging(cls, app, pycore):
        # Inject our custom logger
        app.logger = pycore.log.getChild(""webui"")

    def __new__(cls, pycore, develop=False, path_prefix=None):
        app = flask.Flask(__name__)

        cls._configure_logging(app, pycore)
        cls._configure_api(app, pycore)
        cls._configure_config(app, develop)
        cls._configure_templating(app)
        cls._configure_json_encoding(app)
        cls._configure_session(app)
        cls._configure_blueprints(app, path_prefix)
        cls._configure_extensions(app)
        cls._configure_themes(app, path_prefix or """")
        cls._configure_handlers(app)

        WSGIRequestHandler.protocol_version = ""HTTP/1.1""

        return app
",CWE-1021,137.0,1
"# -*- coding: utf-8 -*-

import hashlib
import os

from ..utils.struct.style import style


# TODO: rewrite using scrypt or argon2_cffi
def _salted_password(password, salt):
    dk = hashlib.pbkdf2_hmac(""sha256"", password.encode(), bytes.fromhex(salt), 100000)
    return salt + dk.hex()


def _gensalt():
    return os.urandom(16).hex()


def _check_password(hashed, clear):
    salt = hashed[:32]
    to_compare = _salted_password(clear, salt)

    return hashed == to_compare


class UserDatabaseMethods:
    @style.queue
    def check_auth(self, user, password):
        self.c.execute(
            ""SELECT id, name, password, role, permission, template, email FROM users WHERE name=?"",
            (user,),
        )
        r = self.c.fetchone()
        if not r:
            return {}

        stored_password = r[2]
        if not _check_password(stored_password, password):
            return {}

        return {
            ""id"": r[0],
            ""name"": r[1],
            ""role"": r[3],
            ""permission"": r[4],
            ""template"": r[5],
            ""email"": r[6],
        }

    @style.queue
    def add_user(self, user, password, role=0, perms=0, reset=False):
        salt_pw = _salted_password(password, _gensalt())

        self.c.execute(""SELECT name FROM users WHERE name=?"", (user,))
        if self.c.fetchone() is not None:
            if reset:
                self.c.execute(
                    ""UPDATE users SET password=?, role=?, permission=? WHERE name=?"",
                    (salt_pw, role, perms, user),
                )
                return True
            else:
                return False
        else:
            self.c.execute(
                ""INSERT INTO users (name, password, role, permission) VALUES (?, ?, ?, ?)"",
                (user, salt_pw, role, perms),
            )
            return True

    @style.queue
    def change_password(self, user, old_password, new_password):
        self.c.execute(""SELECT id, name, password FROM users WHERE name=?"", (user,))
        r = self.c.fetchone()
        if not r:
            return False

        stored_password = r[2]
        if not _check_password(stored_password, old_password):
            return False

        newpw = _salted_password(new_password, _gensalt())

        self.c.execute(""UPDATE users SET password=? WHERE name=?"", (newpw, user))
        return True

    @style.async_
    def set_permission(self, user, perms):
        self.c.execute(""UPDATE users SET permission=? WHERE name=?"", (perms, user))

    @style.async_
    def set_role(self, user, role):
        self.c.execute(""UPDATE users SET role=? WHERE name=?"", (role, user))

    @style.queue
    def list_users(self):
        self.c.execute(""SELECT name FROM users"")
        users = []
        for row in self.c:
            users.append(row[0])
        return users

    @style.queue
    def get_all_user_data(self):
        self.c.execute(""SELECT id, name, permission, role, template, email FROM users"")
        user = {}
        for r in self.c:
            user[r[0]] = {
                ""name"": r[1],
                ""permission"": r[2],
                ""role"": r[3],
                ""template"": r[4],
                ""email"": r[5],
            }

        return user

    @style.queue
    def remove_user(self, user):
        self.c.execute(""DELETE FROM users WHERE name=?"", (user,))
",CWE-613,121.0,1
"# -*- coding: utf-8 -*-

from threading import Lock

from ..utils.struct.lock import lock
from .browser import Browser
from .bucket import Bucket
from .cookie_jar import CookieJar
from .http.http_request import HTTPRequest
from .xdcc.request import XDCCRequest

DEFAULT_REQUEST = None


class RequestFactory:
    def __init__(self, core):
        self.lock = Lock()
        self.pyload = core
        self._ = core._
        self.bucket = Bucket()
        self.update_bucket()
        self.cookiejars = {}

        # TODO: Rewrite...
        global DEFAULT_REQUEST
        if not DEFAULT_REQUEST:
            DEFAULT_REQUEST = self

    def iface(self):
        return self.pyload.config.get(""download"", ""interface"")

    @lock
    def get_request(self, plugin_name, account=None, type=""HTTP"", **kwargs):
        options = self.get_options()
        options.update(kwargs)  #: submit kwargs as additional options

        if type == ""XDCC"":
            req = XDCCRequest(self.bucket, options)

        else:
            req = Browser(self.bucket, options)

            if account:
                cj = self.get_cookie_jar(plugin_name, account)
            else:
                cj = CookieJar(plugin_name)

            req.set_cookie_jar(cj)

        return req

    def get_http_request(self, **kwargs):
        """"""
        returns a http request, dont forget to close it !
        """"""
        options = self.get_options()
        options.update(kwargs)  #: submit kwargs as additional options
        return HTTPRequest(CookieJar(None), options)

    def get_url(self, *args, **kwargs):
        """"""
        see HTTPRequest for argument list.
        """"""
        with HTTPRequest(None, self.get_options()) as h:
            rep = h.load(*args, **kwargs)
        return rep

    def get_cookie_jar(self, plugin_name, account=None):
        if (plugin_name, account) in self.cookiejars:
            return self.cookiejars[(plugin_name, account)]

        cj = CookieJar(plugin_name, account)
        self.cookiejars[(plugin_name, account)] = cj
        return cj

    def get_proxies(self):
        """"""
        returns a proxy list for the request classes.
        """"""
        if not self.pyload.config.get(""proxy"", ""enabled""):
            return {}
        else:
            proxy_type = self.pyload.config.get(""proxy"", ""type"").lower()

            username = None
            if (
                self.pyload.config.get(""proxy"", ""username"")
                and self.pyload.config.get(""proxy"", ""username"").lower() != ""none""
            ):
                username = self.pyload.config.get(""proxy"", ""username"")

            pw = None
            if (
                self.pyload.config.get(""proxy"", ""password"")
                and self.pyload.config.get(""proxy"", ""password"").lower() != ""none""
            ):
                pw = self.pyload.config.get(""proxy"", ""password"")

            return {
                ""type"": proxy_type,
                ""host"": self.pyload.config.get(""proxy"", ""host""),
                ""port"": self.pyload.config.get(""proxy"", ""port""),
                ""username"": username,
                ""password"": pw,
            }

    def get_options(self):
        """"""
        returns options needed for pycurl.
        """"""
        return {
            ""interface"": self.iface(),
            ""proxies"": self.get_proxies(),
            ""ipv6"": self.pyload.config.get(""download"", ""ipv6""),
        }

    def update_bucket(self):
        """"""
        set values in the bucket according to settings.
        """"""
        if not self.pyload.config.get(""download"", ""limit_speed""):
            self.bucket.set_rate(-1)
        else:
            self.bucket.set_rate(self.pyload.config.get(""download"", ""max_speed"") << 10)


def get_url(*args, **kwargs):
    return DEFAULT_REQUEST.get_url(*args, **kwargs)


def get_request(*args, **kwargs):
    return DEFAULT_REQUEST.get_http_request()
",CWE-295,133.0,1
"# -*- coding: utf-8 -*-

import traceback
from ast import literal_eval
from itertools import chain
from logging import getLogger
from urllib.parse import unquote

import flask
from flask.json import jsonify
from pyload import APPID

from ..helpers import clear_session, set_session

bp = flask.Blueprint(""api"", __name__)
log = getLogger(APPID)


# accepting positional arguments, as well as kwargs via post and get
# @bottle.route(
@bp.route(""/api/<func>"", methods=[""GET"", ""POST""], endpoint=""rpc"")
@bp.route(""/api/<func>/<args>"", methods=[""GET"", ""POST""], endpoint=""rpc"")
# @apiver_check
def rpc(func, args=""""):
    api = flask.current_app.config[""PYLOAD_API""]

    if flask.request.authorization:
        user = flask.request.authorization.get(""username"", """")
        password = flask.request.authorization.get(""password"", """")
    else:
        user = flask.request.form.get(""u"", """")
        password = flask.request.form.get(""p"", """")

    if user:
        user_info = api.check_auth(user, password)
        s = set_session(user_info)
    else:
        s = flask.session

    if (
            ""role"" not in s or
            ""perms"" not in s or
            not api.is_authorized(func, {""role"": s[""role""], ""permission"": s[""perms""]})
    ):
        return jsonify({'error': ""Unauthorized""}), 401

    args = args.split("","")
    if len(args) == 1 and not args[0]:
        args = []

    kwargs = {}

    for x, y in chain(flask.request.args.items(), flask.request.form.items()):
        if x not in (""u"", ""p""):
            kwargs[x] = unquote(y)

    try:
        response = call_api(func, *args, **kwargs)
    except Exception as exc:
        response = jsonify(error=str(exc), traceback=traceback.format_exc()), 500

    return response


def call_api(func, *args, **kwargs):
    api = flask.current_app.config[""PYLOAD_API""]

    if func.startswith(""_""):
        flask.flash(f""Invalid API call '{func}'"")
        return jsonify({'error': ""Forbidden""}), 403

    result = getattr(api, func)(
        *[literal_eval(x) for x in args],
        **{x: literal_eval(y) for x, y in kwargs.items()},
    )

    return jsonify(result)


@bp.route(""/api/login"", methods=[""POST""], endpoint=""login"")
# @apiver_check
def login():
    user = flask.request.form[""username""]
    password = flask.request.form[""password""]

    api = flask.current_app.config[""PYLOAD_API""]
    user_info = api.check_auth(user, password)

    if not user_info:
        log.error(f""Login failed for user '{user}'"")
        return jsonify(False)

    s = set_session(user_info)
    log.info(f""User '{user}' successfully logged in"")
    flask.flash(""Logged in successfully"")

    return jsonify(s)


@bp.route(""/api/logout"", endpoint=""logout"")
# @apiver_check
def logout():
    s = flask.session
    user = s.get(""name"")
    clear_session(s)
    if user:
        log.info(f""User '{user}' logged out"")
    return jsonify(True)
",CWE-74,109.0,1
"#       ____________
#   ___/       |    \_____________ _                 _ ___
#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \
# /    \___/  ______/   | '_ \ || | |__/ _ \/ _` / _` |    \
# \             |      | .__/\_, |____\___/\__,_\__,_|    /
#  \_______\    /_______|_|   |__/________________________/
#           \  /
#            \/

# Read more about the various options under:
# http://setuptools.readthedocs.io/en/latest/setuptools.html#configuring-setup-using-setup-cfg-files

[metadata]
name = pyload-ng
description = The free and open-source Download Manager written in pure Python
author = pyLoad team
author_email = support@pyload.net
license = agpl3
license_files = LICENSE.md
url = https://pyload.net
long_description = file: README.md
long_description_content_type = text/markdown
keywords = pyload, download-manager, one-click-hoster, download
platforms = any
maintainer = Walter Purcaro
maintainer_email = vuolter@gmail.com
download_url = https://github.com/pyload/pyload/releases
project_urls =
    Source Code (mirror) = https://gitlab.com/pyload/pyload
    Source Code = https://github.com/pyload/pyload
    Bug Tracker = https://github.com/pyload/pyload/issues
    Documentation = https://github.com/pyload/pyload/wiki
# https://pypi.python.org/pypi?%3Aaction=list_classifiers
classifiers =
    Development Status :: 4 - Beta
    Environment :: Console
    Environment :: Plugins
    Environment :: Web Environment
    Intended Audience :: End Users/Desktop
    License :: OSI Approved :: GNU Affero General Public License v3
    Natural Language :: English
    Operating System :: MacOS :: MacOS X
    Operating System :: Microsoft :: Windows
    Operating System :: POSIX
    Programming Language :: Python
    Programming Language :: Python :: 3 :: Only
    Programming Language :: Python :: 3.6
    Programming Language :: Python :: 3.7
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10
    Programming Language :: Python :: 3.11
    Programming Language :: Python :: Implementation :: CPython
    Programming Language :: Python :: Implementation :: PyPy
    Topic :: Communications
    Topic :: Communications :: File Sharing
    Topic :: Internet
    Topic :: Internet :: File Transfer Protocol (FTP)
    Topic :: Internet :: WWW/HTTP

[options]
zip_safe = False
packages = find:
include_package_data = True
package_dir =
    = src
install_requires =
    Cheroot~=8.4
    Flask;python_version<""3.8""
    Flask~=2.3.0;python_version>=""3.8""
    Flask-Babel~=1.0
    Flask-Caching~=1.9
    Flask-Compress~=1.8
    Flask-Session~=0.3;python_version<""3.7""
    Flask-Session2~=1.3;python_version>=""3.7""
    Flask-Themes2~=1.0
    bitmath~=1.3
    cryptography>=35.0.0;platform_python_implementation!=""PyPy""
    cryptography>=35.0.0,<40.0.0;platform_python_implementation=='PyPy'
    filetype~=1.0
    Js2Py~=0.7
    pycurl~=7.43
    certifi
    # requests-html~=0.10
    semver~=2.10
    setuptools>=38.3
python_requires = >=3.6

[options.packages.find]
where = src

[options.extras_require]
all =
    beautifulsoup4
    colorlog
    Pillow
    pyOpenSSL
    slixmpp
    Send2Trash
    pyobjc-framework-Cocoa;platform_system==""Darwin"" and python_version<""3.8""  # required by Send2Trash

    Babel
    Jinja2
build =
    Babel
    Jinja2
#   Sphinx>1.4
plugins =
    beautifulsoup4
    colorlog
    Pillow
    pyOpenSSL
    slixmpp
    Send2Trash
    pyobjc-framework-Cocoa;platform_system==""Darwin"" and python_version<""3.8""  # required by Send2Trash
# test =
#     nose
#     pytest
#     pytest-cov

[options.entry_points]
console_scripts =
    pyload = pyload.__main__:main

[test]
# py.test options when running `python setup.py test`
# addopts = --verbose
extras = True

[tool:pytest]
# Options for py.test:
# Specify command line options as you would do when invoking py.test directly.
# e.g. --cov-report html (or xml) for html/xml output or --junitxml junit.xml
# in order to write a coverage file that can be read by Jenkins.
addopts =
    --cov pyload --cov-report term-missing
    --verbose
norecursedirs =
    dist
    build
    .tox
testpaths = tests

[bdist_wheel]
# Use this option if your package is pure-python
universal = 0

[build_sphinx]
source_dir = docs
build_dir = docs/_build
# all_files  = 1
# warning-is-error = 1
# fresh-env = 1

[upload_sphinx]
upload-dir = docs/_build/html

[compile_catalog]
domain = pyload
directory = src/pyload/locale
use-fuzzy = 1

[extract_messages]
;mapping_file = babel.cfg
output_file = src/pyload/locale/pyload.pot
input_dirs = src/pyload

[init_catalog]
domain = pyload
output_dir = src/pyload/locale
input_file = src/pyload/locale/pyload.pot
locale = en

[update_catalog]
domain = pyload
output_dir = src/pyload/locale
input_file = src/pyload/locale/pyload.pot

[devpi:upload]
# Options for the devpi: PyPI server and packaging tool
# VCS export must be deactivated since we are using setuptools-scm
no-vcs = 1
formats = bdist_wheel
",CWE-352,184.0,1
"# -*- coding: utf-8 -*-
#       ____________
#   ___/       |    \_____________ _                 _ ___
#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \
# /    \___/  ______/   | '_ \ || | |__/ _ \/ _` / _` |    \
# \             |      | .__/\_, |____\___/\__,_\__,_|    /
#  \_______\    /_______|_|   |__/________________________/
#           \  /
#            \/

import os

import flask
import jinja2
from werkzeug.serving import WSGIRequestHandler

from .blueprints import BLUEPRINTS
from .config import get_default_config
from .extensions import EXTENSIONS, THEMES
from .filters import TEMPLATE_FILTERS
from .globals import TEMPLATE_GLOBALS
from .handlers import ERROR_HANDLERS
from .processors import CONTEXT_PROCESSORS


#: flask app singleton?
class App:

    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS
    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS
    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS
    FLASK_ERROR_HANDLERS = ERROR_HANDLERS
    FLASK_BLUEPRINTS = BLUEPRINTS
    FLASK_EXTENSIONS = EXTENSIONS
    FLASK_THEMES = THEMES


    @classmethod
    def _configure_config(cls, app, develop):
        conf_obj = get_default_config(develop)
        app.config.from_object(conf_obj)

    @classmethod
    def _configure_blueprints(cls, app, path_prefix):
        for blueprint in cls.FLASK_BLUEPRINTS:
            url_prefix = path_prefix if not blueprint.url_prefix else None
            app.register_blueprint(blueprint, url_prefix=url_prefix)

    @classmethod
    def _configure_extensions(cls, app):
        for extension in cls.FLASK_EXTENSIONS:
            extension.init_app(app)

    @classmethod
    def _configure_themes(cls, app, path_prefix=""""):
        for theme in cls.FLASK_THEMES:
            theme.init_app(app, path_prefix)

    @classmethod
    def _configure_handlers(cls, app):
        """"""
        Register app handlers.
        """"""
        for exc, fn in cls.FLASK_ERROR_HANDLERS:
            app.register_error_handler(exc, fn)

        @app.after_request
        def deny_iframe(response):
            response.headers[""X-Frame-Options""] = ""DENY""
            return response

    @classmethod
    def _configure_json_encoding(cls, app):
        try:
            from .helpers import JSONProvider
            app.json = JSONProvider(app)

        except ImportError:
            from .helpers import JSONEncoder
            app.json_encoder = JSONEncoder

    @classmethod
    def _configure_templating(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""jinja"")

        os.makedirs(cache_path, exist_ok=True)

        app.create_jinja_environment()

        # NOTE: enable auto escape for all file extensions (including .js)
        #       maybe this will break .txt rendering, but we don't render this kind of files actually
        #       that does not change 'default_for_string=False' (by default)
        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)
        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)

        for fn in cls.JINJA_TEMPLATE_FILTERS:
            app.add_template_filter(fn)

        for fn in cls.JINJA_TEMPLATE_GLOBALS:
            app.add_template_global(fn)

        for fn in cls.JINJA_CONTEXT_PROCESSORS:
            app.context_processor(fn)

    @classmethod
    def _configure_session(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""flask"")
        os.makedirs(cache_path, exist_ok=True)

        app.config[""SESSION_FILE_DIR""] = cache_path
        app.config[""SESSION_TYPE""] = ""filesystem""
        app.config[""SESSION_COOKIE_NAME""] = ""pyload_session""
        app.config[""SESSION_COOKIE_SECURE""] = app.config[""PYLOAD_API""].get_config_value(""webui"", ""use_ssl"")
        app.config[""SESSION_PERMANENT""] = False

        session_lifetime = max(app.config[""PYLOAD_API""].get_config_value(""webui"", ""session_lifetime""), 1) * 60
        app.config[""PERMANENT_SESSION_LIFETIME""] = session_lifetime

    @classmethod
    def _configure_api(cls, app, pycore):
        app.config[""PYLOAD_API""] = pycore.api

    @classmethod
    def _configure_logging(cls, app, pycore):
        # Inject our custom logger
        app.logger = pycore.log.getChild(""webui"")

    def __new__(cls, pycore, develop=False, path_prefix=None):
        app = flask.Flask(__name__)

        cls._configure_logging(app, pycore)
        cls._configure_api(app, pycore)
        cls._configure_config(app, develop)
        cls._configure_templating(app)
        cls._configure_json_encoding(app)
        cls._configure_session(app)
        cls._configure_blueprints(app, path_prefix)
        cls._configure_extensions(app)
        cls._configure_themes(app, path_prefix or """")
        cls._configure_handlers(app)

        WSGIRequestHandler.protocol_version = ""HTTP/1.1""

        return app
",CWE-352,147.0,1
"# -*- coding: utf-8 -*-
#       ____________
#   ___/       |    \_____________ _                 _ ___
#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \
# /    \___/  ______/   | '_ \ || | |__/ _ \/ _` / _` |    \
# \             |      | .__/\_, |____\___/\__,_\__,_|    /
#  \_______\    /_______|_|   |__/________________________/
#           \  /
#            \/

import os

import flask
import jinja2
from werkzeug.serving import WSGIRequestHandler

from .blueprints import BLUEPRINTS
from .config import get_default_config
from .extensions import EXTENSIONS, THEMES
from .filters import TEMPLATE_FILTERS
from .globals import TEMPLATE_GLOBALS
from .handlers import ERROR_HANDLERS
from .processors import CONTEXT_PROCESSORS


#: flask app singleton?
class App:

    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS
    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS
    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS
    FLASK_ERROR_HANDLERS = ERROR_HANDLERS
    FLASK_BLUEPRINTS = BLUEPRINTS
    FLASK_EXTENSIONS = EXTENSIONS
    FLASK_THEMES = THEMES


    @classmethod
    def _configure_config(cls, app, develop):
        conf_obj = get_default_config(develop)
        app.config.from_object(conf_obj)

    @classmethod
    def _configure_blueprints(cls, app, path_prefix):
        for blueprint in cls.FLASK_BLUEPRINTS:
            url_prefix = path_prefix if not blueprint.url_prefix else None
            app.register_blueprint(blueprint, url_prefix=url_prefix)

    @classmethod
    def _configure_extensions(cls, app):
        for extension in cls.FLASK_EXTENSIONS:
            extension.init_app(app)

    @classmethod
    def _configure_themes(cls, app, path_prefix=""""):
        for theme in cls.FLASK_THEMES:
            theme.init_app(app, path_prefix)

    @classmethod
    def _configure_handlers(cls, app):
        """"""
        Register app handlers.
        """"""
        for exc, fn in cls.FLASK_ERROR_HANDLERS:
            app.register_error_handler(exc, fn)

        @app.after_request
        def deny_iframe(response):
            response.headers[""X-Frame-Options""] = ""DENY""
            return response

    @classmethod
    def _configure_json_encoding(cls, app):
        try:
            from .helpers import JSONProvider
            app.json = JSONProvider(app)

        except ImportError:
            from .helpers import JSONEncoder
            app.json_encoder = JSONEncoder

    @classmethod
    def _configure_templating(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""jinja"")

        os.makedirs(cache_path, exist_ok=True)

        app.create_jinja_environment()

        # NOTE: enable auto escape for all file extensions (including .js)
        #       maybe this will break .txt rendering, but we don't render this kind of files actually
        #       that does not change 'default_for_string=False' (by default)
        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)
        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)

        for fn in cls.JINJA_TEMPLATE_FILTERS:
            app.add_template_filter(fn)

        for fn in cls.JINJA_TEMPLATE_GLOBALS:
            app.add_template_global(fn)

        for fn in cls.JINJA_CONTEXT_PROCESSORS:
            app.context_processor(fn)

    @classmethod
    def _configure_session(cls, app):
        tempdir = app.config[""PYLOAD_API""].get_cachedir()
        cache_path = os.path.join(tempdir, ""flask"")
        os.makedirs(cache_path, exist_ok=True)

        app.config[""SESSION_FILE_DIR""] = cache_path
        app.config[""SESSION_TYPE""] = ""filesystem""
        app.config[""SESSION_COOKIE_NAME""] = ""pyload_session""
        app.config[""SESSION_COOKIE_SAMESITE""] = ""None""
        app.config[""SESSION_COOKIE_SECURE""] = app.config[""PYLOAD_API""].get_config_value(""webui"", ""use_ssl"")
        app.config[""SESSION_PERMANENT""] = False

        session_lifetime = max(app.config[""PYLOAD_API""].get_config_value(""webui"", ""session_lifetime""), 1) * 60
        app.config[""PERMANENT_SESSION_LIFETIME""] = session_lifetime

    @classmethod
    def _configure_api(cls, app, pycore):
        app.config[""PYLOAD_API""] = pycore.api

    @classmethod
    def _configure_logging(cls, app, pycore):
        # Inject our custom logger
        app.logger = pycore.log.getChild(""webui"")

    def __new__(cls, pycore, develop=False, path_prefix=None):
        app = flask.Flask(__name__)

        cls._configure_logging(app, pycore)
        cls._configure_api(app, pycore)
        cls._configure_config(app, develop)
        cls._configure_templating(app)
        cls._configure_json_encoding(app)
        cls._configure_session(app)
        cls._configure_blueprints(app, path_prefix)
        cls._configure_extensions(app)
        cls._configure_themes(app, path_prefix or """")
        cls._configure_handlers(app)

        WSGIRequestHandler.protocol_version = ""HTTP/1.1""

        return app
",CWE-352,148.0,1
"""""""Object level permissions.""""""

from django.contrib.auth.models import Group, Permission
from django.contrib.contenttypes.models import ContentType

from modoboa.core import constants as core_constants, signals as core_signals
from modoboa.core.models import ObjectAccess, User


def get_account_roles(user, account=None):
    """"""Return the list of available account roles.

    This function is used to create or modify an account.

    :param ``User`` user: connected user
    :param ``User`` account: account beeing modified (None on creation)
    :return: list of strings
    """"""
    result = [core_constants.SIMPLEUSERS_ROLE]
    filters = core_signals.user_can_set_role.send(
        sender=""get_account_roles"", user=user, role=""DomainAdmins"",
        account=account)
    condition = (
        user.has_perm(""admin.add_domain"") and
        (not filters or True in [flt[1] for flt in filters]))
    if condition:
        result += [core_constants.DOMAINADMINS_ROLE]
    if user.is_superuser:
        result += [
            core_constants.RESELLERS_ROLE, core_constants.SUPERADMINS_ROLE]
    return sorted(result, key=lambda role: role[1])


def grant_access_to_object(user, obj, is_owner=False):
    """"""Grant access to an object for a given user

    There are two different cases where we want to grant access to an
    object for a specific user:

    * He is the owner (he's just created the object)
    * He is going to administrate the object (but he is not the owner)

    If the user is the owner, we also grant access to this object to
    all super users.

    :param user: a ``User`` object
    :param obj: an admin. object (Domain, Mailbox, ...)
    :param is_owner: the user is the unique object's owner
    """"""
    ct = ContentType.objects.get_for_model(obj)
    entry, created = ObjectAccess.objects.get_or_create(
        user=user, content_type=ct, object_id=obj.id)
    entry.is_owner = is_owner
    entry.save()
    if not created or not is_owner:
        return
    for su in User.objects.filter(is_superuser=True):
        if su == user:
            continue
        ObjectAccess.objects.get_or_create(
            user=su, content_type=ct, object_id=obj.id
        )


def grant_access_to_objects(user, objects, ct):
    """"""Grant access to a collection of objects

    All objects in the collection must share the same type (ie. ``ct``
    applies to all objects).

    :param user: a ``User`` object
    :param objects: a list of objects
    :param ct: the content type
    """"""
    for obj in objects:
        ObjectAccess.objects.get_or_create(
            user=user, content_type=ct, object_id=obj.id)


def ungrant_access_to_object(obj, user=None):
    """"""Ungrant access to an object for a specific user

    If no user is provided, all entries referencing this object are
    deleted from the database.

    If a user is provided, we only remove his access. If it was the
    owner, we give the ownership to the first super admin we find.

    :param obj: an object inheriting from ``models.Model``
    :param user: a ``User`` object
    """"""
    ct = ContentType.objects.get_for_model(obj)
    if user is not None:
        try:
            ObjectAccess.objects.get(
                user=user, content_type=ct, object_id=obj.id
            ).delete()
        except ObjectAccess.DoesNotExist:
            pass
        try:
            ObjectAccess.objects.get(
                content_type=ct, object_id=obj.id, is_owner=True
            )
        except ObjectAccess.DoesNotExist:
            grant_access_to_object(
                User.objects.filter(is_superuser=True)[0], obj, True
            )
    else:
        ObjectAccess.objects.filter(
            content_type=ct, object_id=obj.id
        ).delete()


def ungrant_access_to_objects(objects):
    """"""Cancel all accesses for a given object list.

    :param objects: a list of objects inheriting from ``models.Model``
    """"""
    for obj in objects:
        ct = ContentType.objects.get_for_model(obj)
        ObjectAccess.objects.filter(content_type=ct, object_id=obj.id).delete()


def get_object_owner(obj):
    """"""Return the unique owner of this object

    :param obj: an object inheriting from ``model.Model``
    :return: a ``User`` object
    """"""
    ct = ContentType.objects.get_for_model(obj)
    try:
        entry = ObjectAccess.objects.get(
            content_type=ct, object_id=obj.id, is_owner=True
        )
    except ObjectAccess.DoesNotExist:
        return None
    return entry.user


def add_permissions_to_group(group, permissions):
    """"""Add the specified permissions to a django group.""""""
    if isinstance(group, str):
        group = Group.objects.get(name=group)

    for appname, modelname, permname in permissions:
        ct = ContentType.objects.get_by_natural_key(appname, modelname)
        if group.permissions.filter(
                content_type=ct, codename=permname).exists():
            continue
        group.permissions.add(
            Permission.objects.get(content_type=ct, codename=permname)
        )
",CWE-285,153.0,1
"""""""Parameters viewsets.""""""

from drf_spectacular.utils import extend_schema, OpenApiParameter
from rest_framework import response, viewsets
from rest_framework.decorators import action

from modoboa.lib.throttle import GetThrottleViewsetMixin

from . import serializers
from ... import tools


class ParametersViewSet(GetThrottleViewsetMixin, viewsets.ViewSet):
    """"""Parameter viewset.""""""

    lookup_value_regex = r""\w+""
    serializer_class = None

    @extend_schema(responses=serializers.ApplicationSerializer(many=True))
    @action(methods=[""get""], detail=False)
    def applications(self, request):
        """"""Return the list of registered applications.""""""
        applications = tools.registry.get_applications(""global"")
        return response.Response(applications)

    @extend_schema(responses=serializers.ParameterSerializer(many=True))
    @action(methods=[""get""], detail=False)
    def structure(self, request):
        """"""Return parameter schema.""""""
        app = request.GET.get(""app"")
        data = tools.registry.get_structure(""global"", app)
        return response.Response(data)

    @extend_schema(
        parameters=[
            OpenApiParameter(
                name='id', location=OpenApiParameter.PATH,
                description='A registered application name',
                type=str, required=True
            ),
        ],
        responses=serializers.AppParametersSerializer
    )
    def retrieve(self, request, pk: str):
        """"""Return all parameters for given app.""""""
        parameters = request.localconfig.parameters.get_values_dict(pk)
        serializer = tools.registry.get_serializer_class(""global"", pk)(
            parameters)
        result = serializers.AppParametersSerializer({
            ""label"": tools.registry.get_label(""global"", pk),
            ""params"": serializer.data
        })
        return response.Response(result.data)

    @extend_schema(
        parameters=[
            OpenApiParameter(
                name='id', location=OpenApiParameter.PATH,
                description='A registered application name',
                type=str, required=True
            ),
        ]
    )
    def update(self, request, pk: str):
        """"""Save parameters for given app.""""""
        serializer = tools.registry.get_serializer_class(""global"", pk)(
            data=request.data)
        serializer.is_valid(raise_exception=True)
        request.localconfig.parameters.set_values(
            serializer.validated_data, app=pk)
        request.localconfig.save(update_fields=[""_parameters""])
        return response.Response()
",CWE-285,73.0,1
"""""""Core forms.""""""

import oath

from django import forms
from django.contrib.auth import (
    forms as auth_forms, get_user_model, password_validation
)
from django.db.models import Q
from django.utils.translation import ugettext as _, ugettext_lazy

import django_otp

from modoboa.core.models import User
from modoboa.lib.form_utils import UserKwargModelFormMixin
from modoboa.parameters import tools as param_tools


class LoginForm(forms.Form):
    """"""User login form.""""""

    username = forms.CharField(
        label=ugettext_lazy(""Username""),
        widget=forms.TextInput(attrs={""class"": ""form-control""})
    )
    password = forms.CharField(
        label=ugettext_lazy(""Password""),
        widget=forms.PasswordInput(attrs={""class"": ""form-control""})
    )
    rememberme = forms.BooleanField(
        initial=False,
        required=False
    )


class ProfileForm(forms.ModelForm):
    """"""Form to update User profile.""""""

    oldpassword = forms.CharField(
        label=ugettext_lazy(""Old password""), required=False,
        widget=forms.PasswordInput(attrs={""class"": ""form-control""})
    )
    newpassword = forms.CharField(
        label=ugettext_lazy(""New password""), required=False,
        widget=forms.PasswordInput(attrs={""class"": ""form-control""})
    )
    confirmation = forms.CharField(
        label=ugettext_lazy(""Confirmation""), required=False,
        widget=forms.PasswordInput(attrs={""class"": ""form-control""})
    )

    class Meta(object):
        model = User
        fields = (""first_name"", ""last_name"", ""language"",
                  ""phone_number"", ""secondary_email"")
        widgets = {
            ""first_name"": forms.TextInput(attrs={""class"": ""form-control""}),
            ""last_name"": forms.TextInput(attrs={""class"": ""form-control""})
        }

    def __init__(self, update_password, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if not update_password:
            del self.fields[""oldpassword""]
            del self.fields[""newpassword""]
            del self.fields[""confirmation""]

    def clean_oldpassword(self):
        if self.cleaned_data[""oldpassword""] == """":
            return self.cleaned_data[""oldpassword""]

        if param_tools.get_global_parameter(""authentication_type"") != ""local"":
            return self.cleaned_data[""oldpassword""]

        if not self.instance.check_password(self.cleaned_data[""oldpassword""]):
            raise forms.ValidationError(_(""Old password mismatchs""))
        return self.cleaned_data[""oldpassword""]

    def clean(self):
        super().clean()
        if self.errors:
            return self.cleaned_data
        oldpassword = self.cleaned_data.get(""oldpassword"")
        newpassword = self.cleaned_data.get(""newpassword"")
        confirmation = self.cleaned_data.get(""confirmation"")
        if newpassword and confirmation:
            if oldpassword:
                if newpassword != confirmation:
                    self.add_error(""confirmation"", _(""Passwords mismatch""))
                else:
                    password_validation.validate_password(
                        confirmation, self.instance)
            else:
                self.add_error(""oldpassword"", _(""This field is required.""))
        return self.cleaned_data

    def save(self, commit=True):
        user = super().save(commit=False)
        if commit:
            if self.cleaned_data.get(""confirmation"", """") != """":
                user.set_password(
                    self.cleaned_data[""confirmation""],
                    self.cleaned_data[""oldpassword""]
                )
            user.save()
        return user


class APIAccessForm(forms.Form):
    """"""Form to control API access.""""""

    enable_api_access = forms.BooleanField(
        label=ugettext_lazy(""Enable API access""), required=False)

    def __init__(self, *args, **kwargs):
        """"""Initialize form.""""""
        user = kwargs.pop(""user"")
        super(APIAccessForm, self).__init__(*args, **kwargs)
        self.fields[""enable_api_access""].initial = hasattr(user, ""auth_token"")


class PasswordResetForm(auth_forms.PasswordResetForm):
    """"""Custom password reset form.""""""

    def get_users(self, email):
        """"""Return matching user(s) who should receive a reset.""""""
        return (
            get_user_model()._default_manager.filter(
                email__iexact=email, is_active=True)
            .exclude(Q(secondary_email__isnull=True) | Q(secondary_email=""""))
        )

    def send_mail(self, subject_template_name, email_template_name,
                  context, from_email, to_email,
                  html_email_template_name=None):
        """"""Send message to secondary email instead.""""""
        to_email = context[""user""].secondary_email
        super(PasswordResetForm, self).send_mail(
            subject_template_name, email_template_name,
            context, from_email, to_email, html_email_template_name)


class VerifySMSCodeForm(forms.Form):
    """"""A form to verify a code received by SMS.""""""

    code = forms.CharField(
        label=ugettext_lazy(""Verification code""),
        widget=forms.widgets.TextInput(attrs={""class"": ""form-control""})
    )

    def __init__(self, *args, **kwargs):
        self.totp_secret = kwargs.pop(""totp_secret"")
        super().__init__(*args, **kwargs)

    def clean_code(self):
        code = self.cleaned_data[""code""]
        if not oath.accept_totp(self.totp_secret, code)[0]:
            raise forms.ValidationError(_(""Invalid code""))
        return code


class Verify2FACodeForm(UserKwargModelFormMixin, forms.Form):
    """"""A form to verify 2FA codes validity.""""""

    tfa_code = forms.CharField()

    def clean_tfa_code(self):
        code = self.cleaned_data[""tfa_code""]
        device = django_otp.match_token(self.user, code)
        if device is None:
            raise forms.ValidationError(_(""This code is invalid""))
        return device
",CWE-521,173.0,1
"from __future__ import annotations

from datetime import timedelta as td

from django import forms
from django.contrib.auth import authenticate
from django.contrib.auth.models import User

from hc.accounts.models import REPORT_CHOICES, Member
from hc.api.models import TokenBucket
from hc.lib.tz import all_timezones


class LowercaseEmailField(forms.EmailField):
    def clean(self, value):
        value = super(LowercaseEmailField, self).clean(value)
        return value.lower()


class SignupForm(forms.Form):
    # Call it ""identity"" instead of ""email""
    # to avoid some of the dumber bots
    identity = LowercaseEmailField(
        error_messages={""required"": ""Please enter your email address.""}
    )
    tz = forms.CharField(required=False)

    def clean_identity(self):
        v = self.cleaned_data[""identity""]
        if len(v) > 254:
            raise forms.ValidationError(""Address is too long."")

        if User.objects.filter(email=v).exists():
            raise forms.ValidationError(
                ""An account with this email address already exists.""
            )

        return v

    def clean_tz(self):
        # Declare tz as ""clean"" only if we can find it in hc.lib.tz.all_timezones
        if self.cleaned_data[""tz""] in all_timezones:
            return self.cleaned_data[""tz""]

        # Otherwise, return None, and *don't* throw a validation exception:
        # If user's browser reports a timezone we don't recognize, we
        # should ignore the timezone but still save the rest of the form.


class EmailLoginForm(forms.Form):
    # Call it ""identity"" instead of ""email""
    # to avoid some of the dumber bots
    identity = LowercaseEmailField()

    def clean_identity(self):
        v = self.cleaned_data[""identity""]
        if not TokenBucket.authorize_login_email(v):
            raise forms.ValidationError(""Too many attempts, please try later."")

        try:
            self.user = User.objects.get(email=v)
        except User.DoesNotExist:
            raise forms.ValidationError(""Unknown email address."")

        return v


class PasswordLoginForm(forms.Form):
    email = LowercaseEmailField()
    password = forms.CharField()

    def clean(self):
        username = self.cleaned_data.get(""email"")
        password = self.cleaned_data.get(""password"")

        if username and password:
            if not TokenBucket.authorize_login_password(username):
                raise forms.ValidationError(""Too many attempts, please try later."")

            self.user = authenticate(username=username, password=password)
            if self.user is None or not self.user.is_active:
                raise forms.ValidationError(""Incorrect email or password."")

        return self.cleaned_data


class ReportSettingsForm(forms.Form):
    reports = forms.ChoiceField(choices=REPORT_CHOICES)
    nag_period = forms.IntegerField(min_value=0, max_value=86400)
    tz = forms.CharField()

    def clean_nag_period(self):
        seconds = self.cleaned_data[""nag_period""]

        if seconds not in (0, 3600, 86400):
            raise forms.ValidationError(""Bad nag_period: %d"" % seconds)

        return td(seconds=seconds)

    def clean_tz(self):
        # Declare tz as ""clean"" only if we can find it in hc.lib.tz.all_timezones
        if self.cleaned_data[""tz""] in all_timezones:
            return self.cleaned_data[""tz""]

        # Otherwise, return None, and *don't* throw a validation exception:
        # If user's browser reports a timezone we don't recognize, we
        # should ignore the timezone but still save the rest of the form.


class SetPasswordForm(forms.Form):
    password = forms.CharField(min_length=8)


class ChangeEmailForm(forms.Form):
    error_css_class = ""has-error""
    email = LowercaseEmailField()

    def clean_email(self):
        v = self.cleaned_data[""email""]
        if User.objects.filter(email=v).exists():
            raise forms.ValidationError(""%s is already registered"" % v)

        return v


class InviteTeamMemberForm(forms.Form):
    email = LowercaseEmailField(max_length=254)
    role = forms.ChoiceField(choices=Member.Role.choices)


class RemoveTeamMemberForm(forms.Form):
    email = LowercaseEmailField()


class ProjectNameForm(forms.Form):
    name = forms.CharField(max_length=60)


class TransferForm(forms.Form):
    email = LowercaseEmailField()


class AddWebAuthnForm(forms.Form):
    name = forms.CharField(max_length=100)
    response = forms.CharField()


class WebAuthnForm(forms.Form):
    response = forms.CharField()


class TotpForm(forms.Form):
    error_css_class = ""has-error""
    code = forms.RegexField(regex=r""^\d{6}$"")

    def __init__(self, totp, post=None, files=None):
        self.totp = totp
        super(TotpForm, self).__init__(post, files)

    def clean_code(self):
        if not self.totp.verify(self.cleaned_data[""code""], valid_window=1):
            raise forms.ValidationError(""The code you entered was incorrect."")

        return self.cleaned_data[""code""]
",CWE-203,165.0,1
"from __future__ import annotations

from django.conf import settings
from django.core import mail
from django.test.utils import override_settings

from hc.accounts.models import Credential
from hc.api.models import Check, TokenBucket
from hc.test import BaseTestCase


class LoginTestCase(BaseTestCase):
    def setUp(self):
        super().setUp()
        self.checks_url = f""/projects/{self.project.code}/checks/""

    def test_it_shows_form(self):
        r = self.client.get(""/accounts/login/"")
        self.assertContains(r, ""Email Me a Link"")

    def test_it_redirects_authenticated_get(self):
        self.client.login(username=""alice@example.org"", password=""password"")

        r = self.client.get(""/accounts/login/"")
        self.assertRedirects(r, self.checks_url)

    @override_settings(SITE_ROOT=""http://testserver"", SITE_LOGO_URL=None)
    def test_it_sends_link(self):
        form = {""identity"": ""alice@example.org""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(r, ""/accounts/login_link_sent/"")

        # And email should have been sent
        self.assertEqual(len(mail.outbox), 1)
        message = mail.outbox[0]
        self.assertEqual(message.subject, f""Log in to {settings.SITE_NAME}"")
        html = message.alternatives[0][0]
        self.assertIn(""http://testserver/static/img/logo.png"", html)
        self.assertIn(""http://testserver/docs/"", html)

    @override_settings(SITE_LOGO_URL=""https://example.org/logo.svg"")
    def test_it_uses_custom_logo(self):
        self.client.post(""/accounts/login/"", {""identity"": ""alice@example.org""})
        html = mail.outbox[0].alternatives[0][0]
        self.assertIn(""https://example.org/logo.svg"", html)

    def test_it_sends_link_with_next(self):
        form = {""identity"": ""alice@example.org""}

        r = self.client.post(""/accounts/login/?next="" + self.channels_url, form)
        self.assertRedirects(r, ""/accounts/login_link_sent/"")
        self.assertIn(""auto-login"", r.cookies)

        # The check_token link should have a ?next= query parameter:
        self.assertEqual(len(mail.outbox), 1)
        body = mail.outbox[0].body
        self.assertTrue(""/?next="" + self.channels_url in body)

    @override_settings(SECRET_KEY=""test-secret"")
    def test_it_rate_limits_emails(self):
        # ""d60d..."" is sha1(""alice@example.orgtest-secret"")
        obj = TokenBucket(value=""em-d60db3b2343e713a4de3e92d4eb417e4f05f06ab"")
        obj.tokens = 0
        obj.save()

        form = {""identity"": ""alice@example.org""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertContains(r, ""Too many attempts"")

        # No email should have been sent
        self.assertEqual(len(mail.outbox), 0)

    def test_it_pops_bad_link_from_session(self):
        self.client.session[""bad_link""] = True
        self.client.get(""/accounts/login/"")
        assert ""bad_link"" not in self.client.session

    def test_it_ignores_case(self):
        form = {""identity"": ""ALICE@EXAMPLE.ORG""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(r, ""/accounts/login_link_sent/"")

        self.profile.refresh_from_db()
        self.assertTrue(self.profile.token)

    def test_it_handles_password(self):
        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(r, self.checks_url)

    @override_settings(SECRET_KEY=""test-secret"")
    def test_it_rate_limits_password_attempts(self):
        # ""d60d..."" is sha1(""alice@example.orgtest-secret"")
        obj = TokenBucket(value=""pw-d60db3b2343e713a4de3e92d4eb417e4f05f06ab"")
        obj.tokens = 0
        obj.save()

        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertContains(r, ""Too many attempts"")

    def test_it_handles_password_login_with_redirect(self):
        check = Check.objects.create(project=self.project)

        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}

        samples = [self.channels_url, ""/checks/%s/details/"" % check.code]

        for s in samples:
            r = self.client.post(""/accounts/login/?next=%s"" % s, form)
            self.assertRedirects(r, s)

    def test_it_handles_bad_next_parameter(self):
        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}

        samples = [
            ""/evil/"",
            f""https://example.org/projects/{self.project.code}/checks/"",
        ]

        for sample in samples:
            r = self.client.post(""/accounts/login/?next="" + sample, form)
            self.assertRedirects(r, self.checks_url)

    def test_it_handles_wrong_password(self):
        form = {
            ""action"": ""login"",
            ""email"": ""alice@example.org"",
            ""password"": ""wrong password"",
        }

        r = self.client.post(""/accounts/login/"", form)
        self.assertContains(r, ""Incorrect email or password"")

    @override_settings(REGISTRATION_OPEN=False)
    def test_it_obeys_registration_open(self):
        r = self.client.get(""/accounts/login/"")
        self.assertNotContains(r, ""Create Your Account"")

    def test_it_redirects_to_webauthn_form(self):
        Credential.objects.create(user=self.alice, name=""Alices Key"")

        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}
        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(
            r, ""/accounts/login/two_factor/"", fetch_redirect_response=False
        )

        # It should not log the user in yet
        self.assertNotIn(""_auth_user_id"", self.client.session)

        # Instead, it should set 2fa_user_id in the session
        user_id, email, valid_until = self.client.session[""2fa_user""]
        self.assertEqual(user_id, self.alice.id)

    def test_it_redirects_to_totp_form(self):
        self.profile.totp = ""0"" * 32
        self.profile.save()

        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}
        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(
            r, ""/accounts/login/two_factor/totp/"", fetch_redirect_response=False
        )

        # It should not log the user in yet
        self.assertNotIn(""_auth_user_id"", self.client.session)

        # Instead, it should set 2fa_user_id in the session
        user_id, email, valid_until = self.client.session[""2fa_user""]
        self.assertEqual(user_id, self.alice.id)

    def test_it_handles_missing_profile(self):
        self.profile.delete()

        form = {""action"": ""login"", ""email"": ""alice@example.org"", ""password"": ""password""}

        r = self.client.post(""/accounts/login/"", form)
        self.assertRedirects(r, self.checks_url)
",CWE-203,185.0,1
"from __future__ import annotations

from django.conf import settings
from django.contrib.auth.models import User
from django.core import mail
from django.test import TestCase
from django.test.utils import override_settings

from hc.accounts.models import Profile, Project
from hc.api.models import Channel, Check


class SignupTestCase(TestCase):
    @override_settings(USE_PAYMENTS=False)
    def test_it_works(self):
        form = {""identity"": ""alice@example.org"", ""tz"": ""Europe/Riga""}

        r = self.client.post(""/accounts/signup/"", form)
        self.assertContains(r, ""Account created"")
        self.assertIn(""auto-login"", r.cookies)

        # An user should have been created
        user = User.objects.get()

        # A profile should have been created
        profile = Profile.objects.get()
        self.assertEqual(profile.check_limit, 10000)
        self.assertEqual(profile.sms_limit, 10000)
        self.assertEqual(profile.call_limit, 10000)
        self.assertEqual(profile.tz, ""Europe/Riga"")

        # And email sent
        self.assertEqual(len(mail.outbox), 1)
        subject = ""Log in to %s"" % settings.SITE_NAME
        self.assertEqual(mail.outbox[0].subject, subject)

        # A project should have been created
        project = Project.objects.get()
        self.assertEqual(project.owner, user)
        self.assertEqual(project.badge_key, user.username)

        # And check should be associated with the new user
        check = Check.objects.get()
        self.assertEqual(check.name, ""My First Check"")
        self.assertEqual(check.slug, ""my-first-check"")
        self.assertEqual(check.project, project)

        # A channel should have been created
        channel = Channel.objects.get()
        self.assertEqual(channel.project, project)

    @override_settings(USE_PAYMENTS=True)
    def test_it_sets_limits(self):
        form = {""identity"": ""alice@example.org"", ""tz"": """"}

        self.client.post(""/accounts/signup/"", form)

        profile = Profile.objects.get()
        self.assertEqual(profile.check_limit, 20)
        self.assertEqual(profile.sms_limit, 5)
        self.assertEqual(profile.call_limit, 0)

    @override_settings(REGISTRATION_OPEN=False)
    def test_it_obeys_registration_open(self):
        form = {""identity"": ""dan@example.org"", ""tz"": """"}

        r = self.client.post(""/accounts/signup/"", form)
        self.assertEqual(r.status_code, 403)

    def test_it_ignores_case(self):
        form = {""identity"": ""ALICE@EXAMPLE.ORG"", ""tz"": """"}
        self.client.post(""/accounts/signup/"", form)

        # There should be exactly one user:
        q = User.objects.filter(email=""alice@example.org"")
        self.assertTrue(q.exists)

    def test_it_checks_for_existing_users(self):
        alice = User(username=""alice"", email=""alice@example.org"")
        alice.save()

        form = {""identity"": ""alice@example.org"", ""tz"": """"}
        r = self.client.post(""/accounts/signup/"", form)
        self.assertContains(r, ""already exists"")

    def test_it_checks_syntax(self):
        form = {""identity"": ""alice at example org"", ""tz"": """"}
        r = self.client.post(""/accounts/signup/"", form)
        self.assertContains(r, ""Enter a valid email address"")

    def test_it_checks_length(self):
        aaa = ""a"" * 300
        form = {""identity"": f""alice+{aaa}@example.org"", ""tz"": """"}
        r = self.client.post(""/accounts/signup/"", form)
        self.assertContains(r, ""Address is too long."")

        self.assertFalse(User.objects.exists())

    @override_settings(USE_PAYMENTS=False)
    def test_it_ignores_bad_tz(self):
        form = {""identity"": ""alice@example.org"", ""tz"": ""Foo/Bar""}

        r = self.client.post(""/accounts/signup/"", form)
        self.assertContains(r, ""Account created"")
        self.assertIn(""auto-login"", r.cookies)

        profile = Profile.objects.get()
        self.assertEqual(profile.tz, ""UTC"")
",CWE-203,109.0,1
"import logging
import subprocess

from .base import Plugin
from ..common import *


class NotificationsPlugin(Plugin):
    """"""Receive notifications from phone""""""
    MARK = b'nots'
    NAME = 'NotificationsPlugin'
    MAIN_CONF = dict()
    DEVICE_CONFS = dict()
    CONFIG_SCHEMA = DictEntry('rcmd.conf.json', 'Configuration for remote commands file', False, entries=(
        IntEntry('uin', 'UIN of device for which config will be applied', True, 1, 0xFFFFFFF, None),
        DirEntry('icon_dir', 'Directory to notification icons', True, '$DCNNT_RUNTIME_DIR', True, False),
        TemplateEntry('cmd', 'Template of notification show command',
                      False, 0, 4096, ""notify-send -i '{icon}' '{title}' '{text}'"", replacements=(
                          Rep('uin', 'UIN of device which send notification', True),
                          Rep('name', 'Name of device which send notification', True),
                          Rep('package', 'Name of Android package  which create notification', True),
                          Rep('icon', 'Path to saved notification icon', True),
                          Rep('title', 'Title of notification', True),
                          Rep('text', 'Main content of notification', True),
                      ))
    ))

    def __init__(self, app, handler, device):
        super().__init__(app, handler, device)

    def main(self):
        while True:
            request = self.rpc_read()
            self.log(request)
            if request is None:
                self.log('No more requests, stop handler')
                return
            cmd = self.conf('cmd')
            if not cmd:
                return
            if request.method == 'notification':
                icon_data = self.read() if request.params.get('packageIcon', False) else None
                if request.params.get('event') == 'posted':
                    text, package = map(request.params.get, ('text', 'package'))
                    title = request.params.get('title', 'NULL')
                    name, uin = self.device.name, self.device.uin
                    if text is None:
                        text = ''
                    icon_path = os.path.join(self.conf('icon_dir'), f'{package}.{self.device.uin}.icon.png')
                    if bool(icon_data):
                        try:
                            open(icon_path, 'wb').write(icon_data)
                        except Exception as e:
                            self.log(e, logging.WARNING)
                    icon = icon_path if icon_data else ''
                    command = cmd.format(uin=uin, name=name, icon=icon, text=text, title=title, package=package)
                    self.log('Execute: ""{}""'.format(command))
                    subprocess.call(command, shell=True)
",CWE-77,59.0,1
,CWE-79,,1
,CWE-79,,1
,CWE-79,,1
"import importlib

from django.test import TestCase, override_settings
from django.utils.translation import gettext_lazy as _

from tcms.kiwi_auth import forms


class TestCaptchaField(TestCase):
    def setUp(self):
        self.data = {
            ""username"": ""test_user"",
            ""password1"": ""password"",
            ""password2"": ""password"",
            ""email"": ""new-tester@example.com"",
        }

    def test_captcha_required_when_enabled(self):
        importlib.reload(forms)
        form = forms.RegistrationForm(data=self.data)

        self.assertFalse(form.is_valid())
        self.assertIn(""captcha"", form.errors.keys())
        self.assertIn(_(""This field is required.""), form.errors[""captcha""])

    def test_captcha_fails_when_wrong(self):
        data = self.data.copy()
        data[""captcha_0""] = ""correct""
        data[""captcha_1""] = ""WRONG""

        importlib.reload(forms)
        form = forms.RegistrationForm(data=data)

        self.assertFalse(form.is_valid())
        self.assertIn(""captcha"", form.errors.keys())
        self.assertIn(_(""Invalid CAPTCHA""), form.errors[""captcha""])

    @override_settings(USE_CAPTCHA=False)
    def test_captcha_not_required_when_disabled(self):
        importlib.reload(forms)
        form = forms.RegistrationForm(data=self.data)

        self.assertTrue(form.is_valid())
        self.assertNotIn(""captcha"", form.errors.keys())


@override_settings(USE_CAPTCHA=False)
class TestRegistrationForm(TestCase):
    def setUp(self):
        self.data = {
            ""username"": ""test_user"",
            ""password1"": ""password"",
            ""password2"": ""password"",
            ""email"": ""new-tester@example.com"",
        }

    def test_user_not_created_when_commit(self):
        importlib.reload(forms)
        form = forms.RegistrationForm(data=self.data)

        user = form.save(commit=False)
        self.assertIsNone(user.pk)

    def test_user_created_when_commit(self):
        importlib.reload(forms)
        form = forms.RegistrationForm(data=self.data)

        user = form.save()
        self.assertIsNotNone(user.pk)
",CWE-521,70.0,1
"# -*- coding: utf-8 -*-
from captcha import fields
from django import forms
from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.forms import PasswordResetForm as DjangoPasswordResetForm
from django.contrib.auth.forms import UserCreationForm
from django.contrib.auth.tokens import default_token_generator
from django.contrib.sites.models import Site
from django.urls import reverse
from django.utils.translation import gettext_lazy as _
from django.utils.translation import override

from tcms.core.utils import request_host_link
from tcms.core.utils.mailto import mailto
from tcms.kiwi_auth.models import UserActivationKey
from tcms.utils.permissions import initiate_user_with_default_setups

User = get_user_model()  # pylint: disable=invalid-name


class CustomCaptchaTextInput(fields.CaptchaTextInput):
    template_name = ""captcha_field.html""


class RegistrationForm(UserCreationForm):
    email = forms.EmailField()
    captcha = (
        fields.CaptchaField(
            widget=CustomCaptchaTextInput(attrs={""class"": ""form-control""})
        )
        if settings.USE_CAPTCHA
        else None
    )

    class Meta:
        model = User
        fields = (""username"",)

    def clean_email(self):
        email = self.cleaned_data[""email""]
        try:
            User.objects.get(email=email)
        except User.DoesNotExist:
            return email
        raise forms.ValidationError(_(""A user with that email already exists.""))

    def save(self, commit=True):
        user = super().save(commit=False)
        user.email = self.cleaned_data[""email""]
        user.is_active = False
        user.set_password(self.cleaned_data[""password1""])

        if User.objects.filter(is_superuser=True).count() == 0:
            user.is_superuser = True
            user.is_active = True

        if commit:
            user.save()
            initiate_user_with_default_setups(user)
        return user

    def set_activation_key(self):
        return UserActivationKey.set_random_key_for_user(user=self.instance)

    @override(settings.LANGUAGE_CODE)
    def send_confirm_mail(self, request, activation_key):
        current_site = Site.objects.get(pk=settings.SITE_ID)
        confirm_url = request_host_link(request, current_site.domain) + reverse(
            ""tcms-confirm"",
            args=[
                activation_key.activation_key,
            ],
        )

        mailto(
            template_name=""email/confirm_registration.txt"",
            recipients=self.cleaned_data[""email""],
            subject=_(""Your new %s account confirmation"") % current_site.domain,
            context={
                ""user"": self.instance,
                ""site_domain"": current_site.domain,
                ""confirm_url"": confirm_url,
            },
        )


class PasswordResetForm(
    DjangoPasswordResetForm
):  # pylint: disable=must-inherit-from-model-form
    """"""
    Overrides the default form b/c it uses Site.objects.get_current()
    which uses an internal cache and produces wrong results when
    kiwitcms-tenants is installed.
    """"""

    def save(  # pylint: disable=too-many-arguments
        self,
        domain_override=None,
        subject_template_name=""registration/password_reset_subject.txt"",
        email_template_name=""registration/password_reset_email.html"",
        use_https=False,
        token_generator=default_token_generator,
        from_email=None,
        request=None,
        html_email_template_name=None,
        extra_email_context=None,
    ):
        current_site = Site.objects.get(pk=settings.SITE_ID)
        # call the stock method and just overrides the domain
        super().save(
            current_site.domain,
            subject_template_name,
            email_template_name,
            use_https,
            token_generator,
            from_email,
            request,
            html_email_template_name,
            extra_email_context,
        )
",CWE-770,122.0,1
"# pylint: disable=no-self-use, too-few-public-methods

from django.conf import settings
from django.contrib.sites.models import Site
from django.db.utils import OperationalError, ProgrammingError
from django.http import HttpResponseRedirect
from django.urls import reverse
from django.utils.deprecation import MiddlewareMixin


class CheckDBStructureExistsMiddleware(MiddlewareMixin):
    def process_request(self, request):
        if request.path == ""/init-db/"":
            return None
        try:
            Site.objects.get(pk=settings.SITE_ID)
        except (OperationalError, ProgrammingError):
            # Redirect to Setup view
            return HttpResponseRedirect(reverse(""init-db""))
        return None
",CWE-79,21.0,1
"# pylint: disable=wildcard-import, unused-wildcard-import
""""""
    Django settings for devel env.
""""""

import os

from .common import *  # noqa: F403

# Debug settings
DEBUG = True

# Database settings
DATABASES = {
    ""default"": {
        ""ENGINE"": ""django.db.backends.sqlite3"",
        ""NAME"": str(TEMP_DIR / ""kiwi.devel.sqlite""),  # noqa: F405
        ""USER"": ""root"",
        ""PASSWORD"": """",
        ""HOST"": """",
        ""PORT"": """",
    }
}


CACHES = {
    ""default"": {
        ""BACKEND"": ""django.core.cache.backends.dummy.DummyCache"",
    }
}
# django-debug-toolbar settings

MIDDLEWARE += [""debug_toolbar.middleware.DebugToolbarMiddleware""]  # noqa: F405

INSTALLED_APPS += [""debug_toolbar""]  # noqa: F405

MEDIA_ROOT = os.path.join(TCMS_ROOT_PATH, "".."", ""uploads"")  # noqa: F405

# Needed by django.template.context_processors.debug:
# See:
# http://docs.djangoproject.com/en/dev/ref/templates/api/#django-template-context-processors-debug
INTERNAL_IPS = (""127.0.0.1"",)

STATICFILES_STORAGE = ""tcms.tests.storage.RaiseWhenFileNotFound""
",CWE-79,45.0,1
"# -*- coding: utf-8 -*-
# pylint: disable=attribute-defined-outside-init, invalid-name, objects-update-used

import base64
from xmlrpc.client import Fault

from django.utils.translation import gettext_lazy as _
from parameterized import parameterized

from tcms.rpc.tests.utils import APITestCase


class TestValidators(APITestCase):
    @parameterized.expand(
        [
            ""inline_javascript.svg"",
            ""inline_javascript_mixed_case.svg"",
        ]
    )
    def test_uploading_svg_with_inline_script_should_fail(self, file_name):
        with open(f""tests/ui/data/{file_name}"", ""rb"") as svg_file:
            b64 = base64.b64encode(svg_file.read()).decode()

            message = str(_(""File contains forbidden <script> tag""))
            with self.assertRaisesRegex(Fault, message):
                self.rpc_client.User.add_attachment(""inline_javascript.svg"", b64)

    def test_uploading_filename_ending_in_dot_exe_should_fail(self):
        message = str(_(""Uploading executable files is forbidden""))
        with self.assertRaisesRegex(Fault, message):
            self.rpc_client.User.add_attachment(""hello.exe"", ""a2l3aXRjbXM="")

    def test_uploading_real_exe_file_should_fail(self):
        with open(""tests/ui/data/reactos_csrss.exe"", ""rb"") as exe_file:
            b64 = base64.b64encode(exe_file.read()).decode()

            message = str(_(""Uploading executable files is forbidden""))
            with self.assertRaisesRegex(Fault, message):
                self.rpc_client.User.add_attachment(""csrss.exe_from_reactos"", b64)
",CWE-79,40.0,1
"from django.forms import ValidationError
from django.utils.translation import gettext_lazy as _


def deny_uploads_containing_script_tag(uploaded_file):
    for chunk in uploaded_file.chunks(2048):
        if chunk.lower().find(b""<script"") > -1:
            raise ValidationError(_(""File contains forbidden <script> tag""))


def deny_uploads_ending_in_dot_exe(uploaded_file):
    message = _(""Uploading executable files is forbidden"")

    if uploaded_file.name.find("".exe"") > -1:
        raise ValidationError(message)

    if uploaded_file.content_type in [
        ""application/vnd.microsoft.portable-executable"",
        ""application/x-dosexec"",
        ""application/x-ms-dos-executable"",
        ""application/x-msdownload"",
    ]:
        raise ValidationError(message)
",CWE-79,24.0,1
"# This is a sample configuration file for running the GeoServer Catalog against a H2 database.
# Adapt the url, user, password, and other configuration options to your set up and rename this
# file as jdbcconfig.properties
#
# Note the initialization DDL script for H2 will be automatically run at startup.
# The initialization script is located in the jdbcconfig_scripts directory, named initdb.h2.sql
# The importCatalog configuration option tells GeoServer whether to import the current catalog from the file system
# to the database or not. If set to true, it will be imported and the config option will be set the value 'false'
# for the next start up to avoid trying to re-import the catalog configuration.

enabled=true

initdb=true
initScript=jdbcconfig/scripts/initdb.h2.sql
import=true

jdbcUrl=jdbc:h2:file:${GEOSERVER_DATA_DIR}/jdbcconfig/catalog;AUTO_SERVER=TRUE
driverClassName=org.h2.Driver
username=sa
password=

#
# connection pooling/management parameters
#

# minimum connections in pool  
pool.minIdle=4

# maximum connections in pool
pool.maxActive=10

# whether to pool prepared statements
pool.poolPreparedStatements=true

# size of prepared statement cache, only used if pool.poolPreparedStatements = true 
pool.maxOpenPreparedStatements=50

# whether to validate connections when obtaining from the pool
pool.testOnBorrow=true

# validation query for connections from pool, must be set when pool.testOnBorrow = true
pool.validationQuery=SELECT now()


# The indication of whether objects will be validated by the idle object evictor (if any). If an object fails to validate, it will be dropped from the pool. 
pool.testWhileIdle=false

# The number of milliseconds to sleep between runs of the idle object evictor thread. When non-positive, no idle object evictor thread will be run. 
pool.timeBetweenEvictionRunsMillis=-1L",CWE-89,49.0,1
"# This is a sample configuration file for running the GeoServer Catalog against a PostgreSQL 
# database.
#
# Set the jndiName for a JNDI dataSource provided by your container, or set the jdbcUrl, username, 
# password, and pool.* parameters appropriately to connect directly. If both are specified, then 
# JNDI lookup will be attempted first, and a direct JDBC connection if that fails.
#
# Note the initialization DDL script for PostgreSQL must have been run before starting GeoServer.
# The initialization script is located in the jdbcconfig_scripts directory, named 
# 'initdb.postgres.sql'.
#
# The import configuration option tells GeoServer whether to import the current catalog from the 
# file system to the database or not. If set to true, it will be imported and the config option will
# be set the value 'false' for the next start up to avoid trying to re-import the catalog 
# configuration.

#
# Use JDBCConfig.  Turn off to use the data directory for all configuration instead.
#
enabled=true

#
# Initialize an empty database.  Should be set to false and done manually before starting GeoServer 
# when using Postgres
#
initdb=true
initScript=jdbcconfig/scripts/initdb.postgres.sql

#
# Import the data directory into a new database.  Should only be used on the first run.
#
import=true

#
# The JNDI name for the data source.  Uncomment to use JNDI.
#
#jndiName=java\:/comp/env/jdbc/gsconfig

#
# JDBC direct connection parameters.  Comment out following lines if using JNDI and you don't want 
# a fallback.
#
jdbcUrl=jdbc:postgresql://localhost:5432/gscatalog
driverClassName=org.postgresql.Driver
username=postgres
password=

#
# connection pooling/management parameters
#

# minimum connections in pool  
pool.minIdle=4

# maximum connections in pool
pool.maxActive=10

# whether to pool prepared statements
pool.poolPreparedStatements=true

# size of prepared statement cache, only used if pool.poolPreparedStatements = true 
pool.maxOpenPreparedStatements=50

# whether to validate connections when obtaining from the pool
pool.testOnBorrow=true

# validation query for connections from pool, must be set when pool.testOnBorrow = true
pool.validationQuery=SELECT now()

# The indication of whether objects will be validated by the idle object evictor (if any). If an object fails to validate, it will be dropped from the pool. 
pool.testWhileIdle=false

# The number of milliseconds to sleep between runs of the idle object evictor thread. When non-positive, no idle object evictor thread will be run. 
pool.timeBetweenEvictionRunsMillis=-1L",CWE-89,74.0,1
"#
# Copyright 2022 Apollo Authors
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
spring:
  application:
    name: apollo-portal
  profiles:
    active: ${apollo_profile}
  jpa:
    properties:
      hibernate:
        metadata_builder_contributor: com.ctrip.framework.apollo.common.jpa.SqlFunctionsMetadataBuilderContributor
        query:
          plan_cache_max_size: 192 # limit query plan cache max size
  session:
    store-type: jdbc
    jdbc:
      initialize-schema: never
  servlet:
    multipart:
      max-file-size: 200MB  # import data configs
      max-request-size: 200MB
server:
  port: 8070
  compression:
    enabled: true
  tomcat:
    use-relative-redirects: true

logging:
  file:
    name: /opt/logs/100003173/apollo-portal.log

management:
  health:
    status:
      order: DOWN, OUT_OF_SERVICE, UNKNOWN, UP
    ldap:
      enabled: false # disable ldap health check by default
",CWE-352,52.0,1
"from typing import TYPE_CHECKING, Any, AsyncGenerator, Dict, Generic, Tuple, cast

from starlite.connection.base import (
    ASGIConnection,
    Auth,
    User,
    empty_receive,
    empty_send,
)
from starlite.datastructures.multi_dicts import FormMultiDict
from starlite.enums import RequestEncodingType
from starlite.exceptions import InternalServerException
from starlite.multipart import parse_content_header, parse_multipart_form
from starlite.parsers import parse_url_encoded_form_data
from starlite.types import Empty
from starlite.utils.serialization import decode_json, decode_msgpack

if TYPE_CHECKING:
    from starlite.handlers.http import HTTPRouteHandler  # noqa: F401
    from starlite.types.asgi_types import HTTPScope, Method, Receive, Scope, Send


SERVER_PUSH_HEADERS = {
    ""accept"",
    ""accept-encoding"",
    ""accept-language"",
    ""cache-control"",
    ""user-agent"",
}


class Request(Generic[User, Auth], ASGIConnection[""HTTPRouteHandler"", User, Auth]):
    """"""The Starlite Request class.""""""

    __slots__ = (""_json"", ""_form"", ""_body"", ""_msgpack"", ""_content_type"", ""is_connected"")

    scope: ""HTTPScope""
    """"""The ASGI scope attached to the connection.""""""
    receive: ""Receive""
    """"""The ASGI receive function.""""""
    send: ""Send""
    """"""The ASGI send function.""""""

    def __init__(self, scope: ""Scope"", receive: ""Receive"" = empty_receive, send: ""Send"" = empty_send) -> None:
        """"""Initialize ``Request``.

        Args:
            scope: The ASGI connection scope.
            receive: The ASGI receive function.
            send: The ASGI send function.
        """"""
        super().__init__(scope, receive, send)
        self.is_connected: bool = True
        self._body: Any = scope.get(""_body"", Empty)
        self._form: Any = scope.get(""_form"", Empty)
        self._json: Any = scope.get(""_json"", Empty)
        self._msgpack: Any = scope.get(""_msgpack"", Empty)
        self._content_type: Any = scope.get(""_content_type"", Empty)

    @property
    def method(self) -> ""Method"":
        """"""Return the request method.

        Returns:
            The request :class:`Method <starlite.types.Method>`
        """"""
        return self.scope[""method""]

    @property
    def content_type(self) -> Tuple[str, Dict[str, str]]:
        """"""Parse the request's 'Content-Type' header, returning the header value and any options as a dictionary.

        Returns:
            A tuple with the parsed value and a dictionary containing any options send in it.
        """"""
        if self._content_type is Empty:
            self._content_type = self.scope[""_content_type""] = parse_content_header(self.headers.get(""Content-Type"", """"))  # type: ignore[typeddict-item]
        return cast(""Tuple[str, Dict[str, str]]"", self._content_type)

    async def json(self) -> Any:
        """"""Retrieve the json request body from the request.

        Returns:
            An arbitrary value
        """"""
        if self._json is Empty:
            body = await self.body()
            self._json = self.scope[""_json""] = decode_json(body or b""null"")  # type: ignore[typeddict-item]
        return self._json

    async def msgpack(self) -> Any:
        """"""Retrieve the MessagePack request body from the request.

        Returns:
            An arbitrary value
        """"""
        if self._msgpack is Empty:
            body = await self.body()
            self._msgpack = self.scope[""_msgpack""] = decode_msgpack(body or b""\xc0"")  # type: ignore[typeddict-item]
        return self._msgpack

    async def stream(self) -> AsyncGenerator[bytes, None]:
        """"""Return an async generator that streams chunks of bytes.

        Returns:
            An async generator.

        Raises:
            RuntimeError: if the stream is already consumed
        """"""
        if self._body is Empty:
            if self.is_connected:
                while event := await self.receive():
                    if event[""type""] == ""http.request"":
                        if event[""body""]:
                            yield event[""body""]
                        if not event.get(""more_body"", False):
                            break
                    if event[""type""] == ""http.disconnect"":
                        raise InternalServerException(""client disconnected prematurely"")

                self.is_connected = False
                yield b""""
            else:
                raise InternalServerException(""stream consumed"")
        else:
            yield self._body
            yield b""""
            return

    async def body(self) -> bytes:
        """"""Return the body of the request.

        Returns:
            A byte-string representing the body of the request.
        """"""
        if self._body is Empty:
            self._body = self.scope[""_body""] = b"""".join([c async for c in self.stream()])  # type: ignore[typeddict-item]
        return cast(""bytes"", self._body)

    async def form(self) -> FormMultiDict:
        """"""Retrieve form data from the request. If the request is either a 'multipart/form-data' or an
        'application/x-www-form- urlencoded', return a FormMultiDict instance populated with the values sent in the
        request, otherwise, an empty instance.

        Returns:
            A FormMultiDict instance
        """"""
        if self._form is Empty:
            content_type, options = self.content_type
            if content_type == RequestEncodingType.MULTI_PART:
                self._form = self.scope[""_form""] = form_values = parse_multipart_form(  # type: ignore[typeddict-item]
                    body=await self.body(), boundary=options.get(""boundary"", """").encode()
                )
                return FormMultiDict(form_values)
            if content_type == RequestEncodingType.URL_ENCODED:
                self._form = self.scope[""_form""] = form_values = parse_url_encoded_form_data(  # type: ignore[typeddict-item]
                    await self.body(),
                )
                return FormMultiDict(form_values)
            return FormMultiDict()
        return FormMultiDict(self._form)

    async def send_push_promise(self, path: str) -> None:
        """"""Send a push promise.

        This method requires the `http.response.push` extension to be sent from the ASGI server.

        Args:
            path: Path to send the promise to.

        Returns:
            None
        """"""
        extensions: Dict[str, Dict[Any, Any]] = self.scope.get(""extensions"") or {}
        if ""http.response.push"" in extensions:
            raw_headers = []
            for name in SERVER_PUSH_HEADERS:
                for value in self.headers.getall(name, []):
                    raw_headers.append((name.encode(""latin-1""), value.encode(""latin-1"")))
            await self.send({""type"": ""http.response.push"", ""path"": path, ""headers"": raw_headers})
",CWE-770,182.0,1
"""""""The contents of this file were adapted from sanic.

MIT License

Copyright (c) 2016-present Sanic Community

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
""""""

import re
from collections import defaultdict
from email.utils import decode_rfc2231
from typing import Any, DefaultDict, Dict, List, Tuple
from urllib.parse import unquote

from starlite.datastructures.upload_file import UploadFile
from starlite.exceptions import SerializationException
from starlite.utils.serialization import decode_json

_token, _quoted = r""([\w!#$%&'*+\-.^_`|~]+)"", r'""([^""]*)""'
_param = re.compile(rf"";\s*{_token}=(?:{_token}|{_quoted})"", re.ASCII)
_firefox_quote_escape = re.compile(r'\\""(?!; |\s*$)')


def parse_content_header(value: str) -> Tuple[str, Dict[str, str]]:
    """"""Parse content-type and content-disposition header values.

    Args:
        value: A header string value to parse.

    Returns:
        A tuple containing the normalized header string and a dictionary of parameters.
    """"""
    value = _firefox_quote_escape.sub(""%22"", value)
    pos = value.find("";"")
    if pos == -1:
        options: Dict[str, str] = {}
    else:
        options = {
            m.group(1).lower(): m.group(2) or m.group(3).replace(""%22"", '""') for m in _param.finditer(value[pos:])
        }
        value = value[:pos]
    return value.strip().lower(), options


def parse_multipart_form(body: bytes, boundary: bytes) -> Dict[str, Any]:
    """"""Parse multipart form data.

    Args:
        body: Body of the request.
        boundary: Boundary of the multipart message.

    Returns:
        A dictionary of parsed results.
    """"""

    fields: DefaultDict[str, List[Any]] = defaultdict(list)

    if body and boundary:
        form_parts = body.split(boundary)
        for form_part in form_parts[1:-1]:
            file_name = None
            content_type = ""text/plain""
            content_charset = ""utf-8""
            field_name = None
            line_index = 2
            line_end_index = 0
            headers: List[Tuple[str, str]] = []

            while line_end_index != -1:
                line_end_index = form_part.find(b""\r\n"", line_index)
                form_line = form_part[line_index:line_end_index].decode(""utf-8"")

                if not form_line:
                    break

                line_index = line_end_index + 2
                colon_index = form_line.index("":"")
                current_idx = colon_index + 2
                form_header_field = form_line[0:colon_index].lower()
                form_header_value, form_parameters = parse_content_header(form_line[current_idx:])

                if form_header_field == ""content-disposition"":
                    field_name = form_parameters.get(""name"")
                    file_name = form_parameters.get(""filename"")

                    if file_name is None and (filename_with_asterisk := form_parameters.get(""filename*"")):
                        encoding, _, value = decode_rfc2231(filename_with_asterisk)
                        file_name = unquote(value, encoding=encoding or content_charset)

                elif form_header_field == ""content-type"":
                    content_type = form_header_value
                    content_charset = form_parameters.get(""charset"", ""utf-8"")
                headers.append((form_header_field, form_header_value))

            if field_name:
                post_data = form_part[line_index:-4].lstrip(b""\r\n"")
                if file_name:
                    form_file = UploadFile(
                        content_type=content_type, filename=file_name, file_data=post_data, headers=dict(headers)
                    )
                    fields[field_name].append(form_file)
                else:
                    try:
                        fields[field_name].append(decode_json(post_data))
                    except SerializationException:
                        fields[field_name].append(post_data.decode(content_charset))

    return {k: v if len(v) > 1 else v[0] for k, v in fields.items()}
",CWE-770,126.0,1
"import inspect
from typing import List
from unittest.mock import MagicMock, PropertyMock

import pytest

from starlite import LoggingConfig
from starlite.app import DEFAULT_CACHE_CONFIG, Starlite
from starlite.config.app import AppConfig
from starlite.router import Router


@pytest.fixture()
def app_config_object() -> AppConfig:
    return AppConfig(
        after_exception=[],
        after_request=None,
        after_response=None,
        after_shutdown=[],
        after_startup=[],
        allowed_hosts=[],
        before_request=None,
        before_send=[],
        before_shutdown=[],
        before_startup=[],
        cache_config=DEFAULT_CACHE_CONFIG,
        cache_control=None,
        compression_config=None,
        cors_config=None,
        csrf_config=None,
        debug=False,
        dependencies={},
        exception_handlers={},
        guards=[],
        initial_state={},
        logging_config=None,
        middleware=[],
        on_shutdown=[],
        on_startup=[],
        openapi_config=None,
        opt={},
        parameters={},
        plugins=[],
        response_class=None,
        response_cookies=[],
        response_headers={},
        route_handlers=[],
        security=[],
        static_files_config=[],
        tags=[],
        template_config=None,
        request_class=None,
        websocket_class=None,
        etag=None,
    )


def test_app_params_defined_on_app_config_object() -> None:
    """"""Ensures that all parameters to the `Starlite` constructor are present on the `AppConfig` object.""""""
    starlite_signature = inspect.signature(Starlite)
    app_config_fields = AppConfig.__fields__
    for name in starlite_signature.parameters:
        if name in (""on_app_init"", ""initial_state""):
            continue
        assert name in app_config_fields
    # ensure there are not fields defined on AppConfig that aren't in the Starlite signature
    assert not (app_config_fields.keys() - starlite_signature.parameters.keys())


def test_app_config_object_used(app_config_object: AppConfig, monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure that the properties on the `AppConfig` object are accessed within the `Starlite` constructor.

    In the test we replace every field on the `AppConfig` type with a property mock so that we can check that it has at
    least been accessed. It doesn't actually check that we do the right thing with it, but is a guard against the case
    of adding a parameter to the `Starlite` signature and to the `AppConfig` object, and using the value from the
    parameter downstream from construction of the `AppConfig` object.
    """"""

    # replace each field on the `AppConfig` object with a `PropertyMock`, this allows us to assert that the properties
    # have been accessed during app instantiation.
    property_mocks: List[PropertyMock] = []
    for name in AppConfig.__fields__:
        if name == ""cache_config"":
            property_mock = PropertyMock(return_value=DEFAULT_CACHE_CONFIG)
        else:
            # default iterable return value allows the mock properties that need to be iterated over in
            # `Starlite.__init__()` to not blow up, for other properties it shouldn't matter what the value is for the
            # sake of this test.
            property_mock = PropertyMock(return_value=[])
        property_mocks.append(property_mock)
        monkeypatch.setattr(type(app_config_object), name, property_mock, raising=False)

    # Things that we don't actually need to call for this test
    monkeypatch.setattr(Starlite, ""register"", MagicMock())
    monkeypatch.setattr(Starlite, ""_create_asgi_handler"", MagicMock())
    monkeypatch.setattr(Router, ""__init__"", MagicMock())

    # instantiates the app with an `on_app_config` that returns our patched `AppConfig` object.
    Starlite(route_handlers=[], on_app_init=[MagicMock(return_value=app_config_object)])

    # this ensures that each of the properties of the `AppConfig` object have been accessed within `Starlite.__init__()`
    for mock in property_mocks:
        mock.assert_called()


def test_app_debug_create_logger() -> None:
    app = Starlite([], debug=True)

    assert app.logging_config
    assert app.logging_config.loggers[""starlite""][""level""] == ""DEBUG""  # type: ignore[attr-defined]


def test_app_debug_explicitly_disable_logging() -> None:
    app = Starlite([], debug=True, logging_config=None)

    assert not app.logging_config


def test_app_debug_update_logging_config() -> None:
    logging_config = LoggingConfig()
    app = Starlite([], debug=True, logging_config=logging_config)

    assert app.logging_config is logging_config
    assert app.logging_config.loggers[""starlite""][""level""] == ""DEBUG""  # type: ignore[attr-defined]


def test_set_initial_state() -> None:
    def set_initial_state_in_hook(app_config: AppConfig) -> AppConfig:
        assert isinstance(app_config.initial_state, dict)
        app_config.initial_state[""c""] = ""D""  # pyright:ignore
        app_config.initial_state[""e""] = ""f""  # pyright:ignore
        return app_config

    app = Starlite(route_handlers=[], initial_state={""a"": ""b"", ""c"": ""d""}, on_app_init=[set_initial_state_in_hook])
    assert app.state._state == {""a"": ""b"", ""c"": ""D"", ""e"": ""f""}
",CWE-770,136.0,1
"from collections import OrderedDict, namedtuple
from decimal import Decimal
import uuid

from django.core import validators
from django.template import engines

from nautobot.dcim import choices  # TODO move dcim.choices.CableLengthUnitChoices into core


# Setup UtilizationData named tuple for use by multiple methods
UtilizationData = namedtuple(""UtilizationData"", [""numerator"", ""denominator""])


def deepmerge(original, new):
    """"""
    Deep merge two dictionaries (new into original) and return a new dict
    """"""
    merged = OrderedDict(original)
    for key, val in new.items():
        if key in original and isinstance(original[key], dict) and isinstance(val, dict):
            merged[key] = deepmerge(original[key], val)
        else:
            merged[key] = val
    return merged


def flatten_dict(d, prefix="""", separator="".""):
    """"""
    Flatten nested dictionaries into a single level by joining key names with a separator.

    :param d: The dictionary to be flattened
    :param prefix: Initial prefix (if any)
    :param separator: The character to use when concatenating key names
    """"""
    ret = {}
    for k, v in d.items():
        key = separator.join([prefix, k]) if prefix else k
        if isinstance(v, dict):
            ret.update(flatten_dict(v, prefix=key))
        else:
            ret[key] = v
    return ret


def flatten_iterable(iterable):
    """"""
    Flatten a nested iterable such as a list of lists, keeping strings intact.

    :param iterable: The iterable to be flattened
    :returns: generator
    """"""
    for i in iterable:
        if hasattr(i, ""__iter__"") and not isinstance(i, str):
            for j in flatten_iterable(i):
                yield j
        else:
            yield i


def is_uuid(value):
    try:
        if isinstance(value, uuid.UUID) or uuid.UUID(value):
            return True
    except (ValueError, TypeError, AttributeError):
        pass
    return False


def is_url(value):
    """"""
    Validate whether a value is a URL.

    Args:
        value (str): String to validate.

    Returns:
        (bool): True if the value is a valid URL, False otherwise.
    """"""
    try:
        return validators.URLValidator()(value) is None
    except validators.ValidationError:
        return False


def merge_dicts_without_collision(d1, d2):
    """"""
    Merge two dicts into a new dict, but raise a ValueError if any key exists with differing values across both dicts.
    """"""
    intersection = d1.keys() & d2.keys()
    for k in intersection:
        if d1[k] != d2[k]:
            raise ValueError(f'Conflicting values for key ""{k}"": ({d1[k]!r}, {d2[k]!r})')
    return {**d1, **d2}


def render_jinja2(template_code, context):
    """"""
    Render a Jinja2 template with the provided context. Return the rendered content.
    """"""
    rendering_engine = engines[""jinja""]
    template = rendering_engine.from_string(template_code)
    return template.render(context=context)


def shallow_compare_dict(source_dict, destination_dict, exclude=None):
    """"""
    Return a new dictionary of the different keys. The values of `destination_dict` are returned. Only the equality of
    the first layer of keys/values is checked. `exclude` is a list or tuple of keys to be ignored.
    """"""
    difference = {}

    for key in destination_dict:
        if source_dict.get(key) != destination_dict[key]:
            if isinstance(exclude, (list, tuple)) and key in exclude:
                continue
            difference[key] = destination_dict[key]

    return difference


def to_meters(length, unit):
    """"""
    Convert the given length to meters.
    """"""
    length = int(length)
    if length < 0:
        raise ValueError(""Length must be a positive integer"")

    valid_units = choices.CableLengthUnitChoices.values()
    if unit not in valid_units:
        raise ValueError(f""Unknown unit {unit}. Must be one of the following: {', '.join(valid_units)}"")

    if unit == choices.CableLengthUnitChoices.UNIT_METER:
        return length
    if unit == choices.CableLengthUnitChoices.UNIT_CENTIMETER:
        return length / 100
    if unit == choices.CableLengthUnitChoices.UNIT_FOOT:
        return length * Decimal(""0.3048"")
    if unit == choices.CableLengthUnitChoices.UNIT_INCH:
        return length * Decimal(""0.3048"") * 12
    raise ValueError(f""Unknown unit {unit}. Must be 'm', 'cm', 'ft', or 'in'."")
",CWE-79,143.0,1
"from django import template
from django.contrib.contenttypes.models import ContentType
from django.utils.html import escape
from django.utils.safestring import mark_safe

from nautobot.extras.models import ComputedField

register = template.Library()


@register.simple_tag(takes_context=True)
def has_computed_fields(context, obj):
    """"""
    Return a boolean value indicating if an object's content type has associated computed fields.
    """"""
    content_type = ContentType.objects.get_for_model(obj)
    return ComputedField.objects.filter(content_type=content_type).exists()


@register.simple_tag(takes_context=True)
def computed_fields(context, obj, advanced_ui=None):
    """"""
    Render all applicable links for the given object.
    This can also check whether the advanced_ui attribute is True or False for UI display purposes.
    """"""
    fields = obj.get_computed_fields(label_as_key=True, advanced_ui=advanced_ui)
    if not computed_fields:
        return """"

    template_code = """"

    for label, value in fields.items():
        escaped_label = escape(label)
        template_code += f""""""
            <tr>
                <td><span title=""{escaped_label}"">{escaped_label}</span></td>
                <td>{escape(value)}</td>
            <tr>
            """"""
    return mark_safe(template_code)
",CWE-79,41.0,1
"from collections import OrderedDict

from django import template
from django.contrib.contenttypes.models import ContentType
from django.utils.safestring import mark_safe

from nautobot.core.utils.data import render_jinja2
from nautobot.extras.models import CustomLink


register = template.Library()

LINK_BUTTON = '<a href=""{}""{} class=""btn btn-sm btn-{}"">{}</a>\n'
GROUP_BUTTON = (
    '<div class=""btn-group"">\n'
    '<button type=""button"" class=""btn btn-sm btn-{} dropdown-toggle"" data-toggle=""dropdown"">\n'
    '{} <span class=""caret""></span>\n'
    ""</button>\n""
    '<ul class=""dropdown-menu pull-right"">\n'
    ""{}</ul></div>\n""
)
GROUP_LINK = '<li><a href=""{}""{}>{}</a></li>\n'


@register.simple_tag(takes_context=True)
def custom_links(context, obj):
    """"""
    Render all applicable links for the given object.
    """"""
    content_type = ContentType.objects.get_for_model(obj)
    links = CustomLink.objects.filter(content_type=content_type)
    if not links:
        return """"

    # Pass select context data when rendering the CustomLink
    link_context = {
        ""obj"": obj,
        ""debug"": context.get(""debug"", False),  # django.template.context_processors.debug
        ""request"": context[""request""],  # django.template.context_processors.request
        ""user"": context[""user""],  # django.contrib.auth.context_processors.auth
        ""perms"": context[""perms""],  # django.contrib.auth.context_processors.auth
    }
    template_code = """"
    group_names = OrderedDict()

    for cl in links:
        # Organize custom links by group
        if cl.group_name and cl.group_name in group_names:
            group_names[cl.group_name].append(cl)
        elif cl.group_name:
            group_names[cl.group_name] = [cl]

        # Add non-grouped links
        else:
            try:
                text_rendered = render_jinja2(cl.text, link_context)
                if text_rendered:
                    link_rendered = render_jinja2(cl.target_url, link_context)
                    link_target = ' target=""_blank""' if cl.new_window else """"
                    template_code += LINK_BUTTON.format(link_rendered, link_target, cl.button_class, text_rendered)
            except Exception as e:
                template_code += (
                    f'<a class=""btn btn-sm btn-default"" disabled=""disabled"" title=""{e}"">'
                    f'<i class=""mdi mdi-alert""></i> {cl.name}</a>\n'
                )

    # Add grouped links to template
    for group, links in group_names.items():
        links_rendered = []

        for cl in links:
            try:
                text_rendered = render_jinja2(cl.text, link_context)
                if text_rendered:
                    link_target = ' target=""_blank""' if cl.new_window else """"
                    link_rendered = render_jinja2(cl.target_url, link_context)
                    links_rendered.append(GROUP_LINK.format(link_rendered, link_target, text_rendered))
            except Exception as e:
                links_rendered.append(
                    f'<li><a disabled=""disabled"" title=""{e}""><span class=""text-muted"">'
                    f'<i class=""mdi mdi-alert""></i> {cl.name}</span></a></li>'
                )

        if links_rendered:
            template_code += GROUP_BUTTON.format(links[0].button_class, group, """".join(links_rendered))

    return mark_safe(template_code)
",CWE-79,88.0,1
"from collections import OrderedDict

from django import template
from django.contrib.contenttypes.models import ContentType
from django.urls import reverse
from django.utils.safestring import mark_safe

from nautobot.extras.models import JobButton
from nautobot.core.utils.data import render_jinja2


register = template.Library()

GROUP_DROPDOWN = """"""
<div class=""btn-group"">
  <button type=""button"" class=""btn btn-sm btn-{group_button_class} dropdown-toggle"" data-toggle=""dropdown"">
    {group_name} <span class=""caret""></span>
  </button>
  <ul class=""dropdown-menu pull-right"">
    {grouped_buttons}
  </ul>
</div>
""""""

HIDDEN_INPUTS = """"""
<input type=""hidden"" name=""csrfmiddlewaretoken"" value=""{csrf_token}"">
<input type=""hidden"" name=""object_pk"" value=""{object_pk}"">
<input type=""hidden"" name=""object_model_name"" value=""{object_model_name}"">
<input type=""hidden"" name=""redirect_path"" value=""{redirect_path}"">
""""""

NO_CONFIRM_BUTTON = """"""
<button type=""submit"" form=""form_id_{button_id}"" class=""btn btn-sm btn-{button_class}"" {disabled}>{button_text}</button>
""""""

NO_CONFIRM_FORM = """"""
<form id=""form_id_{button_id}"" action=""{button_url}"" method=""post"" class=""form"">
  {hidden_inputs}
</form>
""""""

CONFIRM_BUTTON = """"""
<button type=""button"" class=""btn btn-sm btn-{button_class}"" data-toggle=""modal"" data-target=""#confirm_modal_id_{button_id}"" {disabled}>
  {button_text}
</button>
""""""

CONFIRM_MODAL = """"""
<div class=""modal fade"" id=""confirm_modal_id_{button_id}"" tabindex=""-1"" role=""dialog"" aria-labelledby=""confirm_modal_label_{button_id}"">
  <div class=""modal-dialog"" role=""document"">
    <div class=""modal-content"">
      <div class=""modal-header"">
        <button type=""button"" class=""close"" data-dismiss=""modal"" aria-label=""Close""><span aria-hidden=""true"">&times;</span></button>
        <h4 class=""modal-title"" id=""confirm_modal_label_{button_id}"">Confirmation</h4>
      </div>
      <form id=""form_id_{button_id}"" action=""{button_url}"" method=""post"" class=""form"">
        <div class=""modal-body"">
          {hidden_inputs}
          Run Job <strong>'{job}'</strong> with object <strong>'{object}'</strong>?
        </div>
        <div class=""modal-footer"">
          <button type=""button"" class=""btn btn-default"" data-dismiss=""modal"">Cancel</button>
          <button type=""submit"" class=""btn btn-primary"">Confirm</button>
        </div>
      </form>
    </div>
  </div>
</div>
""""""


@register.simple_tag(takes_context=True)
def job_buttons(context, obj):
    """"""
    Render all applicable job buttons for the given object.
    """"""
    content_type = ContentType.objects.get_for_model(obj)
    buttons = JobButton.objects.filter(content_types=content_type)
    if not buttons:
        return """"

    # Pass select context data when rendering the JobButton
    button_context = {
        ""obj"": obj,
        ""debug"": context.get(""debug"", False),  # django.template.context_processors.debug
        ""request"": context[""request""],  # django.template.context_processors.request
        ""user"": context[""user""],  # django.contrib.auth.context_processors.auth
        ""perms"": context[""perms""],  # django.contrib.auth.context_processors.auth
    }
    buttons_html = forms_html = """"
    group_names = OrderedDict()

    hidden_inputs = HIDDEN_INPUTS.format(
        csrf_token=context[""csrf_token""],
        object_pk=obj.pk,
        object_model_name=f""{content_type.app_label}.{content_type.model}"",
        redirect_path=context[""request""].path,
    )

    for jb in buttons:
        template_args = {
            ""button_id"": jb.pk,
            ""button_text"": jb.text,
            ""button_class"": jb.button_class,
            ""button_url"": reverse(""extras:jobbutton_run"", kwargs={""pk"": jb.pk}),
            ""object"": obj,
            ""job"": jb.job,
            ""hidden_inputs"": hidden_inputs,
            ""disabled"": """" if context[""user""].has_perms((""extras.run_jobbutton"", ""extras.run_job"")) else ""disabled"",
        }

        # Organize job buttons by group
        if jb.group_name:
            group_names.setdefault(jb.group_name, [])
            group_names[jb.group_name].append(jb)

        # Add non-grouped buttons
        else:
            try:
                text_rendered = render_jinja2(jb.text, button_context)
                if text_rendered:
                    template_args[""button_text""] = text_rendered
                    if jb.confirmation:
                        buttons_html += CONFIRM_BUTTON.format(**template_args)
                        forms_html += CONFIRM_MODAL.format(**template_args)
                    else:
                        buttons_html += NO_CONFIRM_BUTTON.format(**template_args)
                        forms_html += NO_CONFIRM_FORM.format(**template_args)
            except Exception as e:
                buttons_html += (
                    f'<a class=""btn btn-sm btn-default"" disabled=""disabled"" title=""{e}"">'
                    f'<i class=""mdi mdi-alert""></i> {jb.name}</a>\n'
                )

    # Add grouped buttons to template
    for group_name, buttons in group_names.items():
        group_button_class = buttons[0].button_class

        buttons_rendered = """"

        for jb in buttons:
            template_args = {
                ""button_id"": jb.pk,
                ""button_text"": jb.text,
                ""button_class"": ""link"",
                ""button_url"": reverse(""extras:jobbutton_run"", kwargs={""pk"": jb.pk}),
                ""object"": obj,
                ""job"": jb.job,
                ""hidden_inputs"": hidden_inputs,
                ""disabled"": """" if context[""user""].has_perms((""extras.run_jobbutton"", ""extras.run_job"")) else ""disabled"",
            }
            try:
                text_rendered = render_jinja2(jb.text, button_context)
                if text_rendered:
                    template_args[""button_text""] = text_rendered
                    if jb.confirmation:
                        buttons_rendered += ""<li>"" + CONFIRM_BUTTON.format(**template_args) + ""</li>""
                        forms_html += CONFIRM_MODAL.format(**template_args)
                    else:
                        buttons_rendered += ""<li>"" + NO_CONFIRM_BUTTON.format(**template_args) + ""</li>""
                        forms_html += NO_CONFIRM_FORM.format(**template_args)
            except Exception as e:
                buttons_rendered += (
                    f'<li><a disabled=""disabled"" title=""{e}""><span class=""text-muted"">'
                    f'<i class=""mdi mdi-alert""></i> {jb.name}</span></a></li>'
                )

        if buttons_rendered:
            buttons_html += GROUP_DROPDOWN.format(
                group_button_class=group_button_class,
                group_name=group_name,
                grouped_buttons=buttons_rendered,
            )

    # We want all of the buttons first and then any modals and forms so the buttons render properly
    return mark_safe(buttons_html + forms_html)
",CWE-79,177.0,1
"import logging

from django import template as template_
from django.conf import settings
from django.utils.safestring import mark_safe

from nautobot.extras.plugins import Banner, TemplateExtension
from nautobot.extras.registry import registry

register = template_.Library()


logger = logging.getLogger(__name__)


def _get_registered_content(obj, method, template_context, return_html=True):
    """"""
    Given an object and a TemplateExtension method name and the template context, return all the
    registered content for the object's model.
    """"""
    context = {
        ""object"": obj,
        ""request"": template_context[""request""],
        ""settings"": template_context[""settings""],
        ""csrf_token"": template_context[""csrf_token""],
        ""perms"": template_context[""perms""],
    }

    model_name = obj._meta.label_lower
    template_extensions = registry[""plugin_template_extensions""].get(model_name, [])
    objects = []
    html = """"
    for template_extension in template_extensions:
        # If the class has not overridden the specified method, we can skip it (because we know it
        # will raise NotImplementedError).
        if getattr(template_extension, method) == getattr(TemplateExtension, method):
            continue

        # Update context with plugin-specific configuration parameters
        plugin_name = template_extension.__module__.split(""."")[0]
        context[""config""] = settings.PLUGINS_CONFIG.get(plugin_name, {})

        # Call the method to render content
        instance = template_extension(context)
        content = getattr(instance, method)()
        if not return_html:
            for i, content in enumerate(content):
                objects.append({f""{plugin_name}:{i+1}"": content})
        else:
            html += content

    if not return_html:
        return objects

    return mark_safe(html)


@register.simple_tag(takes_context=True)
def plugin_buttons(context, obj):
    """"""
    Render all buttons registered by plugins
    """"""
    return _get_registered_content(obj, ""buttons"", context)


@register.simple_tag(takes_context=True)
def plugin_left_page(context, obj):
    """"""
    Render all left page content registered by plugins
    """"""
    return _get_registered_content(obj, ""left_page"", context)


@register.simple_tag(takes_context=True)
def plugin_right_page(context, obj):
    """"""
    Render all right page content registered by plugins
    """"""
    return _get_registered_content(obj, ""right_page"", context)


@register.simple_tag(takes_context=True)
def plugin_full_width_page(context, obj):
    """"""
    Render all full width page content registered by plugins
    """"""
    return _get_registered_content(obj, ""full_width_page"", context)


@register.inclusion_tag(""extras/templatetags/plugin_object_detail_tabs.html"", takes_context=True)
def plugin_object_detail_tabs(context, obj):
    """"""
    Render all custom tabs registered by plugins for the object detail view
    """"""
    context[""plugin_object_detail_tabs""] = _get_registered_content(obj, ""detail_tabs"", context, return_html=False)
    return context


@register.inclusion_tag(""extras/templatetags/plugin_banners.html"", takes_context=True)
def plugin_banners(context):
    """"""
    Render all banners registered by plugins.
    """"""
    banners = []
    for banner_function in registry[""plugin_banners""]:
        try:
            banner = banner_function(context)
        except Exception as exc:
            logger.error(""Plugin banner function %s raised an exception: %s"", banner_function, exc)
            continue

        if banner:
            if isinstance(banner, Banner):
                banners.append(banner)
            else:
                logger.error(
                    ""Plugin banner function %s should return a Banner, but instead returned %s"",
                    banner_function,
                    banner,
                )

    return {""banners"": banners}
",CWE-79,123.0,1
"from django.conf import settings
from django.conf.urls import include
from django.urls import path
from django.views.static import serve

from nautobot.core.views import CustomGraphQLView, HomeView, StaticMediaFailureView, SearchView, nautobot_metrics_view
from nautobot.extras.plugins.urls import (
    plugin_admin_patterns,
    plugin_patterns,
)
from nautobot.users.views import LoginView, LogoutView
from .admin import admin_site


urlpatterns = [
    # Base views
    path("""", HomeView.as_view(), name=""home""),
    path(""search/"", SearchView.as_view(), name=""search""),
    # Login/logout
    path(""login/"", LoginView.as_view(), name=""login""),
    path(""logout/"", LogoutView.as_view(), name=""logout""),
    # Apps
    path(""circuits/"", include(""nautobot.circuits.urls"")),
    path(""dcim/"", include(""nautobot.dcim.urls"")),
    path(""extras/"", include(""nautobot.extras.urls"")),
    path(""ipam/"", include(""nautobot.ipam.urls"")),
    path(""tenancy/"", include(""nautobot.tenancy.urls"")),
    path(""user/"", include(""nautobot.users.urls"")),
    path(""virtualization/"", include(""nautobot.virtualization.urls"")),
    # API
    path(""api/"", include(""nautobot.core.api.urls"")),
    # GraphQL
    path(""graphql/"", CustomGraphQLView.as_view(graphiql=True), name=""graphql""),
    # Serving static media in Django
    path(""media/<path:path>"", serve, {""document_root"": settings.MEDIA_ROOT}),
    # Admin
    path(""admin/"", admin_site.urls),
    # Errors
    path(""media-failure/"", StaticMediaFailureView.as_view(), name=""media_failure""),
    # Plugins
    path(""plugins/"", include((plugin_patterns, ""plugins""))),
    path(""admin/plugins/"", include(plugin_admin_patterns)),
    # Social auth/SSO
    path("""", include(""social_django.urls"", namespace=""social"")),
    # django-health-check
    path(r""health/"", include(""health_check.urls"")),
    # FileProxy attachments download/get URLs used in admin views only
    path(""files/"", include(""db_file_storage.urls"")),
]


if settings.DEBUG:
    try:
        import debug_toolbar

        urlpatterns += [
            path(""__debug__/"", include(debug_toolbar.urls)),
        ]
    except ImportError:
        pass

if settings.METRICS_ENABLED:
    urlpatterns += [
        path(""metrics/"", nautobot_metrics_view, name=""metrics""),
    ]

handler404 = ""nautobot.core.views.resource_not_found""
handler500 = ""nautobot.core.views.server_error""
",CWE-306,69.0,1
"SEARCH_MAX_RESULTS = 15

#
# Filter lookup expressions
#

SEARCH_MAX_RESULTS = 15

FILTER_CHAR_BASED_LOOKUP_MAP = {
    ""n"": ""exact"",
    ""ic"": ""icontains"",
    ""nic"": ""icontains"",
    ""iew"": ""iendswith"",
    ""niew"": ""iendswith"",
    ""isw"": ""istartswith"",
    ""nisw"": ""istartswith"",
    ""ie"": ""iexact"",
    ""nie"": ""iexact"",
    ""re"": ""regex"",
    ""nre"": ""regex"",
    ""ire"": ""iregex"",
    ""nire"": ""iregex"",
}

FILTER_NUMERIC_BASED_LOOKUP_MAP = {
    ""n"": ""exact"",
    ""lte"": ""lte"",
    ""lt"": ""lt"",
    ""gte"": ""gte"",
    ""gt"": ""gt"",
}

FILTER_NEGATION_LOOKUP_MAP = {""n"": ""exact""}

#
# Reserved Names
#

RESERVED_NAMES_FOR_OBJECT_DETAIL_VIEW_SCHEMA = [""Other Fields"", ""Object Details""]

#
# Factory defaults
#

NAUTOBOT_BOOL_ITERATOR_DEFAULT_LENGTH = 8
NAUTOBOT_BOOL_ITERATOR_DEFAULT_PROBABILITY = 50


#
# CSV Import/Export
#

CSV_NULL_TYPE = ""NULL""
CSV_NO_OBJECT = ""NoObject""
# VarbinaryIPField Represents b'NoObject' as `::4e6f:4f62:6a65:6374`
VARBINARY_IP_FIELD_REPR_OF_CSV_NO_OBJECT = ""::4e6f:4f62:6a65:6374""


# For our purposes, COMPOSITE_KEY_SEPARATOR needs to be:
# 1. Safe in a URL path component (so that we can do URLS like ""/dcim/devices/<composite_key>/delete/"")
#    Per RFC3986 section 2.3 the general ""unreserved"" characters are ALPHA and DIGIT and the characters -._~
#    Per RFC3986 section 3.3 path components also permit characters :@ and the ""sub-delims"" characters !$&'()*+,;=
# 2. Not readily confused with characters commonly seen in un-escaped natural key component fields
#    ""."" is already ruled out as an unreserved character but also would appear in IPv4 IPAddress and Prefix objects
#    "":"" similarly would appear in IPv6 IPAddress/Prefix objects
#    ""/"" would appear in Prefix objects as well as various numbered device component names
# 3. Safe in a URL query string component (so that we can do URLs like ""/dcim/devices/?location=<composite_key>""
#    This rules out ""&"" and ""=""
COMPOSITE_KEY_SEPARATOR = "";""

# For the natural slug separator, it's much simpler and we can just go with ""_"".
NATURAL_SLUG_SEPARATOR = ""_""
",CWE-79,73.0,1
"""""""Utilities for working with log messages and similar features.""""""

import logging
import re

from django.conf import settings

logger = logging.getLogger(__name__)


def sanitize(dirty, replacement=""(redacted)""):
    """"""
    Make an attempt at stripping potentially-sensitive information from the given string, bytes or iterable thereof.

    Obviously this will never be 100% foolproof but we can at least try.

    Uses settings.SANITIZER_PATTERNS as the list of (regexp, repl) tuples to apply.
    """"""
    # Don't allow regex match groups to be referenced in the replacement string!
    if re.search(r""\\\d|\\g<\d+>"", replacement):
        raise RuntimeError(""Invalid replacement string! Must not contain regex match group references."")

    if isinstance(dirty, (list, tuple)):
        clean = []
        for item in dirty:
            if isinstance(item, (list, tuple, bytes, str)):
                clean.append(sanitize(item))
            else:
                # Pass through anything that isn't a string or iterable of strings
                clean.append(item)
        if isinstance(dirty, tuple):
            clean = tuple(clean)
        return clean

    if isinstance(dirty, bytes):
        return sanitize(dirty.decode(""utf-8"")).encode(""utf-8"")

    if isinstance(dirty, str):
        clean = dirty
        for sanitizer, repl in settings.SANITIZER_PATTERNS:
            try:
                clean = sanitizer.sub(repl.format(replacement=replacement), clean)
            except re.error:
                logger.error('Error in string sanitization using ""%s""', sanitizer)

        return clean

    logger.warning(""No sanitizer support for %s data"", type(dirty))
    return dirty
",CWE-79,50.0,1
"""""""
Socket server forwarding request to internal server
""""""
import logging
import asyncio
from typing import Optional

from ..ua.ua_binary import header_from_binary
from ..common.utils import Buffer, NotEnoughData
from .uaprocessor import UaProcessor
from .internal_server import InternalServer

logger = logging.getLogger(__name__)


class OPCUAProtocol(asyncio.Protocol):
    """"""
    Instantiated for every connection.
    """"""

    def __init__(self, iserver: InternalServer, policies, clients, closing_tasks):
        self.peer_name = None
        self.transport = None
        self.processor = None
        self._buffer = b''
        self.iserver: InternalServer = iserver
        self.policies = policies
        self.clients = clients
        self.closing_tasks = closing_tasks
        self.messages = asyncio.Queue()
        self._task = None

    def __str__(self):
        return f'OPCUAProtocol({self.peer_name}, {self.processor.session})'

    __repr__ = __str__

    def connection_made(self, transport):
        self.peer_name = transport.get_extra_info('peername')
        logger.info('New connection from %s', self.peer_name)
        self.transport = transport
        self.processor = UaProcessor(self.iserver, self.transport)
        self.processor.set_policies(self.policies)
        self.iserver.asyncio_transports.append(transport)
        self.clients.append(self)
        self._task = asyncio.create_task(self._process_received_message_loop())

    def connection_lost(self, ex):
        logger.info('Lost connection from %s, %s', self.peer_name, ex)
        self.transport.close()
        self.iserver.asyncio_transports.remove(self.transport)
        closing_task = asyncio.create_task(self.processor.close())
        self.closing_tasks.append(closing_task)
        if self in self.clients:
            self.clients.remove(self)
        self.messages.put_nowait((None, None))
        self._task.cancel()

    def data_received(self, data):
        self._buffer += data
        # try to parse the incoming data
        while self._buffer:
            try:
                buf = Buffer(self._buffer)
                try:
                    header = header_from_binary(buf)
                except NotEnoughData:
                    logger.debug('Not enough data while parsing header from client, waiting for more')
                    return
                if len(buf) < header.body_size:
                    logger.debug('We did not receive enough data from client. Need %s got %s', header.body_size,
                                 len(buf))
                    return
                # we have a complete message
                self.messages.put_nowait((header, buf))
                self._buffer = self._buffer[(header.header_size + header.body_size):]
            except Exception:
                logger.exception('Exception raised while parsing message from client')
                return

    async def _process_received_message_loop(self):
        """"""
        Take message from the queue and try to process it.
        """"""
        while True:
            header, buf = await self.messages.get()
            if header is None and buf is None:
                # Connection was closed, end task
                break
            try:
                await self._process_one_msg(header, buf)
            except Exception:
                logger.exception('Exception raised while processing message from client')

    async def _process_one_msg(self, header, buf):
        logger.debug('_process_received_message %s %s', header.body_size, len(buf))
        ret = await self.processor.process(header, buf)
        if not ret:
            logger.info('processor returned False, we close connection from %s', self.peer_name)
            self.transport.close()
            return


class BinaryServer:
    def __init__(self, internal_server: InternalServer, hostname, port):
        self.logger = logging.getLogger(__name__)
        self.hostname = hostname
        self.port = port
        self.iserver: InternalServer = internal_server
        self._server: Optional[asyncio.AbstractServer] = None
        self._policies = []
        self.clients = []
        self.closing_tasks = []
        self.cleanup_task = None

    def set_policies(self, policies):
        self._policies = policies

    def _make_protocol(self):
        """"""Protocol Factory""""""
        return OPCUAProtocol(
            iserver=self.iserver,
            policies=self._policies,
            clients=self.clients,
            closing_tasks=self.closing_tasks,
        )

    async def start(self):
        self._server = await asyncio.get_running_loop().create_server(self._make_protocol, self.hostname, self.port)
        # get the port and the hostname from the created server socket
        # only relevant for dynamic port asignment (when self.port == 0)
        if self.port == 0 and len(self._server.sockets) == 1:
            # will work for AF_INET and AF_INET6 socket names
            # these are to only families supported by the create_server call
            sockname = self._server.sockets[0].getsockname()
            self.hostname = sockname[0]
            self.port = sockname[1]
        self.logger.info('Listening on %s:%s', self.hostname, self.port)
        self.cleanup_task = asyncio.create_task(self._close_task_loop())

    async def stop(self):
        self.logger.info('Closing asyncio socket server')
        for transport in self.iserver.asyncio_transports:
            transport.close()

        # stop cleanup process and run it a last time
        self.cleanup_task.cancel()
        try:
            await self.cleanup_task
        except asyncio.CancelledError:
            pass
        await self._close_tasks()

        if self._server:
            asyncio.get_running_loop().call_soon(self._server.close)
            await self._server.wait_closed()

    async def _close_task_loop(self):
        while True:
            await self._close_tasks()
            await asyncio.sleep(10)

    async def _close_tasks(self):
        while self.closing_tasks:
            task = self.closing_tasks.pop()
            try:
                await task
            except asyncio.CancelledError:
                # this means a stop request has been sent, it should not be catched
                raise
            except Exception:
                logger.exception(""Unexpected crash in BinaryServer._close_tasks"")
",CWE-835,173.0,1
"# coding: utf-8
import asyncio
import pytest

from asyncua import Client, Server
from asyncua.ua.uaerrors import BadMaxConnectionsReached

from .conftest import port_num, find_free_port

pytestmark = pytest.mark.asyncio


async def test_max_connections_1(opc):
    opc.server.iserver.isession.__class__.max_connections = 1
    port = opc.server.endpoint.port
    if port == port_num:
        # if client we already have one connection
        with pytest.raises(BadMaxConnectionsReached):
            async with Client(f'opc.tcp://127.0.0.1:{port}'):
                pass
    else:
        async with Client(f'opc.tcp://127.0.0.1:{port}'):
            with pytest.raises(BadMaxConnectionsReached):
                async with Client(f'opc.tcp://127.0.0.1:{port}'):
                    pass
    opc.server.iserver.isession.__class__.max_connections = 1000


async def test_safe_disconnect():
    c = Client(url=""opc.tcp://example:4840"")
    await c.disconnect()
    # second disconnect should be noop
    await c.disconnect()


async def test_client_connection_lost():
    # Test the disconnect behavoir
    port = find_free_port()
    srv = Server()
    await srv.init()
    srv.set_endpoint(f'opc.tcp://127.0.0.1:{port}')
    await srv.start()
    async with Client(f'opc.tcp://127.0.0.1:{port}', timeout=0.5, watchdog_intervall=1) as cl:
        await srv.stop()
        await asyncio.sleep(2)
        with pytest.raises(ConnectionError):
            # check if connection is alive
            await cl.check_connection()
        # check if exception is correct rethrown on second call
        with pytest.raises(ConnectionError):
            await cl.check_connection()
        # check if a exception is thrown when a normal function is called
        with pytest.raises(ConnectionError):
            await cl.get_namespace_array()
",CWE-835,55.0,1
"import os
import zipfile
import tarfile

from flask import request, current_app as ca
from flask_restx import Resource
import tempfile
import multipart
import requests

from mindsdb.utilities import log
from mindsdb.api.http.utils import http_error
from mindsdb.api.http.namespaces.configs.files import ns_conf
from mindsdb.utilities.config import Config
from mindsdb.utilities.context import context as ctx


@ns_conf.route('/')
class FilesList(Resource):
    @ns_conf.doc('get_files_list')
    def get(self):
        '''List all files'''
        return ca.file_controller.get_files()


@ns_conf.route('/<name>')
@ns_conf.param('name', ""MindsDB's name for file"")
class File(Resource):
    @ns_conf.doc('put_file')
    def put(self, name: str):
        ''' add new file
            params in FormData:
                - file
                - original_file_name [optional]
        '''

        data = {}
        mindsdb_file_name = name

        existing_file_names = ca.file_controller.get_files_names()

        def on_field(field):
            name = field.field_name.decode()
            value = field.value.decode()
            data[name] = value

        file_object = None

        def on_file(file):
            nonlocal file_object
            data['file'] = file.file_name.decode()
            file_object = file.file_object

        temp_dir_path = tempfile.mkdtemp(prefix='mindsdb_file_')

        if request.headers['Content-Type'].startswith('multipart/form-data'):
            parser = multipart.create_form_parser(
                headers=request.headers,
                on_field=on_field,
                on_file=on_file,
                config={
                    'UPLOAD_DIR': temp_dir_path.encode(),    # bytes required
                    'UPLOAD_KEEP_FILENAME': True,
                    'UPLOAD_KEEP_EXTENSIONS': True,
                    'MAX_MEMORY_FILE_SIZE': 0
                }
            )

            while True:
                chunk = request.stream.read(8192)
                if not chunk:
                    break
                parser.write(chunk)
            parser.finalize()
            parser.close()

            if file_object is not None and not file_object.closed:
                file_object.close()
        else:
            data = request.json

        if mindsdb_file_name in existing_file_names:
            return http_error(
                400,
                ""File already exists"",
                f""File with name '{data['file']}' already exists""
            )

        if data.get('source_type') == 'url':
            url = data['source']
            data['file'] = data['name']

            config = Config()
            is_cloud = config.get('cloud', False)
            if is_cloud is True and ctx.user_class != 1:
                info = requests.head(url)
                file_size = info.headers.get('Content-Length')
                try:
                    file_size = int(file_size)
                except Exception:
                    pass

                if file_size is None:
                    return http_error(
                        400,
                        ""Error getting file info"",
                        ""an't determine remote file size""
                    )
                if file_size > 1024 * 1024 * 100:
                    return http_error(
                        400,
                        ""File is too big"",
                        ""Upload limit for file is 100Mb""
                    )
            with requests.get(url, stream=True) as r:
                if r.status_code != 200:
                    return http_error(
                        400,
                        ""Error getting file"",
                        f""Got status code: {r.status_code}""
                    )
                file_path = os.path.join(temp_dir_path, data['file'])
                with open(file_path, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)

        original_file_name = data.get('original_file_name')

        file_path = os.path.join(temp_dir_path, data['file'])
        lp = file_path.lower()
        if lp.endswith(('.zip', '.tar.gz')):
            if lp.endswith('.zip'):
                with zipfile.ZipFile(file_path) as f:
                    f.extractall(temp_dir_path)
            elif lp.endswith('.tar.gz'):
                with tarfile.open(file_path) as f:
                    f.extractall(temp_dir_path)
            os.remove(file_path)
            files = os.listdir(temp_dir_path)
            if len(files) != 1:
                os.rmdir(temp_dir_path)
                return http_error(400, 'Wrong content.', 'Archive must contain only one data file.')
            file_path = os.path.join(temp_dir_path, files[0])
            mindsdb_file_name = files[0]
            if not os.path.isfile(file_path):
                os.rmdir(temp_dir_path)
                return http_error(400, 'Wrong content.', 'Archive must contain data file in root.')

        ca.file_controller.save_file(mindsdb_file_name, file_path, file_name=original_file_name)

        os.rmdir(temp_dir_path)

        return '', 200

    @ns_conf.doc('delete_file')
    def delete(self, name: str):
        '''delete file'''

        try:
            ca.file_controller.delete_file(name)
        except Exception as e:
            log.logger.error(e)
            return http_error(
                400,
                ""Error deleting file"",
                f""There was an error while tring to delete file with name '{name}'""
            )
        return '', 200
",CWE-22,169.0,1
"import json

from flask import Response


def http_error(status_code, title, detail=''):
    ''' Wrapper for error responce acoording with RFC 7807 (https://tools.ietf.org/html/rfc7807)

        :param status_code: int - http status code for response
        :param title: str
        :param detail: str

        :return: flask Response object
    '''
    return Response(
        response=json.dumps({
            'title': title,
            'detail': detail
        }),
        status=status_code,
        headers={
            'Content-Type': 'application/problem+json'
        }
    )
",CWE-22,25.0,1
"import os
import tarfile
import tempfile
import zipfile

import multipart
import requests
from flask import current_app as ca
from flask import request
from flask_restx import Resource

from mindsdb.api.http.namespaces.configs.files import ns_conf
from mindsdb.api.http.utils import http_error, safe_extract
from mindsdb.utilities.config import Config
from mindsdb.utilities.context import context as ctx
from mindsdb.utilities import log

logger = log.getLogger(__name__)


@ns_conf.route(""/"")
class FilesList(Resource):
    @ns_conf.doc(""get_files_list"")
    def get(self):
        """"""List all files""""""
        return ca.file_controller.get_files()


@ns_conf.route(""/<name>"")
@ns_conf.param(""name"", ""MindsDB's name for file"")
class File(Resource):
    @ns_conf.doc(""put_file"")
    def put(self, name: str):
        """"""add new file
        params in FormData:
            - file
            - original_file_name [optional]
        """"""

        data = {}
        mindsdb_file_name = name

        existing_file_names = ca.file_controller.get_files_names()

        def on_field(field):
            name = field.field_name.decode()
            value = field.value.decode()
            data[name] = value

        file_object = None

        def on_file(file):
            nonlocal file_object
            data[""file""] = file.file_name.decode()
            file_object = file.file_object

        temp_dir_path = tempfile.mkdtemp(prefix=""mindsdb_file_"")

        if request.headers[""Content-Type""].startswith(""multipart/form-data""):
            parser = multipart.create_form_parser(
                headers=request.headers,
                on_field=on_field,
                on_file=on_file,
                config={
                    ""UPLOAD_DIR"": temp_dir_path.encode(),  # bytes required
                    ""UPLOAD_KEEP_FILENAME"": True,
                    ""UPLOAD_KEEP_EXTENSIONS"": True,
                    ""MAX_MEMORY_FILE_SIZE"": 0,
                },
            )

            while True:
                chunk = request.stream.read(8192)
                if not chunk:
                    break
                parser.write(chunk)
            parser.finalize()
            parser.close()

            if file_object is not None and not file_object.closed:
                file_object.close()
        else:
            data = request.json

        if mindsdb_file_name in existing_file_names:
            return http_error(
                400,
                ""File already exists"",
                f""File with name '{data['file']}' already exists"",
            )

        if data.get(""source_type"") == ""url"":
            url = data[""source""]
            data[""file""] = data[""name""]

            config = Config()
            is_cloud = config.get(""cloud"", False)
            if is_cloud is True and ctx.user_class != 1:
                info = requests.head(url)
                file_size = info.headers.get(""Content-Length"")
                try:
                    file_size = int(file_size)
                except Exception:
                    pass

                if file_size is None:
                    return http_error(
                        400,
                        ""Error getting file info"",
                        ""an't determine remote file size"",
                    )
                if file_size > 1024 * 1024 * 100:
                    return http_error(
                        400, ""File is too big"", ""Upload limit for file is 100Mb""
                    )
            with requests.get(url, stream=True) as r:
                if r.status_code != 200:
                    return http_error(
                        400, ""Error getting file"", f""Got status code: {r.status_code}""
                    )
                file_path = os.path.join(temp_dir_path, data[""file""])
                with open(file_path, ""wb"") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)

        original_file_name = data.get(""original_file_name"")

        file_path = os.path.join(temp_dir_path, data[""file""])
        lp = file_path.lower()
        if lp.endswith(("".zip"", "".tar.gz"")):
            if lp.endswith("".zip""):
                with zipfile.ZipFile(file_path) as f:
                    f.extractall(temp_dir_path)
            elif lp.endswith("".tar.gz""):
                with tarfile.open(file_path) as f:
                    safe_extract(f, temp_dir_path)
            os.remove(file_path)
            files = os.listdir(temp_dir_path)
            if len(files) != 1:
                os.rmdir(temp_dir_path)
                return http_error(
                    400, ""Wrong content."", ""Archive must contain only one data file.""
                )
            file_path = os.path.join(temp_dir_path, files[0])
            mindsdb_file_name = files[0]
            if not os.path.isfile(file_path):
                os.rmdir(temp_dir_path)
                return http_error(
                    400, ""Wrong content."", ""Archive must contain data file in root.""
                )

        ca.file_controller.save_file(
            mindsdb_file_name, file_path, file_name=original_file_name
        )

        os.rmdir(temp_dir_path)

        return """", 200

    @ns_conf.doc(""delete_file"")
    def delete(self, name: str):
        """"""delete file""""""

        try:
            ca.file_controller.delete_file(name)
        except Exception as e:
            logger.error(e)
            return http_error(
                400,
                ""Error deleting file"",
                f""There was an error while tring to delete file with name '{name}'"",
            )
        return """", 200
",CWE-918,174.0,1
"import pandas as pd

from mindsdb_sql.parser import ast

from mindsdb.integrations.libs.api_handler import APIHandler, APITable
from mindsdb.integrations.utilities.sql_utils import extract_comparison_conditions, project_dataframe

from mindsdb.integrations.libs.response import (
    HandlerStatusResponse as StatusResponse,
    HandlerResponse as Response,
    RESPONSE_TYPE
)

from .urlcrawl_helpers import get_df_from_query_str, get_all_websites


class CrawlerTable(APITable):

    def select(self, query: ast.Select) -> pd.DataFrame:

        conditions = extract_comparison_conditions(query.where)
        urls = []
        for op, arg1, arg2 in conditions:

            if op == 'or':
                raise NotImplementedError(f'OR is not supported')

            if arg1 == 'url':
                url = arg2

                if op == '=':
                    urls = [str(url)]
                elif op == 'in':
                    if type(url) == str:
                        urls = [str(url)]
                    else:
                        urls = url
                else:
                    raise NotImplementedError(
                        f'url can be url = ""someurl"", you can also crawl multiple sites, as follows: url IN (""url1"", ""url2"", ..)')

            else:
                pass

        if len(urls) == 0:
            raise NotImplementedError(
                f'You must specify what url you want to crawl, for example: SELECT * FROM crawl WHERE url IN (""someurl"", ..)')

        if query.limit is None:
            raise NotImplementedError(f'You must specify a LIMIT which defines the number of pages to crawl')
        limit = query.limit.value

        if limit < 0:
            limit = 0
            
        result = get_all_websites(urls, limit, html=False)
        if len(result) > limit:
            result = result[:limit]
        # filter targets
        result = project_dataframe(result, query.targets, self.get_columns())
        return result

    def get_columns(self):
        return [
            'url',
            'text_content',
            'error'
        ]


class WebHandler(APIHandler):
    """"""A class for handling crawling content from websites.

    Attributes:
        
    """"""

    def __init__(self, name=None, **kwargs):
        super().__init__(name)

        self.api = None
        self.is_connected = True
        crawler = CrawlerTable(self)
        self._register_table('crawler', crawler)

    def check_connection(self) -> StatusResponse:

        response = StatusResponse(False)
        response.success = True

        return response

    def native_query(self, query_string: str = None):

        df = get_df_from_query_str(query_string)

        return Response(
            RESPONSE_TYPE.TABLE,
            data_frame=df
        )
",CWE-918,101.0,1
,CWE-918,,1
"[build-system]
requires = [""hatchling""]
build-backend = ""hatchling.build""

[project]
name = ""starlette""
dynamic = [""version""]
description = ""The little ASGI library that shines.""
readme = ""README.md""
license = ""BSD-3-Clause""
requires-python = "">=3.8""
authors = [
    { name = ""Tom Christie"", email = ""tom@tomchristie.com"" },
]
classifiers = [
    ""Development Status :: 3 - Alpha"",
    ""Environment :: Web Environment"",
    ""Framework :: AnyIO"",
    ""Intended Audience :: Developers"",
    ""License :: OSI Approved :: BSD License"",
    ""Operating System :: OS Independent"",
    ""Programming Language :: Python :: 3"",
    ""Programming Language :: Python :: 3.8"",
    ""Programming Language :: Python :: 3.9"",
    ""Programming Language :: Python :: 3.10"",
    ""Programming Language :: Python :: 3.11"",
    ""Programming Language :: Python :: 3.12"",
    ""Topic :: Internet :: WWW/HTTP"",
]
dependencies = [
    ""anyio>=3.4.0,<5"",
    ""typing_extensions>=3.10.0; python_version < '3.10'"",
]

[project.optional-dependencies]
full = [
    ""itsdangerous"",
    ""jinja2"",
    ""python-multipart"",
    ""pyyaml"",
    ""httpx>=0.22.0"",
]

[project.urls]
Homepage = ""https://github.com/encode/starlette""
Documentation = ""https://www.starlette.io/""
Changelog = ""https://www.starlette.io/release-notes/""
Funding = ""https://github.com/sponsors/encode""
Source = ""https://github.com/encode/starlette""

[tool.hatch.version]
path = ""starlette/__init__.py""

[tool.ruff.lint]
select = [""E"", ""F"", ""I""]

[tool.ruff.lint.isort]
combine-as-imports = true

[tool.mypy]
strict = true
ignore_missing_imports = true
python_version = ""3.8""

[[tool.mypy.overrides]]
module = ""starlette.testclient.*""
implicit_optional = true

# TODO: Uncomment the following configuration when
# https://github.com/python/mypy/issues/10045 is solved. In the meantime,
# we are calling `mypy tests` directly. Check `scripts/check` for more info.
# [[tool.mypy.overrides]]
# module = ""tests.*""
# disallow_untyped_defs = false
# check_untyped_defs = true

[tool.pytest.ini_options]
addopts = ""-rxXs --strict-config --strict-markers""
xfail_strict = true
filterwarnings = [
    # Turn warnings that aren't filtered into exceptions
    ""error"",
    ""ignore: run_until_first_complete is deprecated and will be removed in a future version.:DeprecationWarning"",
    ""ignore: starlette.middleware.wsgi is deprecated and will be removed in a future release.*:DeprecationWarning"",
    ""ignore: Async generator 'starlette.requests.Request.stream' was garbage collected before it had been exhausted.*:ResourceWarning"",
    ""ignore: path is deprecated.*:DeprecationWarning:certifi"",
    ""ignore: Use 'content=<...>' to upload raw bytes/text content.:DeprecationWarning"",
    ""ignore: The `allow_redirects` argument is deprecated. Use `follow_redirects` instead.:DeprecationWarning"",
    ""ignore: 'cgi' is deprecated and slated for removal in Python 3.13:DeprecationWarning"",
    ""ignore: You seem to already have a custom sys.excepthook handler installed. I'll skip installing Trio's custom handler, but this means MultiErrors will not show full tracebacks.:RuntimeWarning"",
]

[tool.coverage.run]
source_pkgs = [
    ""starlette"",
    ""tests"",
]

[tool.coverage.report]
exclude_lines = [
    ""pragma: no cover"",
    ""pragma: nocover"",
    ""if typing.TYPE_CHECKING:"",
    ""@typing.overload"",
]
",CWE-1333,106.0,1
"from mage_ai.api.utils import authenticate_client_and_token
from mage_ai.orchestration.db.models.oauth import Oauth2Application
from mage_ai.settings import REQUIRE_USER_AUTHENTICATION
import terminado
import tornado.websocket
import re


class MageTermManager(terminado.NamedTermManager):
    def get_terminal(self, term_name: str, **kwargs):
        assert term_name is not None

        if term_name in self.terminals:
            return self.terminals[term_name]

        if self.max_terminals and len(self.terminals) >= self.max_terminals:
            raise terminado.management.MaxTerminalsReached(self.max_terminals)

        # Create new terminal
        self.log.info(""New terminal with specified name: %s"", term_name)
        term = self.new_terminal(**kwargs)
        term.term_name = term_name
        self.terminals[term_name] = term
        self.start_reading(term)
        return term


class MageUniqueTermManager(terminado.UniqueTermManager):
    def get_terminal(self, url_component=None, **kwargs):
        if self.max_terminals and len(self.ptys_by_fd) >= self.max_terminals:
            raise terminado.management.MaxTerminalsReached(self.max_terminals)

        term = self.new_terminal(**kwargs)
        self.start_reading(term)
        return term


class TerminalWebsocketServer(terminado.TermSocket):
    @property
    def term_command(self):
        return next(iter(self.term_manager.shell_command))

    def check_origin(self, origin):
        return True

    def on_pty_read(self, text):
        """"""Data read from pty; send to frontend""""""
        updated_text = text
        if self.term_command == 'cmd':
            xterm_escape = re.compile(r'(?:\x1B\]0;).*\x07')
            updated_text = xterm_escape.sub('', text)
        self.send_json_message([""stdout"", updated_text])

    def open(self, *args, **kwargs):
        """"""Websocket connection opened.

        Call our terminal manager to get a terminal, and connect to it as a
        client.
        """"""
        # Jupyter has a mixin to ping websockets and keep connections through
        # proxies alive. Call super() to allow that to set up:
        tornado.websocket.WebSocketHandler.open(self, *args, **kwargs)
        api_key = self.get_argument('api_key', None, True)
        token = self.get_argument('token', None, True)

        cwd = self.get_argument('cwd', None, True)
        term_name = self.get_argument('term_name', None, True)

        user = None
        if REQUIRE_USER_AUTHENTICATION and api_key and token:
            oauth_client = Oauth2Application.query.filter(
                Oauth2Application.client_id == api_key,
            ).first()
            if oauth_client:
                oauth_token, valid = authenticate_client_and_token(oauth_client.id, token)
                valid = valid and \
                    oauth_token and \
                    oauth_token.user
                if valid:
                    user = oauth_token.user
                else:
                    raise Exception('Invalid token')

        self.term_name = term_name if term_name else 'tty'
        if user:
            self.term_name = f'{self.term_name}_{user.id}'

        self._logger.info(""TermSocket.open: %s"", self.term_name)

        self.terminal = self.term_manager.get_terminal(self.term_name, cwd=cwd)
        self.terminal.clients.append(self)
        self.__initiate_terminal(self.terminal)

    def __initiate_terminal(self, terminal):
        self.send_json_message([""setup"", {}])
        self._logger.info(""TermSocket.open: Opened %s"", self.term_name)
        # Now drain the preopen buffer, if reconnect.
        buffered = """"
        preopen_buffer = terminal.read_buffer.copy()
        while True:
            if not preopen_buffer:
                break
            s = preopen_buffer.popleft()
            buffered += s
        if buffered:
            self.on_pty_read(buffered)

        # Turn enable-bracketed-paste off since it can mess up the output.
        if self.term_command == 'bash':
            terminal.ptyproc.write(
                ""bind 'set enable-bracketed-paste off' # Mage terminal settings command\r"")
        terminal.read_buffer.clear()
",CWE-306,113.0,1
"# Copyright 2020 Planet Labs, Inc.
# Copyright 2022 Planet Labs PBC.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import json
import logging

import pytest

from planet import auth

LOGGER = logging.getLogger(__name__)


# skip the global mock of _SecretFile.read
# for this module
@pytest.fixture(autouse=True, scope='module')
def test_secretfile_read():
    return


@pytest.fixture
def secret_path(monkeypatch, tmp_path):
    secret_path = str(tmp_path / '.test')
    monkeypatch.setattr(auth, 'SECRET_FILE_PATH', secret_path)
    yield secret_path


def test_Auth_from_key():
    test_auth_env1 = auth.Auth.from_key('testkey')
    assert test_auth_env1.value == 'testkey'


def test_Auth_from_key_empty():
    with pytest.raises(auth.APIKeyAuthException):
        _ = auth.Auth.from_key('')


def test_Auth_from_file(secret_path):
    with open(secret_path, 'w') as fp:
        fp.write('{""key"": ""testvar""}')

    test_auth = auth.Auth.from_file()
    assert test_auth.value == 'testvar'


def test_Auth_from_file_doesnotexist(secret_path):
    with pytest.raises(auth.AuthException):
        _ = auth.Auth.from_file(secret_path)


def test_Auth_from_file_wrongformat(secret_path):
    with open(secret_path, 'w') as fp:
        fp.write('{""notkey"": ""testvar""}')

    with pytest.raises(auth.AuthException):
        _ = auth.Auth.from_file(secret_path)


def test_Auth_from_file_alternate(tmp_path):
    secret_path = str(tmp_path / '.test')
    with open(secret_path, 'w') as fp:
        fp.write('{""key"": ""testvar""}')

    test_auth = auth.Auth.from_file(secret_path)
    assert test_auth.value == 'testvar'


def test_Auth_from_env(monkeypatch):
    monkeypatch.setenv('PL_API_KEY', 'testkey')
    test_auth_env = auth.Auth.from_env()
    assert test_auth_env.value == 'testkey'


def test_Auth_from_env_failure(monkeypatch):
    monkeypatch.delenv('PL_API_KEY', raising=False)
    with pytest.raises(auth.AuthException):
        _ = auth.Auth.from_env()


def test_Auth_from_env_alternate_success(monkeypatch):
    alternate = 'OTHER_VAR'
    monkeypatch.setenv(alternate, 'testkey')
    monkeypatch.delenv('PL_API_KEY', raising=False)

    test_auth_env = auth.Auth.from_env(alternate)
    assert test_auth_env.value == 'testkey'


def test_Auth_from_env_alternate_doesnotexist(monkeypatch):
    alternate = 'OTHER_VAR'
    monkeypatch.delenv(alternate, raising=False)
    monkeypatch.delenv('PL_API_KEY', raising=False)

    with pytest.raises(auth.AuthException):
        _ = auth.Auth.from_env(alternate)


def test_Auth_from_login(monkeypatch):
    auth_data = 'authdata'

    def login(*args, **kwargs):
        return {'api_key': auth_data}

    monkeypatch.setattr(auth.AuthClient, 'login', login)

    test_auth = auth.Auth.from_login('email', 'pw')
    assert test_auth.value == auth_data


def test_Auth_store_doesnotexist(tmp_path):
    test_auth = auth.Auth.from_key('test')
    secret_path = str(tmp_path / '.test')
    test_auth.store(secret_path)

    with open(secret_path, 'r') as fp:
        assert json.loads(fp.read()) == {""key"": ""test""}


def test_Auth_store_exists(tmp_path):
    secret_path = str(tmp_path / '.test')

    with open(secret_path, 'w') as fp:
        fp.write('{""existing"": ""exists""}')

    test_auth = auth.Auth.from_key('test')
    test_auth.store(secret_path)

    with open(secret_path, 'r') as fp:
        assert json.loads(fp.read()) == {""key"": ""test"", ""existing"": ""exists""}
",CWE-732,141.0,1
"""""""Meta related things.""""""
from collections import namedtuple
import re

RE_VER = re.compile(
    r'''(?x)
    (?P<major>\d+)(?:\.(?P<minor>\d+))?(?:\.(?P<micro>\d+))?
    (?:(?P<type>a|b|rc)(?P<pre>\d+))?
    (?:\.post(?P<post>\d+))?
    (?:\.dev(?P<dev>\d+))?
    '''
)

REL_MAP = {
    "".dev"": """",
    "".dev-alpha"": ""a"",
    "".dev-beta"": ""b"",
    "".dev-candidate"": ""rc"",
    ""alpha"": ""a"",
    ""beta"": ""b"",
    ""candidate"": ""rc"",
    ""final"": """"
}

DEV_STATUS = {
    "".dev"": ""2 - Pre-Alpha"",
    "".dev-alpha"": ""2 - Pre-Alpha"",
    "".dev-beta"": ""2 - Pre-Alpha"",
    "".dev-candidate"": ""2 - Pre-Alpha"",
    ""alpha"": ""3 - Alpha"",
    ""beta"": ""4 - Beta"",
    ""candidate"": ""4 - Beta"",
    ""final"": ""5 - Production/Stable""
}

PRE_REL_MAP = {""a"": 'alpha', ""b"": 'beta', ""rc"": 'candidate'}


class Version(namedtuple(""Version"", [""major"", ""minor"", ""micro"", ""release"", ""pre"", ""post"", ""dev""])):
    """"""
    Get the version (PEP 440).

    A biased approach to the PEP 440 semantic version.

    Provides a tuple structure which is sorted for comparisons `v1 > v2` etc.
      (major, minor, micro, release type, pre-release build, post-release build, development release build)
    Release types are named in is such a way they are comparable with ease.
    Accessors to check if a development, pre-release, or post-release build. Also provides accessor to get
    development status for setup files.

    How it works (currently):

    - You must specify a release type as either `final`, `alpha`, `beta`, or `candidate`.
    - To define a development release, you can use either `.dev`, `.dev-alpha`, `.dev-beta`, or `.dev-candidate`.
      The dot is used to ensure all development specifiers are sorted before `alpha`.
      You can specify a `dev` number for development builds, but do not have to as implicit development releases
      are allowed.
    - You must specify a `pre` value greater than zero if using a prerelease as this project (not PEP 440) does not
      allow implicit prereleases.
    - You can optionally set `post` to a value greater than zero to make the build a post release. While post releases
      are technically allowed in prereleases, it is strongly discouraged, so we are rejecting them. It should be
      noted that we do not allow `post0` even though PEP 440 does not restrict this. This project specifically
      does not allow implicit post releases.
    - It should be noted that we do not support epochs `1!` or local versions `+some-custom.version-1`.

    Acceptable version releases:

    ```
    Version(1, 0, 0, ""final"")                    1.0
    Version(1, 2, 0, ""final"")                    1.2
    Version(1, 2, 3, ""final"")                    1.2.3
    Version(1, 2, 0, "".dev-alpha"", pre=4)        1.2a4
    Version(1, 2, 0, "".dev-beta"", pre=4)         1.2b4
    Version(1, 2, 0, "".dev-candidate"", pre=4)    1.2rc4
    Version(1, 2, 0, ""final"", post=1)            1.2.post1
    Version(1, 2, 3, "".dev"")                     1.2.3.dev0
    Version(1, 2, 3, "".dev"", dev=1)              1.2.3.dev1
    ```

    """"""

    def __new__(cls, major, minor, micro, release=""final"", pre=0, post=0, dev=0):
        """"""Validate version info.""""""

        # Ensure all parts are positive integers.
        for value in (major, minor, micro, pre, post):
            if not (isinstance(value, int) and value >= 0):
                raise ValueError(""All version parts except 'release' should be integers."")

        if release not in REL_MAP:
            raise ValueError(""'{}' is not a valid release type."".format(release))

        # Ensure valid pre-release (we do not allow implicit pre-releases).
        if "".dev-candidate"" < release < ""final"":
            if pre == 0:
                raise ValueError(""Implicit pre-releases not allowed."")
            elif dev:
                raise ValueError(""Version is not a development release."")
            elif post:
                raise ValueError(""Post-releases are not allowed with pre-releases."")

        # Ensure valid development or development/pre release
        elif release < ""alpha"":
            if release > "".dev"" and pre == 0:
                raise ValueError(""Implicit pre-release not allowed."")
            elif post:
                raise ValueError(""Post-releases are not allowed with pre-releases."")

        # Ensure a valid normal release
        else:
            if pre:
                raise ValueError(""Version is not a pre-release."")
            elif dev:
                raise ValueError(""Version is not a development release."")

        return super(Version, cls).__new__(cls, major, minor, micro, release, pre, post, dev)

    def _is_pre(self):
        """"""Is prerelease.""""""

        return self.pre > 0

    def _is_dev(self):
        """"""Is development.""""""

        return bool(self.release < ""alpha"")

    def _is_post(self):
        """"""Is post.""""""

        return self.post > 0

    def _get_dev_status(self):  # pragma: no cover
        """"""Get development status string.""""""

        return DEV_STATUS[self.release]

    def _get_canonical(self):
        """"""Get the canonical output string.""""""

        # Assemble major, minor, micro version and append `pre`, `post`, or `dev` if needed..
        if self.micro == 0:
            ver = ""{}.{}"".format(self.major, self.minor)
        else:
            ver = ""{}.{}.{}"".format(self.major, self.minor, self.micro)
        if self._is_pre():
            ver += '{}{}'.format(REL_MAP[self.release], self.pre)
        if self._is_post():
            ver += "".post{}"".format(self.post)
        if self._is_dev():
            ver += "".dev{}"".format(self.dev)

        return ver


def parse_version(ver, pre=False):
    """"""Parse version into a comparable Version tuple.""""""

    m = RE_VER.match(ver)

    # Handle major, minor, micro
    major = int(m.group('major'))
    minor = int(m.group('minor')) if m.group('minor') else 0
    micro = int(m.group('micro')) if m.group('micro') else 0

    # Handle pre releases
    if m.group('type'):
        release = PRE_REL_MAP[m.group('type')]
        pre = int(m.group('pre'))
    else:
        release = ""final""
        pre = 0

    # Handle development releases
    dev = m.group('dev') if m.group('dev') else 0
    if m.group('dev'):
        dev = int(m.group('dev'))
        release = '.dev-' + release if pre else '.dev'
    else:
        dev = 0

    # Handle post
    post = int(m.group('post')) if m.group('post') else 0

    return Version(major, minor, micro, release, pre, post, dev)


__version_info__ = Version(9, 11, 0, ""final"")
__version__ = __version_info__._get_canonical()
",CWE-22,190.0,1
"#
# Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
#

from __future__ import annotations

import logging
import warnings
from collections.abc import Mapping
from typing import Any


def getSnowLogger(
    name: str,
    extra: Mapping[str, object] | None = None,
) -> SnowLogger:
    logger = logging.getLogger(name)
    return SnowLogger(logger, extra)  # type:ignore[arg-type]


class SnowLogger(logging.LoggerAdapter):
    """"""Snowflake Python logger wrapper of the built-in Python logger.

    This logger wrapper supports user-provided logging info about
    file name, function name and line number. This wrapper can be
    used in Cython code (.pyx).
    """"""

    def debug(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.log(logging.DEBUG, msg, path_name, func_name, *args, **kwargs)

    def info(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.log(logging.INFO, msg, path_name, func_name, *args, **kwargs)

    def warning(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.log(logging.WARNING, msg, path_name, func_name, *args, **kwargs)

    def warn(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        warnings.warn(
            ""The 'warn' method is deprecated, "" ""use 'warning' instead"",
            DeprecationWarning,
            2,
        )
        self.warning(msg, path_name, func_name, *args, **kwargs)

    def error(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.log(logging.ERROR, msg, path_name, func_name, *args, **kwargs)

    def exception(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        exc_info: bool = True,
        **kwargs: Any,
    ) -> None:
        """"""Convenience method for logging an ERROR with exception information.""""""
        self.error(msg, path_name, func_name, *args, exc_info=exc_info, **kwargs)

    def critical(  # type: ignore[override]
        self,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.log(logging.CRITICAL, msg, path_name, func_name, *args, **kwargs)

    fatal = critical

    def log(  # type: ignore[override]
        self,
        level: int,
        msg: str,
        path_name: str | None = None,
        func_name: str | None = None,
        line_num: int = 0,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        """"""Generalized log method of SnowLogger wrapper.

        Args:
            level: Logging level.
            msg: Logging message.
            path_name: Absolute or relative path of the file where the logger gets called.
            func_name: Function inside which the logger gets called.
            line_num: Line number at which the logger gets called.
        """"""
        if not path_name:
            path_name = ""path_name not provided""
        if not func_name:
            func_name = ""func_name not provided""
        if not isinstance(level, int):
            if logging.raiseExceptions:
                raise TypeError(""level must be an integer"")
            else:
                return
        if self.logger.isEnabledFor(level):
            record = self.logger.makeRecord(
                self.logger.name,
                level,
                path_name,
                line_num,
                msg,
                args,
                None,
                func_name,
                **kwargs,
            )
            self.logger.handle(record)
",CWE-77,149.0,1
,CWE-77,,1
,CWE-77,,1
"class LinkNotFoundError(Exception):
    """"""Exception raised when mechanicalsoup fails to find something.

    This happens in situations like (non-exhaustive list):

    * :func:`~mechanicalsoup.StatefulBrowser.find_link` is called, but
      no link is found.

    * The browser was configured with raise_on_404=True and a 404
      error is triggered while browsing.

    * The user tried to fill-in a field which doesn't exist in a form
      (e.g. browser[""name""] = ""val"" with browser being a
      StatefulBrowser).
    """"""
    pass
",CWE-20,17.0,1
,CWE-200,,1
"import os
import sys
import xml.etree.ElementTree as etree

from .compat_utils import passthrough_module

passthrough_module(__name__, '._deprecated')
del passthrough_module


# HTMLParseError has been deprecated in Python 3.3 and removed in
# Python 3.5. Introducing dummy exception for Python >3.5 for compatible
# and uniform cross-version exception handling
class compat_HTMLParseError(ValueError):
    pass


class _TreeBuilder(etree.TreeBuilder):
    def doctype(self, name, pubid, system):
        pass


def compat_etree_fromstring(text):
    return etree.XML(text, parser=etree.XMLParser(target=_TreeBuilder()))


compat_os_name = os._name if os.name == 'java' else os.name


if compat_os_name == 'nt':
    def compat_shlex_quote(s):
        import re
        return s if re.match(r'^[-_\w./]+$', s) else '""%s""' % s.replace('""', '\\""')
else:
    from shlex import quote as compat_shlex_quote  # noqa: F401


def compat_ord(c):
    return c if isinstance(c, int) else ord(c)


if compat_os_name == 'nt' and sys.version_info < (3, 8):
    # os.path.realpath on Windows does not follow symbolic links
    # prior to Python 3.8 (see https://bugs.python.org/issue9949)
    def compat_realpath(path):
        while os.path.islink(path):
            path = os.path.abspath(os.readlink(path))
        return os.path.realpath(path)
else:
    compat_realpath = os.path.realpath


# Python 3.8+ does not honor %HOME% on windows, but this breaks compatibility with youtube-dl
# See https://github.com/yt-dlp/yt-dlp/issues/792
# https://docs.python.org/3/library/os.path.html#os.path.expanduser
if compat_os_name in ('nt', 'ce'):
    def compat_expanduser(path):
        HOME = os.environ.get('HOME')
        if not HOME:
            return os.path.expanduser(path)
        elif not path.startswith('~'):
            return path
        i = path.replace('\\', '/', 1).find('/')  # ~user
        if i < 0:
            i = len(path)
        userhome = os.path.join(os.path.dirname(HOME), path[1:i]) if i > 1 else HOME
        return userhome + path[i:]
else:
    compat_expanduser = os.path.expanduser


def urllib_req_to_req(urllib_request):
    """"""Convert urllib Request to a networking Request""""""
    from ..networking import Request
    from ..utils.networking import HTTPHeaderDict
    return Request(
        urllib_request.get_full_url(), data=urllib_request.data, method=urllib_request.get_method(),
        headers=HTTPHeaderDict(urllib_request.headers, urllib_request.unredirected_hdrs),
        extensions={'timeout': urllib_request.timeout} if hasattr(urllib_request, 'timeout') else None)
",CWE-78,80.0,1
"import subprocess

from .common import PostProcessor
from ..compat import compat_shlex_quote
from ..utils import PostProcessingError, encodeArgument, variadic


class ExecPP(PostProcessor):

    def __init__(self, downloader, exec_cmd):
        PostProcessor.__init__(self, downloader)
        self.exec_cmd = variadic(exec_cmd)

    def parse_cmd(self, cmd, info):
        tmpl, tmpl_dict = self._downloader.prepare_outtmpl(cmd, info)
        if tmpl_dict:  # if there are no replacements, tmpl_dict = {}
            return self._downloader.escape_outtmpl(tmpl) % tmpl_dict

        filepath = info.get('filepath', info.get('_filename'))
        # If video, and no replacements are found, replace {} for backard compatibility
        if filepath:
            if '{}' not in cmd:
                cmd += ' {}'
            cmd = cmd.replace('{}', compat_shlex_quote(filepath))
        return cmd

    def run(self, info):
        for tmpl in self.exec_cmd:
            cmd = self.parse_cmd(tmpl, info)
            self.to_screen('Executing command: %s' % cmd)
            retCode = subprocess.call(encodeArgument(cmd), shell=True)
            if retCode != 0:
                raise PostProcessingError('Command returned error code %d' % retCode)
        return [], info


# Deprecated
class ExecAfterDownloadPP(ExecPP):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.deprecation_warning(
            'yt_dlp.postprocessor.ExecAfterDownloadPP is deprecated '
            'and may be removed in a future version. Use yt_dlp.postprocessor.ExecPP instead')
",CWE-78,44.0,1
"from .common import InfoExtractor
from ..utils import (
    ExtractorError,
    smuggle_url,
    str_or_none,
    traverse_obj,
    urlencode_postdata,
)


class CybraryBaseIE(InfoExtractor):
    _API_KEY = 'AIzaSyCX9ru6j70PX2My1Eq6Q1zoMAhuTdXlzSw'
    _ENDPOINTS = {
        'course': 'https://app.cybrary.it/courses/api/catalog/browse/course/{}',
        'course_enrollment': 'https://app.cybrary.it/courses/api/catalog/{}/enrollment',
        'enrollment': 'https://app.cybrary.it/courses/api/enrollment/{}',
        'launch': 'https://app.cybrary.it/courses/api/catalog/{}/launch',
        'vimeo_oembed': 'https://vimeo.com/api/oembed.json?url=https://vimeo.com/{}',
    }
    _NETRC_MACHINE = 'cybrary'
    _TOKEN = None

    def _perform_login(self, username, password):
        CybraryBaseIE._TOKEN = self._download_json(
            f'https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={self._API_KEY}',
            None, data=urlencode_postdata({'email': username, 'password': password, 'returnSecureToken': True}),
            note='Logging in')['idToken']

    def _real_initialize(self):
        if not self._TOKEN:
            self.raise_login_required(method='password')

    def _call_api(self, endpoint, item_id):
        return self._download_json(
            self._ENDPOINTS[endpoint].format(item_id), item_id,
            note=f'Downloading {endpoint} JSON metadata',
            headers={'Authorization': f'Bearer {self._TOKEN}'})

    def _get_vimeo_id(self, activity_id):
        launch_api = self._call_api('launch', activity_id)

        if launch_api.get('url'):
            return self._search_regex(r'https?://player\.vimeo\.com/video/(?P<vimeo_id>[0-9]+)', launch_api['url'], 'vimeo_id')
        return traverse_obj(launch_api, ('vendor_data', 'content', ..., 'videoId'), get_all=False)


class CybraryIE(CybraryBaseIE):
    _VALID_URL = r'https?://app\.cybrary\.it/immersive/(?P<enrollment>[0-9]+)/activity/(?P<id>[0-9]+)'
    _TESTS = [{
        'url': 'https://app.cybrary.it/immersive/12487950/activity/63102',
        'md5': '9ae12d37e555cb2ed554223a71a701d0',
        'info_dict': {
            'id': '646609770',
            'ext': 'mp4',
            'title': 'Getting Started',
            'thumbnail': 'https://i.vimeocdn.com/video/1301817996-76a268f0c56cff18a5cecbbdc44131eb9dda0c80eb0b3a036_1280',
            'series_id': '63111',
            'uploader_url': 'https://vimeo.com/user30867300',
            'duration': 88,
            'uploader_id': 'user30867300',
            'series': 'Cybrary Orientation',
            'uploader': 'Cybrary',
            'chapter': 'Cybrary Orientation Series',
            'chapter_id': '63110'
        },
        'expected_warnings': ['No authenticators for vimeo']
    }, {
        'url': 'https://app.cybrary.it/immersive/12747143/activity/52686',
        'md5': '62f26547dccc59c44363e2a13d4ad08d',
        'info_dict': {
            'id': '445638073',
            'ext': 'mp4',
            'title': 'Azure Virtual Network IP Addressing',
            'thumbnail': 'https://i.vimeocdn.com/video/936667051-1647ace66c627d4a2382185e0dae8deb830309bfddd53f8b2367b2f91e92ed0e-d_1280',
            'series_id': '52733',
            'uploader_url': 'https://vimeo.com/user30867300',
            'duration': 426,
            'uploader_id': 'user30867300',
            'series': 'AZ-500: Microsoft Azure Security Technologies',
            'uploader': 'Cybrary',
            'chapter': 'Implement Network Security',
            'chapter_id': '52693'
        },
        'expected_warnings': ['No authenticators for vimeo']
    }]

    def _real_extract(self, url):
        activity_id, enrollment_id = self._match_valid_url(url).group('id', 'enrollment')
        course = self._call_api('enrollment', enrollment_id)['content']
        activity = traverse_obj(course, ('learning_modules', ..., 'activities', lambda _, v: int(activity_id) == v['id']), get_all=False)

        if activity.get('type') not in ['Video Activity', 'Lesson Activity']:
            raise ExtractorError('The activity is not a video', expected=True)

        module = next((m for m in course.get('learning_modules') or []
                      if int(activity_id) in traverse_obj(m, ('activities', ..., 'id') or [])), None)

        vimeo_id = self._get_vimeo_id(activity_id)

        return {
            '_type': 'url_transparent',
            'series': traverse_obj(course, ('content_description', 'title')),
            'series_id': str_or_none(traverse_obj(course, ('content_description', 'id'))),
            'id': vimeo_id,
            'chapter': module.get('title'),
            'chapter_id': str_or_none(module.get('id')),
            'title': activity.get('title'),
            'url': smuggle_url(f'https://player.vimeo.com/video/{vimeo_id}', {'http_headers': {'Referer': 'https://api.cybrary.it'}})
        }


class CybraryCourseIE(CybraryBaseIE):
    _VALID_URL = r'https://app\.cybrary\.it/browse/course/(?P<id>[\w-]+)/?(?:$|[#?])'
    _TESTS = [{
        'url': 'https://app.cybrary.it/browse/course/az-500-microsoft-azure-security-technologies',
        'info_dict': {
            'id': 898,
            'title': 'AZ-500: Microsoft Azure Security Technologies',
            'description': 'md5:69549d379c0fc1dec92926d4e8b6fbd4'
        },
        'playlist_count': 59
    }, {
        'url': 'https://app.cybrary.it/browse/course/cybrary-orientation',
        'info_dict': {
            'id': 1245,
            'title': 'Cybrary Orientation',
            'description': 'md5:9e69ff66b32fe78744e0ad4babe2e88e'
        },
        'playlist_count': 4
    }]

    def _real_extract(self, url):
        course_id = self._match_id(url)
        course = self._call_api('course', course_id)
        enrollment_info = self._call_api('course_enrollment', course['id'])

        entries = [self.url_result(
            f'https://app.cybrary.it/immersive/{enrollment_info[""id""]}/activity/{activity[""id""]}')
            for activity in traverse_obj(course, ('content_item', 'learning_modules', ..., 'activities', ...))]

        return self.playlist_result(
            entries,
            traverse_obj(course, ('content_item', 'id'), expected_type=str_or_none),
            course.get('title'), course.get('short_description'))
",CWE-444,145.0,1
"import re
import urllib.parse

from .common import InfoExtractor
from .youtube import YoutubeTabIE
from ..utils import parse_qs, smuggle_url, traverse_obj


class EmbedlyIE(InfoExtractor):
    _VALID_URL = r'https?://(?:www|cdn\.)?embedly\.com/widgets/media\.html\?(?:[^#]*?&)?(?:src|url)=(?:[^#&]+)'
    _TESTS = [{
        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',
        'info_dict': {
            'id': 'UUGLim4T2loE5rwCMdpCIPVg',
            'modified_date': '20221225',
            'view_count': int,
            'uploader_url': 'https://www.youtube.com/@TraciHinesMusic',
            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',
            'uploader': 'TraciJHines',
            'channel_url': 'https://www.youtube.com/@TraciHinesMusic',
            'channel': 'TraciJHines',
            'availability': 'public',
            'uploader_id': 'UCGLim4T2loE5rwCMdpCIPVg',
            'description': '',
            'tags': [],
            'title': 'Uploads from TraciJHines',
        },
        'playlist_mincount': 10,
    }, {
        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',
        'params': {'noplaylist': True},
        'info_dict': {
            'id': 'SU4fj_aEMVw',
            'ext': 'mp4',
            'title': 'I\'m on Patreon!',
            'age_limit': 0,
            'categories': ['Entertainment'],
            'thumbnail': 'https://i.ytimg.com/vi_webp/SU4fj_aEMVw/maxresdefault.webp',
            'live_status': 'not_live',
            'playable_in_embed': True,
            'channel': 'TraciJHines',
            'uploader_id': 'TraciJHines',
            'channel_url': 'https://www.youtube.com/channel/UCGLim4T2loE5rwCMdpCIPVg',
            'uploader_url': 'http://www.youtube.com/user/TraciJHines',
            'upload_date': '20150211',
            'duration': 282,
            'availability': 'public',
            'channel_follower_count': int,
            'tags': 'count:39',
            'view_count': int,
            'comment_count': int,
            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',
            'like_count': int,
            'uploader': 'TraciJHines',
            'description': 'md5:8af6425f50bd46fbf29f3db0fc3a8364',
            'chapters': list,

        },
    }, {
        'url': 'https://cdn.embedly.com/widgets/media.html?src=https://player.vimeo.com/video/1234567?h=abcdefgh',
        'only_matching': True,
    }]

    _WEBPAGE_TESTS = [{
        'url': 'http://www.permacultureetc.com/2022/12/comment-greffer-facilement-les-arbres-fruitiers.html',
        'info_dict': {
            'id': 'pfUK_ADTvgY',
            'ext': 'mp4',
            'title': 'Comment greffer facilement les arbres fruitiers ? (mois par mois)',
            'description': 'md5:d3a876995e522f138aabb48e040bfb4c',
            'view_count': int,
            'upload_date': '20221210',
            'comment_count': int,
            'live_status': 'not_live',
            'channel_id': 'UCsM4_jihNFYe4CtSkXvDR-Q',
            'channel_follower_count': int,
            'tags': ['permaculture', 'jardinage', 'dekarz', 'autonomie', 'greffe', 'fruitiers', 'arbres', 'jardin fort', 'fort comestible', 'damien'],
            'playable_in_embed': True,
            'uploader': 'permaculture agrocologie etc...',
            'channel': 'permaculture agrocologie etc...',
            'thumbnail': 'https://i.ytimg.com/vi/pfUK_ADTvgY/sddefault.jpg',
            'duration': 1526,
            'channel_url': 'https://www.youtube.com/channel/UCsM4_jihNFYe4CtSkXvDR-Q',
            'age_limit': 0,
            'uploader_id': 'permacultureetc',
            'like_count': int,
            'uploader_url': 'http://www.youtube.com/user/permacultureetc',
            'categories': ['Education'],
            'availability': 'public',
        },
    }]

    @classmethod
    def _extract_from_webpage(cls, url, webpage):
        # Bypass ""ie=cls"" and suitable check
        for mobj in re.finditer(r'class=[""\']embedly-card[""\'][^>]href=[""\'](?P<url>[^""\']+)', webpage):
            yield cls.url_result(mobj.group('url'))

        for mobj in re.finditer(r'class=[""\']embedly-embed[""\'][^>]src=[""\'][^""\']*url=(?P<url>[^&]+)', webpage):
            yield cls.url_result(urllib.parse.unquote(mobj.group('url')))

    def _real_extract(self, url):
        qs = parse_qs(url)
        src = urllib.parse.unquote(traverse_obj(qs, ('url', 0)) or '')
        if src and YoutubeTabIE.suitable(src):
            return self.url_result(src, YoutubeTabIE)
        return self.url_result(smuggle_url(
            urllib.parse.unquote(traverse_obj(qs, ('src', 0), ('url', 0))),
            {'http_headers': {'Referer': url}}))
",CWE-444,110.0,1
"import functools

from .common import InfoExtractor
from ..utils import (
    format_field,
    int_or_none,
    OnDemandPagedList,
    smuggle_url,
)


class StoryFireBaseIE(InfoExtractor):
    _VALID_URL_BASE = r'https?://(?:www\.)?storyfire\.com/'

    def _call_api(self, path, video_id, resource, query=None):
        return self._download_json(
            'https://storyfire.com/app/%s/%s' % (path, video_id), video_id,
            'Downloading %s JSON metadata' % resource, query=query)

    def _parse_video(self, video):
        title = video['title']
        vimeo_id = self._search_regex(
            r'https?://player\.vimeo\.com/external/(\d+)',
            video['vimeoVideoURL'], 'vimeo id')

        uploader_id = video.get('hostID')

        return {
            '_type': 'url_transparent',
            'id': vimeo_id,
            'title': title,
            'description': video.get('description'),
            'url': smuggle_url(
                'https://player.vimeo.com/video/' + vimeo_id, {
                    'http_headers': {
                        'Referer': 'https://storyfire.com/',
                    }
                }),
            'thumbnail': video.get('storyImage'),
            'view_count': int_or_none(video.get('views')),
            'like_count': int_or_none(video.get('likesCount')),
            'comment_count': int_or_none(video.get('commentsCount')),
            'duration': int_or_none(video.get('videoDuration')),
            'timestamp': int_or_none(video.get('publishDate')),
            'uploader': video.get('username'),
            'uploader_id': uploader_id,
            'uploader_url': format_field(uploader_id, None, 'https://storyfire.com/user/%s/video'),
            'episode_number': int_or_none(video.get('episodeNumber') or video.get('episode_number')),
        }


class StoryFireIE(StoryFireBaseIE):
    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'video-details/(?P<id>[0-9a-f]{24})'
    _TEST = {
        'url': 'https://storyfire.com/video-details/5df1d132b6378700117f9181',
        'md5': 'caec54b9e4621186d6079c7ec100c1eb',
        'info_dict': {
            'id': '378954662',
            'ext': 'mp4',
            'title': 'Buzzfeed Teaches You About Memes',
            'uploader_id': 'ntZAJFECERSgqHSxzonV5K2E89s1',
            'timestamp': 1576129028,
            'description': 'md5:0b4e28021548e144bed69bb7539e62ea',
            'uploader': 'whang!',
            'upload_date': '20191212',
            'duration': 418,
            'view_count': int,
            'like_count': int,
            'comment_count': int,
        },
        'params': {
            'skip_download': True,
        },
        'expected_warnings': ['Unable to download JSON metadata']
    }

    def _real_extract(self, url):
        video_id = self._match_id(url)
        video = self._call_api(
            'generic/video-detail', video_id, 'video')['video']
        return self._parse_video(video)


class StoryFireUserIE(StoryFireBaseIE):
    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'user/(?P<id>[^/]+)/video'
    _TEST = {
        'url': 'https://storyfire.com/user/UQ986nFxmAWIgnkZQ0ftVhq4nOk2/video',
        'info_dict': {
            'id': 'UQ986nFxmAWIgnkZQ0ftVhq4nOk2',
        },
        'playlist_mincount': 151,
    }
    _PAGE_SIZE = 20

    def _fetch_page(self, user_id, page):
        videos = self._call_api(
            'publicVideos', user_id, 'page %d' % (page + 1), {
                'skip': page * self._PAGE_SIZE,
            })['videos']
        for video in videos:
            yield self._parse_video(video)

    def _real_extract(self, url):
        user_id = self._match_id(url)
        entries = OnDemandPagedList(functools.partial(
            self._fetch_page, user_id), self._PAGE_SIZE)
        return self.playlist_result(entries, user_id)


class StoryFireSeriesIE(StoryFireBaseIE):
    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'write/series/stories/(?P<id>[^/?&#]+)'
    _TESTS = [{
        'url': 'https://storyfire.com/write/series/stories/-Lq6MsuIHLODO6d2dDkr/',
        'info_dict': {
            'id': '-Lq6MsuIHLODO6d2dDkr',
        },
        'playlist_mincount': 13,
    }, {
        'url': 'https://storyfire.com/write/series/stories/the_mortal_one/',
        'info_dict': {
            'id': 'the_mortal_one',
        },
        'playlist_count': 0,
    }]

    def _extract_videos(self, stories):
        for story in stories.values():
            if story.get('hasVideo'):
                yield self._parse_video(story)

    def _real_extract(self, url):
        series_id = self._match_id(url)
        stories = self._call_api(
            'seriesStories', series_id, 'series stories')
        return self.playlist_result(self._extract_videos(stories), series_id)
",CWE-444,136.0,1
"import collections
import random
import urllib.parse
import urllib.request

from ._utils import remove_start


def random_user_agent():
    _USER_AGENT_TPL = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/%s Safari/537.36'
    _CHROME_VERSIONS = (
        '90.0.4430.212',
        '90.0.4430.24',
        '90.0.4430.70',
        '90.0.4430.72',
        '90.0.4430.85',
        '90.0.4430.93',
        '91.0.4472.101',
        '91.0.4472.106',
        '91.0.4472.114',
        '91.0.4472.124',
        '91.0.4472.164',
        '91.0.4472.19',
        '91.0.4472.77',
        '92.0.4515.107',
        '92.0.4515.115',
        '92.0.4515.131',
        '92.0.4515.159',
        '92.0.4515.43',
        '93.0.4556.0',
        '93.0.4577.15',
        '93.0.4577.63',
        '93.0.4577.82',
        '94.0.4606.41',
        '94.0.4606.54',
        '94.0.4606.61',
        '94.0.4606.71',
        '94.0.4606.81',
        '94.0.4606.85',
        '95.0.4638.17',
        '95.0.4638.50',
        '95.0.4638.54',
        '95.0.4638.69',
        '95.0.4638.74',
        '96.0.4664.18',
        '96.0.4664.45',
        '96.0.4664.55',
        '96.0.4664.93',
        '97.0.4692.20',
    )
    return _USER_AGENT_TPL % random.choice(_CHROME_VERSIONS)


class HTTPHeaderDict(collections.UserDict, dict):
    """"""
    Store and access keys case-insensitively.
    The constructor can take multiple dicts, in which keys in the latter are prioritised.
    """"""

    def __init__(self, *args, **kwargs):
        super().__init__()
        for dct in args:
            if dct is not None:
                self.update(dct)
        self.update(kwargs)

    def __setitem__(self, key, value):
        if isinstance(value, bytes):
            value = value.decode('latin-1')
        super().__setitem__(key.title(), str(value))

    def __getitem__(self, key):
        return super().__getitem__(key.title())

    def __delitem__(self, key):
        super().__delitem__(key.title())

    def __contains__(self, key):
        return super().__contains__(key.title() if isinstance(key, str) else key)


std_headers = HTTPHeaderDict({
    'User-Agent': random_user_agent(),
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-us,en;q=0.5',
    'Sec-Fetch-Mode': 'navigate',
})


def clean_proxies(proxies: dict, headers: HTTPHeaderDict):
    req_proxy = headers.pop('Ytdl-Request-Proxy', None)
    if req_proxy:
        proxies.clear()  # XXX: compat: Ytdl-Request-Proxy takes preference over everything, including NO_PROXY
        proxies['all'] = req_proxy
    for proxy_key, proxy_url in proxies.items():
        if proxy_url == '__noproxy__':
            proxies[proxy_key] = None
            continue
        if proxy_key == 'no':  # special case
            continue
        if proxy_url is not None:
            # Ensure proxies without a scheme are http.
            try:
                proxy_scheme = urllib.request._parse_proxy(proxy_url)[0]
            except ValueError:
                # Ignore invalid proxy URLs. Sometimes these may be introduced through environment
                # variables unrelated to proxy settings - e.g. Colab `COLAB_LANGUAGE_SERVER_PROXY`.
                # If the proxy is going to be used, the Request Handler proxy validation will handle it.
                continue
            if proxy_scheme is None:
                proxies[proxy_key] = 'http://' + remove_start(proxy_url, '//')

            replace_scheme = {
                'socks5': 'socks5h',  # compat: socks5 was treated as socks5h
                'socks': 'socks4'  # compat: non-standard
            }
            if proxy_scheme in replace_scheme:
                proxies[proxy_key] = urllib.parse.urlunparse(
                    urllib.parse.urlparse(proxy_url)._replace(scheme=replace_scheme[proxy_scheme]))


def clean_headers(headers: HTTPHeaderDict):
    if 'Youtubedl-No-Compression' in headers:  # compat
        del headers['Youtubedl-No-Compression']
        headers['Accept-Encoding'] = 'identity'


def remove_dot_segments(path):
    # Implements RFC3986 5.2.4 remote_dot_segments
    # Pseudo-code: https://tools.ietf.org/html/rfc3986#section-5.2.4
    # https://github.com/urllib3/urllib3/blob/ba49f5c4e19e6bca6827282feb77a3c9f937e64b/src/urllib3/util/url.py#L263
    output = []
    segments = path.split('/')
    for s in segments:
        if s == '.':
            continue
        elif s == '..':
            if output:
                output.pop()
        else:
            output.append(s)
    if not segments[0] and (not output or output[0]):
        output.insert(0, '')
    if segments[-1] in ('.', '..'):
        output.append('')
    return '/'.join(output)


def escape_rfc3986(s):
    """"""Escape non-ASCII characters as suggested by RFC 3986""""""
    return urllib.parse.quote(s, b""%/;:@&=+$,!~*'()?#[]"")


def normalize_url(url):
    """"""Normalize URL as suggested by RFC 3986""""""
    url_parsed = urllib.parse.urlparse(url)
    return url_parsed._replace(
        netloc=url_parsed.netloc.encode('idna').decode('ascii'),
        path=escape_rfc3986(remove_dot_segments(url_parsed.path)),
        params=escape_rfc3986(url_parsed.params),
        query=escape_rfc3986(url_parsed.query),
        fragment=escape_rfc3986(url_parsed.fragment)
    ).geturl()
",CWE-444,164.0,1
"""""""authentik multi-stage authentication engine""""""
from datetime import timedelta

from django.contrib import messages
from django.http import HttpRequest, HttpResponse
from django.urls import reverse
from django.utils.http import urlencode
from django.utils.text import slugify
from django.utils.timezone import now
from django.utils.translation import gettext as _
from rest_framework.fields import CharField
from rest_framework.serializers import ValidationError

from authentik.flows.challenge import Challenge, ChallengeResponse, ChallengeTypes
from authentik.flows.models import FlowToken
from authentik.flows.planner import PLAN_CONTEXT_IS_RESTORED, PLAN_CONTEXT_PENDING_USER
from authentik.flows.stage import ChallengeStageView
from authentik.flows.views.executor import QS_KEY_TOKEN
from authentik.stages.email.models import EmailStage
from authentik.stages.email.tasks import send_mails
from authentik.stages.email.utils import TemplateEmailMessage

PLAN_CONTEXT_EMAIL_SENT = ""email_sent""
PLAN_CONTEXT_EMAIL_OVERRIDE = ""email""


class EmailChallenge(Challenge):
    """"""Email challenge""""""

    component = CharField(default=""ak-stage-email"")


class EmailChallengeResponse(ChallengeResponse):
    """"""Email challenge resposen. No fields. This challenge is
    always declared invalid to give the user a chance to retry""""""

    component = CharField(default=""ak-stage-email"")

    def validate(self, attrs):
        raise ValidationError(detail=""email-sent"", code=""email-sent"")


class EmailStageView(ChallengeStageView):
    """"""Email stage which sends Email for verification""""""

    response_class = EmailChallengeResponse

    def get_full_url(self, **kwargs) -> str:
        """"""Get full URL to be used in template""""""
        base_url = reverse(
            ""authentik_core:if-flow"",
            kwargs={""flow_slug"": self.executor.flow.slug},
        )
        relative_url = f""{base_url}?{urlencode(kwargs)}""
        return self.request.build_absolute_uri(relative_url)

    def get_token(self) -> FlowToken:
        """"""Get token""""""
        pending_user = self.get_pending_user()
        current_stage: EmailStage = self.executor.current_stage
        valid_delta = timedelta(
            minutes=current_stage.token_expiry + 1
        )  # + 1 because django timesince always rounds down
        identifier = slugify(f""ak-email-stage-{current_stage.name}-{pending_user}"")
        # Don't check for validity here, we only care if the token exists
        tokens = FlowToken.objects.filter(identifier=identifier)
        if not tokens.exists():
            return FlowToken.objects.create(
                expires=now() + valid_delta,
                user=pending_user,
                identifier=identifier,
                flow=self.executor.flow,
                _plan=FlowToken.pickle(self.executor.plan),
            )
        token = tokens.first()
        # Check if token is expired and rotate key if so
        if token.is_expired:
            token.expire_action()
        return token

    def send_email(self):
        """"""Helper function that sends the actual email. Implies that you've
        already checked that there is a pending user.""""""
        pending_user = self.get_pending_user()
        email = self.executor.plan.context.get(PLAN_CONTEXT_EMAIL_OVERRIDE, None)
        if not email:
            email = pending_user.email
        current_stage: EmailStage = self.executor.current_stage
        token = self.get_token()
        # Send mail to user
        message = TemplateEmailMessage(
            subject=_(current_stage.subject),
            to=[email],
            language=pending_user.locale(self.request),
            template_name=current_stage.template,
            template_context={
                ""url"": self.get_full_url(**{QS_KEY_TOKEN: token.key}),
                ""user"": pending_user,
                ""expires"": token.expires,
            },
        )
        send_mails(current_stage, message)

    def get(self, request: HttpRequest, *args, **kwargs) -> HttpResponse:
        # Check if the user came back from the email link to verify
        restore_token: FlowToken = self.executor.plan.context.get(PLAN_CONTEXT_IS_RESTORED, None)
        user = self.get_pending_user()
        if restore_token:
            if restore_token.user != user:
                self.logger.warning(""Flow token for non-matching user, denying request"")
                return self.executor.stage_invalid()
            messages.success(request, _(""Successfully verified Email.""))
            if self.executor.current_stage.activate_user_on_success:
                user.is_active = True
                user.save()
            return self.executor.stage_ok()
        if PLAN_CONTEXT_PENDING_USER not in self.executor.plan.context:
            self.logger.debug(""No pending user"")
            messages.error(self.request, _(""No pending user.""))
            return self.executor.stage_invalid()
        # Check if we've already sent the initial e-mail
        if PLAN_CONTEXT_EMAIL_SENT not in self.executor.plan.context:
            self.send_email()
            self.executor.plan.context[PLAN_CONTEXT_EMAIL_SENT] = True
        return super().get(request, *args, **kwargs)

    def get_challenge(self) -> Challenge:
        challenge = EmailChallenge(
            data={
                ""type"": ChallengeTypes.NATIVE.value,
                ""title"": _(""Email sent.""),
            }
        )
        return challenge

    def challenge_valid(self, response: ChallengeResponse) -> HttpResponse:
        return super().challenge_invalid(response)

    def challenge_invalid(self, response: ChallengeResponse) -> HttpResponse:
        if PLAN_CONTEXT_PENDING_USER not in self.executor.plan.context:
            messages.error(self.request, _(""No pending user.""))
            return super().challenge_invalid(response)
        self.send_email()
        # We can't call stage_ok yet, as we're still waiting
        # for the user to click the link in the email
        return super().challenge_invalid(response)
",CWE-203,147.0,1
"""""""email tests""""""
from smtplib import SMTPException
from unittest.mock import MagicMock, PropertyMock, patch

from django.core import mail
from django.core.mail.backends.locmem import EmailBackend
from django.urls import reverse
from rest_framework.test import APITestCase

from authentik.core.tests.utils import create_test_admin_user, create_test_flow
from authentik.events.models import Event, EventAction
from authentik.flows.markers import StageMarker
from authentik.flows.models import FlowDesignation, FlowStageBinding
from authentik.flows.planner import PLAN_CONTEXT_PENDING_USER, FlowPlan
from authentik.flows.views.executor import SESSION_KEY_PLAN
from authentik.stages.email.models import EmailStage


class TestEmailStageSending(APITestCase):
    """"""Email tests""""""

    def setUp(self):
        super().setUp()
        self.user = create_test_admin_user()

        self.flow = create_test_flow(FlowDesignation.AUTHENTICATION)
        self.stage = EmailStage.objects.create(
            name=""email"",
        )
        self.binding = FlowStageBinding.objects.create(target=self.flow, stage=self.stage, order=2)

    def test_pending_user(self):
        """"""Test with pending user""""""
        plan = FlowPlan(flow_pk=self.flow.pk.hex, bindings=[self.binding], markers=[StageMarker()])
        plan.context[PLAN_CONTEXT_PENDING_USER] = self.user
        session = self.client.session
        session[SESSION_KEY_PLAN] = plan
        session.save()

        url = reverse(""authentik_api:flow-executor"", kwargs={""flow_slug"": self.flow.slug})
        with patch(
            ""authentik.stages.email.models.EmailStage.backend_class"",
            PropertyMock(return_value=EmailBackend),
        ):
            response = self.client.post(url)
            self.assertEqual(response.status_code, 200)
            self.assertEqual(len(mail.outbox), 1)
            self.assertEqual(mail.outbox[0].subject, ""authentik"")
            events = Event.objects.filter(action=EventAction.EMAIL_SENT)
            self.assertEqual(len(events), 1)
            event = events.first()
            self.assertEqual(event.context[""message""], f""Email to {self.user.email} sent"")
            self.assertEqual(event.context[""subject""], ""authentik"")
            self.assertEqual(event.context[""to_email""], [self.user.email])
            self.assertEqual(event.context[""from_email""], ""system@authentik.local"")

    def test_send_error(self):
        """"""Test error during sending (sending will be retried)""""""
        plan = FlowPlan(flow_pk=self.flow.pk.hex, bindings=[self.binding], markers=[StageMarker()])
        plan.context[PLAN_CONTEXT_PENDING_USER] = self.user
        session = self.client.session
        session[SESSION_KEY_PLAN] = plan
        session.save()

        url = reverse(""authentik_api:flow-executor"", kwargs={""flow_slug"": self.flow.slug})
        with patch(
            ""authentik.stages.email.models.EmailStage.backend_class"",
            PropertyMock(return_value=EmailBackend),
        ):
            with patch(
                ""django.core.mail.backends.locmem.EmailBackend.send_messages"",
                MagicMock(side_effect=[SMTPException, EmailBackend.send_messages]),
            ):
                response = self.client.post(url)
            response = self.client.post(url)
            self.assertEqual(response.status_code, 200)
            self.assertTrue(len(mail.outbox) >= 1)
            self.assertEqual(mail.outbox[0].subject, ""authentik"")
",CWE-203,79.0,1
,CWE-306,,1
"metadata:
  name: Default - Out-of-box-experience flow
version: 1
entries:
- attrs:
    denied_action: message_continue
    designation: stage_configuration
    name: default-oobe-setup
    title: Welcome to authentik!
  id: flow
  identifiers:
    slug: initial-setup
  model: authentik_flows.flow
- attrs:
    order: 100
    placeholder: Welcome to authentik! Please set a password for the default admin
      user, akadmin.
    placeholder_expression: false
    required: true
    sub_text: ''
    type: static
    field_key: oobe-header-text
    label: oobe-header-text
  id: prompt-field-header
  identifiers:
    name: initial-setup-field-header
  model: authentik_stages_prompt.prompt
- attrs:
    order: 101
    placeholder: Admin email
    placeholder_expression: false
    required: true
    sub_text: ''
    type: email
    field_key: email
    label: Email
  id: prompt-field-email
  identifiers:
    name: initial-setup-field-email
  model: authentik_stages_prompt.prompt
- attrs:
    order: 300
    placeholder: Password
    placeholder_expression: false
    required: true
    sub_text: ''
    type: password
    field_key: password
    label: Password
  id: prompt-field-password
  identifiers:
    name: initial-setup-field-password
  model: authentik_stages_prompt.prompt
- attrs:
    order: 301
    placeholder: Password (repeat)
    placeholder_expression: false
    required: true
    sub_text: ''
    type: password
    field_key: password_repeat
    label: Password (repeat)
  id: prompt-field-password-repeat
  identifiers:
    name: initial-setup-field-password-repeat
  model: authentik_stages_prompt.prompt
- attrs:
    expression: |
      # This policy sets the user for the currently running flow
      # by injecting ""pending_user""
      akadmin = ak_user_by(username=""akadmin"")
      context[""flow_plan""].context[""pending_user""] = akadmin
      return True
  id: policy-default-oobe-prefill-user
  identifiers:
    name: default-oobe-prefill-user
  model: authentik_policies_expression.expressionpolicy
- attrs:
    expression: |
      # This policy ensures that the setup flow can only be
      # executed when the admin user doesn''t have a password set
      akadmin = ak_user_by(username=""akadmin"")
      return not akadmin.has_usable_password()
  id: policy-default-oobe-password-usable
  identifiers:
    name: default-oobe-password-usable
  model: authentik_policies_expression.expressionpolicy
- attrs:
    fields:
    - !KeyOf prompt-field-header
    - !KeyOf prompt-field-email
    - !KeyOf prompt-field-password
    - !KeyOf prompt-field-password-repeat
    validation_policies: []
  id: stage-default-oobe-password
  identifiers:
    name: stage-default-oobe-password
  model: authentik_stages_prompt.promptstage
- id: stage-default-authentication-login
  identifiers:
    name: default-authentication-login
  model: authentik_stages_user_login.userloginstage
- id: stage-default-password-change-write
  identifiers:
    name: default-password-change-write
  model: authentik_stages_user_write.userwritestage
  attrs:
    user_creation_mode: never_create
- attrs:
    evaluate_on_plan: true
    invalid_response_action: retry
    re_evaluate_policies: false
  identifiers:
    order: 10
    stage: !KeyOf stage-default-oobe-password
    target: !KeyOf flow
  model: authentik_flows.flowstagebinding
- attrs:
    evaluate_on_plan: false
    invalid_response_action: retry
    re_evaluate_policies: true
  id: binding-password-write
  identifiers:
    order: 20
    stage: !KeyOf stage-default-password-change-write
    target: !KeyOf flow
  model: authentik_flows.flowstagebinding
- attrs:
    evaluate_on_plan: true
    invalid_response_action: retry
    re_evaluate_policies: false
  identifiers:
    order: 100
    stage: !KeyOf stage-default-authentication-login
    target: !KeyOf flow
  model: authentik_flows.flowstagebinding
- identifiers:
    order: 0
    policy: !KeyOf policy-default-oobe-password-usable
    target: !KeyOf flow
  model: authentik_policies.policybinding
- identifiers:
    order: 0
    policy: !KeyOf policy-default-oobe-prefill-user
    target: !KeyOf binding-password-write
  model: authentik_policies.policybinding
",CWE-306,147.0,1
,CWE-287,,1
"from django.conf import settings
from django.utils.decorators import method_decorator
from django.views.decorators.cache import never_cache
from rest_framework import serializers
from rest_framework.authentication import SessionAuthentication
from rest_framework.permissions import IsAuthenticated
from rest_framework.request import Request
from rest_framework.response import Response

from sentry import analytics
from sentry.api.base import Endpoint, control_silo_endpoint
from sentry.api.fields import MultipleChoiceField
from sentry.api.serializers import serialize
from sentry.auth.superuser import is_active_superuser
from sentry.models import ApiToken
from sentry.security import capture_security_activity


class ApiTokenSerializer(serializers.Serializer):
    scopes = MultipleChoiceField(required=True, choices=settings.SENTRY_SCOPES)


@control_silo_endpoint
class ApiTokensEndpoint(Endpoint):
    authentication_classes = (SessionAuthentication,)
    permission_classes = (IsAuthenticated,)

    @method_decorator(never_cache)
    def get(self, request: Request) -> Response:
        user_id = request.user.id
        if is_active_superuser(request):
            user_id = request.GET.get(""userId"", user_id)

        token_list = list(
            ApiToken.objects.filter(application__isnull=True, user_id=user_id).select_related(
                ""application""
            )
        )

        return Response(serialize(token_list, request.user))

    @method_decorator(never_cache)
    def post(self, request: Request) -> Response:
        serializer = ApiTokenSerializer(data=request.data)

        if serializer.is_valid():
            result = serializer.validated_data

            token = ApiToken.objects.create(
                user_id=request.user.id,
                scope_list=result[""scopes""],
                refresh_token=None,
                expires_at=None,
            )

            capture_security_activity(
                account=request.user,
                type=""api-token-generated"",
                actor=request.user,
                ip_address=request.META[""REMOTE_ADDR""],
                context={},
                send_email=True,
            )

            analytics.record(""api_token.created"", user_id=request.user.id)

            return Response(serialize(token, request.user), status=201)
        return Response(serializer.errors, status=400)

    @method_decorator(never_cache)
    def delete(self, request: Request):
        user_id = request.user.id
        if is_active_superuser(request):
            user_id = request.data.get(""userId"", user_id)
        token = request.data.get(""token"")
        if not token:
            return Response({""token"": """"}, status=400)

        ApiToken.objects.filter(user_id=user_id, token=token, application__isnull=True).delete()

        analytics.record(""api_token.deleted"", user_id=request.user.id)

        return Response(status=204)
",CWE-287,84.0,1
"from django.conf import settings
from django.utils.decorators import method_decorator
from django.views.decorators.cache import never_cache
from rest_framework import serializers
from rest_framework.authentication import SessionAuthentication
from rest_framework.permissions import IsAuthenticated
from rest_framework.request import Request
from rest_framework.response import Response

from sentry import analytics
from sentry.api.base import Endpoint, control_silo_endpoint
from sentry.api.fields import MultipleChoiceField
from sentry.api.serializers import serialize
from sentry.auth.superuser import is_active_superuser
from sentry.models import ApiToken
from sentry.security import capture_security_activity


class ApiTokenSerializer(serializers.Serializer):
    scopes = MultipleChoiceField(required=True, choices=settings.SENTRY_SCOPES)


@control_silo_endpoint
class ApiTokensEndpoint(Endpoint):
    authentication_classes = (SessionAuthentication,)
    permission_classes = (IsAuthenticated,)

    @method_decorator(never_cache)
    def get(self, request: Request) -> Response:
        user_id = request.user.id
        if is_active_superuser(request):
            user_id = request.GET.get(""userId"", user_id)

        token_list = list(
            ApiToken.objects.filter(application__isnull=True, user_id=user_id).select_related(
                ""application""
            )
        )

        return Response(serialize(token_list, request.user))

    @method_decorator(never_cache)
    def post(self, request: Request) -> Response:
        serializer = ApiTokenSerializer(data=request.data)

        if serializer.is_valid():
            result = serializer.validated_data

            token = ApiToken.objects.create(
                user_id=request.user.id,
                scope_list=result[""scopes""],
                refresh_token=None,
                expires_at=None,
            )

            capture_security_activity(
                account=request.user,
                type=""api-token-generated"",
                actor=request.user,
                ip_address=request.META[""REMOTE_ADDR""],
                context={},
                send_email=True,
            )

            analytics.record(""api_token.created"", user_id=request.user.id)

            return Response(serialize(token, request.user), status=201)
        return Response(serializer.errors, status=400)

    @method_decorator(never_cache)
    def delete(self, request: Request):
        user_id = request.user.id
        if is_active_superuser(request):
            user_id = request.data.get(""userId"", user_id)
        token = request.data.get(""token"")
        if not token:
            return Response({""token"": """"}, status=400)

        ApiToken.objects.filter(user_id=user_id, token=token, application__isnull=True).delete()

        analytics.record(""api_token.deleted"", user_id=request.user.id)

        return Response(status=204)
",CWE-284,84.0,1
"from django.urls import reverse
from rest_framework import status

from sentry.models import ApiToken
from sentry.testutils.cases import APITestCase
from sentry.testutils.silo import control_silo_test


@control_silo_test(stable=True)
class ApiTokensListTest(APITestCase):
    def test_simple(self):
        ApiToken.objects.create(user=self.user)
        ApiToken.objects.create(user=self.user)

        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.get(url)
        assert response.status_code == 200, response.content
        assert len(response.data) == 2

    def test_never_cache(self):
        ApiToken.objects.create(user=self.user)
        ApiToken.objects.create(user=self.user)

        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.get(url)
        assert response.status_code == 200, response.content
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )


@control_silo_test(stable=True)
class ApiTokensCreateTest(APITestCase):
    def test_no_scopes(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url)
        assert response.status_code == 400

    def test_simple(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url, data={""scopes"": [""event:read""]})
        assert response.status_code == 201
        token = ApiToken.objects.get(user=self.user)
        assert not token.expires_at
        assert not token.refresh_token
        assert token.get_scopes() == [""event:read""]

    def test_never_cache(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url, data={""scopes"": [""event:read""]})
        assert response.status_code == 201
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )

    def test_invalid_choice(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(
            url,
            data={
                ""scopes"": [
                    ""Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.""
                ]
            },
        )
        assert response.status_code == 400
        assert not ApiToken.objects.filter(user=self.user).exists()


@control_silo_test(stable=True)
class ApiTokensDeleteTest(APITestCase):
    def test_simple(self):
        token = ApiToken.objects.create(user=self.user)
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.delete(url, data={""token"": token.token})
        assert response.status_code == 204
        assert not ApiToken.objects.filter(id=token.id).exists()

    def test_never_cache(self):
        token = ApiToken.objects.create(user=self.user)
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.delete(url, data={""token"": token.token})
        assert response.status_code == 204
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )


@control_silo_test(stable=True)
class ApiTokensSuperUserTest(APITestCase):
    url = reverse(""sentry-api-0-api-tokens"")

    def test_get_as_su(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.get(self.url, {""userId"": self.user.id})
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] == user_token.token

    def test_get_as_su_implicit_userid(self):
        super_user = self.create_user(is_superuser=True)
        superuser_token = ApiToken.objects.create(user=super_user)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.get(self.url)
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] != user_token.token
        assert response.data[0][""token""] == superuser_token.token

    def test_get_as_user(self):
        super_user = self.create_user(is_superuser=True)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user)
        # Ignores trying to fetch the user's token, since we're not an active superuser
        response = self.client.get(self.url, {""userId"": self.user.id})
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] == su_token.token

    def test_delete_as_su(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.delete(self.url, {""userId"": self.user.id, ""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert not ApiToken.objects.filter(id=user_token.id).exists()

    def test_delete_as_su_implicit_userid(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user, superuser=True)

        response = self.client.delete(self.url, {""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert ApiToken.objects.filter(id=su_token.id).exists()

        response = self.client.delete(self.url, {""token"": su_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert not ApiToken.objects.filter(id=su_token.id).exists()

    def test_delete_as_user(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user)
        # Fails trying to delete the user's token, since we're not an active superuser
        response = self.client.delete(self.url, {""userId"": self.user.id, ""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert ApiToken.objects.filter(id=su_token.id).exists()
",CWE-287,171.0,1
"from django.urls import reverse
from rest_framework import status

from sentry.models import ApiToken
from sentry.testutils.cases import APITestCase
from sentry.testutils.silo import control_silo_test


@control_silo_test(stable=True)
class ApiTokensListTest(APITestCase):
    def test_simple(self):
        ApiToken.objects.create(user=self.user)
        ApiToken.objects.create(user=self.user)

        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.get(url)
        assert response.status_code == 200, response.content
        assert len(response.data) == 2

    def test_never_cache(self):
        ApiToken.objects.create(user=self.user)
        ApiToken.objects.create(user=self.user)

        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.get(url)
        assert response.status_code == 200, response.content
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )


@control_silo_test(stable=True)
class ApiTokensCreateTest(APITestCase):
    def test_no_scopes(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url)
        assert response.status_code == 400

    def test_simple(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url, data={""scopes"": [""event:read""]})
        assert response.status_code == 201
        token = ApiToken.objects.get(user=self.user)
        assert not token.expires_at
        assert not token.refresh_token
        assert token.get_scopes() == [""event:read""]

    def test_never_cache(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(url, data={""scopes"": [""event:read""]})
        assert response.status_code == 201
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )

    def test_invalid_choice(self):
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.post(
            url,
            data={
                ""scopes"": [
                    ""Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.""
                ]
            },
        )
        assert response.status_code == 400
        assert not ApiToken.objects.filter(user=self.user).exists()


@control_silo_test(stable=True)
class ApiTokensDeleteTest(APITestCase):
    def test_simple(self):
        token = ApiToken.objects.create(user=self.user)
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.delete(url, data={""token"": token.token})
        assert response.status_code == 204
        assert not ApiToken.objects.filter(id=token.id).exists()

    def test_never_cache(self):
        token = ApiToken.objects.create(user=self.user)
        self.login_as(self.user)
        url = reverse(""sentry-api-0-api-tokens"")
        response = self.client.delete(url, data={""token"": token.token})
        assert response.status_code == 204
        assert (
            response.get(""cache-control"")
            == ""max-age=0, no-cache, no-store, must-revalidate, private""
        )


@control_silo_test(stable=True)
class ApiTokensSuperUserTest(APITestCase):
    url = reverse(""sentry-api-0-api-tokens"")

    def test_get_as_su(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.get(self.url, {""userId"": self.user.id})
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] == user_token.token

    def test_get_as_su_implicit_userid(self):
        super_user = self.create_user(is_superuser=True)
        superuser_token = ApiToken.objects.create(user=super_user)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.get(self.url)
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] != user_token.token
        assert response.data[0][""token""] == superuser_token.token

    def test_get_as_user(self):
        super_user = self.create_user(is_superuser=True)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user)
        # Ignores trying to fetch the user's token, since we're not an active superuser
        response = self.client.get(self.url, {""userId"": self.user.id})
        assert response.status_code == status.HTTP_200_OK
        assert len(response.data) == 1
        assert response.data[0][""token""] == su_token.token

    def test_delete_as_su(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        self.login_as(super_user, superuser=True)

        response = self.client.delete(self.url, {""userId"": self.user.id, ""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert not ApiToken.objects.filter(id=user_token.id).exists()

    def test_delete_as_su_implicit_userid(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user, superuser=True)

        response = self.client.delete(self.url, {""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert ApiToken.objects.filter(id=su_token.id).exists()

        response = self.client.delete(self.url, {""token"": su_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert not ApiToken.objects.filter(id=su_token.id).exists()

    def test_delete_as_user(self):
        super_user = self.create_user(is_superuser=True)
        user_token = ApiToken.objects.create(user=self.user)
        su_token = ApiToken.objects.create(user=super_user)
        self.login_as(super_user)
        # Fails trying to delete the user's token, since we're not an active superuser
        response = self.client.delete(self.url, {""userId"": self.user.id, ""token"": user_token.token})
        assert response.status_code == status.HTTP_204_NO_CONTENT
        assert ApiToken.objects.filter(id=user_token.id).exists()
        assert ApiToken.objects.filter(id=su_token.id).exists()
",CWE-284,171.0,1
,CWE-400,,1
,CWE-400,,1
"from typing import Optional
from zipfile import ZipFile

MAX_FILE_SIZE = 16 * 1024 * 1024  # 16 MB
CHUNK_SIZE = 1024


def verify_zip(zip_file: ZipFile, max_file_size: Optional[int] = None) -> None:
    """"""
    Function to safely verify the contents of zipped files. It prevents potential
    'zip bomb' attacks by checking the file size of the files in the zip without fully
    extracting them. If the size of any file in the zip exceeds the specified
    max_file_size, it raises a ValueError. If the max_file_size is not provided,
    it uses a default value of 16 MB.

    :param zip_file: A ZipFile object to be verified.
    :param max_file_size: An optional integer specifying the maximum bytes allowed per file. If not provided, a default value is used.
    :raises ValueError: If a file in the zip file exceeds the maximum allowed size
    """"""

    if max_file_size is None:
        max_file_size = MAX_FILE_SIZE

    for file_info in zip_file.infolist():
        file_size = 0

        with zip_file.open(file_info) as file:
            # wraps the file read in an iterator that stops once no bytes
            # are returned or the max file size is reached
            for chunk in iter(lambda: file.read(CHUNK_SIZE), b""""):
                file_size += len(chunk)

                if file_size > max_file_size:
                    raise ValueError(""File size exceeds maximum allowed size"")
",CWE-400,35.0,1
"from io import BytesIO
from zipfile import ZipFile

import pytest

from fides.api.util.unsafe_file_util import verify_zip
from tests.ops.test_helpers.saas_test_utils import create_zip_file


class TestVerifyZip:
    @pytest.fixture
    def zip_file(self) -> BytesIO:
        return create_zip_file(
            {
                ""config.yml"": ""This file isn't that big, but it will be considered suspicious if the max file size is set too low"",
            }
        )

    def test_verify_zip(self, zip_file):
        verify_zip(ZipFile(zip_file))

    def test_verify_zip_with_small_file_size_limit(self, zip_file):
        """"""We set the max file size to 1 byte, so the zip file should be rejected.""""""
        with pytest.raises(ValueError) as exc:
            verify_zip(ZipFile(zip_file), 1)
        assert ""File size exceeds maximum allowed size"" in str(exc.value)
",CWE-400,27.0,1
"from typing import Optional

from fideslang.models import Dataset
from pydantic import BaseModel, validator

from fides.api.schemas.saas.saas_config import SaaSConfig
from fides.api.service.authentication.authentication_strategy_oauth2_authorization_code import (
    OAuth2AuthorizationCodeAuthenticationStrategy,
)
from fides.api.util.saas_util import load_config_from_string, load_dataset_from_string


class ConnectorTemplate(BaseModel):
    """"""
    A collection of artifacts that make up a complete
    SaaS connector (SaaS config, dataset, icon, functions, etc.)
    """"""

    config: str
    dataset: str
    icon: Optional[str]
    functions: Optional[str]
    human_readable: str

    @validator(""config"")
    def validate_config(cls, config: str) -> str:
        """"""Validates the config at the given path""""""
        saas_config = SaaSConfig(**load_config_from_string(config))
        if saas_config.fides_key != ""<instance_fides_key>"":
            raise ValueError(
                ""Hard-coded fides_key detected in the config, replace all instances of it with <instance_fides_key>""
            )
        return config

    @validator(""dataset"")
    def validate_dataset(cls, dataset: str) -> str:
        """"""Validates the dataset at the given path""""""
        saas_dataset = Dataset(**load_dataset_from_string(dataset))
        if saas_dataset.fides_key != ""<instance_fides_key>"":
            raise ValueError(
                ""Hard-coded fides_key detected in the dataset, replace all instances of it with <instance_fides_key>""
            )
        return dataset

    @property
    def authorization_required(self) -> bool:
        """"""Determines if the auth strategy for the given connector template requires authorization.""""""

        config = SaaSConfig(**load_config_from_string(self.config))
        authentication = config.client_config.authentication
        return (
            authentication.strategy
            == OAuth2AuthorizationCodeAuthenticationStrategy.name
            if authentication
            else False
        )

    @property
    def user_guide(self) -> Optional[str]:
        config = SaaSConfig(**load_config_from_string(self.config))
        return config.user_guide
",CWE-94,62.0,1
"from typing import Optional

from fideslang.models import Dataset
from pydantic import BaseModel, validator

from fides.api.schemas.saas.saas_config import SaaSConfig
from fides.api.service.authentication.authentication_strategy_oauth2_authorization_code import (
    OAuth2AuthorizationCodeAuthenticationStrategy,
)
from fides.api.util.saas_util import load_config_from_string, load_dataset_from_string


class ConnectorTemplate(BaseModel):
    """"""
    A collection of artifacts that make up a complete
    SaaS connector (SaaS config, dataset, icon, functions, etc.)
    """"""

    config: str
    dataset: str
    icon: Optional[str]
    functions: Optional[str]
    human_readable: str

    @validator(""config"")
    def validate_config(cls, config: str) -> str:
        """"""Validates the config at the given path""""""
        saas_config = SaaSConfig(**load_config_from_string(config))
        if saas_config.fides_key != ""<instance_fides_key>"":
            raise ValueError(
                ""Hard-coded fides_key detected in the config, replace all instances of it with <instance_fides_key>""
            )
        return config

    @validator(""dataset"")
    def validate_dataset(cls, dataset: str) -> str:
        """"""Validates the dataset at the given path""""""
        saas_dataset = Dataset(**load_dataset_from_string(dataset))
        if saas_dataset.fides_key != ""<instance_fides_key>"":
            raise ValueError(
                ""Hard-coded fides_key detected in the dataset, replace all instances of it with <instance_fides_key>""
            )
        return dataset

    @property
    def authorization_required(self) -> bool:
        """"""Determines if the auth strategy for the given connector template requires authorization.""""""

        config = SaaSConfig(**load_config_from_string(self.config))
        authentication = config.client_config.authentication
        return (
            authentication.strategy
            == OAuth2AuthorizationCodeAuthenticationStrategy.name
            if authentication
            else False
        )

    @property
    def user_guide(self) -> Optional[str]:
        config = SaaSConfig(**load_config_from_string(self.config))
        return config.user_guide
",CWE-693,62.0,1
"from typing import Optional

from sqlalchemy.orm import Session

from fides.api.models.custom_connector_template import CustomConnectorTemplate


class TestCustomConnectorTemplate:
    def test_create_custom_connector_template(
        self,
        db: Session,
        planet_express_config,
        planet_express_dataset,
        planet_express_icon,
        planet_express_functions,
    ) -> None:
        template = CustomConnectorTemplate(
            key=""planet_express"",
            name=""Planet Express"",
            config=planet_express_config,
            dataset=planet_express_dataset,
            icon=planet_express_icon,
            functions=planet_express_functions,
        )
        template.save(db=db)

        # assert we can retrieve a connector template by key and
        # that the values are the same as what we persisted
        custom_connector: Optional[
            CustomConnectorTemplate
        ] = CustomConnectorTemplate.get_by_key_or_id(
            db=db, data={""key"": ""planet_express""}
        )
        assert custom_connector
        assert custom_connector.name == ""Planet Express""
        assert custom_connector.config == planet_express_config
        assert custom_connector.dataset == planet_express_dataset
        assert custom_connector.icon == planet_express_icon
        assert custom_connector.functions == planet_express_functions
",CWE-94,40.0,1
"from typing import Optional

from sqlalchemy.orm import Session

from fides.api.models.custom_connector_template import CustomConnectorTemplate


class TestCustomConnectorTemplate:
    def test_create_custom_connector_template(
        self,
        db: Session,
        planet_express_config,
        planet_express_dataset,
        planet_express_icon,
        planet_express_functions,
    ) -> None:
        template = CustomConnectorTemplate(
            key=""planet_express"",
            name=""Planet Express"",
            config=planet_express_config,
            dataset=planet_express_dataset,
            icon=planet_express_icon,
            functions=planet_express_functions,
        )
        template.save(db=db)

        # assert we can retrieve a connector template by key and
        # that the values are the same as what we persisted
        custom_connector: Optional[
            CustomConnectorTemplate
        ] = CustomConnectorTemplate.get_by_key_or_id(
            db=db, data={""key"": ""planet_express""}
        )
        assert custom_connector
        assert custom_connector.name == ""Planet Express""
        assert custom_connector.config == planet_express_config
        assert custom_connector.dataset == planet_express_dataset
        assert custom_connector.icon == planet_express_icon
        assert custom_connector.functions == planet_express_functions
",CWE-693,40.0,1
,CWE-913,,1
"##############################################################################
#
# Copyright (c) 2002 Zope Foundation and Contributors.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED ""AS IS"" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE
#
##############################################################################

import math
import random
import string


utility_builtins = {}

utility_builtins['string'] = string
utility_builtins['math'] = math
utility_builtins['random'] = random
utility_builtins['whrandom'] = random
utility_builtins['set'] = set
utility_builtins['frozenset'] = frozenset

try:
    import DateTime
    utility_builtins['DateTime'] = DateTime.DateTime
except ImportError:
    pass


def same_type(arg1, *args):
    """"""Compares the class or type of two or more objects.""""""
    t = getattr(arg1, '__class__', type(arg1))
    for arg in args:
        if getattr(arg, '__class__', type(arg)) is not t:
            return False
    return True


utility_builtins['same_type'] = same_type


def test(*args):
    length = len(args)
    for i in range(1, length, 2):
        if args[i - 1]:
            return args[i]

    if length % 2:
        return args[-1]


utility_builtins['test'] = test


def reorder(s, with_=None, without=()):
    # s, with_, and without are sequences treated as sets.
    # The result is subtract(intersect(s, with_), without),
    # unless with_ is None, in which case it is subtract(s, without).
    if with_ is None:
        with_ = s
    orig = {}
    for item in s:
        if isinstance(item, tuple) and len(item) == 2:
            key, value = item
        else:
            key = value = item
        orig[key] = value

    result = []

    for item in without:
        if isinstance(item, tuple) and len(item) == 2:
            key, ignored = item
        else:
            key = item
        if key in orig:
            del orig[key]

    for item in with_:
        if isinstance(item, tuple) and len(item) == 2:
            key, ignored = item
        else:
            key = item
        if key in orig:
            result.append((key, orig[key]))
            del orig[key]

    return result


utility_builtins['reorder'] = reorder
",CWE-74,97.0,1
"import math
import random
import string


def test_string_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['string'] is string


def test_math_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['math'] is math


def test_whrandom_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['whrandom'] is random


def test_random_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['random'] is random


def test_set_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['set'] is set


def test_frozenset_in_utility_builtins():
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['frozenset'] is frozenset


def test_DateTime_in_utility_builtins_if_importable():
    try:
        import DateTime
    except ImportError:
        pass
    else:
        from RestrictedPython.Utilities import utility_builtins
        assert DateTime.__name__ in utility_builtins


def test_same_type_in_utility_builtins():
    from RestrictedPython.Utilities import same_type
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['same_type'] is same_type


def test_test_in_utility_builtins():
    from RestrictedPython.Utilities import test
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['test'] is test


def test_reorder_in_utility_builtins():
    from RestrictedPython.Utilities import reorder
    from RestrictedPython.Utilities import utility_builtins
    assert utility_builtins['reorder'] is reorder


def test_sametype_only_one_arg():
    from RestrictedPython.Utilities import same_type
    assert same_type(object())


def test_sametype_only_two_args_same():
    from RestrictedPython.Utilities import same_type
    assert same_type(object(), object())


def test_sametype_only_two_args_different():
    from RestrictedPython.Utilities import same_type

    class Foo:
        pass
    assert same_type(object(), Foo()) is False


def test_sametype_only_multiple_args_same():
    from RestrictedPython.Utilities import same_type
    assert same_type(object(), object(), object(), object())


def test_sametype_only_multipe_args_one_different():
    from RestrictedPython.Utilities import same_type

    class Foo:
        pass
    assert same_type(object(), object(), Foo()) is False


def test_test_single_value_true():
    from RestrictedPython.Utilities import test
    assert test(True) is True


def test_test_single_value_False():
    from RestrictedPython.Utilities import test
    assert test(False) is False


def test_test_even_values_first_true():
    from RestrictedPython.Utilities import test
    assert test(True, 'first', True, 'second') == 'first'


def test_test_even_values_not_first_true():
    from RestrictedPython.Utilities import test
    assert test(False, 'first', True, 'second') == 'second'


def test_test_odd_values_first_true():
    from RestrictedPython.Utilities import test
    assert test(True, 'first', True, 'second', False) == 'first'


def test_test_odd_values_not_first_true():
    from RestrictedPython.Utilities import test
    assert test(False, 'first', True, 'second', False) == 'second'


def test_test_odd_values_last_true():
    from RestrictedPython.Utilities import test
    assert test(False, 'first', False, 'second', 'third') == 'third'


def test_test_odd_values_last_false():
    from RestrictedPython.Utilities import test
    assert test(False, 'first', False, 'second', False) is False


def test_reorder_with__None():
    from RestrictedPython.Utilities import reorder
    before = ['a', 'b', 'c', 'd', 'e']
    without = ['a', 'c', 'e']
    after = reorder(before, without=without)
    assert after == [('b', 'b'), ('d', 'd')]


def test_reorder_with__not_None():
    from RestrictedPython.Utilities import reorder
    before = ['a', 'b', 'c', 'd', 'e']
    with_ = ['a', 'd']
    without = ['a', 'c', 'e']
    after = reorder(before, with_=with_, without=without)
    assert after == [('d', 'd')]
",CWE-74,150.0,1
"from RestrictedPython.Utilities import reorder
from RestrictedPython.Utilities import test


def test_Utilities__test_1():
    """"""It returns the first arg after the first argument which is True""""""
    assert test(True, 1, False, 2) == 1
    assert test(False, 1, True, 2) == 2
    assert test(False, 1, False, 2, True, 3) == 3


def test_Utilities__test_2():
    """"""If the above is not met, and there is an extra argument
    it returns it.""""""
    assert test(False, 1, False, 2, 3) == 3
    assert test(False, 1, 2) == 2
    assert test(1) == 1
    assert not test(False)


def test_Utilities__test_3():
    """"""It returns None if there are only False args followed by something.""""""
    assert test(False, 1) is None
    assert test(False, 1, False, 2) is None


def test_Utilities__reorder_1():
    """"""It also supports 2-tuples containing key, value.""""""
    s = [('k1', 'v1'), ('k2', 'v2'), ('k3', 'v3')]
    _with = [('k2', 'v2'), ('k3', 'v3')]
    without = [('k2', 'v2'), ('k4', 'v4')]
    assert reorder(s, _with, without) == [('k3', 'v3')]
",CWE-74,33.0,1
"from odoo.tests import common, tagged
from odoo import exceptions
import uuid
import logging
from ..models.web_progress import last_report_time

_logger = logging.getLogger(__name__)


@tagged('at_install', '-post_install')
class WebProgressTest(common.SavepointCase):

    def check_all_progress_data_empty(self):
        """"""
        Check that all global progress data is empty after tests
        """"""
        self.assertFalse(last_report_time, msg=""Global variable last_report_time shall be empty by now"")

    def setUp(self):
        super(WebProgressTest, self).setUp()
        self.maxDiff = None
        self.partner_obj = self.env['res.partner']
        self.web_progress_obj = self.env['web.progress']
        self.partner_ids = self.partner_obj
        self.partner_vals = {}
        for idx in range(20):
            self.partner_vals[idx] = dict(name='Test{}'.format(idx),
                                          email='email{}@test.me'.format(idx))
            self.partner_ids |= self.partner_obj.create(dict(self.partner_vals[idx]))
        self.addCleanup(self.check_all_progress_data_empty)

    def _check_web_progress_iter_recordset(self, total, recur_level=0):
        """"""
        Check that web_progress_iter works correctly for a recordset
        :param total: total number of collection elements
        """"""
        progress_iter = self.partner_ids[:total].with_progress(msg=""Total {} Level {}"".format(total,
                                                                                              recur_level))
        self.assertEqual(len(progress_iter), total, msg=""Length shall be accessible"")
        if total > 0:
            self.assertEqual(progress_iter[0], self.partner_ids[0], msg=""Indexing shall be accessible"")
            self.assertEqual(progress_iter._name, self.partner_ids._name, msg=""Attributes shall be accessible"")
        if total == len(self.partner_ids):
            self.assertEqual(progress_iter.ids, self.partner_ids.ids, msg=""Attributes shall be accessible"")
        count = 0
        for idx, partner_id in zip(range(total),progress_iter):
            self.assertEqual(partner_id.name, self.partner_vals[idx]['name'].format(idx), msg=""Wrong name"")
            self.assertEqual(partner_id.email, self.partner_vals[idx]['email'].format(idx), msg=""Wrong email"")
            count += 1
            if recur_level > 0:
                self._check_web_progress_iter_recordset(total, recur_level - 1)
        self.assertEqual(count, total, msg=""Not all elements are yielded from a collection"")

    def _check_web_progress_iter_recordset_many(self, recur_level=0):
        """"""
        Iterate recordsets of different lengths
        :param recur_level: recursion level of iterations
        """"""
        # iterate all partners
        self._check_web_progress_iter_recordset(len(self.partner_ids), recur_level)
        # iterate half of all partners
        self._check_web_progress_iter_recordset(round(len(self.partner_ids)/2), recur_level)
        # iterate again all partners (no recursion)
        self._check_web_progress_iter_recordset(len(self.partner_ids))
        # iterate one partner
        self._check_web_progress_iter_recordset(1, recur_level)
        # iterate empty recordset
        self._check_web_progress_iter_recordset(0, recur_level)

    def _check_web_progress_cancelled(self):
        """"""
        Checks that the current operation has been cancelled
        """"""
        code = self.partner_ids._context.get('progress_code', None)
        self.assertIsNotNone(code, msg=""Progress code shall be in the context"")
        cancelled = self.web_progress_obj._check_cancelled(dict(code=code))
        self.assertTrue(cancelled, msg=""Currect operation should have been cancelled"")

    def test_web_progress_iter_without_web_progress_code(self):
        """"""
        Check that web_progress_iter works correctly without a progress_code in context
        """"""
        self._check_web_progress_iter_recordset_many(0)
        self._check_web_progress_iter_recordset_many(1)

    def test_web_progress_iter_with_web_progress_code(self):
        """"""
        Check that web_progress_iter works correctly with a progress_code in context
        """"""
        progress_code = str(uuid.uuid4())
        self.partner_ids = self.partner_ids.with_context(progress_code=progress_code)
        self._check_web_progress_iter_recordset_many(0)
        self._check_web_progress_iter_recordset_many(1)

    def test_web_progress_iter_with_web_progress_code_cancel(self):
        """"""
        Check that cancel request is respected by web_progress_iter
        """"""
        progress_code = str(uuid.uuid4())
        self.partner_ids = self.partner_ids.with_context(progress_code=progress_code)
        self._check_web_progress_iter_recordset_many(0)
        self.partner_ids.web_progress_cancel()
        self._check_web_progress_cancelled()
        # any further iteration shall raise UserError
        with self.assertRaises(exceptions.UserError, msg=""Exception UserErro shall have been raised""):
            self._check_web_progress_iter_recordset_many(0)
        self._check_web_progress_cancelled()

    def test_web_progress_percent(self):
        """"""
        Check web_progress_percent
        """"""
        progress_code = str(uuid.uuid4())
        self.partner_ids = self.partner_ids.with_context(progress_code=progress_code)
        self.partner_ids.web_progress_percent(0, ""Start"")
        self.partner_ids.web_progress_percent(50, ""Middle"")
        self.partner_ids.web_progress_percent(100, ""End"")
",CWE-89,118.0,1
"from __future__ import annotations

import contextvars
import logging
import pprint
import typing as t
from abc import ABCMeta, abstractmethod

from piccolo.querystring import QueryString
from piccolo.utils.sync import run_sync
from piccolo.utils.warnings import Level, colored_string, colored_warning

if t.TYPE_CHECKING:  # pragma: no cover
    from piccolo.query.base import Query


logger = logging.getLogger(__name__)


class Batch:
    pass


TransactionClass = t.TypeVar(""TransactionClass"")


class Engine(t.Generic[TransactionClass], metaclass=ABCMeta):

    __slots__ = (""query_id"",)

    def __init__(self):
        run_sync(self.check_version())
        run_sync(self.prep_database())
        self.query_id = 0

    @property
    @abstractmethod
    def engine_type(self) -> str:
        pass

    @property
    @abstractmethod
    def min_version_number(self) -> float:
        pass

    @abstractmethod
    async def get_version(self) -> float:
        pass

    @abstractmethod
    def get_version_sync(self) -> float:
        pass

    @abstractmethod
    async def prep_database(self):
        pass

    @abstractmethod
    async def batch(
        self,
        query: Query,
        batch_size: int = 100,
        node: t.Optional[str] = None,
    ) -> Batch:
        pass

    @abstractmethod
    async def run_querystring(self, querystring: QueryString, in_pool: bool):
        pass

    @abstractmethod
    async def run_ddl(self, ddl: str, in_pool: bool = True):
        pass

    @abstractmethod
    def transaction(self):
        pass

    @abstractmethod
    def atomic(self):
        pass

    async def check_version(self):
        """"""
        Warn if the database version isn't supported.
        """"""
        try:
            version_number = await self.get_version()
        except Exception as exception:
            colored_warning(
                f""Unable to fetch server version: {exception}"",
                level=Level.high,
            )
            return

        engine_type = self.engine_type.capitalize()
        logger.info(f""Running {engine_type} version {version_number}"")
        if version_number and (version_number < self.min_version_number):
            message = (
                f""This version of {self.engine_type} isn't supported ""
                f""(< {self.min_version_number}) - some features might not be ""
                ""available. For instructions on installing databases, see the ""
                ""Piccolo docs.""
            )
            colored_warning(message, stacklevel=3)

    def _connection_pool_warning(self):
        message = (
            f""Connection pooling is not supported for {self.engine_type}.""
        )
        logger.warning(message)
        colored_warning(message, stacklevel=3)

    async def start_connection_pool(self):
        """"""
        The database driver doesn't implement connection pooling.
        """"""
        self._connection_pool_warning()

    async def close_connection_pool(self):
        """"""
        The database driver doesn't implement connection pooling.
        """"""
        self._connection_pool_warning()

    ###########################################################################

    current_transaction: contextvars.ContextVar[t.Optional[TransactionClass]]

    def transaction_exists(self) -> bool:
        """"""
        Find out if a transaction is currently active.

        :returns:
            ``True`` if a transaction is already active for the current
            asyncio task. This is useful to know, because nested transactions
            aren't currently supported, so you can check if an existing
            transaction is already active, before creating a new one.

        """"""
        return self.current_transaction.get() is not None

    ###########################################################################
    # Logging queries and responses

    def get_query_id(self) -> int:
        self.query_id += 1
        return self.query_id

    def print_query(self, query_id: int, query: str):
        print(colored_string(f""\nQuery {query_id}:""))
        print(query)

    def print_response(self, query_id: int, response: t.List):
        print(
            colored_string(f""\nQuery {query_id} response:"", level=Level.high)
        )
        pprint.pprint(response)
",CWE-89,159.0,1
"import os

from celery import shared_task
from django.conf import settings
from django.core.mail import send_mail, EmailMultiAlternatives
from django.utils.translation import gettext_lazy as _

from .utils import get_logger

logger = get_logger(__file__)


def task_activity_callback(self, subject, message, recipient_list, *args, **kwargs):
    from users.models import User
    email_list = recipient_list
    resource_ids = list(User.objects.filter(email__in=email_list).values_list('id', flat=True))
    return resource_ids,


@shared_task(verbose_name=_(""Send email""), activity_callback=task_activity_callback)
def send_mail_async(*args, **kwargs):
    """""" Using celery to send email async

    You can use it as django send_mail function

    Example:
    send_mail_sync.delay(subject, message, from_mail, recipient_list, fail_silently=False, html_message=None)

    Also, you can ignore the from_mail, unlike django send_mail, from_email is not a required args:

    Example:
    send_mail_sync.delay(subject, message, recipient_list, fail_silently=False, html_message=None)
    """"""
    if len(args) == 3:
        args = list(args)
        args[0] = (settings.EMAIL_SUBJECT_PREFIX or '') + args[0]
        from_email = settings.EMAIL_FROM or settings.EMAIL_HOST_USER
        args.insert(2, from_email)

    args[3] = [mail for mail in args[3] if mail != 'admin@mycomany.com']
    args = tuple(args)

    try:
        return send_mail(*args, **kwargs)
    except Exception as e:
        logger.error(""Sending mail error: {}"".format(e))


@shared_task(verbose_name=_(""Send email attachment""), activity_callback=task_activity_callback)
def send_mail_attachment_async(subject, message, recipient_list, attachment_list=None):
    if attachment_list is None:
        attachment_list = []
    from_email = settings.EMAIL_FROM or settings.EMAIL_HOST_USER
    subject = (settings.EMAIL_SUBJECT_PREFIX or '') + subject
    recipient_list = [mail for mail in recipient_list if mail != 'admin@mycomany.com']
    email = EmailMultiAlternatives(
        subject=subject,
        body=message,
        from_email=from_email,
        to=recipient_list
    )
    for attachment in attachment_list:
        email.attach_file(attachment)
        os.remove(attachment)
    try:
        return email.send()
    except Exception as e:
        logger.error(""Sending mail attachment error: {}"".format(e))
",CWE-640,69.0,1
,CWE-640,,1
"import os
from rest_framework.exceptions import ValidationError


def cast_bool_from_str(value):
    if isinstance(value, str):
        if value.lower() in ['true', 'yes', 'on', '1']:
            value = True
        elif value.lower() in ['false', 'no', 'not', 'off', '0']:
            value = False
        else:
            raise ValueError(f'Incorrect bool value ""{value}"". '
                             f'It should be one of [1, 0, true, false, yes, no]')
    return value


def bool_from_request(params, key, default):
    """""" Get boolean value from request GET, POST, etc

    :param params: dict POST, GET, etc
    :param key: key to find
    :param default: default value
    :return: boolean
    """"""
    value = params.get(key, default)

    try:
        if isinstance(value, str):
            value = cast_bool_from_str(value)
        return bool(int(value))
    except Exception as e:
        raise ValidationError({key: str(e)})


def int_from_request(params, key, default):
    """""" Get integer from request GET, POST, etc

    :param params: dict POST, GET, etc
    :param key: key to find
    :param default: default value
    :return: int
    """"""
    value = params.get(key, default)

    # str
    if isinstance(value, str):
        try:
            return int(value)
        except ValueError:
            raise ValidationError({key: f'Incorrect value in key ""{key}"" = ""{value}"". It should be digit string.'})
        except Exception as e:
            raise ValidationError({key: str(e)})
    # int
    elif isinstance(value, int):
        return value
    # other
    else:
        raise ValidationError({key: f'Incorrect value type in key ""{key}"" = ""{value}"". '
                                    f'It should be digit string or integer.'})


def float_from_request(params, key, default):
    """""" Get float from request GET, POST, etc

    :param params: dict POST, GET, etc
    :param key: key to find
    :param default: default value
    :return: float
    """"""
    value = params.get(key, default)

    # str
    if isinstance(value, str):
        try:
            return float(value)
        except ValueError:
            raise ValidationError({key: f'Incorrect value in key ""{key}"" = ""{value}"". It should be digit string.'})
    # float
    elif isinstance(value, float) or isinstance(value, int):
        return float(value)
    # other
    else:
        raise ValidationError({key: f'Incorrect value type in key ""{key}"" = ""{value}"". '
                                    f'It should be digit string or float.'})


def list_of_strings_from_request(params, key, default):
    """""" Get list of strings from request GET, POST, etc

    :param params: dict POST, GET, etc
    :param key: key to find
    :param default: default value
    :return: float
    """"""
    value = params.get(key, default)
    if value is None:
        return
    splitters = (',', ';', '|')
    # str
    if isinstance(value, str):
        for splitter in splitters:
            if splitter in value:
                return value.split(splitter)
        return [value]
    else:
        raise ValidationError({key: f'Incorrect value type in key ""{key}"" = ""{value}"". '
                                    f'It should be digit string or float.'})


def get_env(name, default=None, is_bool=False):
    for env_key in ['LABEL_STUDIO_' + name, 'HEARTEX_' + name, name]:
        value = os.environ.get(env_key)
        if value is not None:
            if is_bool:
                return bool_from_request(os.environ, env_key, default)
            else:
                return value
    return default


def get_bool_env(key, default):
    return get_env(key, default, is_bool=True)


def get_env_list_int(key, default=None):
    """"""
    ""1,2,3"" in env variable => [1, 2, 3] in python
    """"""
    value = get_env(key)
    if not value:
        if default is None:
            return []
        return default
    return [int(el) for el in value.split(',')]


def get_all_env_with_prefix(prefix=None, is_bool=True, default_value=None):
    out = {}
    for key in os.environ.keys():
        if not key.startswith(prefix):
            continue
        if is_bool:
            out[key] = bool_from_request(os.environ, key, default_value)
        else:
            out[key] = os.environ[key]
    return out
",CWE-200,147.0,1
"from unittest import mock
from unittest.mock import Mock

import pytest
from core.utils.io import validate_upload_url
from data_import.uploader import check_tasks_max_file_size, load_tasks
from django.conf import settings
from rest_framework.exceptions import ValidationError

pytestmark = pytest.mark.django_db


class MockedRequest:
    FILES = ()

    def __init__(self, url):
        self.url = url

    @property
    def content_type(self):
        return 'application/x-www-form-urlencoded'

    @property
    def data(self):
        return {'url': self.url}

    @property
    def user(self):
        return None


class TestUploader:
    @pytest.fixture
    def project(self, configured_project, settings):
        return configured_project

    class TestLoadTasks:
        @mock.patch('core.utils.io.validate_upload_url', wraps=validate_upload_url)
        @pytest.mark.parametrize('url', ('file:///etc/passwd', 'ftp://example.org'))
        def test_raises_for_unsafe_urls(self, validate_upload_url_mock, url, project):
            request = MockedRequest(url=url)

            with pytest.raises(ValidationError) as e:
                load_tasks(request, project)
                assert 'The provided URL was not valid.' in e.value

            validate_upload_url_mock.assert_called_once_with(url, block_local_urls=False)

        @mock.patch('core.utils.io.validate_upload_url', wraps=validate_upload_url)
        def test_raises_for_local_urls_with_ssrf_protection_enabled(self, validate_upload_url_mock, project, settings):
            settings.SSRF_PROTECTION_ENABLED = True
            request = MockedRequest(url='http://0.0.0.0')

            with pytest.raises(ValidationError) as e:
                load_tasks(request, project)
                assert 'The provided URL was not valid.' in e.value

            validate_upload_url_mock.assert_called_once_with('http://0.0.0.0', block_local_urls=True)

        def test_local_url_after_redirect(self, project, settings):
            settings.SSRF_PROTECTION_ENABLED = True
            request = MockedRequest(url='http://validurl.com')

            # Mock the necessary parts of the response object
            mock_response = Mock()
            mock_response.raw._connection.sock.getpeername.return_value = ('127.0.0.1', 8080)

            # Patch the requests.get call in the data_import.uploader module
            with mock.patch('core.utils.io.requests.get', return_value=mock_response), pytest.raises(
                ValidationError
            ) as e:
                load_tasks(request, project)
            assert 'The provided URL was not valid.' in str(e.value)


class TestTasksFileChecks:
    @pytest.mark.parametrize('value', (0, settings.TASKS_MAX_FILE_SIZE - 1))
    def test_check_tasks_max_file_size_does_not_raise_for_correct_value(self, value):
        check_tasks_max_file_size(value)

    def test_check_tasks_max_file_size_raises_for_too_big_value(self):
        value = settings.TASKS_MAX_FILE_SIZE + 1

        with pytest.raises(ValidationError) as e:
            check_tasks_max_file_size(value)

        assert f'Maximum total size of all files is {settings.TASKS_MAX_FILE_SIZE} bytes' in str(e.value)
",CWE-918,88.0,1
,CWE-400,,1
"import re
from pathlib import Path
from typing import Iterator, List, Optional, Sequence, Tuple, Union

from langchain_core.stores import ByteStore

from langchain.storage.exceptions import InvalidKeyException


class LocalFileStore(ByteStore):
    """"""BaseStore interface that works on the local file system.

    Examples:
        Create a LocalFileStore instance and perform operations on it:

        .. code-block:: python

            from langchain.storage import LocalFileStore

            # Instantiate the LocalFileStore with the root path
            file_store = LocalFileStore(""/path/to/root"")

            # Set values for keys
            file_store.mset([(""key1"", b""value1""), (""key2"", b""value2"")])

            # Get values for keys
            values = file_store.mget([""key1"", ""key2""])  # Returns [b""value1"", b""value2""]

            # Delete keys
            file_store.mdelete([""key1""])

            # Iterate over keys
            for key in file_store.yield_keys():
                print(key)

    """"""

    def __init__(self, root_path: Union[str, Path]) -> None:
        """"""Implement the BaseStore interface for the local file system.

        Args:
            root_path (Union[str, Path]): The root path of the file store. All keys are
                interpreted as paths relative to this root.
        """"""
        self.root_path = Path(root_path)

    def _get_full_path(self, key: str) -> Path:
        """"""Get the full path for a given key relative to the root path.

        Args:
            key (str): The key relative to the root path.

        Returns:
            Path: The full path for the given key.
        """"""
        if not re.match(r""^[a-zA-Z0-9_.\-/]+$"", key):
            raise InvalidKeyException(f""Invalid characters in key: {key}"")
        return self.root_path / key

    def mget(self, keys: Sequence[str]) -> List[Optional[bytes]]:
        """"""Get the values associated with the given keys.

        Args:
            keys: A sequence of keys.

        Returns:
            A sequence of optional values associated with the keys.
            If a key is not found, the corresponding value will be None.
        """"""
        values: List[Optional[bytes]] = []
        for key in keys:
            full_path = self._get_full_path(key)
            if full_path.exists():
                value = full_path.read_bytes()
                values.append(value)
            else:
                values.append(None)
        return values

    def mset(self, key_value_pairs: Sequence[Tuple[str, bytes]]) -> None:
        """"""Set the values for the given keys.

        Args:
            key_value_pairs: A sequence of key-value pairs.

        Returns:
            None
        """"""
        for key, value in key_value_pairs:
            full_path = self._get_full_path(key)
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_bytes(value)

    def mdelete(self, keys: Sequence[str]) -> None:
        """"""Delete the given keys and their associated values.

        Args:
            keys (Sequence[str]): A sequence of keys to delete.

        Returns:
            None
        """"""
        for key in keys:
            full_path = self._get_full_path(key)
            if full_path.exists():
                full_path.unlink()

    def yield_keys(self, prefix: Optional[str] = None) -> Iterator[str]:
        """"""Get an iterator over keys that match the given prefix.

        Args:
            prefix (Optional[str]): The prefix to match.

        Returns:
            Iterator[str]: An iterator over keys that match the given prefix.
        """"""
        prefix_path = self._get_full_path(prefix) if prefix else self.root_path
        for file in prefix_path.rglob(""*""):
            if file.is_file():
                relative_path = file.relative_to(self.root_path)
                yield str(relative_path)
",CWE-22,122.0,1
"import os
import tempfile
from typing import Generator

import pytest

from langchain.storage.exceptions import InvalidKeyException
from langchain.storage.file_system import LocalFileStore


@pytest.fixture
def file_store() -> Generator[LocalFileStore, None, None]:
    # Create a temporary directory for testing
    with tempfile.TemporaryDirectory() as temp_dir:
        # Instantiate the LocalFileStore with the temporary directory as the root path
        store = LocalFileStore(temp_dir)
        yield store


def test_mset_and_mget(file_store: LocalFileStore) -> None:
    # Set values for keys
    key_value_pairs = [(""key1"", b""value1""), (""key2"", b""value2"")]
    file_store.mset(key_value_pairs)

    # Get values for keys
    values = file_store.mget([""key1"", ""key2""])

    # Assert that the retrieved values match the original values
    assert values == [b""value1"", b""value2""]


def test_mdelete(file_store: LocalFileStore) -> None:
    # Set values for keys
    key_value_pairs = [(""key1"", b""value1""), (""key2"", b""value2"")]
    file_store.mset(key_value_pairs)

    # Delete keys
    file_store.mdelete([""key1""])

    # Check if the deleted key is present
    values = file_store.mget([""key1""])

    # Assert that the value is None after deletion
    assert values == [None]


def test_set_invalid_key(file_store: LocalFileStore) -> None:
    """"""Test that an exception is raised when an invalid key is set.""""""
    # Set a key-value pair
    key = ""crying-cat/""
    value = b""This is a test value""
    with pytest.raises(InvalidKeyException):
        file_store.mset([(key, value)])


def test_set_key_and_verify_content(file_store: LocalFileStore) -> None:
    """"""Test that the content of the file is the same as the value set.""""""
    # Set a key-value pair
    key = ""test_key""
    value = b""This is a test value""
    file_store.mset([(key, value)])

    # Verify the content of the actual file
    full_path = file_store._get_full_path(key)
    assert full_path.exists()
    assert full_path.read_bytes() == b""This is a test value""


def test_yield_keys(file_store: LocalFileStore) -> None:
    # Set values for keys
    key_value_pairs = [(""key1"", b""value1""), (""subdir/key2"", b""value2"")]
    file_store.mset(key_value_pairs)

    # Iterate over keys
    keys = list(file_store.yield_keys())

    # Assert that the yielded keys match the expected keys
    expected_keys = [""key1"", os.path.join(""subdir"", ""key2"")]
    assert keys == expected_keys
",CWE-22,80.0,1
"import re
from typing import List, Optional, Sequence, Union
from urllib.parse import urljoin, urlparse

PREFIXES_TO_IGNORE = (""javascript:"", ""mailto:"", ""#"")
SUFFIXES_TO_IGNORE = (
    "".css"",
    "".js"",
    "".ico"",
    "".png"",
    "".jpg"",
    "".jpeg"",
    "".gif"",
    "".svg"",
    "".csv"",
    "".bz2"",
    "".zip"",
    "".epub"",
)
SUFFIXES_TO_IGNORE_REGEX = (
    ""(?!"" + ""|"".join([re.escape(s) + r""[\#'\""]"" for s in SUFFIXES_TO_IGNORE]) + "")""
)
PREFIXES_TO_IGNORE_REGEX = (
    ""(?!"" + ""|"".join([re.escape(s) for s in PREFIXES_TO_IGNORE]) + "")""
)
DEFAULT_LINK_REGEX = (
    rf""href=[\""']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)[\#'\""]""
)


def find_all_links(
    raw_html: str, *, pattern: Union[str, re.Pattern, None] = None
) -> List[str]:
    """"""Extract all links from a raw html string.

    Args:
        raw_html: original html.
        pattern: Regex to use for extracting links from raw html.

    Returns:
        List[str]: all links
    """"""
    pattern = pattern or DEFAULT_LINK_REGEX
    return list(set(re.findall(pattern, raw_html)))


def extract_sub_links(
    raw_html: str,
    url: str,
    *,
    base_url: Optional[str] = None,
    pattern: Union[str, re.Pattern, None] = None,
    prevent_outside: bool = True,
    exclude_prefixes: Sequence[str] = (),
) -> List[str]:
    """"""Extract all links from a raw html string and convert into absolute paths.

    Args:
        raw_html: original html.
        url: the url of the html.
        base_url: the base url to check for outside links against.
        pattern: Regex to use for extracting links from raw html.
        prevent_outside: If True, ignore external links which are not children
            of the base url.
        exclude_prefixes: Exclude any URLs that start with one of these prefixes.

    Returns:
        List[str]: sub links
    """"""
    base_url = base_url if base_url is not None else url
    all_links = find_all_links(raw_html, pattern=pattern)
    absolute_paths = set()
    for link in all_links:
        # Some may be absolute links like https://to/path
        if link.startswith(""http""):
            absolute_paths.add(link)
        # Some may have omitted the protocol like //to/path
        elif link.startswith(""//""):
            absolute_paths.add(f""{urlparse(url).scheme}:{link}"")
        else:
            absolute_paths.add(urljoin(url, link))
    res = []
    for path in absolute_paths:
        if any(path.startswith(exclude) for exclude in exclude_prefixes):
            continue
        if prevent_outside and not path.startswith(base_url):
            continue
        res.append(path)
    return res
",CWE-918,90.0,1
"from langchain_core.utils.html import (
    PREFIXES_TO_IGNORE,
    SUFFIXES_TO_IGNORE,
    extract_sub_links,
    find_all_links,
)


def test_find_all_links_none() -> None:
    html = ""<span>Hello world</span>""
    actual = find_all_links(html)
    assert actual == []


def test_find_all_links_single() -> None:
    htmls = [
        ""href='foobar.com'"",
        'href=""foobar.com""',
        '<div><a class=""blah"" href=""foobar.com"">hullo</a></div>',
    ]
    actual = [find_all_links(html) for html in htmls]
    assert actual == [[""foobar.com""]] * 3


def test_find_all_links_multiple() -> None:
    html = (
        '<div><a class=""blah"" href=""https://foobar.com"">hullo</a></div>'
        '<div><a class=""bleh"" href=""/baz/cool"">buhbye</a></div>'
    )
    actual = find_all_links(html)
    assert sorted(actual) == [
        ""/baz/cool"",
        ""https://foobar.com"",
    ]


def test_find_all_links_ignore_suffix() -> None:
    html = 'href=""foobar{suffix}""'
    for suffix in SUFFIXES_TO_IGNORE:
        actual = find_all_links(html.format(suffix=suffix))
        assert actual == []

    # Don't ignore if pattern doesn't occur at end of link.
    html = 'href=""foobar{suffix}more""'
    for suffix in SUFFIXES_TO_IGNORE:
        actual = find_all_links(html.format(suffix=suffix))
        assert actual == [f""foobar{suffix}more""]


def test_find_all_links_ignore_prefix() -> None:
    html = 'href=""{prefix}foobar""'
    for prefix in PREFIXES_TO_IGNORE:
        actual = find_all_links(html.format(prefix=prefix))
        assert actual == []

    # Don't ignore if pattern doesn't occur at beginning of link.
    html = 'href=""foobar{prefix}more""'
    for prefix in PREFIXES_TO_IGNORE:
        # Pound signs are split on when not prefixes.
        if prefix == ""#"":
            continue
        actual = find_all_links(html.format(prefix=prefix))
        assert actual == [f""foobar{prefix}more""]


def test_find_all_links_drop_fragment() -> None:
    html = 'href=""foobar.com/woah#section_one""'
    actual = find_all_links(html)
    assert actual == [""foobar.com/woah""]


def test_extract_sub_links() -> None:
    html = (
        '<a href=""https://foobar.com"">one</a>'
        '<a href=""http://baz.net"">two</a>'
        '<a href=""//foobar.com/hello"">three</a>'
        '<a href=""/how/are/you/doing"">four</a>'
    )
    expected = sorted(
        [
            ""https://foobar.com"",
            ""https://foobar.com/hello"",
            ""https://foobar.com/how/are/you/doing"",
        ]
    )
    actual = sorted(extract_sub_links(html, ""https://foobar.com""))
    assert actual == expected

    actual = extract_sub_links(html, ""https://foobar.com/hello"")
    expected = [""https://foobar.com/hello""]
    assert actual == expected

    actual = sorted(
        extract_sub_links(html, ""https://foobar.com/hello"", prevent_outside=False)
    )
    expected = sorted(
        [
            ""https://foobar.com"",
            ""http://baz.net"",
            ""https://foobar.com/hello"",
            ""https://foobar.com/how/are/you/doing"",
        ]
    )
    assert actual == expected


def test_extract_sub_links_base() -> None:
    html = (
        '<a href=""https://foobar.com"">one</a>'
        '<a href=""http://baz.net"">two</a>'
        '<a href=""//foobar.com/hello"">three</a>'
        '<a href=""/how/are/you/doing"">four</a>'
        '<a href=""alexis.html""</a>'
    )

    expected = sorted(
        [
            ""https://foobar.com"",
            ""https://foobar.com/hello"",
            ""https://foobar.com/how/are/you/doing"",
            ""https://foobar.com/hello/alexis.html"",
        ]
    )
    actual = sorted(
        extract_sub_links(
            html, ""https://foobar.com/hello/bill.html"", base_url=""https://foobar.com""
        )
    )
    assert actual == expected


def test_extract_sub_links_exclude() -> None:
    html = (
        '<a href=""https://foobar.com"">one</a>'
        '<a href=""http://baz.net"">two</a>'
        '<a href=""//foobar.com/hello"">three</a>'
        '<a href=""/how/are/you/doing"">four</a>'
        '<a href=""alexis.html""</a>'
    )

    expected = sorted(
        [
            ""http://baz.net"",
            ""https://foobar.com"",
            ""https://foobar.com/hello"",
            ""https://foobar.com/hello/alexis.html"",
        ]
    )
    actual = sorted(
        extract_sub_links(
            html,
            ""https://foobar.com/hello/bill.html"",
            base_url=""https://foobar.com"",
            prevent_outside=False,
            exclude_prefixes=(""https://foobar.com/how"", ""http://baz.org""),
        )
    )
    assert actual == expected
",CWE-918,159.0,1
"import re
import xml.etree.ElementTree as ET
from typing import Any, AsyncIterator, Dict, Iterator, List, Optional, Union

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import BaseMessage
from langchain_core.output_parsers.transform import BaseTransformOutputParser
from langchain_core.runnables.utils import AddableDict

XML_FORMAT_INSTRUCTIONS = """"""The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags [""foo"", ""bar"", ""baz""]:
1. String ""<foo>\n   <bar>\n      <baz></baz>\n   </bar>\n</foo>"" is a well-formatted instance of the schema. 
2. String ""<foo>\n   <bar>\n   </foo>"" is a badly-formatted instance.
3. String ""<foo>\n   <tag>\n   </tag>\n</foo>"" is a badly-formatted instance.

Here are the output tags:
```
{tags}
```""""""  # noqa: E501


class XMLOutputParser(BaseTransformOutputParser):
    """"""Parse an output using xml format.""""""

    tags: Optional[List[str]] = None
    encoding_matcher: re.Pattern = re.compile(
        r""<([^>]*encoding[^>]*)>\n(.*)"", re.MULTILINE | re.DOTALL
    )

    def get_format_instructions(self) -> str:
        return XML_FORMAT_INSTRUCTIONS.format(tags=self.tags)

    def parse(self, text: str) -> Dict[str, List[Any]]:
        # Try to find XML string within triple backticks
        match = re.search(r""```(xml)?(.*)```"", text, re.DOTALL)
        if match is not None:
            # If match found, use the content within the backticks
            text = match.group(2)
        encoding_match = self.encoding_matcher.search(text)
        if encoding_match:
            text = encoding_match.group(2)

        text = text.strip()
        try:
            root = ET.fromstring(text)
            return self._root_to_dict(root)

        except ET.ParseError as e:
            msg = f""Failed to parse XML format from completion {text}. Got: {e}""
            raise OutputParserException(msg, llm_output=text) from e

    def _transform(
        self, input: Iterator[Union[str, BaseMessage]]
    ) -> Iterator[AddableDict]:
        xml_start_re = re.compile(r""<[a-zA-Z:_]"")
        parser = ET.XMLPullParser([""start"", ""end""])
        xml_started = False
        current_path: List[str] = []
        current_path_has_children = False
        buffer = """"
        for chunk in input:
            if isinstance(chunk, BaseMessage):
                # extract text
                chunk_content = chunk.content
                if not isinstance(chunk_content, str):
                    continue
                chunk = chunk_content
            # add chunk to buffer of unprocessed text
            buffer += chunk
            # if xml string hasn't started yet, continue to next chunk
            if not xml_started:
                if match := xml_start_re.search(buffer):
                    # if xml string has started, remove all text before it
                    buffer = buffer[match.start() :]
                    xml_started = True
                else:
                    continue
            # feed buffer to parser
            parser.feed(buffer)
            buffer = """"
            # yield all events
            for event, elem in parser.read_events():
                if event == ""start"":
                    # update current path
                    current_path.append(elem.tag)
                    current_path_has_children = False
                elif event == ""end"":
                    # remove last element from current path
                    current_path.pop()
                    # yield element
                    if not current_path_has_children:
                        yield nested_element(current_path, elem)
                    # prevent yielding of parent element
                    if current_path:
                        current_path_has_children = True
                    else:
                        xml_started = False
        # close parser
        parser.close()

    async def _atransform(
        self, input: AsyncIterator[Union[str, BaseMessage]]
    ) -> AsyncIterator[AddableDict]:
        parser = ET.XMLPullParser([""start"", ""end""])
        current_path: List[str] = []
        current_path_has_children = False
        async for chunk in input:
            if isinstance(chunk, BaseMessage):
                # extract text
                chunk_content = chunk.content
                if not isinstance(chunk_content, str):
                    continue
                chunk = chunk_content
            # pass chunk to parser
            parser.feed(chunk)
            # yield all events
            for event, elem in parser.read_events():
                if event == ""start"":
                    # update current path
                    current_path.append(elem.tag)
                    current_path_has_children = False
                elif event == ""end"":
                    # remove last element from current path
                    current_path.pop()
                    # yield element
                    if not current_path_has_children:
                        yield nested_element(current_path, elem)
                    # prevent yielding of parent element
                    current_path_has_children = True
        # close parser
        parser.close()

    def _root_to_dict(self, root: ET.Element) -> Dict[str, List[Any]]:
        """"""Converts xml tree to python dictionary.""""""
        result: Dict[str, List[Any]] = {root.tag: []}
        for child in root:
            if len(child) == 0:
                result[root.tag].append({child.tag: child.text})
            else:
                result[root.tag].append(self._root_to_dict(child))
        return result

    @property
    def _type(self) -> str:
        return ""xml""


def nested_element(path: List[str], elem: ET.Element) -> Any:
    """"""Get nested element from path.""""""
    if len(path) == 0:
        return AddableDict({elem.tag: elem.text})
    else:
        return AddableDict({path[0]: [nested_element(path[1:], elem)]})
",CWE-776,158.0,1
"[tool.poetry]
name = ""langchain-core""
version = ""0.1.33""
description = ""Building applications with LLMs through composability""
authors = []
license = ""MIT""
readme = ""README.md""
repository = ""https://github.com/langchain-ai/langchain""


[tool.poetry.dependencies]
python = "">=3.8.1,<4.0""
pydantic = "">=1,<3""
langsmith = ""^0.1.0""
tenacity = ""^8.1.0""
jsonpatch = ""^1.33""
anyio = "">=3,<5""
PyYAML = "">=5.3""
requests = ""^2""
packaging = ""^23.2""
jinja2 = { version = ""^3"", optional = true }

[tool.poetry.group.lint]
optional = true

[tool.poetry.group.lint.dependencies]
ruff = ""^0.1.5""

[tool.poetry.group.typing]
optional = true

[tool.poetry.group.typing.dependencies]
mypy = ""^1""
types-pyyaml = ""^6.0.12.2""
types-requests = ""^2.28.11.5""
types-jinja2 = ""^2.11.9""
langchain-text-splitters = { path = ""../text-splitters"", develop = true }

[tool.poetry.group.dev]
optional = true

[tool.poetry.group.dev.dependencies]
jupyter = ""^1.0.0""
setuptools = ""^67.6.1""
grandalf = ""^0.8""

[tool.poetry.group.test]
optional = true

[tool.poetry.group.test.dependencies]
# The only dependencies that should be added are
# dependencies used for running tests (e.g., pytest, freezegun, response).
# Any dependencies that do not meet that criteria will be removed.
pytest = ""^7.3.0""
freezegun = ""^1.2.2""
pytest-mock = ""^3.10.0""
syrupy = ""^4.0.2""
pytest-watcher = ""^0.3.4""
pytest-asyncio = ""^0.21.1""
grandalf = ""^0.8""
pytest-profiling = ""^1.7.0""
responses = ""^0.25.0""
numpy = ""^1.24.0""


[tool.poetry.group.test_integration]
optional = true
dependencies = {}

[tool.poetry.extras]
extended_testing = [""jinja2""]

[tool.ruff.lint]
select = [
  ""E"",    # pycodestyle
  ""F"",    # pyflakes
  ""I"",    # isort
  ""T201"", # print
]

[tool.mypy]
disallow_untyped_defs = ""True""
exclude = [""notebooks"", ""examples"", ""example_data"", ""langchain_core/pydantic""]

[tool.coverage.run]
omit = [""tests/*""]

[build-system]
requires = [""poetry-core>=1.0.0""]
build-backend = ""poetry.core.masonry.api""

[tool.pytest.ini_options]
# --strict-markers will raise errors on unknown marks.
# https://docs.pytest.org/en/7.1.x/how-to/mark.html#raising-errors-on-unknown-marks
#
# https://docs.pytest.org/en/7.1.x/reference/reference.html
# --strict-config       any warnings encountered while parsing the `pytest`
#                       section of the configuration file raise errors.
#
# https://github.com/tophat/syrupy
# --snapshot-warn-unused    Prints a warning on unused snapshots rather than fail the test suite.
addopts = ""--snapshot-warn-unused --strict-markers --strict-config --durations=5""
# Registering custom markers.
# https://docs.pytest.org/en/7.1.x/example/markers.html#registering-markers
markers = [
  ""requires: mark tests as requiring a specific library"",
  ""asyncio: mark tests as requiring asyncio"",
  ""compile: mark placeholder test used to compile integration tests without running them"",
]
asyncio_mode = ""auto""
",CWE-776,111.0,1
"""""""Test XMLOutputParser""""""
import pytest

from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers.xml import XMLOutputParser

DEF_RESULT_ENCODING = """"""<?xml version=""1.0"" encoding=""UTF-8""?>
 <foo>
    <bar>
        <baz></baz>
        <baz>slim.shady</baz>
    </bar>
    <baz>tag</baz>
</foo>""""""

DEF_RESULT_EXPECTED = {
    ""foo"": [
        {""bar"": [{""baz"": None}, {""baz"": ""slim.shady""}]},
        {""baz"": ""tag""},
    ],
}


@pytest.mark.parametrize(
    ""result"",
    [
        DEF_RESULT_ENCODING,
        DEF_RESULT_ENCODING[DEF_RESULT_ENCODING.find(""\n"") :],
        f""""""
```xml
{DEF_RESULT_ENCODING}
```
"""""",
        f""""""
Some random text
```xml
{DEF_RESULT_ENCODING}
```
More random text
"""""",
    ],
)
def test_xml_output_parser(result: str) -> None:
    """"""Test XMLOutputParser.""""""

    xml_parser = XMLOutputParser()

    xml_result = xml_parser.parse(result)
    assert DEF_RESULT_EXPECTED == xml_result
    assert list(xml_parser.transform(iter(result))) == [
        {""foo"": [{""bar"": [{""baz"": None}]}]},
        {""foo"": [{""bar"": [{""baz"": ""slim.shady""}]}]},
        {""foo"": [{""baz"": ""tag""}]},
    ]


@pytest.mark.parametrize(""result"", [""foo></foo>"", ""<foo></foo"", ""foo></foo"", ""foofoo""])
def test_xml_output_parser_fail(result: str) -> None:
    """"""Test XMLOutputParser where complete output is not in XML format.""""""

    xml_parser = XMLOutputParser()

    with pytest.raises(OutputParserException) as e:
        xml_parser.parse(result)
    assert ""Failed to parse"" in str(e)
",CWE-776,66.0,1
"import warnings

from flask import Blueprint

with warnings.catch_warnings():
    warnings.filterwarnings(
        ""ignore"",
        (
            ""\nThe dash_html_components package is deprecated. Please replace""
            ""\n`import dash_html_components as html` with `from dash import html`""
        ),
    )
    warnings.filterwarnings(""ignore"", module=""matplotlib\\..*"")  # noqa: W605

    dtale = Blueprint(""dtale"", __name__, url_prefix=""/dtale"")

    ALLOW_CELL_EDITS = True
    HIDE_SHUTDOWN = False
    GITHUB_FORK = False
    HIDE_HEADER_EDITOR = False
    LOCK_HEADER_MENU = False
    HIDE_HEADER_MENU = False
    HIDE_MAIN_MENU = False
    HIDE_COLUMN_MENUS = False
    ENABLE_CUSTOM_FILTERS = False

    # flake8: NOQA
    from dtale.app import show, get_instance, instances, offline_chart  # isort:skip
    from dtale.cli.loaders import LOADERS  # isort:skip
    from dtale.cli.clickutils import retrieve_meta_info_and_version
    from dtale.global_state import update_id  # isort:skip

    for loader_name, loader in LOADERS.items():
        if hasattr(loader, ""show_loader""):
            globals()[""show_{}"".format(loader_name)] = loader.show_loader

    __version__ = retrieve_meta_info_and_version(""dtale"")[1]
",CWE-918,38.0,1
"import pandas as pd
import requests
import zipfile

from six import BytesIO


def covid():
    from dtale.cli.loaders.csv_loader import loader_func as load_csv

    data = load_csv(
        path=""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"",
        parse_dates=[""date""],
    )
    codes = load_csv(
        path=""https://raw.githubusercontent.com/jasonong/List-of-US-States/master/states.csv""
    )
    codes = codes.set_index(""State"").to_dict()[""Abbreviation""]
    data[""state_code""] = data[""state""].map(codes)
    return data, None


def seinfeld():
    from dtale.cli.loaders.csv_loader import loader_func as load_csv

    episodes = load_csv(
        path=""https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/episode_info.csv""
    )
    episodes = episodes[[c for c in episodes.columns if c not in [""Unnamed: 0""]]]
    scripts = load_csv(
        path=""https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/scripts.csv""
    )
    scripts = scripts[
        [c for c in scripts.columns if c not in [""Unnamed: 0"", ""Season"", ""EpisodeNo""]]
    ]
    return pd.merge(episodes, scripts, how=""inner"", on=""SEID""), None


def load_zip(url):
    response = requests.get(url)
    with zipfile.ZipFile(BytesIO(response.content)) as thezip:
        for zipinfo in thezip.infolist():
            yield zipinfo.filename, thezip.open(zipinfo.filename)


def simpsons():
    from dtale.cli.loaders.csv_loader import loader_func as load_csv
    import dtale.global_state as global_state

    global_state.set_app_settings(dict(max_column_width=100, max_row_height=100))
    episodes = load_csv(
        path=""https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_episodes.csv""
    )
    episodes = episodes.rename(columns={""id"": ""episode_id""})
    episodes.loc[:, ""image_url""] = episodes[""image_url""].apply(
        lambda x: ""<img src='{}' style='height: auto; width: 100px;' />"".format(x)
    )
    _, scripts = next(
        load_zip(
            ""https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_script_lines.csv.zip""
        )
    )
    scripts = pd.read_csv(scripts)
    df = pd.merge(episodes, scripts, how=""inner"", on=""episode_id"")
    formatting = {""image_url"": {""fmt"": {""html"": True}}}
    return df, {""columnFormats"": formatting}


def video_games():
    _, games = next(
        load_zip(
            ""https://github.com/aschonfeld/dtale-media/raw/master/datasets/vgsales.csv.zip""
        )
    )
    return pd.read_csv(games), None


def movies():
    _, movies = next(
        load_zip(
            ""https://github.com/aschonfeld/dtale-media/raw/master/datasets/IMDb_movies.csv.zip""
        )
    )
    movies = pd.read_csv(movies)
    movies.loc[:, ""year""] = (
        movies[""year""].where(~(movies[""year""] == ""TV Movie 2019""), ""2019"").astype(""int"")
    )
    return movies, None


def time_dataframe():
    try:
        from pandas._testing import makeTimeDataFrame

        return makeTimeDataFrame(), None
    except ImportError:
        from pandas.util.testing import makeTimeDataFrame

        return makeTimeDataFrame(), None
",CWE-918,100.0,1
"importlib-metadata<=3.7.3; python_version <= '3.6'
importlib-metadata; python_version != '3.6'
ipython<8.0.0
mock
nbconvert
pytest
pytest-cov
pytest-server-fixtures
",CWE-918,9.0,1
"from django_q import models as q_models
from rest_framework import serializers

from authentication.models import User
from automation.models import HttpAutomatedTest, PingAutomatedTest
from testing.models import TlsScanHistory

#
# Model: User
#


class UserInputLoginSerializer(serializers.ModelSerializer):
    username = serializers.CharField(max_length=200, required=True)
    password = serializers.CharField(max_length=200, required=True)

    class Meta:
        model = User
        fields = [
            ""username"",
            ""email"",
        ]


class UserSerializer(serializers.ModelSerializer):
    class Meta:
        model = User
        fields = [""id"", ""username"", ""company_name""]


class UserInputSerializer(serializers.ModelSerializer):
    username = serializers.CharField(max_length=200, required=True)
    email = serializers.CharField(max_length=200, required=True)
    password = serializers.CharField(max_length=200, required=True)
    company_name = serializers.CharField(max_length=200, required=True)
    address = serializers.CharField(max_length=200, required=True)
    post_code = serializers.CharField(max_length=200, required=True)
    city = serializers.CharField(max_length=200, required=True)
    vat_number = serializers.CharField(max_length=200, required=True)

    class Meta:
        model = User
        fields = [
            ""username"",
            ""email"",
            ""password"",
            ""company_name"",
            ""address"",
            ""post_code"",
            ""city"",
            ""vat_number"",
        ]


#
# Model: AutomatedTest
#
class AutomatedTestHTTPSerializer(serializers.ModelSerializer):
    class Meta:
        model = HttpAutomatedTest
        fields = [""frequency"", ""time"", ""weekday"", ""monthly_test_date""]


class AutomatedTestPingSerializer(serializers.ModelSerializer):
    class Meta:
        model = PingAutomatedTest
        fields = [""frequency"", ""time"", ""weekday"", ""monthly_test_date""]


#
# Model: TLS Scan History
#
class TlsScanHistorySerializer(serializers.ModelSerializer):
    class Meta:
        model = TlsScanHistory
        fields = [""scan_id"", ""domain""]


#
# Model: AutomatedTasks
#
class AutomatedSuccessSerializer(serializers.ModelSerializer):
    class Meta:
        model = q_models.Success
        fields = [""id"", ""name"", ""func"", ""args"", ""started"", ""stopped"", ""result""]


class AutomatedScheduledSerializer(serializers.ModelSerializer):
    class Meta:
        model = q_models.Schedule
        fields = [""id"", ""name"", ""func"", ""schedule_type"", ""next_run""]


class AutomatedFailedSerializer(serializers.ModelSerializer):
    class Meta:
        model = q_models.Failure
        fields = [""id"", ""name"", ""func"", ""started"", ""stopped""]


#
# InfraTesting
#
class FileSerializer(serializers.Serializer):
    file = serializers.FileField(help_text=""File to check."")

    class Meta:
        fields = [""file""]


class IPv6Serializer(serializers.Serializer):
    ip_v6 = serializers.CharField(
        max_length=200, required=True, help_text=""Domain name.""
    )

    class Meta:
        fields = [""ip_v6""]


class DomainNameSerializer(serializers.Serializer):
    domain_name = serializers.CharField(
        max_length=200, required=True, help_text=""Domain name.""
    )

    class Meta:
        fields = [""domain_name""]


class DomainNameAndServiceSerializer(serializers.Serializer):
    domain_name = serializers.CharField(
        max_length=200, required=True, help_text=""Domain name.""
    )
    service = serializers.ChoiceField(
        [(""web"", ""Web""), (""mail"", ""Email"")],
        required=True,
        help_text=""The service to be checked."",
    )

    class Meta:
        fields = [""domain_name"", ""service""]
",CWE-20,140.0,1
"[tool.poetry]
name = ""testing-platform""
version = ""0.1.0""
description = ""NC3 Testing Platform""
authors = [
    ""Romain Kieffer <romain.kieffer@nc3.lu>"",
    ""Philippe Parage <philippe.parage@nc3.lu>"",
    ""Cdric Bonhomme <cedric@cedricbonhomme.org>"",
]
license = ""AGPL-3.0-or-later""
readme = ""README.md""
packages = [{include = ""testing_platform""}]

homepage = ""https://github.com/NC3-LU/TestingPlatform""
repository = ""https://github.com/NC3-LU/TestingPlatform""
documentation = ""https://testingplatform.readthedocs.io""

keywords = [""test"", ""security"", ""internet-standard""]

[tool.poetry.dependencies]
python = "">=3.9,<4.0""
django = ""^4.1.7""
django-bootstrap5 = ""^22.1""
django-icons = ""^22.1""
django-widget-tweaks = "">=1.4.8,<1.5.0""
django-q = "">=1.3.9,<1.4.0""
python-decouple = "">=3.5,<4.0""
dj-database-url = "">=0.5.0,<0.6.0""
requests = ""^2.28.2""
pyjwt = "">=2.2.0,<2.5.0""
sgqlc = "">=14.1,<15.0""
croniter = "">=1.0.15,<1.1.0""
imap-tools = ""^0.57.0""
xmltodict = ""^0.13.0""
ipwhois = ""^1.2.0""
onekey-client = ""^2.0.2""
psutil = ""^5.9.4""
certifi = ""^2023.7.22""
django-enumfields = ""^2.1.1""
pypandora = ""^1.4.0""
checkdmarc = ""^4.5.2""
python3-nmap = ""^1.6.0""
python-owasp-zap-v2-4 = ""^0.0.21""
pycryptodome = ""^3.18.0""
pandas = ""^2.0.2""
djangorestframework = ""^3.14.0""
drf-spectacular = ""^0.26.4""
drf-spectacular-sidecar = ""^2023.7.1""
django-extensions = ""^3.2.3""
weasyprint = ""^60.1""
django-cors-headers = ""^4.3.0""
djangorestframework-simplejwt = ""^5.3.0""

[tool.poetry.group.dev.dependencies]
flake8 = ""^6.1.0""
pre-commit = ""^3.4.0""
black = ""^23.9.1""
pyupgrade = ""^3.14.0""
autoflake = ""^2.2.1""
mypy = ""^1.5.1""
types-requests = ""^2.31.0.7""
pip-audit = ""^2.6.1""
isort = ""^5.12.0""


[tool.poetry.group.docs]
optional = true

[tool.poetry.group.docs.dependencies]
sphinx-book-theme = ""^1.0.1""
sphinx-multiversion = ""^0.2.4""
sphinx-autodoc-typehints = ""^1.20.1""
sphinxcontrib-mermaid = ""^0.7.1""
sphinxcontrib-bibtex = ""^2.5.0""
sphinxcontrib-openapi = ""^0.8.1""
pydot = ""^1.4.2""

[build-system]
requires = [""poetry-core""]
build-backend = ""poetry.core.masonry.api""

[tool.mypy]
python_version = ""3.11""
check_untyped_defs = true
ignore_errors = false
ignore_missing_imports = true
strict_optional = true
no_implicit_optional = true
warn_unused_ignores = true
warn_redundant_casts = true
warn_unused_configs = true
warn_unreachable = true

show_error_context = true
pretty = true

exclude = ""migrations|docs""

[tool.isort]
profile = ""black""
",CWE-20,101.0,1
,CWE-20,,1
"from flask import Flask, json, request
from scripts.watch.process_single import process_single
from scripts.watch.filetypes import ACCEPTED_MIMES
api = Flask(__name__)

WATCH_DIRECTORY = ""hotdir""
@api.route('/process', methods=['POST'])
def process_file():
  content = request.json
  target_filename = content.get('filename')
  print(f""Processing {target_filename}"")
  success, reason = process_single(WATCH_DIRECTORY, target_filename)
  return json.dumps({'filename': target_filename, 'success': success, 'reason': reason})

@api.route('/accepts', methods=['GET'])
def get_accepted_filetypes():
  return json.dumps(ACCEPTED_MIMES)

@api.route('/', methods=['GET'])
def root():
  return ""<p>Use POST /process with filename key in JSON body in order to process a file. File by that name must exist in hotdir already.</p>""",CWE-20,21.0,1
"from django.contrib.sites.shortcuts import get_current_site
from django.shortcuts import render
from django.template import loader
from django.http import HttpResponseRedirect
from .models import Employee, OTP
from .forms import *
from django.views.decorators.csrf import csrf_exempt  # To Disable CSRF
from django.contrib.auth import authenticate, login, logout
from django.urls import reverse
from django.contrib import messages
from django.contrib.auth.decorators import login_required
from django.core.mail import EmailMessage
from django.contrib.auth.forms import PasswordResetForm
import logging
from django.conf import settings
from .email import send_forget_password_OTP
from threading import Thread

# Get an instance of a logger
logger = logging.getLogger(__name__)



def loginForm(request, next=''):
    # if this is a POST request we need to process the form data
    if request.method == 'POST':
        # create a form instance and populate it with data from the request:
        form = Login_Form(request.POST)
        # check whether it's valid:
        if form.is_valid():
            username = request.POST.get('username')
            password = request.POST.get('password')
            user = user = authenticate(username=username, password=password)
            if user and user.is_active:
                login(request, user)
                if 'next' in request.POST:
                    return HttpResponseRedirect(request.POST.get('next'))
                else:
                    return HttpResponseRedirect(reverse('CalendarinhoApp:Dashboard'))
            else:
                messages.error(request, ""Invalid login details given"")
                form = Login_Form()
                return render(request, 'CalendarinhoApp/login.html', {'form': form})

    # if a GET (or any other method) we'll create a blank form
    else:
        form = Login_Form()
        return render(request, 'CalendarinhoApp/login.html', {'form': form})


@login_required
def logout_view(request):
    logout(request)
    return HttpResponseRedirect(reverse('CalendarinhoApp:login'))

def reset_password(email, from_email,
        template='CalendarinhoApp/emails/new_user_password_reset_email.html'):
    """"""
    Reset the password for an (active) user with given E-Mail address
    """"""
    form = PasswordResetForm({'email': email})
    if form.is_valid():
        return form.save(from_email=from_email, html_email_template_name=template,email_template_name=template, domain_override=settings.DOMAIN, use_https=settings.USE_HTTPS)


def forgetPasswordInit(request):
    form = passwordforgetInitForm()
    return render(request,""CalendarinhoApp/forgetpasswordInit.html"",{""form"": form})

def forgetpasswordOTP(request):
    if (request.method == 'POST'):
        #A thread to send an email in the background. Otherwise we will have an email enumeration using time-based attack.
        thread = Thread(target = send_forget_password_OTP, args= (request,))
        thread.start()
        form = passwordforgetEndForm()
        emp_mail = request.POST.get(""email"")
        return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def forgetpasswordEnd(request):
    if (request.method == 'POST'):
        emp_mail = request.POST.get(""emp_mail"")
        form = passwordforgetEndForm(request.POST)

        fromDatabase = OTP.objects.filter(Email=emp_mail).first()
        if(not fromDatabase):
            messages.error(request, ""Something is Wrong!"")
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})

        if(fromDatabase.OTP == request.POST.get(""OTP"") and int(fromDatabase.Tries) <= 5 and fromDatabase.now_diff() < 300):
            if form.is_valid():
                emp = Employee.objects.filter(email=emp_mail).first()
                emp.set_password(request.POST.get(""new_Password""))
                emp.save()

                fromDatabase.delete()


                notifyAfterPasswordReset(emp)

                messages.success(request, ""Password Changed Successfully!"")
                Login_form = Login_Form()
                return render(request,""CalendarinhoApp/login.html"",{""form"":Login_form})
            else:
                return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
        else:
            messages.error(request, ""Something went wrong!"")

            #Increase number of tries:
            fromDatabase.Tries = str(int(fromDatabase.Tries)+1)

            fromDatabase.save()
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def notifyAfterPasswordReset(user):
    """"""Send email to the user after password reset.""""""

    context = {
                'username': user.username,
                'protocol': 'https' if settings.USE_HTTPS == True else 'http',
                'domain' : settings.DOMAIN,
            }
    email_body = loader.render_to_string(
            'CalendarinhoApp/emails/password_reset_complete_email.html', context)
    email = EmailMessage('Calendarinho password reset', email_body, to=[user.email])
    email.content_subtype = ""html""
    try:
        thread = Thread(target = email.send, args= ())
        thread.start()
    except ConnectionRefusedError as e:
        logger.error(""Failed to send emails: \n"" + str(e))",CWE-601,134.0,1
"from django.contrib.sites.shortcuts import get_current_site
from django.shortcuts import render
from django.template import loader
from django.http import HttpResponseRedirect
from .models import Employee, OTP
from .forms import *
from django.views.decorators.csrf import csrf_exempt  # To Disable CSRF
from django.contrib.auth import authenticate, login, logout
from django.urls import reverse
from django.contrib import messages
from django.contrib.auth.decorators import login_required
from django.core.mail import EmailMessage
from django.contrib.auth.forms import PasswordResetForm
import logging
from django.conf import settings
from .email import send_forget_password_OTP
from threading import Thread

# Get an instance of a logger
logger = logging.getLogger(__name__)



def loginForm(request, next=''):
    # if this is a POST request we need to process the form data
    if request.method == 'POST':
        # create a form instance and populate it with data from the request:
        form = Login_Form(request.POST)
        # check whether it's valid:
        if form.is_valid():
            username = request.POST.get('username')
            password = request.POST.get('password')
            user = user = authenticate(username=username, password=password)
            if user and user.is_active:
                login(request, user)
                next_url = request.POST.get('next', '')
                if next_url and next_url.startswith('/'):
                    return HttpResponseRedirect(next_url)
                else:
                    return HttpResponseRedirect(reverse('CalendarinhoApp:Dashboard'))
            else:
                messages.error(request, ""Invalid login details given"")
                form = Login_Form()
                return render(request, 'CalendarinhoApp/login.html', {'form': form})

    # if a GET (or any other method) we'll create a blank form
    else:
        form = Login_Form()
        return render(request, 'CalendarinhoApp/login.html', {'form': form})


@login_required
def logout_view(request):
    logout(request)
    return HttpResponseRedirect(reverse('CalendarinhoApp:login'))

def reset_password(email, from_email,
        template='CalendarinhoApp/emails/new_user_password_reset_email.html'):
    """"""
    Reset the password for an (active) user with given E-Mail address
    """"""
    form = PasswordResetForm({'email': email})
    if form.is_valid():
        return form.save(from_email=from_email, html_email_template_name=template,email_template_name=template, domain_override=settings.DOMAIN, use_https=settings.USE_HTTPS)


def forgetPasswordInit(request):
    form = passwordforgetInitForm()
    return render(request,""CalendarinhoApp/forgetpasswordInit.html"",{""form"": form})

def forgetpasswordOTP(request):
    if (request.method == 'POST'):
        #A thread to send an email in the background. Otherwise we will have an email enumeration using time-based attack.
        thread = Thread(target = send_forget_password_OTP, args= (request,))
        thread.start()
        form = passwordforgetEndForm()
        emp_mail = request.POST.get(""email"")
        return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def forgetpasswordEnd(request):
    if (request.method == 'POST'):
        emp_mail = request.POST.get(""emp_mail"")
        form = passwordforgetEndForm(request.POST)

        fromDatabase = OTP.objects.filter(Email=emp_mail).first()
        if(not fromDatabase):
            messages.error(request, ""Something is Wrong!"")
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})

        if(fromDatabase.OTP == request.POST.get(""OTP"") and int(fromDatabase.Tries) <= 5 and fromDatabase.now_diff() < 300):
            if form.is_valid():
                emp = Employee.objects.filter(email=emp_mail).first()
                emp.set_password(request.POST.get(""new_Password""))
                emp.save()

                fromDatabase.delete()


                notifyAfterPasswordReset(emp)

                messages.success(request, ""Password Changed Successfully!"")
                Login_form = Login_Form()
                return render(request,""CalendarinhoApp/login.html"",{""form"":Login_form})
            else:
                return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
        else:
            messages.error(request, ""Something went wrong!"")

            #Increase number of tries:
            fromDatabase.Tries = str(int(fromDatabase.Tries)+1)

            fromDatabase.save()
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def notifyAfterPasswordReset(user):
    """"""Send email to the user after password reset.""""""

    context = {
                'username': user.username,
                'protocol': 'https' if settings.USE_HTTPS == True else 'http',
                'domain' : settings.DOMAIN,
            }
    email_body = loader.render_to_string(
            'CalendarinhoApp/emails/password_reset_complete_email.html', context)
    email = EmailMessage('Calendarinho password reset', email_body, to=[user.email])
    email.content_subtype = ""html""
    try:
        thread = Thread(target = email.send, args= ())
        thread.start()
    except ConnectionRefusedError as e:
        logger.error(""Failed to send emails: \n"" + str(e))",CWE-601,135.0,1
"from django.contrib.sites.shortcuts import get_current_site
from django.shortcuts import render
from django.template import loader
from django.http import HttpResponseRedirect
from .models import Employee, OTP
from .forms import *
from django.views.decorators.csrf import csrf_exempt  # To Disable CSRF
from django.contrib.auth import authenticate, login, logout
from django.urls import reverse
from django.contrib import messages
from django.contrib.auth.decorators import login_required
from django.core.mail import EmailMessage
from django.contrib.auth.forms import PasswordResetForm
from django.utils.http import url_has_allowed_host_and_scheme
import logging
from django.conf import settings
from .email import send_forget_password_OTP
from threading import Thread

# Get an instance of a logger
logger = logging.getLogger(__name__)



def loginForm(request, next=''):
    # if this is a POST request we need to process the form data
    if request.method == 'POST':
        # create a form instance and populate it with data from the request:
        form = Login_Form(request.POST)
        # check whether it's valid:
        if form.is_valid():
            username = request.POST.get('username')
            password = request.POST.get('password')
            user = user = authenticate(username=username, password=password)
            if user and user.is_active:
                login(request, user)
                next_url = request.POST.get('next', '')
                if (next_url and url_has_allowed_host_and_scheme(next_url, settings.ALLOWED_HOSTS)):
                    print(""Good People"")
                    return HttpResponseRedirect(next_url)
                else:
                    print(""fucking bad shit"")
                    return HttpResponseRedirect(reverse('CalendarinhoApp:Dashboard'))
            else:
                messages.error(request, ""Invalid login details given"")
                form = Login_Form()
                return render(request, 'CalendarinhoApp/login.html', {'form': form})

    # if a GET (or any other method) we'll create a blank form
    else:
        form = Login_Form()
        return render(request, 'CalendarinhoApp/login.html', {'form': form})


@login_required
def logout_view(request):
    logout(request)
    return HttpResponseRedirect(reverse('CalendarinhoApp:login'))

def reset_password(email, from_email,
        template='CalendarinhoApp/emails/new_user_password_reset_email.html'):
    """"""
    Reset the password for an (active) user with given E-Mail address
    """"""
    form = PasswordResetForm({'email': email})
    if form.is_valid():
        return form.save(from_email=from_email, html_email_template_name=template,email_template_name=template, domain_override=settings.DOMAIN, use_https=settings.USE_HTTPS)


def forgetPasswordInit(request):
    form = passwordforgetInitForm()
    return render(request,""CalendarinhoApp/forgetpasswordInit.html"",{""form"": form})

def forgetpasswordOTP(request):
    if (request.method == 'POST'):
        #A thread to send an email in the background. Otherwise we will have an email enumeration using time-based attack.
        thread = Thread(target = send_forget_password_OTP, args= (request,))
        thread.start()
        form = passwordforgetEndForm()
        emp_mail = request.POST.get(""email"")
        return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def forgetpasswordEnd(request):
    if (request.method == 'POST'):
        emp_mail = request.POST.get(""emp_mail"")
        form = passwordforgetEndForm(request.POST)

        fromDatabase = OTP.objects.filter(Email=emp_mail).first()
        if(not fromDatabase):
            messages.error(request, ""Something is Wrong!"")
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})

        if(fromDatabase.OTP == request.POST.get(""OTP"") and int(fromDatabase.Tries) <= 5 and fromDatabase.now_diff() < 300):
            if form.is_valid():
                emp = Employee.objects.filter(email=emp_mail).first()
                emp.set_password(request.POST.get(""new_Password""))
                emp.save()

                fromDatabase.delete()


                notifyAfterPasswordReset(emp)

                messages.success(request, ""Password Changed Successfully!"")
                Login_form = Login_Form()
                return render(request,""CalendarinhoApp/login.html"",{""form"":Login_form})
            else:
                return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
        else:
            messages.error(request, ""Something went wrong!"")

            #Increase number of tries:
            fromDatabase.Tries = str(int(fromDatabase.Tries)+1)

            fromDatabase.save()
            return render(request,""CalendarinhoApp/forgetpasswordOTP.html"",{""form"":form,""emp_mail"":emp_mail})
    else:
        return HttpResponseRedirect(""/login/"")

def notifyAfterPasswordReset(user):
    """"""Send email to the user after password reset.""""""

    context = {
                'username': user.username,
                'protocol': 'https' if settings.USE_HTTPS == True else 'http',
                'domain' : settings.DOMAIN,
            }
    email_body = loader.render_to_string(
            'CalendarinhoApp/emails/password_reset_complete_email.html', context)
    email = EmailMessage('Calendarinho password reset', email_body, to=[user.email])
    email.content_subtype = ""html""
    try:
        thread = Thread(target = email.send, args= ())
        thread.start()
    except ConnectionRefusedError as e:
        logger.error(""Failed to send emails: \n"" + str(e))",CWE-601,138.0,1
"from yaml import load
from yaml import YAMLError

try:
    from yaml import CLoader as Loader
except ImportError:
    from yaml import Loader

SETTINGS_FILE = ""settings.yaml""
SETTINGS_STRUCT = {
    ""client_config_backend"": {
        ""type"": str,
        ""required"": True,
        ""default"": ""file"",
        ""dependency"": [
            {""value"": ""file"", ""attribute"": [""client_config_file""]},
            {""value"": ""settings"", ""attribute"": [""client_config""]},
            {""value"": ""service"", ""attribute"": [""service_config""]},
        ],
    },
    ""save_credentials"": {
        ""type"": bool,
        ""required"": True,
        ""default"": False,
        ""dependency"": [
            {""value"": True, ""attribute"": [""save_credentials_backend""]}
        ],
    },
    ""get_refresh_token"": {""type"": bool, ""required"": False, ""default"": False},
    ""client_config_file"": {
        ""type"": str,
        ""required"": False,
        ""default"": ""client_secrets.json"",
    },
    ""save_credentials_backend"": {
        ""type"": str,
        ""required"": False,
        ""dependency"": [
            {""value"": ""file"", ""attribute"": [""save_credentials_file""]},
            {""value"": ""dictionary"", ""attribute"": [""save_credentials_dict""]},
            {""value"": ""dictionary"", ""attribute"": [""save_credentials_key""]},
        ],
    },
    ""client_config"": {
        ""type"": dict,
        ""required"": False,
        ""struct"": {
            ""client_id"": {""type"": str, ""required"": True},
            ""client_secret"": {""type"": str, ""required"": True},
            ""auth_uri"": {
                ""type"": str,
                ""required"": True,
                ""default"": ""https://accounts.google.com/o/oauth2/auth"",
            },
            ""token_uri"": {
                ""type"": str,
                ""required"": True,
                ""default"": ""https://accounts.google.com/o/oauth2/token"",
            },
            ""redirect_uri"": {
                ""type"": str,
                ""required"": True,
                ""default"": ""urn:ietf:wg:oauth:2.0:oob"",
            },
            ""revoke_uri"": {""type"": str, ""required"": True, ""default"": None},
        },
    },
    ""service_config"": {
        ""type"": dict,
        ""required"": False,
        ""struct"": {
            ""client_user_email"": {
                ""type"": str,
                ""required"": True,
                ""default"": None,
            },
            ""client_service_email"": {""type"": str, ""required"": False},
            ""client_pkcs12_file_path"": {""type"": str, ""required"": False},
            ""client_json_file_path"": {""type"": str, ""required"": False},
            ""client_json_dict"": {
                ""type"": dict,
                ""required"": False,
                ""struct"": {},
            },
            ""client_json"": {""type"": str, ""required"": False},
        },
    },
    ""oauth_scope"": {
        ""type"": list,
        ""required"": True,
        ""struct"": str,
        ""default"": [""https://www.googleapis.com/auth/drive""],
    },
    ""save_credentials_file"": {""type"": str, ""required"": False},
    ""save_credentials_dict"": {""type"": dict, ""required"": False, ""struct"": {}},
    ""save_credentials_key"": {""type"": str, ""required"": False},
}


class SettingsError(IOError):
    """"""Error while loading/saving settings""""""


class InvalidConfigError(IOError):
    """"""Error trying to read client configuration.""""""


def LoadSettingsFile(filename=SETTINGS_FILE):
    """"""Loads settings file in yaml format given file name.

    :param filename: path for settings file. 'settings.yaml' by default.
    :type filename: str.
    :raises: SettingsError
    """"""
    try:
        with open(filename) as stream:
            data = load(stream, Loader=Loader)
    except (YAMLError, OSError) as e:
        raise SettingsError(e)
    return data


def ValidateSettings(data):
    """"""Validates if current settings is valid.

    :param data: dictionary containing all settings.
    :type data: dict.
    :raises: InvalidConfigError
    """"""
    _ValidateSettingsStruct(data, SETTINGS_STRUCT)


def _ValidateSettingsStruct(data, struct):
    """"""Validates if provided data fits provided structure.

    :param data: dictionary containing settings.
    :type data: dict.
    :param struct: dictionary containing structure information of settings.
    :type struct: dict.
    :raises: InvalidConfigError
    """"""
    # Validate required elements of the setting.
    for key in struct:
        if struct[key][""required""]:
            _ValidateSettingsElement(data, struct, key)


def _ValidateSettingsElement(data, struct, key):
    """"""Validates if provided element of settings data fits provided structure.

    :param data: dictionary containing settings.
    :type data: dict.
    :param struct: dictionary containing structure information of settings.
    :type struct: dict.
    :param key: key of the settings element to validate.
    :type key: str.
    :raises: InvalidConfigError
    """"""
    # Check if data exists. If not, check if default value exists.
    value = data.get(key)
    data_type = struct[key][""type""]
    if value is None:
        try:
            default = struct[key][""default""]
        except KeyError:
            raise InvalidConfigError(""Missing required setting %s"" % key)
        else:
            data[key] = default
    # If data exists, Check type of the data
    elif not isinstance(value, data_type):
        raise InvalidConfigError(f""Setting {key} should be type {data_type}"")
    # If type of this data is dict, check if structure of the data is valid.
    if data_type is dict:
        _ValidateSettingsStruct(data[key], struct[key][""struct""])
    # If type of this data is list, check if all values in the list is valid.
    elif data_type is list:
        for element in data[key]:
            if not isinstance(element, struct[key][""struct""]):
                raise InvalidConfigError(
                    ""Setting %s should be list of %s""
                    % (key, struct[key][""struct""])
                )
    # Check dependency of this attribute.
    dependencies = struct[key].get(""dependency"")
    if dependencies:
        for dependency in dependencies:
            if value == dependency[""value""]:
                for reqkey in dependency[""attribute""]:
                    _ValidateSettingsElement(data, struct, reqkey)
",CWE-502,190.0,1
"# coding=utf-8

import os
import requests
import mimetypes

from flask import request, abort, render_template, Response, session, send_file, stream_with_context, Blueprint
from functools import wraps
from urllib.parse import unquote

from constants import headers
from sonarr.info import get_sonarr_info, url_sonarr
from radarr.info import get_radarr_info, url_radarr
from utilities.helper import check_credentials

from .config import settings, base_url
from .database import System
from .get_args import args

ui_bp = Blueprint('ui', __name__,
                  template_folder=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                                               'frontend', 'build'),
                  static_folder=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend',
                                             'build', 'assets'),
                  static_url_path='/assets')

if os.path.exists(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'build',
                               'images')):
    static_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'build',
                                    'images')
else:
    static_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'public',
                                    'images')
static_bp = Blueprint('images', __name__, static_folder=static_directory, static_url_path='/images')

ui_bp.register_blueprint(static_bp)


mimetypes.add_type('application/javascript', '.js')
mimetypes.add_type('text/css', '.css')
mimetypes.add_type('font/woff2', '.woff2')
mimetypes.add_type('image/svg+xml', '.svg')
mimetypes.add_type('image/png', '.png')
mimetypes.add_type('image/x-icon', '.ico')


def check_login(actual_method):
    @wraps(actual_method)
    def wrapper(*args, **kwargs):
        if settings.auth.type == 'basic':
            auth = request.authorization
            if not (auth and
                    check_credentials(request.authorization.username, request.authorization.password, request)):
                return ('Unauthorized', 401, {
                    'WWW-Authenticate': 'Basic realm=""Login Required""'
                })
        elif settings.auth.type == 'form':
            if 'logged_in' not in session:
                return abort(401, message=""Unauthorized"")
        actual_method(*args, **kwargs)


@ui_bp.route('/', defaults={'path': ''})
@ui_bp.route('/<path:path>')
def catch_all(path):
    auth = True
    if settings.auth.type == 'basic':
        auth = request.authorization
        if not (auth and check_credentials(request.authorization.username, request.authorization.password, request,
                                           log_success=False)):
            return ('Unauthorized', 401, {
                'WWW-Authenticate': 'Basic realm=""Login Required""'
            })
    elif settings.auth.type == 'form':
        if 'logged_in' not in session or not session['logged_in']:
            auth = False

    try:
        updated = System.get().updated
    except Exception:
        updated = '0'

    inject = dict()

    if not path.startswith('api/'):
        inject[""baseUrl""] = base_url
        inject[""canUpdate""] = not args.no_update
        inject[""hasUpdate""] = updated != '0'

        if auth:
            inject[""apiKey""] = settings.auth.apikey

    template_url = base_url
    if not template_url.endswith(""/""):
        template_url += ""/""

    return render_template(""index.html"", BAZARR_SERVER_INJECT=inject, baseUrl=template_url)


@check_login
@ui_bp.route('/bazarr.log')
def download_log():
    return send_file(os.path.join(args.config_dir, 'log', 'bazarr.log'), max_age=0, as_attachment=True)


@check_login
@ui_bp.route('/images/series/<path:url>', methods=['GET'])
def series_images(url):
    url = url.strip(""/"")
    apikey = settings.sonarr.apikey
    baseUrl = settings.sonarr.base_url
    if get_sonarr_info.is_legacy():
        url_image = (url_sonarr() + '/api/' + url.lstrip(baseUrl) + '?apikey=' +
                     apikey).replace('poster-250', 'poster-500')
    else:
        url_image = (url_sonarr() + '/api/v3/' + url.lstrip(baseUrl) + '?apikey=' +
                     apikey).replace('poster-250', 'poster-500')
    try:
        req = requests.get(url_image, stream=True, timeout=15, verify=False, headers=headers)
    except Exception:
        return '', 404
    else:
        return Response(stream_with_context(req.iter_content(2048)), content_type=req.headers['content-type'])


@check_login
@ui_bp.route('/images/movies/<path:url>', methods=['GET'])
def movies_images(url):
    apikey = settings.radarr.apikey
    baseUrl = settings.radarr.base_url
    if get_radarr_info.is_legacy():
        url_image = url_radarr() + '/api/' + url.lstrip(baseUrl) + '?apikey=' + apikey
    else:
        url_image = url_radarr() + '/api/v3/' + url.lstrip(baseUrl) + '?apikey=' + apikey
    try:
        req = requests.get(url_image, stream=True, timeout=15, verify=False, headers=headers)
    except Exception:
        return '', 404
    else:
        return Response(stream_with_context(req.iter_content(2048)), content_type=req.headers['content-type'])


@check_login
@ui_bp.route('/system/backup/download/<path:filename>', methods=['GET'])
def backup_download(filename):
    return send_file(os.path.join(settings.backup.folder, filename), max_age=0, as_attachment=True)


@ui_bp.route('/api/swaggerui/static/<path:filename>', methods=['GET'])
def swaggerui_static(filename):
    return send_file(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'libs', 'flask_restx',
                     'static', filename))


def configured():
    System.update({System.configured: '1'}).execute()


@check_login
@ui_bp.route('/test', methods=['GET'])
@ui_bp.route('/test/<protocol>/<path:url>', methods=['GET'])
def proxy(protocol, url):
    url = protocol + '://' + unquote(url)
    params = request.args
    try:
        result = requests.get(url, params, allow_redirects=False, verify=False, timeout=5, headers=headers)
    except Exception as e:
        return dict(status=False, error=repr(e))
    else:
        if result.status_code == 200:
            try:
                version = result.json()['version']
                return dict(status=True, version=version)
            except Exception:
                return dict(status=False, error='Error Occurred. Check your settings.')
        elif result.status_code == 401:
            return dict(status=False, error='Access Denied. Check API key.')
        elif result.status_code == 404:
            return dict(status=False, error='Cannot get version. Maybe unsupported legacy API call?')
        elif 300 <= result.status_code <= 399:
            return dict(status=False, error='Wrong URL Base.')
        else:
            return dict(status=False, error=result.raise_for_status())
",CWE-22,184.0,1
"# coding=utf-8

import os
import requests
import mimetypes

from flask import request, abort, render_template, Response, session, send_file, stream_with_context, Blueprint
from functools import wraps
from urllib.parse import unquote

from constants import headers
from sonarr.info import get_sonarr_info, url_sonarr
from radarr.info import get_radarr_info, url_radarr
from utilities.helper import check_credentials

from .config import settings, base_url
from .database import System
from .get_args import args

ui_bp = Blueprint('ui', __name__,
                  template_folder=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                                               'frontend', 'build'),
                  static_folder=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend',
                                             'build', 'assets'),
                  static_url_path='/assets')

if os.path.exists(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'build',
                               'images')):
    static_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'build',
                                    'images')
else:
    static_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'frontend', 'public',
                                    'images')
static_bp = Blueprint('images', __name__, static_folder=static_directory, static_url_path='/images')

ui_bp.register_blueprint(static_bp)


mimetypes.add_type('application/javascript', '.js')
mimetypes.add_type('text/css', '.css')
mimetypes.add_type('font/woff2', '.woff2')
mimetypes.add_type('image/svg+xml', '.svg')
mimetypes.add_type('image/png', '.png')
mimetypes.add_type('image/x-icon', '.ico')


def check_login(actual_method):
    @wraps(actual_method)
    def wrapper(*args, **kwargs):
        if settings.auth.type == 'basic':
            auth = request.authorization
            if not (auth and
                    check_credentials(request.authorization.username, request.authorization.password, request)):
                return ('Unauthorized', 401, {
                    'WWW-Authenticate': 'Basic realm=""Login Required""'
                })
        elif settings.auth.type == 'form':
            if 'logged_in' not in session:
                return abort(401, message=""Unauthorized"")
        actual_method(*args, **kwargs)


@ui_bp.route('/', defaults={'path': ''})
@ui_bp.route('/<path:path>')
def catch_all(path):
    auth = True
    if settings.auth.type == 'basic':
        auth = request.authorization
        if not (auth and check_credentials(request.authorization.username, request.authorization.password, request,
                                           log_success=False)):
            return ('Unauthorized', 401, {
                'WWW-Authenticate': 'Basic realm=""Login Required""'
            })
    elif settings.auth.type == 'form':
        if 'logged_in' not in session or not session['logged_in']:
            auth = False

    try:
        updated = System.get().updated
    except Exception:
        updated = '0'

    inject = dict()

    if not path.startswith('api/'):
        inject[""baseUrl""] = base_url
        inject[""canUpdate""] = not args.no_update
        inject[""hasUpdate""] = updated != '0'

        if auth:
            inject[""apiKey""] = settings.auth.apikey

    template_url = base_url
    if not template_url.endswith(""/""):
        template_url += ""/""

    return render_template(""index.html"", BAZARR_SERVER_INJECT=inject, baseUrl=template_url)


@check_login
@ui_bp.route('/bazarr.log')
def download_log():
    return send_file(os.path.join(args.config_dir, 'log', 'bazarr.log'), max_age=0, as_attachment=True)


@check_login
@ui_bp.route('/images/series/<path:url>', methods=['GET'])
def series_images(url):
    url = url.strip(""/"")
    apikey = settings.sonarr.apikey
    baseUrl = settings.sonarr.base_url
    if get_sonarr_info.is_legacy():
        url_image = (url_sonarr() + '/api/' + url.lstrip(baseUrl) + '?apikey=' +
                     apikey).replace('poster-250', 'poster-500')
    else:
        url_image = (url_sonarr() + '/api/v3/' + url.lstrip(baseUrl) + '?apikey=' +
                     apikey).replace('poster-250', 'poster-500')
    try:
        req = requests.get(url_image, stream=True, timeout=15, verify=False, headers=headers)
    except Exception:
        return '', 404
    else:
        return Response(stream_with_context(req.iter_content(2048)), content_type=req.headers['content-type'])


@check_login
@ui_bp.route('/images/movies/<path:url>', methods=['GET'])
def movies_images(url):
    apikey = settings.radarr.apikey
    baseUrl = settings.radarr.base_url
    if get_radarr_info.is_legacy():
        url_image = url_radarr() + '/api/' + url.lstrip(baseUrl) + '?apikey=' + apikey
    else:
        url_image = url_radarr() + '/api/v3/' + url.lstrip(baseUrl) + '?apikey=' + apikey
    try:
        req = requests.get(url_image, stream=True, timeout=15, verify=False, headers=headers)
    except Exception:
        return '', 404
    else:
        return Response(stream_with_context(req.iter_content(2048)), content_type=req.headers['content-type'])


@check_login
@ui_bp.route('/system/backup/download/<path:filename>', methods=['GET'])
def backup_download(filename):
    return send_file(os.path.join(settings.backup.folder, filename), max_age=0, as_attachment=True)


@ui_bp.route('/api/swaggerui/static/<path:filename>', methods=['GET'])
def swaggerui_static(filename):
    return send_file(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'libs', 'flask_restx',
                     'static', filename))


def configured():
    System.update({System.configured: '1'}).execute()


@check_login
@ui_bp.route('/test', methods=['GET'])
@ui_bp.route('/test/<protocol>/<path:url>', methods=['GET'])
def proxy(protocol, url):
    url = protocol + '://' + unquote(url)
    params = request.args
    try:
        result = requests.get(url, params, allow_redirects=False, verify=False, timeout=5, headers=headers)
    except Exception as e:
        return dict(status=False, error=repr(e))
    else:
        if result.status_code == 200:
            try:
                version = result.json()['version']
                return dict(status=True, version=version)
            except Exception:
                return dict(status=False, error='Error Occurred. Check your settings.')
        elif result.status_code == 401:
            return dict(status=False, error='Access Denied. Check API key.')
        elif result.status_code == 404:
            return dict(status=False, error='Cannot get version. Maybe unsupported legacy API call?')
        elif 300 <= result.status_code <= 399:
            return dict(status=False, error='Wrong URL Base.')
        else:
            return dict(status=False, error=result.raise_for_status())
",CWE-918,184.0,1
"from django.contrib.messages.views import SuccessMessageMixin
from django.http import Http404
from django.shortcuts import get_object_or_404
from django.urls import reverse, reverse_lazy
from django.utils.translation import gettext as _
from django.views.generic.base import RedirectView
from django.views.generic.edit import CreateView, UpdateView
from django.views.generic.list import ListView

from users.mixins import LoginRequiredMixin, ManagerPermMixin

from .forms import AdminTaskCommentForm, AdminTaskCreateForm, AdminTaskUpdateForm
from .models import AdminTask, AdminTaskComment


class MyAdminTasksListView(LoginRequiredMixin, ManagerPermMixin, ListView):
    template_name = ""admin_tasks_yours.html""
    paginate_by = 10

    def get_queryset(self):
        return AdminTask.objects.filter(assigned_to=self.request.user).select_related(
            ""new_hire"", ""assigned_to""
        )

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context[""title""] = ""Your tasks""
        context[""subtitle""] = ""Tasks""
        context[""add_action""] = reverse_lazy(""admin_tasks:create"")
        return context


class AllAdminTasksListView(LoginRequiredMixin, ManagerPermMixin, ListView):
    template_name = ""admin_tasks_all.html""
    paginate_by = 10

    def get_queryset(self):
        return AdminTask.objects.all().select_related(""new_hire"", ""assigned_to"")

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context[""title""] = ""All tasks""
        context[""subtitle""] = ""Tasks""
        context[""add_action""] = reverse_lazy(""admin_tasks:create"")
        return context


class AdminTaskToggleDoneView(LoginRequiredMixin, ManagerPermMixin, RedirectView):
    permanent = False
    pattern_name = ""admin_tasks:detail""

    def get(self, request, *args, **kwargs):
        task_id = self.kwargs.get(""pk"", -1)
        admin_task = get_object_or_404(AdminTask, id=task_id)
        admin_task.completed = not admin_task.completed
        admin_task.save()
        return super().get(request, *args, **kwargs)


class AdminTasksCreateView(
    LoginRequiredMixin, ManagerPermMixin, SuccessMessageMixin, CreateView
):
    template_name = ""admin_tasks_create.html""
    form_class = AdminTaskCreateForm
    model = AdminTask
    success_message = _(""Task has been created"")
    success_url = reverse_lazy(""admin_tasks:all"")

    def form_valid(self, form):
        self.object = form.save()
        AdminTaskComment.objects.create(
            admin_task=self.object,
            content=form.cleaned_data[""comment""],
            comment_by=self.request.user,
        )
        # Send message to person that got assigned to this
        if self.request.user.id != form.cleaned_data[""assigned_to""].id:
            self.object.send_notification_new_assigned()

        # Send notification based on extra notification option
        self.object.send_notification_third_party()
        return super().form_valid(form)

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context[""title""] = _(""New task"")
        context[""subtitle""] = _(""Tasks"")
        return context


class AdminTasksUpdateView(
    LoginRequiredMixin, ManagerPermMixin, SuccessMessageMixin, UpdateView
):
    template_name = ""admin_tasks_detail.html""
    form_class = AdminTaskUpdateForm
    model = AdminTask
    success_message = _(""Task has been updated"")

    def get_success_url(self):
        return self.request.path

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        task = get_object_or_404(AdminTask, pk=self.kwargs.get(""pk""))
        context[""object""] = task
        context[""title""] = _(""Task: %(name)s"") % {""name"": task.name}
        context[""subtitle""] = _(""Tasks"")
        context[""comment_form""] = AdminTaskCommentForm
        return context

    def form_valid(self, form):
        # send email/bot message to newly assigned person
        initial_assigned_to = AdminTask.objects.get(id=form.instance.id).assigned_to
        form.save()
        if (
            form.cleaned_data[""assigned_to""] != initial_assigned_to
            and form.cleaned_data[""assigned_to""] != self.request.user
        ):
            form.instance.send_notification_new_assigned()
        return super().form_valid(form)


class AdminTasksCommentCreateView(
    LoginRequiredMixin, ManagerPermMixin, SuccessMessageMixin, CreateView
):
    template_name = ""admin_tasks_detail.html""
    model = AdminTaskComment
    fields = [
        ""content"",
    ]
    success_message = _(""Comment has been posted"")

    def get_success_url(self):
        task = get_object_or_404(AdminTask, pk=self.kwargs.get(""pk""))
        return reverse(""admin_tasks:detail"", args=[task.id])

    def form_valid(self, form):
        task = get_object_or_404(AdminTask, pk=self.kwargs.get(""pk""))
        # Can't post comments when item is completed
        if task.completed:
            raise Http404
        form.instance.comment_by = self.request.user
        form.instance.admin_task = task
        item = form.save()
        item.send_notification_new_message()
        return super().form_valid(form)
",CWE-352,147.0,1
"import re
from typing import Any, Dict, List, Optional

import anyio
import httpx

from prefect._internal.pydantic import HAS_PYDANTIC_V2

if HAS_PYDANTIC_V2:
    import pydantic.v1 as pydantic
else:
    import pydantic

from prefect._vendor.starlette import status

import prefect.context
import prefect.settings
from prefect.client.base import PrefectHttpxClient
from prefect.client.schemas import Workspace
from prefect.exceptions import PrefectException
from prefect.settings import (
    PREFECT_API_KEY,
    PREFECT_CLOUD_API_URL,
    PREFECT_UNIT_TEST_MODE,
)

PARSE_API_URL_REGEX = re.compile(r""accounts/(.{36})/workspaces/(.{36})"")


def get_cloud_client(
    host: Optional[str] = None,
    api_key: Optional[str] = None,
    httpx_settings: Optional[dict] = None,
    infer_cloud_url: bool = False,
) -> ""CloudClient"":
    """"""
    Needs a docstring.
    """"""
    if httpx_settings is not None:
        httpx_settings = httpx_settings.copy()

    if infer_cloud_url is False:
        host = host or PREFECT_CLOUD_API_URL.value()
    else:
        configured_url = prefect.settings.PREFECT_API_URL.value()
        host = re.sub(PARSE_API_URL_REGEX, """", configured_url)

    return CloudClient(
        host=host,
        api_key=api_key or PREFECT_API_KEY.value(),
        httpx_settings=httpx_settings,
    )


class CloudUnauthorizedError(PrefectException):
    """"""
    Raised when the CloudClient receives a 401 or 403 from the Cloud API.
    """"""


class CloudClient:
    def __init__(
        self,
        host: str,
        api_key: str,
        httpx_settings: dict = None,
    ) -> None:
        httpx_settings = httpx_settings or dict()
        httpx_settings.setdefault(""headers"", dict())
        httpx_settings[""headers""].setdefault(""Authorization"", f""Bearer {api_key}"")

        httpx_settings.setdefault(""base_url"", host)
        if not PREFECT_UNIT_TEST_MODE.value():
            httpx_settings.setdefault(""follow_redirects"", True)
        self._client = PrefectHttpxClient(**httpx_settings)

    async def api_healthcheck(self):
        """"""
        Attempts to connect to the Cloud API and raises the encountered exception if not
        successful.

        If successful, returns `None`.
        """"""
        with anyio.fail_after(10):
            await self.read_workspaces()

    async def read_workspaces(self) -> List[Workspace]:
        return pydantic.parse_obj_as(List[Workspace], await self.get(""/me/workspaces""))

    async def read_worker_metadata(self) -> Dict[str, Any]:
        configured_url = prefect.settings.PREFECT_API_URL.value()
        account_id, workspace_id = re.findall(PARSE_API_URL_REGEX, configured_url)[0]
        return await self.get(
            f""accounts/{account_id}/workspaces/{workspace_id}/collections/work_pool_types""
        )

    async def __aenter__(self):
        await self._client.__aenter__()
        return self

    async def __aexit__(self, *exc_info):
        return await self._client.__aexit__(*exc_info)

    def __enter__(self):
        raise RuntimeError(
            ""The `CloudClient` must be entered with an async context. Use 'async ""
            ""with CloudClient(...)' not 'with CloudClient(...)'""
        )

    def __exit__(self, *_):
        assert False, ""This should never be called but must be defined for __enter__""

    async def get(self, route, **kwargs):
        return await self.request(""GET"", route, **kwargs)

    async def request(self, method, route, **kwargs):
        try:
            res = await self._client.request(method, route, **kwargs)
            res.raise_for_status()
        except httpx.HTTPStatusError as exc:
            if exc.response.status_code in (
                status.HTTP_401_UNAUTHORIZED,
                status.HTTP_403_FORBIDDEN,
            ):
                raise CloudUnauthorizedError
            else:
                raise exc

        if res.status_code == status.HTTP_204_NO_CONTENT:
            return

        return res.json()
",CWE-352,133.0,1
"# Test select.poll in combination with file descriptors.

try:
    import select, errno

    select.poll  # Raises AttributeError for CPython implementations without poll()
except (ImportError, AttributeError):
    print(""SKIP"")
    raise SystemExit

# Check that poll supports registering file descriptors (integers).
try:
    select.poll().register(0)
except OSError:
    print(""SKIP"")
    raise SystemExit

# Register invalid file descriptor.
try:
    select.poll().register(-1)
except ValueError:
    print(""ValueError"")

# Test polling stdout, it should be writable.
poller = select.poll()
poller.register(1)
poller.modify(1, select.POLLOUT)
print(poller.poll())

# Unregister then re-register.
poller.unregister(1)
poller.register(1, select.POLLIN)

# Poll for input, should return an empty list.
print(poller.poll(0))

# Test registering a very large number of file descriptors.
poller = select.poll()
for fd in range(6000):
    poller.register(fd)
try:
    poller.poll()
except OSError as er:
    print(er.errno == errno.EINVAL)
",CWE-416,45.0,1
,CWE-78,,1
"""""""
project: lollms_webui
file: chat_bar.py 
author: ParisNeo
description: 
    This module contains a set of FastAPI routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes are linked to lollms_webui chatbox

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from pydantic import BaseModel, Field
from lollms_webui import LOLLMSWebUI
from pydantic import BaseModel
from starlette.responses import StreamingResponse
from lollms.types import MSG_TYPE
from lollms.main_config import BaseConfig
from lollms.utilities import detect_antiprompt, remove_text_from_string, trace_exception, find_first_available_file_index
from ascii_colors import ASCIIColors
from lollms.databases.discussions_database import DiscussionsDB
from lollms.types import SENDER_TYPES
from typing import List
from pathlib import Path
from safe_store.text_vectorizer import TextVectorizer, VectorizationMethod, VisualizationMethod
import tqdm
from fastapi import FastAPI, UploadFile, File
import shutil
import os
import platform
from functools import partial
from datetime import datetime
from utilities.execution_engines.python_execution_engine import execute_python
from utilities.execution_engines.latex_execution_engine import execute_latex
from utilities.execution_engines.shell_execution_engine import execute_bash

from lollms.internet import scrape_and_save
import threading
# ----------------------- Defining router and main class ------------------------------

router = APIRouter()
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()

class AddWebPageRequest(BaseModel):
    client_id: str  = Field(...)
    url: str = Field(..., description=""Url to be used"")

class CmdExecutionRequest(BaseModel):
    client_id: str  = Field(...)
    command: str = Field(..., description=""Url to be used"")
    parameters: List



""""""
@router.post(""/execute_personality_command"")
async def execute_personality_command(request: CmdExecutionRequest):
    client_id = request.client_id
    client = lollmsElfServer.session.get_client(client_id)

    lollmsElfServer.cancel_gen = False
    client.generated_text=""""
    client.cancel_generation=False
    client.continuing=False
    client.first_chunk=True
    
    if not lollmsElfServer.model:
        ASCIIColors.error(""Model not selected. Please select a model"")
        lollmsElfServer.error(""Model not selected. Please select a model"", client_id=client_id)
        return {'status':False,""error"":""Model not selected. Please select a model""}

    if not lollmsElfServer.busy:
        if lollmsElfServer.session.get_client(client_id).discussion is None:
            if lollmsElfServer.db.does_last_discussion_have_messages():
                lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.create_discussion()
            else:
                lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.load_last_discussion()

        ump = lollmsElfServer.config.discussion_prompt_separator +lollmsElfServer.config.user_name.strip() if lollmsElfServer.config.use_user_name_in_discussions else lollmsElfServer.personality.user_message_prefix
        message = lollmsElfServer.session.get_client(client_id).discussion.add_message(
            message_type    = MSG_TYPE.MSG_TYPE_FULL.value,
            sender_type     = SENDER_TYPES.SENDER_TYPES_USER.value,
            sender          = ump.replace(lollmsElfServer.config.discussion_prompt_separator,"""").replace("":"",""""),
            content="""",
            metadata=None,
            parent_message_id=lollmsElfServer.message_id
        )
        lollmsElfServer.busy=True

        command = request.command
        parameters =  request.parameters
        lollmsElfServer.prepare_reception(client_id)
        if lollmsElfServer.personality.processor is not None:
            lollmsElfServer.start_time = datetime.now()
            lollmsElfServer.personality.processor.callback = partial(lollmsElfServer.process_chunk, client_id=client_id)
            lollmsElfServer.personality.processor.execute_command(command, parameters)
        else:
            lollmsElfServer.warning(""Non scripted personalities do not support commands"",client_id=client_id)
        lollmsElfServer.close_message(client_id)
        lollmsElfServer.busy=False

        #tpe = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message_id, client_id))
        #tpe.start()
    else:
        lollmsElfServer.error(""I am busy. Come back later."", client_id=client_id)
        return {'status':False,""error"":""I am busy. Come back later.""}

    lollmsElfServer.busy=False
    return {'status':True,}
""""""


@router.post(""/add_webpage"")
async def add_webpage(request: AddWebPageRequest):
    client = lollmsElfServer.session.get_client(request.client_id)
    if client is None:
        raise HTTPException(status_code=400, detail=""Unknown client. This service only accepts lollms webui requests"")
        
    def do_scraping():
        lollmsElfServer.ShowBlockingMessage(""Scraping web page\nPlease wait..."")
        ASCIIColors.yellow(""Scaping web page"")
        client = lollmsElfServer.session.get_client(request.client_id)
        url = request.url
        index =  find_first_available_file_index(lollmsElfServer.lollms_paths.personal_uploads_path,""web_"","".txt"")
        file_path=lollmsElfServer.lollms_paths.personal_uploads_path/f""web_{index}.txt""
        scrape_and_save(url=url, file_path=file_path)
        try:
            if not lollmsElfServer.personality.processor is None:
                lollmsElfServer.personality.processor.add_file(file_path, client, partial(lollmsElfServer.process_chunk, client_id = request.client_id))
                # File saved successfully
            else:
                lollmsElfServer.personality.add_file(file_path, client, partial(lollmsElfServer.process_chunk, client_id = request.client_id))
                # File saved successfully
            lollmsElfServer.HideBlockingMessage()
            lollmsElfServer.refresh_files()
        except Exception as e:
            # Error occurred while saving the file
            lollmsElfServer.HideBlockingMessage()
            lollmsElfServer.refresh_files()
            return {'status':False,""error"":str(e)}
    client.generation_thread = threading.Thread(target=do_scraping)
    client.generation_thread.start()
        
    return {'status':True}
",CWE-78,144.0,1
"""""""
project: lollms_message
file: lollms_discussion.py 
author: ParisNeo
description: 
    This module contains a set of FastAPI routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes allow users to manipulate the message elements.

""""""
from fastapi import APIRouter, Body, Request
from pydantic import Field
from lollms_webui import LOLLMSWebUI
from pydantic import BaseModel
from starlette.responses import StreamingResponse
from lollms.types import MSG_TYPE
from lollms.utilities import detect_antiprompt, remove_text_from_string, trace_exception
from ascii_colors import ASCIIColors
from lollms.databases.discussions_database import DiscussionsDB

from safe_store.text_vectorizer import TextVectorizer, VectorizationMethod, VisualizationMethod
import tqdm
from typing import Any, Optional
from pydantic import BaseModel, ValidationError
import json

# ----------------------- Defining router and main class ------------------------------

router = APIRouter()
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()

class EditMessageParameters(BaseModel):
    client_id: str = Field(..., min_length=1)
    id: int = Field(...)
    message: str = Field(...)
    metadata: list = Field(default=[])

@router.post(""/edit_message"")
async def edit_message(edit_params: EditMessageParameters):
    client_id = edit_params.client_id
    message_id = edit_params.id
    new_message = edit_params.message
    metadata = json.dumps(edit_params.metadata,indent=4)
    try:
        lollmsElfServer.session.get_client(client_id).discussion.edit_message(message_id, new_message, new_metadata=metadata)
        return {""status"": True}
    except Exception as ex:
        trace_exception(ex)  # Assuming 'trace_exception' function logs the error
        return {""status"": False, ""error"": ""There was an error editing the message""}



class MessageRankParameters(BaseModel):
    client_id: str = Field(..., min_length=1)
    id: int = Field(...)

@router.post(""/message_rank_up"")
async def message_rank_up(rank_params: MessageRankParameters):
    client_id = rank_params.client_id
    message_id = rank_params.id

    try:
        new_rank = lollmsElfServer.session.get_client(client_id).discussion.message_rank_up(message_id)
        return {""status"": True, ""new_rank"": new_rank}
    except Exception as ex:
        trace_exception(ex)  # Assuming 'trace_exception' function logs the error
        return {""status"": False, ""error"": ""There was an error ranking up the message""}


@router.post(""/message_rank_down"")
def message_rank_down(rank_params: MessageRankParameters):
    client_id = rank_params.client_id
    message_id = rank_params.id
    try:
        new_rank = lollmsElfServer.session.get_client(client_id).discussion.message_rank_down(message_id)
        return {""status"": True, ""new_rank"": new_rank}
    except Exception as ex:
        return {""status"": False, ""error"":str(ex)}

class MessageDeleteParameters(BaseModel):
    client_id: str = Field(..., min_length=1)
    id: int = Field(...)

@router.post(""/delete_message"")
async def delete_message(delete_params: MessageDeleteParameters):
    client_id = delete_params.client_id
    message_id = delete_params.id

    if lollmsElfServer.session.get_client(client_id).discussion is None:
        return {""status"": False,""message"":""No discussion is selected""}
    else:
        try:
            new_rank = lollmsElfServer.session.get_client(client_id).discussion.delete_message(message_id)
            ASCIIColors.yellow(""Message deleted"")
            return {""status"":True,""new_rank"": new_rank}
        except Exception as ex:
            trace_exception(ex)  # Assuming 'trace_exception' function logs the error
            return {""status"": False, ""error"": ""There was an error deleting the message""}


",CWE-78,100.0,1
"""""""
project: lollms_webui
file: lollms_xtts.py 
author: ParisNeo
description: 
    This module contains a set of FastAPI routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes allow users to 

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from lollms_webui import LOLLMSWebUI
from pydantic import BaseModel, Field
from starlette.responses import StreamingResponse
from lollms.types import MSG_TYPE
from lollms.main_config import BaseConfig
from lollms.utilities import detect_antiprompt, remove_text_from_string, trace_exception, find_first_available_file_index, add_period, PackageManager
from lollms.security import sanitize_path_from_endpoint, validate_path
from pathlib import Path
from ascii_colors import ASCIIColors
import os
import platform
import yaml, json
# ----------------------- Defining router and main class ------------------------------

router = APIRouter()
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()


# ----------------------- voice ------------------------------
@router.get(""/get_presets"")
def get_presets():
    presets = []
    presets_folder = Path(""__file__"").parent/""presets""
    for filename in presets_folder.glob('*.yaml'):
        with open(filename, 'r', encoding='utf-8') as file:
            preset = yaml.safe_load(file)
            if preset is not None:
                presets.append(preset)
    presets_folder = lollmsElfServer.lollms_paths.personal_discussions_path/""lollms_playground_presets""
    presets_folder.mkdir(exist_ok=True, parents=True)
    for filename in presets_folder.glob('*.yaml'):
        with open(filename, 'r', encoding='utf-8') as file:
            preset = yaml.safe_load(file)
            if preset is not None:
                presets.append(preset)
    return presets

class PresetData(BaseModel):
    name: str = Field(..., min_length=1)

@router.post(""/add_preset"")
async def add_preset(preset_data: PresetData):
    """"""
    Changes current voice

    :param request: The HTTP request object.
    :return: A JSON response with the status of the operation.
    """"""
    try:

        presets_folder = lollmsElfServer.lollms_paths.personal_discussions_path/""lollms_playground_presets""
        if not presets_folder.exists():
            presets_folder.mkdir(exist_ok=True, parents=True)

        # Ensure the name doesn't contain any path manipulation characters
        sanitize_path_from_endpoint(preset_data.name,exception_text=""Invalid preset name"")

        fn = preset_data.name.lower().replace("" "",""_"")
        filename = presets_folder/f""{fn}.yaml""
        with open(filename, 'w', encoding='utf-8') as file:
            yaml.dump(preset_data, file)
        return {""status"": True}
    except Exception as ex:
        trace_exception(ex)  # Assuming 'trace_exception' function logs the error
        return {""status"": False, ""error"": ""There was an error adding the preset""}

@router.post(""/del_preset"")
async def del_preset(preset_data: PresetData):
    """"""
    Saves a preset to a file.

    :param preset_data: The data of the preset.
    :return: A JSON response with the status of the operation.
    """"""
    # Get the JSON data from the POST request.
    if preset_data.name is None:
        raise HTTPException(status_code=400, detail=""Preset name is missing in the request"")
    
    # Ensure the name doesn't contain any path manipulation characters
    sanitize_path_from_endpoint(preset_data.name,exception_text=""Invalid preset name"")

    presets_file = lollmsElfServer.lollms_paths.personal_discussions_path/""lollms_playground_presets""/preset_data.name
    try:
        presets_file.unlink()
        return {""status"":True}
    except:
        return {""status"":False}


class PresetDataWithValue(BaseModel):
    name: str = Field(..., min_length=1)
    preset: str
    
@router.post(""/save_presets"")
async def save_presets(preset_data: PresetDataWithValue):
    """"""
    Saves a preset to a file.

    :param preset_data: The data of the preset.
    :return: A JSON response with the status of the operation.
    """"""
    # Get the JSON data from the POST request.
    if preset_data.preset is None:
        raise HTTPException(status_code=400, detail=""Preset data is missing in the request"")


    # Ensure the name doesn't contain any path manipulation characters
    sanitize_path_from_endpoint(preset_data.name,exception_text=""Invalid preset name"")

    presets_file = lollmsElfServer.lollms_paths.personal_discussions_path/""presets.json""
    # Save the JSON data to a file.
    with open(presets_file, ""w"") as f:
        json.dump(preset_data.preset, f, indent=4)

    return {""status"":True,""message"":""Preset saved successfully!""}",CWE-78,126.0,1
"""""""
project: lollms_webui
file: lollms_webui_infos.py 
author: ParisNeo
description: 
    This module contains a set of FastAPI routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes allow users to retrieve details such as the current version number, a list of available databases, and options for 
    updating or restarting the software.

""""""

from fastapi import APIRouter, Request
import pkg_resources
from lollms_webui import LOLLMSWebUI
from ascii_colors import ASCIIColors
from lollms.utilities import load_config, run_async
from pathlib import Path
from typing import List
import sys
import socketio
import time
# ----------------------- Defining router and main class ------------------------------

# Create an instance of the LoLLMSWebUI class
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()
router = APIRouter()


@router.get(""/get_versionID"")
async def get_lollms_webui_version():
   """"""Get the version of the LoLLMs Web UI application.""""""
   # Return the version string
   return {""id"":4}

@router.get(""/get_lollms_webui_version"")
async def get_lollms_webui_version():
   """"""Get the version of the LoLLMs Web UI application.""""""
   # Return the version string
   return lollmsElfServer.version


@router.get(""/restart_program"")
async def restart_program():
    """"""Restart the program.""""""
    if lollmsElfServer.config.headless_server_mode:
        return {""status"":False,""error"":""Restarting app is blocked when in headless mode for obvious security reasons!""}

    if lollmsElfServer.config.host!=""localhost"" and lollmsElfServer.config.host!=""127.0.0.1"":
        return {""status"":False,""error"":""Restarting app is blocked when the server is exposed outside for very obvious reasons!""}

    lollmsElfServer.ShowBlockingMessage(""Restarting program.\nPlease stand by..."")
    # Stop the socketIO server
    run_async(lollmsElfServer.sio.shutdown)
    # Sleep for 1 second before rebooting
    time.sleep(1)
    lollmsElfServer.HideBlockingMessage()
    # Reboot the program
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("" "")
    ASCIIColors.info(""               Restarting backend                  "")
    ASCIIColors.info("" "")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    lollmsElfServer.run_restart_script(lollmsElfServer.args)
    
@router.get(""/update_software"")
async def update_software():
    """"""Update the software.""""""
    if lollmsElfServer.config.headless_server_mode:
        return {""status"":False,""error"":""Updating app is blocked when in headless mode for obvious security reasons!""}

    if lollmsElfServer.config.host!=""localhost"" and lollmsElfServer.config.host!=""127.0.0.1"":
        return {""status"":False,""error"":""Updating app is blocked when the server is exposed outside for very obvious reasons!""}

    # Display an informative message
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info(""                Updating backend                  "")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    ASCIIColors.info("""")
    # Stop the socketIO server
    await lollmsElfServer.sio.shutdown()
    # Sleep for 1 second before rebooting
    time.sleep(1) 

    # Run the update script using the provided arguments
    lollmsElfServer.run_update_script(lollmsElfServer.args)
    # Exit the program after successful update
    sys.exit()


@router.get(""/check_update"")
def check_update():
    """"""Checks if an update is available""""""
    if lollmsElfServer.config.headless_server_mode:
        return {""status"":False,""error"":""Checking updates is blocked when in headless mode for obvious security reasons!""}

    if lollmsElfServer.config.host!=""localhost"" and lollmsElfServer.config.host!=""127.0.0.1"":
        return {""status"":False,""error"":""Checking updates is blocked when the server is exposed outside for very obvious reasons!""}
    
    if lollmsElfServer.config.auto_update:
        res = lollmsElfServer.check_update_()
        return {'update_availability':res}
    else:
        return {'update_availability':False}
",CWE-78,113.0,1
"""""""
project: lollms
file: lollms_discussion_events.py 
author: ParisNeo
description: 
    This module contains a set of Socketio routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes are specific to discussion operation

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from pydantic import BaseModel
import pkg_resources
from lollms.server.elf_server import LOLLMSElfServer
from fastapi.responses import FileResponse
from lollms.binding import BindingBuilder, InstallOption
from ascii_colors import ASCIIColors
from lollms.personality import MSG_TYPE, AIPersonality
from lollms.types import MSG_TYPE, SENDER_TYPES
from lollms.utilities import load_config, trace_exception, gc
from lollms.utilities import find_first_available_file_index, convert_language_name, PackageManager, run_async
from lollms_webui import LOLLMSWebUI
from pathlib import Path
from typing import List
from functools import partial
import socketio
import threading
import os
import time

from lollms.internet import scrape_and_save
from lollms.databases.discussions_database import Discussion
from datetime import datetime

router = APIRouter()
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()


# ----------------------------------- events -----------------------------------------
def add_events(sio:socketio):
    @sio.on('create_empty_message')
    def create_empty_message(sid, data):
        client_id = sid
        type = int(data.get(""type"",0))
        message = data.get(""message"","""")
        if type==0:
            ASCIIColors.info(f""Building empty User message requested by : {client_id}"")
            # send the message to the bot
            print(f""Creating an empty message for AI answer orientation"")
            if lollmsElfServer.session.get_client(client_id).discussion:
                if not lollmsElfServer.model:
                    lollmsElfServer.error(""No model selected. Please make sure you select a model before starting generation"", client_id = client_id)
                    return          
                lollmsElfServer.new_message(client_id, lollmsElfServer.config.user_name, message, sender_type=SENDER_TYPES.SENDER_TYPES_USER, open=True)
        else:
            if lollmsElfServer.personality is None:
                lollmsElfServer.warning(""Select a personality"")
                return
            ASCIIColors.info(f""Building empty AI message requested by : {client_id}"")
            # send the message to the bot
            print(f""Creating an empty message for AI answer orientation"")
            if lollmsElfServer.session.get_client(client_id).discussion:
                if not lollmsElfServer.model:
                    lollmsElfServer.error(""No model selected. Please make sure you select a model before starting generation"", client_id=client_id)
                    return          
                lollmsElfServer.new_message(client_id, lollmsElfServer.personality.name, ""[edit this to put your ai answer start]"", open=True)


    @sio.on('add_webpage')
    def add_webpage(sid, data):
        lollmsElfServer.ShowBlockingMessage(""Scraping web page\nPlease wait..."")
        ASCIIColors.yellow(""Scaping web page"")
        client = lollmsElfServer.session.get_client(sid)
        url = data['url']
        index =  find_first_available_file_index(lollmsElfServer.lollms_paths.personal_uploads_path,""web_"","".txt"")
        file_path=lollmsElfServer.lollms_paths.personal_uploads_path/f""web_{index}.txt""
        scrape_and_save(url=url, file_path=file_path)
        try:
            if not lollmsElfServer.personality.processor is None:
                lollmsElfServer.personality.processor.add_file(file_path, client, partial(lollmsElfServer.process_chunk, client_id = sid))
                # File saved successfully
                run_async(partial(sio.emit,'web_page_added', {'status':True,}))
            else:
                lollmsElfServer.personality.add_file(file_path, client, partial(lollmsElfServer.process_chunk, client_id = sid))
                # File saved successfully
                run_async(partial(sio.emit,'web_page_added', {'status':True}))
            lollmsElfServer.HideBlockingMessage()
        except Exception as e:
            # Error occurred while saving the file
            run_async(partial(sio.emit,'web_page_added', {'status':False}))
            lollmsElfServer.HideBlockingMessage()

    @sio.on('take_picture')
    def take_picture(sid):
        try:
            client = lollmsElfServer.session.get_client(sid)
            lollmsElfServer.info(""Loading camera"")
            if not PackageManager.check_package_installed(""cv2""):
                PackageManager.install_package(""opencv-python"")
            import cv2
            cap = cv2.VideoCapture(0)
            n = time.time()
            lollmsElfServer.info(""Stand by for taking a shot in 2s"")
            while(time.time()-n<2):
                _, frame = cap.read()
            _, frame = cap.read()
            cap.release()
            lollmsElfServer.info(""Shot taken"")
            cam_shot_path = client.discussion.discussion_images_folder
            cam_shot_path.mkdir(parents=True, exist_ok=True)
            filename = find_first_available_file_index(cam_shot_path, ""cam_shot_"", extension="".png"")
            save_path = cam_shot_path/f""cam_shot_{filename}.png""  # Specify the desired folder path

            try:
                cv2.imwrite(str(save_path), frame)
                if not lollmsElfServer.personality.processor is None:
                    lollmsElfServer.info(""Sending file to scripted persona"")
                    lollmsElfServer.personality.processor.add_file(save_path, client, partial(lollmsElfServer.process_chunk, client_id = sid))
                    # File saved successfully
                    run_async(partial(sio.emit,'picture_taken', {'status':True, 'progress': 100}))
                    lollmsElfServer.info(""File sent to scripted persona"")
                else:
                    lollmsElfServer.info(""Sending file to persona"")
                    lollmsElfServer.personality.add_file(save_path, client, partial(lollmsElfServer.process_chunk, client_id = sid))
                    # File saved successfully
                    run_async(partial(sio.emit,'picture_taken', {'status':True, 'progress': 100}))
                    lollmsElfServer.info(""File sent to persona"")
            except Exception as e:
                trace_exception(e)
                # Error occurred while saving the file
                run_async(partial(sio.emit,'picture_taken', {'status':False, 'error': str(e)}))
                

        except Exception as ex:
            trace_exception(ex)
            lollmsElfServer.error(""Couldn't use the webcam"")
",CWE-78,137.0,1
"""""""
project: lollms
file: lollms_discussion_events.py 
author: ParisNeo
description: 
    This module contains a set of Socketio routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes are specific to discussion operation

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from pydantic import BaseModel
import pkg_resources
from lollms.server.elf_server import LOLLMSElfServer
from fastapi.responses import FileResponse
from lollms.binding import BindingBuilder, InstallOption
from ascii_colors import ASCIIColors
from lollms.personality import MSG_TYPE, AIPersonality
from lollms.types import MSG_TYPE, SENDER_TYPES
from lollms.utilities import load_config, trace_exception, gc
from lollms.utilities import find_first_available_file_index, convert_language_name, PackageManager
from lollms_webui import LOLLMSWebUI
from pathlib import Path
from typing import List
import socketio
import threading
import os

from lollms.databases.discussions_database import Discussion
from datetime import datetime

router = APIRouter()
lollmsElfServer = LOLLMSWebUI.get_instance()


# ----------------------------------- events -----------------------------------------
def add_events(sio:socketio):
        @sio.on('new_discussion')
        async def new_discussion(sid, data):
            if lollmsElfServer.personality is None:
                lollmsElfServer.error(""Please select a personality first"")
                return
            ASCIIColors.yellow(""New descussion requested"")
            client_id = sid
            title = data[""title""]
            lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.create_discussion(title)
            # Get the current timestamp
            timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")
            
            # Return a success response
            if lollmsElfServer.session.get_client(client_id).discussion is None:
                lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.load_last_discussion()
        
            if lollmsElfServer.personality.welcome_message!="""":
                if lollmsElfServer.personality.welcome_audio_path.exists():
                    for voice in lollmsElfServer.personality.welcome_audio_path.iterdir():
                        if voice.suffix.lower() in ["".wav"","".mp3""]:
                                try:
                                    if not PackageManager.check_package_installed(""pygame""):
                                        PackageManager.install_package(""pygame"")
                                    import pygame
                                    pygame.mixer.init()
                                    pygame.mixer.music.load(voice)
                                    pygame.mixer.music.play()
                                except Exception as ex:
                                    pass
                if lollmsElfServer.config.force_output_language_to_be and lollmsElfServer.config.force_output_language_to_be.lower().strip() !=""english"":
                    welcome_message = lollmsElfServer.personality.fast_gen(f""!@>instruction: Translate the following text to {lollmsElfServer.config.force_output_language_to_be.lower()}:\n{lollmsElfServer.personality.welcome_message}\n!@>translation:"")
                else:
                    welcome_message = lollmsElfServer.personality.welcome_message

                message = lollmsElfServer.session.get_client(client_id).discussion.add_message(
                    message_type        = MSG_TYPE.MSG_TYPE_FULL.value if lollmsElfServer.personality.include_welcome_message_in_disucssion else MSG_TYPE.MSG_TYPE_FULL_INVISIBLE_TO_AI.value,
                    sender_type         = SENDER_TYPES.SENDER_TYPES_AI.value,
                    sender              = lollmsElfServer.personality.name,
                    content             = welcome_message,
                    metadata            = None,
                    rank                = 0, 
                    parent_message_id   = -1, 
                    binding             = lollmsElfServer.config.binding_name, 
                    model               = lollmsElfServer.config.model_name,
                    personality         = lollmsElfServer.config.personalities[lollmsElfServer.config.active_personality_id], 
                    created_at=None, 
                    finished_generating_at=None
                )
 
                await lollmsElfServer.sio.emit('discussion_created',
                            {'id':lollmsElfServer.session.get_client(client_id).discussion.discussion_id},
                            to=client_id
                )                        
            else:
                await lollmsElfServer.sio.emit('discussion_created',
                            {'id':0},
                            to=client_id
                )                        

        @sio.on('load_discussion')
        async def load_discussion(sid, data):   
            client_id = sid
            ASCIIColors.yellow(f""Loading discussion for client {client_id} ... "", end="""")
            if ""id"" in data:
                discussion_id = data[""id""]
                lollmsElfServer.session.get_client(client_id).discussion = Discussion(discussion_id, lollmsElfServer.db)
            else:
                if lollmsElfServer.session.get_client(client_id).discussion is not None:
                    discussion_id = lollmsElfServer.session.get_client(client_id).discussion.discussion_id
                    lollmsElfServer.session.get_client(client_id).discussion = Discussion(discussion_id, lollmsElfServer.db)
                else:
                    lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.create_discussion()
            messages = lollmsElfServer.session.get_client(client_id).discussion.get_messages()
            jsons = [m.to_json() for m in messages]
            await lollmsElfServer.sio.emit('discussion',
                        jsons,
                        to=client_id
            )
            ASCIIColors.green(f""ok"")",CWE-78,116.0,1
"""""""
project: lollms
file: lollms_generation_events.py 
author: ParisNeo
description: 
    This module contains a set of Socketio routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes are specific to text generation operation

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from pydantic import BaseModel
import pkg_resources
from lollms.server.elf_server import LOLLMSElfServer
from fastapi.responses import FileResponse
from lollms.binding import BindingBuilder, InstallOption
from ascii_colors import ASCIIColors
from lollms.personality import MSG_TYPE, AIPersonality
from lollms.types import MSG_TYPE, SENDER_TYPES
from lollms.utilities import load_config, trace_exception, gc
from lollms.utilities import find_first_available_file_index, convert_language_name
from lollms_webui import LOLLMSWebUI
from pathlib import Path
from typing import List
import socketio
import threading
import os

router = APIRouter()
lollmsElfServer = LOLLMSWebUI.get_instance()


# ----------------------------------- events -----------------------------------------
def add_events(sio:socketio):
    @sio.on('generate_msg')
    def handle_generate_msg(sid, data):        
        client_id = sid
        lollmsElfServer.cancel_gen = False
        client = lollmsElfServer.session.get_client(client_id)

        client.generated_text=""""
        client.cancel_generation=False
        client.continuing=False
        client.first_chunk=True
        

        
        if not lollmsElfServer.model:
            ASCIIColors.error(""Model not selected. Please select a model"")
            lollmsElfServer.error(""Model not selected. Please select a model"", client_id=client_id)
            return

        if not lollmsElfServer.busy:
            if lollmsElfServer.session.get_client(client_id).discussion is None:
                if lollmsElfServer.db.does_last_discussion_have_messages():
                    lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.create_discussion()
                else:
                    lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.load_last_discussion()

            prompt = data[""prompt""]
            ump = lollmsElfServer.config.discussion_prompt_separator +lollmsElfServer.config.user_name.strip() if lollmsElfServer.config.use_user_name_in_discussions else lollmsElfServer.personality.user_message_prefix
            message = lollmsElfServer.session.get_client(client_id).discussion.add_message(
                message_type    = MSG_TYPE.MSG_TYPE_FULL.value,
                sender_type     = SENDER_TYPES.SENDER_TYPES_USER.value,
                sender          = ump.replace(lollmsElfServer.config.discussion_prompt_separator,"""").replace("":"",""""),
                content=prompt,
                metadata=None,
                parent_message_id=lollmsElfServer.message_id
            )

            ASCIIColors.green(""Starting message generation by ""+lollmsElfServer.personality.name)
            client.generation_thread = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message.id, client_id))
            client.generation_thread.start()
            
            # lollmsElfServer.sio.sleep(0.01)
            ASCIIColors.info(""Started generation task"")
            lollmsElfServer.busy=True
            #tpe = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message_id, client_id))
            #tpe.start()
        else:
            lollmsElfServer.error(""I am busy. Come back later."", client_id=client_id)
    @sio.on('generate_msg_with_internet')
    def generate_msg_with_internet(sid, data):        
        client_id = sid
        lollmsElfServer.cancel_gen = False
        client = lollmsElfServer.session.get_client(client_id)

        client.generated_text=""""
        client.cancel_generation=False
        client.continuing=False
        client.first_chunk=True
        

        
        if not lollmsElfServer.model:
            ASCIIColors.error(""Model not selected. Please select a model"")
            lollmsElfServer.error(""Model not selected. Please select a model"", client_id=client_id)
            return

        if not lollmsElfServer.busy:
            if lollmsElfServer.session.get_client(client_id).discussion is None:
                if lollmsElfServer.db.does_last_discussion_have_messages():
                    lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.create_discussion()
                else:
                    lollmsElfServer.session.get_client(client_id).discussion = lollmsElfServer.db.load_last_discussion()

            prompt = data[""prompt""]
            ump = lollmsElfServer.config.discussion_prompt_separator +lollmsElfServer.config.user_name.strip() if lollmsElfServer.config.use_user_name_in_discussions else lollmsElfServer.personality.user_message_prefix
            message = lollmsElfServer.session.get_client(client_id).discussion.add_message(
                message_type    = MSG_TYPE.MSG_TYPE_FULL.value,
                sender_type     = SENDER_TYPES.SENDER_TYPES_USER.value,
                sender          = ump.replace(lollmsElfServer.config.discussion_prompt_separator,"""").replace("":"",""""),
                content=prompt,
                metadata=None,
                parent_message_id=lollmsElfServer.message_id
            )

            ASCIIColors.green(""Starting message generation by ""+lollmsElfServer.personality.name)
            
            client.generation_thread = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message.id, client_id, False, None, True))
            client.generation_thread.start()
            
            # lollmsElfServer.sio.sleep(0.01)
            ASCIIColors.info(""Started generation task"")
            lollmsElfServer.busy=True
            #tpe = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message_id, client_id))
            #tpe.start()
        else:
            lollmsElfServer.error(""I am busy. Come back later."", client_id=client_id)




    @sio.on('generate_msg_from')
    def handle_generate_msg_from(sid, data):
        client_id = sid
        client = lollmsElfServer.session.get_client(client_id)
        lollmsElfServer.cancel_gen = False
        client.continuing=False
        client.first_chunk=True
        
        if lollmsElfServer.session.get_client(client_id).discussion is None:
            ASCIIColors.warning(""Please select a discussion"")
            lollmsElfServer.error(""Please select a discussion first"", client_id=client_id)
            return
        id_ = data['id']
        generation_type = data.get('msg_type',None)
        if id_==-1:
            message = lollmsElfServer.session.get_client(client_id).discussion.current_message
        else:
            message = lollmsElfServer.session.get_client(client_id).discussion.load_message(id_)
        if message is None:
            return            
        client.generation_thread = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message.id, client_id, False, generation_type))
        client.generation_thread.start()

    @sio.on('continue_generate_msg_from')
    def handle_continue_generate_msg_from(sid, data):
        client_id = sid
        client = lollmsElfServer.session.get_client(client_id)
        lollmsElfServer.cancel_gen = False
        client.continuing=True
        client.first_chunk=True
        
        if lollmsElfServer.session.get_client(client_id).discussion is None:
            ASCIIColors.yellow(""Please select a discussion"")
            lollmsElfServer.error(""Please select a discussion"", client_id=client_id)
            return
        id_ = data['id']
        if id_==-1:
            message = lollmsElfServer.session.get_client(client_id).discussion.current_message
        else:
            message = lollmsElfServer.session.get_client(client_id).discussion.load_message(id_)

        client.generated_text=message.content
        client.generation_thread = threading.Thread(target=lollmsElfServer.start_message_generation, args=(message, message.id, client_id, True))
        client.generation_thread.start()

",CWE-78,179.0,1
"""""""
project: lollms
file: lollms_discussion_events.py 
author: ParisNeo
description: 
    This module contains a set of Socketio routes that provide information about the Lord of Large Language and Multimodal Systems (LoLLMs) Web UI
    application. These routes are specific to discussion operation

""""""
from fastapi import APIRouter, Request
from fastapi import HTTPException
from pydantic import BaseModel
import pkg_resources
from lollms.server.elf_server import LOLLMSElfServer
from fastapi.responses import FileResponse
from lollms.binding import BindingBuilder, InstallOption
from ascii_colors import ASCIIColors
from lollms.personality import MSG_TYPE, AIPersonality
from lollms.types import MSG_TYPE, SENDER_TYPES
from lollms.utilities import load_config, trace_exception, gc
from lollms.utilities import find_first_available_file_index, convert_language_name, PackageManager, run_async
from lollms_webui import LOLLMSWebUI
from pathlib import Path
from typing import List
from functools import partial
import socketio
import threading
import os
import time

from lollms.databases.discussions_database import Discussion
from datetime import datetime

router = APIRouter()
lollmsElfServer:LOLLMSWebUI = LOLLMSWebUI.get_instance()


# ----------------------------------- events -----------------------------------------
def add_events(sio:socketio):
    @sio.on('start_webcam_video_stream')
    def start_webcam_video_stream(sid):
        lollmsElfServer.info(""Starting video capture"")
        try:
            from lollms.media import WebcamImageSender
            lollmsElfServer.webcam = WebcamImageSender(sio,lollmsCom=lollmsElfServer)
            lollmsElfServer.webcam.start_capture()
        except:
            lollmsElfServer.InfoMessage(""Couldn't load media library.\nYou will not be able to perform any of the media linked operations. please verify the logs and install any required installations"")

    @sio.on('stop_webcam_video_stream')
    def stop_webcam_video_stream(sid):
        lollmsElfServer.info(""Stopping video capture"")
        lollmsElfServer.webcam.stop_capture()

    @sio.on('start_audio_stream')
    def start_audio_stream(sid):
        lollmsElfServer.info(""Starting audio capture"")
        try:
            from lollms.media import AudioRecorder
            lollmsElfServer.rec_output_folder = lollmsElfServer.lollms_paths.personal_outputs_path/""audio_rec""
            lollmsElfServer.rec_output_folder.mkdir(exist_ok=True, parents=True)
            lollmsElfServer.summoned = False
            lollmsElfServer.audio_cap = AudioRecorder(sio,lollmsElfServer.rec_output_folder/""rt.wav"", callback=lollmsElfServer.audio_callback,lollmsCom=lollmsElfServer)
            lollmsElfServer.audio_cap.start_recording()
        except:
            lollmsElfServer.InfoMessage(""Couldn't load media library.\nYou will not be able to perform any of the media linked operations. please verify the logs and install any required installations"")


    @sio.on('stop_audio_stream')
    def stop_audio_stream(sid):
        lollmsElfServer.info(""Stopping audio capture"")
        lollmsElfServer.audio_cap.stop_recording()

",CWE-78,74.0,1
,CWE-366,,1
,CWE-79,,1
,CWE-384,,1
,CWE-79,,1
,CWE-22,,1
""""""" tornado handler for managing and communicating with language servers
""""""
from typing import Optional, Text

from jupyter_server.base.handlers import APIHandler
from jupyter_server.base.zmqhandlers import WebSocketHandler, WebSocketMixin
from jupyter_server.utils import url_path_join as ujoin

from .manager import LanguageServerManager
from .schema import SERVERS_RESPONSE
from .specs.utils import censored_spec


class BaseHandler(APIHandler):
    manager = None  # type: LanguageServerManager

    def initialize(self, manager: LanguageServerManager):
        self.manager = manager


class LanguageServerWebSocketHandler(  # type: ignore
    WebSocketMixin, WebSocketHandler, BaseHandler
):
    """"""Setup tornado websocket to route to language server sessions""""""

    language_server: Optional[Text] = None

    async def open(self, language_server):
        await self.manager.ready()
        self.language_server = language_server
        self.manager.subscribe(self)
        self.log.debug(""[{}] Opened a handler"".format(self.language_server))
        super().open()

    async def on_message(self, message):
        self.log.debug(""[{}] Handling a message"".format(self.language_server))
        await self.manager.on_client_message(message, self)

    def on_close(self):
        self.manager.unsubscribe(self)
        self.log.debug(""[{}] Closed a handler"".format(self.language_server))


class LanguageServersHandler(BaseHandler):
    """"""Reports the status of all current servers

    Response should conform to schema in schema/servers.schema.json
    """"""

    validator = SERVERS_RESPONSE

    def initialize(self, *args, **kwargs):
        super().initialize(*args, **kwargs)

    async def get(self):
        """"""finish with the JSON representations of the sessions""""""
        await self.manager.ready()

        response = {
            ""version"": 2,
            ""sessions"": {
                language_server: session.to_json()
                for language_server, session in self.manager.sessions.items()
            },
            ""specs"": {
                key: censored_spec(spec)
                for key, spec in self.manager.all_language_servers.items()
            },
        }

        errors = list(self.validator.iter_errors(response))

        if errors:  # pragma: no cover
            self.log.warning(""{} validation errors: {}"".format(len(errors), errors))

        self.finish(response)


def add_handlers(nbapp):
    """"""Add Language Server routes to the notebook server web application""""""
    lsp_url = ujoin(nbapp.base_url, ""lsp"")
    re_langservers = ""(?P<language_server>.*)""

    opts = {""manager"": nbapp.language_server_manager}

    nbapp.web_app.add_handlers(
        "".*"",
        [
            (ujoin(lsp_url, ""status""), LanguageServersHandler, opts),
            (
                ujoin(lsp_url, ""ws"", re_langservers),
                LanguageServerWebSocketHandler,
                opts,
            ),
        ],
    )
",CWE-22,97.0,1
"import os
import pathlib
import re
from urllib.parse import unquote, urlparse

RE_PATH_ANCHOR = r""^file://([^/]+|/[A-Z]:)""


def normalized_uri(root_dir):
    """"""Attempt to make an LSP rootUri from a ContentsManager root_dir

    Special care must be taken around windows paths: the canonical form of
    windows drives and UNC paths is lower case
    """"""
    root_uri = pathlib.Path(root_dir).expanduser().resolve().as_uri()
    root_uri = re.sub(
        RE_PATH_ANCHOR, lambda m: ""file://{}"".format(m.group(1).lower()), root_uri
    )
    return root_uri


def file_uri_to_path(file_uri):
    """"""Return a path string for give file:/// URI.

    Respect the different path convention on Windows.
    Based on https://stackoverflow.com/a/57463161/6646912, BSD 0
    """"""
    windows_path = os.name == ""nt""
    file_uri_parsed = urlparse(file_uri)
    file_uri_path_unquoted = unquote(file_uri_parsed.path)
    if windows_path and file_uri_path_unquoted.startswith(""/""):
        result = file_uri_path_unquoted[1:]  # pragma: no cover
    else:
        result = file_uri_path_unquoted  # pragma: no cover
    return result
",CWE-22,36.0,1
""""""" add language server support to the running jupyter notebook application
""""""
import json
from pathlib import Path

import traitlets

from .handlers import add_handlers
from .manager import LanguageServerManager
from .paths import normalized_uri


async def initialize(nbapp, virtual_documents_uri):  # pragma: no cover
    """"""Perform lazy initialization.""""""
    import concurrent.futures

    from .virtual_documents_shadow import setup_shadow_filesystem

    manager: LanguageServerManager = nbapp.language_server_manager

    with concurrent.futures.ThreadPoolExecutor() as pool:
        await nbapp.io_loop.run_in_executor(pool, manager.initialize)

    servers_requiring_disk_access = [
        server_id
        for server_id, server in manager.language_servers.items()
        if server.get(""requires_documents_on_disk"", True)
    ]

    if any(servers_requiring_disk_access):
        nbapp.log.debug(
            ""[lsp] Servers that requested virtual documents on disk: %s"",
            servers_requiring_disk_access,
        )
        setup_shadow_filesystem(virtual_documents_uri=virtual_documents_uri)
    else:
        nbapp.log.debug(
            ""[lsp] None of the installed servers require virtual documents""
            "" disabling shadow filesystem.""
        )

    nbapp.log.debug(
        ""[lsp] The following Language Servers will be available: {}"".format(
            json.dumps(manager.language_servers, indent=2, sort_keys=True)
        )
    )


def load_jupyter_server_extension(nbapp):
    """"""create a LanguageServerManager and add handlers""""""
    nbapp.add_traits(language_server_manager=traitlets.Instance(LanguageServerManager))
    manager = nbapp.language_server_manager = LanguageServerManager(parent=nbapp)

    contents = nbapp.contents_manager
    page_config = nbapp.web_app.settings.setdefault(""page_config_data"", {})

    root_uri = """"
    virtual_documents_uri = """"

    # try to set the rootUri from the contents manager path
    if hasattr(contents, ""root_dir""):
        root_uri = normalized_uri(contents.root_dir)
        nbapp.log.debug(""[lsp] rootUri will be %s"", root_uri)
        virtual_documents_uri = normalized_uri(
            Path(contents.root_dir) / manager.virtual_documents_dir
        )
        nbapp.log.debug(""[lsp] virtualDocumentsUri will be %s"", virtual_documents_uri)
    else:  # pragma: no cover
        nbapp.log.warn(
            ""[lsp] %s did not appear to have a root_dir, could not set rootUri"",
            contents,
        )
    page_config.update(rootUri=root_uri, virtualDocumentsUri=virtual_documents_uri)

    add_handlers(nbapp)
    nbapp.io_loop.call_later(0, initialize, nbapp, virtual_documents_uri)
",CWE-22,77.0,1
"import json
import pathlib
import shutil
from typing import Text

from jupyter_server.serverapp import ServerApp
from pytest import fixture
from tornado.httputil import HTTPServerRequest
from tornado.queues import Queue
from tornado.web import Application

# local imports
from jupyter_lsp import LanguageServerManager
from jupyter_lsp.constants import APP_CONFIG_D_SECTIONS
from jupyter_lsp.handlers import LanguageServersHandler, LanguageServerWebSocketHandler

# these should always be available in a test environment
KNOWN_SERVERS = [
    ""bash-language-server"",
    ""dockerfile-language-server-nodejs"",
    ""typescript-language-server"",
    ""pylsp"",
    ""unified-language-server"",
    ""sql-language-server"",
    ""vscode-css-languageserver-bin"",
    ""vscode-html-languageserver-bin"",
    ""vscode-json-languageserver-bin"",
    ""yaml-language-server"",
]

CMD_BASED_SERVERS = {
    ""Rscript"": [""r-languageserver""],
    ""texlab"": [""texlab""],
    ""jedi-language-server"": [""jedi-language-server""],
    ""julia"": [""julia-language-server""],
}

KNOWN_SERVERS += sum(
    [langs for cmd, langs in CMD_BASED_SERVERS.items() if shutil.which(cmd)], []
)

KNOWN_UNKNOWN_SERVERS = [""foo-language-server""]


@fixture
def manager() -> LanguageServerManager:
    return LanguageServerManager()


@fixture
def echo_spec():
    return {""argv"": [""echo"", ""no server here""], ""languages"": [""klingon""], ""version"": 2}


@fixture
def echo_conf_json(echo_spec) -> str:
    return json.dumps(
        {""LanguageServerManager"": {""language_servers"": {""_echo_"": echo_spec}}},
        indent=2,
        sort_keys=True,
    )


@fixture(params=sorted(APP_CONFIG_D_SECTIONS))
def app_config_d(request, tmp_path, monkeypatch) -> pathlib.Path:
    conf_d = tmp_path / f""jupyter{request.param}config.d""
    conf_d.mkdir()
    monkeypatch.setenv(""JUPYTER_CONFIG_PATH"", f""{tmp_path}"")
    return conf_d


@fixture(params=sorted(KNOWN_SERVERS))
def known_server(request):
    return request.param


@fixture(params=sorted(KNOWN_UNKNOWN_SERVERS))
def known_unknown_server(request):
    return request.param


@fixture
def handlers(manager):
    ws_handler = MockWebsocketHandler()
    ws_handler.initialize(manager)
    handler = MockHandler()
    handler.initialize(manager)
    return handler, ws_handler


@fixture
def jsonrpc_init_msg():
    return json.dumps(
        {
            ""id"": 0,
            ""jsonrpc"": ""2.0"",
            ""method"": ""initialize"",
            ""params"": {
                ""capabilities"": {
                    # see: https://github.com/julia-vscode/LanguageServer.jl/issues/1008
                    # LanguageServer.jl assumes that it is not missing
                    ""workspace"": {""didChangeConfiguration"": {}},
                    # LanguageServer.jl assumes that it is not missing
                    ""textDocument"": {},
                },
                ""initializationOptions"": None,
                ""processId"": None,
                ""rootUri"": pathlib.Path(__file__).parent.as_uri(),
                ""workspaceFolders"": None,
            },
        }
    )


@fixture
def app():
    return MockServerApp()


# mocks
class MockWebsocketHandler(LanguageServerWebSocketHandler):
    _messages_wrote = None  # type: Queue
    _ping_sent = None  # type: bool

    def __init__(self):
        self.request = HTTPServerRequest()
        self.application = Application()

    def initialize(self, manager):
        super().initialize(manager)
        self._messages_wrote = Queue()
        self._ping_sent = False

    def write_message(self, message: Text) -> None:  # type: ignore
        self.log.warning(""write_message %s"", message)
        self._messages_wrote.put_nowait(message)

    def send_ping(self):
        self._ping_sent = True


class MockHandler(LanguageServersHandler):
    _payload = None

    def __init__(self):
        pass

    def finish(self, payload):
        self._payload = payload


class MockServerApp(ServerApp):
    pass
",CWE-22,154.0,1
,CWE-22,,1
"import pathlib
import platform
import sys

import pytest

from ..paths import file_uri_to_path, normalized_uri

WIN = platform.system() == ""Windows""
HOME = pathlib.Path(""~"").expanduser()
PY35 = sys.version_info[:2] == (3, 5)


@pytest.mark.skipif(WIN, reason=""can't test POSIX paths on Windows"")
@pytest.mark.parametrize(""root_dir, expected_root_uri"", [[""~"", HOME.as_uri()]])
def test_normalize_posix_path_home(root_dir, expected_root_uri):  # pragma: no cover
    assert normalized_uri(root_dir) == expected_root_uri


@pytest.mark.skipif(PY35, reason=""can't test non-existent paths on py35"")
@pytest.mark.skipif(WIN, reason=""can't test POSIX paths on Windows"")
@pytest.mark.parametrize(
    ""root_dir, expected_root_uri"",
    [
        # probably need to try some other things
        [str(HOME / ""foo""), (HOME / ""foo"").as_uri()]
    ],
)
def test_normalize_posix_path_home_subdir(
    root_dir, expected_root_uri
):  # pragma: no cover
    assert normalized_uri(root_dir) == expected_root_uri


@pytest.mark.skipif(not WIN, reason=""can't test Windows paths on POSIX"")
@pytest.mark.parametrize(
    ""root_dir, expected_root_uri"",
    [
        [""c:\\Users\\user1"", ""file:///c:/Users/user1""],
        [""C:\\Users\\user1"", ""file:///c:/Users/user1""],
        [""//VBOXSVR/shared-folder"", ""file://vboxsvr/shared-folder/""],
    ],
)
def test_normalize_windows_path_case(root_dir, expected_root_uri):  # pragma: no cover
    try:
        normalized = normalized_uri(root_dir)
    except FileNotFoundError as err:
        if sys.version_info >= (3, 10):
            # apparently, this triggers resolving the path on win/py3.10
            return
        raise err

    assert normalized == expected_root_uri


@pytest.mark.skipif(WIN, reason=""can't test POSIX paths on Windows"")
@pytest.mark.parametrize(
    ""file_uri, expected_posix_path"",
    [
        [""file:///C:/Windows/System32/Drivers/etc"", ""/C:/Windows/System32/Drivers/etc""],
        [""file:///C:/some%20dir/some%20file.txt"", ""/C:/some dir/some file.txt""],
        [""file:///home/user/some%20file.txt"", ""/home/user/some file.txt""],
    ],
)
def test_file_uri_to_path_posix(file_uri, expected_posix_path):  # pragma: no cover
    assert file_uri_to_path(file_uri) == expected_posix_path


@pytest.mark.skipif(not WIN, reason=""can't test Windows paths on POSIX"")
@pytest.mark.parametrize(
    ""file_uri, expected_windows_path"",
    [
        # https://github.com/jupyter-lsp/jupyterlab-lsp/pull/305#issuecomment-665996145
        [""file:///C:/Windows/System32/Drivers/etc"", ""C:/Windows/System32/Drivers/etc""],
        [""file:///C:/some%20dir/some%20file.txt"", ""C:/some dir/some file.txt""],
    ],
)
def test_file_uri_to_path_windows(file_uri, expected_windows_path):  # pragma: no cover
    assert file_uri_to_path(file_uri) == expected_windows_path
",CWE-22,80.0,1
"#!/usr/bin/env python3
""""""Bump version of selected packages or core requirements (JupyterLab)""""""
import sys
from argparse import ArgumentParser
from dataclasses import dataclass
from difflib import context_diff
from pathlib import Path
from typing import List

from integrity import CHANGELOG
from integrity import PIPE_FILE as PIPELINE

ROOT = Path.cwd()

sys.path.insert(0, str(ROOT))

if True:
    # a workaround for isort 4.0 limitations
    # see https://github.com/timothycrosley/isort/issues/468
    from versions import JUPYTERLAB_LSP_VERSION  # noqa
    from versions import JUPYTER_LSP_VERSION, JUPYTERLAB_VERSION, REQUIRED_JUPYTERLAB


META_PACKAGE = Path(""packages/metapackage/package.json"")
JUPYTERLAB_LSP_PACKAGE = Path(""packages/jupyterlab-lsp/package.json"")
README = Path(""README.md"")

NPM_PACKAGE_VERSION_TEMPLATE = '""version"": ""{version}""'


@dataclass
class VersionLocation:
    path: Path
    template: str


@dataclass
class PackageVersionInfo:
    name: str
    current_version: str
    locations: List[VersionLocation]

    def maybe_change_version(self, dry: bool):
        print(f""Current {self.name} version is: {self.current_version}"")
        version = input(""Change it to [default=skip]: "").strip()
        if version:
            self.change_version(new_version=version, dry=dry)

    def change_version(self, new_version: str, dry: bool):

        changelog = CHANGELOG.read_text(encoding=""utf-8"")
        if new_version not in changelog:
            raise Exception(
                (
                    f""{new_version} is absent in CHANGELOG.md file.""
                    f"" Please update the changelog first.""
                ).format(new_version=new_version)
            )

        for location in self.locations:
            replace_version(
                path=location.path,
                template=location.template,
                old=self.current_version,
                new=new_version,
                dry=dry,
            )


def replace_version(path: Path, template: str, old: str, new: str, dry: bool):
    old_content = path.read_text(encoding=""utf-8"")
    new_content = old_content.replace(
        template.format(version=old), template.format(version=new)
    )
    if dry:
        diff = context_diff(
            old_content.splitlines(),
            new_content.splitlines(),
            fromfile=""current"",
            tofile=""new (proposed update)"",
            n=4,
        )
        relative_path = path.relative_to(ROOT) if path.is_absolute() else path
        print(""\n## Summary of changes proposed to {path}"".format(path=relative_path))
        print(""\n"".join(diff) + ""\n"")
    else:
        path.write_text(new_content)


def update_versions(dry: bool):
    packages: List[PackageVersionInfo] = [
        PackageVersionInfo(
            name=""jupyter-lsp (Python backend)"",
            current_version=JUPYTER_LSP_VERSION,
            locations=[
                VersionLocation(
                    path=Path(""python_packages/jupyter_lsp/jupyter_lsp/_version.py""),
                    template='__version__ = ""{version}""',
                ),
                VersionLocation(path=PIPELINE, template=""PY_JLSP_VERSION: {version}""),
            ],
        ),
        PackageVersionInfo(
            name=""jupyterlab-lsp (frontend package)"",
            current_version=JUPYTERLAB_LSP_VERSION,
            locations=[
                VersionLocation(
                    path=JUPYTERLAB_LSP_PACKAGE,
                    template=NPM_PACKAGE_VERSION_TEMPLATE,
                ),
                VersionLocation(path=PIPELINE, template=""JS_JLLSP_VERSION: {version}""),
                VersionLocation(
                    path=META_PACKAGE, template=NPM_PACKAGE_VERSION_TEMPLATE
                ),
            ],
        ),
        PackageVersionInfo(
            name=""JupyterLab - exact"",
            current_version=JUPYTERLAB_VERSION,
            locations=[
                VersionLocation(
                    path=JUPYTERLAB_LSP_PACKAGE,
                    template='""@jupyterlab/application"": ""~{version}""',
                )
            ],
        ),
        PackageVersionInfo(
            name=""JupyterLab - range"",
            current_version=REQUIRED_JUPYTERLAB,
            locations=[
                VersionLocation(
                    path=Path(""binder/environment.yml""),
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=README,
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=README,
                    template=""JupyterLab {version}"",
                ),
                VersionLocation(
                    path=Path(""CONTRIBUTING.md""),
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=Path(""docs/rtd.yml""),
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=Path(""requirements/lab.txt""),
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=Path(""python_packages/jupyterlab_lsp/setup.cfg""),
                    template=""jupyterlab {version}"",
                ),
                VersionLocation(
                    path=Path("".github/workflows/job.test.yml""),
                    template=""lab: ['{version}']"",
                ),
            ],
        ),
    ]
    for package in packages:
        package.maybe_change_version(dry=dry)


if __name__ == ""__main__"":
    parser = ArgumentParser()
    parser.add_argument(
        ""--dry"",
        action=""store_true"",
        help=""do not perform the update, only show the changes"",
    )
    args = parser.parse_args()
    update_versions(dry=args.dry)
",CWE-22,179.0,1
"[% WRAPPER ""ui-header.html""
stylesheet=""ledgersmb.css""
include_stylesheet=[""system/setup.css""] %]
[% PROCESS elements.html %]
<body id=""setup-confirm-operation"" class=""lsmb [% dojo_theme %]"">
<div><div class=""setupconsole"">
<h2>[% text('Database Management Console') %]</h2>
[% # notice, message, and operation are all localized. %]
[% INCLUDE 'setup/ui-db-credentials.html' %]
<div class=""listtop"">[% text('Confirm Operation') %]</div>
<div id=""notice"">[% notice %]</div>
<div id=""message"">[% message %]</div>
<div id=""operation"">[% operation %]</div>
<form data-dojo-type=""lsmb/SimpleForm""
      action=""setup.pl""
      method=""POST""
      name=""confirm_operation"">
[% INCLUDE input element_data = {
    name = 'database'
    type = 'hidden'
   value = database
} %]
<div class=""inputrow"">
[% INCLUDE button element_data = {
    name = '__action'
   value = next_action
    type = 'submit'
   class = 'submit'
    text = text('Yes')
} %]
</div>
<div id=""sep"" class=""listheading"">[% text('Other Actions') %]</div>
[% IF next_action == 'rebuild_modules' %]
<div id=""copy-database"">
[% INCLUDE input element_data = {
    name = 'new_name'
    type = 'text'
   class = 'dbname'
   label = text('Copy to New Name') #'
}; %]
[% INCLUDE button element_data = {
    name = '__action'
   value = 'copy_db'
    type = 'submit'
   class = 'submit'
    text = text('Copy') #'
}; %]
</div>
<div id=""user"">
<div>[% text('Users') %]</div>
[% INCLUDE button element_data = {
    name = '__action'
   value = 'add_user'
    type = 'submit'
   class = 'submit'
    text = text('Add User') #'
}; %]
[% INCLUDE button element_data = {
    name = '__action'
   value = 'list_users'
    type = 'submit'
   class = 'submit'
    text = text('List Users') #'
}; %]
</div>
<div id=""templates"">
<div>[% text('Templates') %]</div>
[% INCLUDE button element_data = {
    name = '__action'
   value = 'load_templates'
    type = 'submit'
   class = 'submit'
    text = text('Load Templates') #'
};
INCLUDE input element_data = {
    name = ""only_templates""
   value = ""1""
    type = ""hidden""
}; %]
</div>
[% END %]
[% IF next_action != 'create_db' %]
<div id=""others"">[% text('Backup') %]</div>
<div class=""inputrow"">
[% INCLUDE button element_data = {
    name = '__action'
   value = 'backup_db'
    type = 'submit'
   class = 'submit'
    text = text('Backup DB') #'
} %]
[% INCLUDE button element_data = {
    name = '__action'
   value = 'backup_roles'
    type = 'submit'
   class = 'next'
    text = text('Backup Roles') #'
} %]
</div>
<div id=""diagnostics"">[% text('System diagnostics') %]</div>
<div class=""inputrow"">
[% INCLUDE button element_data = {
    name = '__action'
   value = 'system_info'
    type = 'submit'
   class = 'submit'
    text = text('System Info') #'
} %]
[% INCLUDE button element_data = {
    name = '__action'
   value = 'consistency'
    type = 'submit'
   class = 'submit'
    text = text('Check consistency') #'
} %]
</div>
[% END %]
</form>
[% IF lsmb_info %]
<table class='lsmb_info'>
  <thead>
  <tr><th colspan=""2"">[% text('LedgerSMB Database Statistics') %]</th></tr>
  <tr><th colspan=""2"">[% text('Row counts') %]</th></tr>
  </thead>
  <tbody>
  <tr><th>[% text('AP') %]</th><td>[% lsmb_info.ap_count %]</td></tr>
  <tr><th>[% text('AR') %]</th><td>[% lsmb_info.ar_count %]</td></tr>
  <tr><th>[% text('GL') %]</th><td>[% lsmb_info.gl_count %]</td></tr>
  <tr><th>[% text('Journal Lines') %]</th><td>[% lsmb_info.acc_trans_count %]</td></tr>
  <tr><th>[% text('Orders') %]</th><td>[% lsmb_info.oe_count %]</td></tr>
  <tr><th>[% text('Customer/Vendor Accounts') %]</th><td>[% lsmb_info.eca_count %]</td></tr>
  <tr><th>[% text('Transactions') %]</th><td>[% lsmb_info.transactions_count %]</td></tr>
  <tr><th>[% text('Users') %]</th><td>[% lsmb_info.users_count %]</td></tr>
  </tbody>
</table>
[% END %]
</div></div>
</body>
[% END %]
",CWE-352,140.0,1
"[% WRAPPER ""ui-header.html""
       stylesheet=""ledgersmb.css""
       include_stylesheet=[""system/setup.css""];
       PROCESS elements.html -%]
<body id=""setup-login"" class=""lsmb [% dojo_theme%]"">
  <div style=""width:100%;height:100%"">
    <div>
        <div class=""setupconsole"">
          <div id=""loading"">
                <img style=""display:block;position:absolute;margin:auto;top:50%;left:50%;transsform:translateX(-50%) translateY(-50%)""
                    src=""js/dijit/icons/images/loadingAnimation.gif""
                    alt=""If this text is showing, there's most likely a problem with the Dojo setup""
                    title=""Loading ...""
                  width=""20"" height=""20"" />
          </div>
            <div id=""logindiv"">
                <div class=""login"" align=""center"">
                    <a href=""http://www.ledgersmb.org/""
                    target=""_top"">
                    <img src=""images/ledgersmb.png""
                            class=""logo""
                            alt=""LedgerSMB Logo"" />
                    </a>
                    <h2 align=""center"" style=""margin-top: 0"">
                        [% version %]
                    </h2>
                    <div class=""listtop"">
                        [% text('Database administrator credentials') %]
                    </div>
                </div>
                <form id=""loginform""
                      name=""credentials""
                      style=""margin-top:1em"">
                  <div class=""login_form"">
                    [% select_hint = text('Select or Enter User');
                       INCLUDE select element_data = {
                                   name = 's_user'
                                   id = 's-user'
                                   options =  [ { value = 'lsmb_dbadmin',
                                                  text = 'lsmb_dbadmin'},
                                                { value = 'postgres',
                                                  text  = 'postgres'} ]
                                   class = 'username'
                                   tabindex = 1
                                   label = text('DB admin login')
                                   ""data-dojo-type"" = ""dijit/form/ComboBox""
                                   ""data-dojo-props"" = ""value:'$s_user', placeHolder:'$select_hint'""
                                    attributes = { autocomplete = 'off'}
                       };
                       INCLUDE input element_data = {
                                    name = 's_password'
                                    id = 's-password'
                                    value = s_password
                                    type = 'password'
                                    size = '15'
                                    class = 'password'
                                    tabindex = 2
                                    label = text('Password')
                                    attributes = { autocomplete = 'off'}
                       };
                       INCLUDE input element_data = {
                                    name = 'database'
                                    value = database
                                    type = 'text'
                                    size = '15'
                                    class = 'database'
                                    tabindex = 3
                                    label = text('Database')
                       } %]
                  </div>
                  <div class=""inputrow""
                       style=""text-align:right; padding-right: 4ex; margin-top: 1ex"">
                    <button data-dojo-type=""lsmb/SetupLoginButton""
                            class=""submit""
                            data-dojo-props=""action:'login'""
                            tabindex=""4""
                            >[% text('Login') %]</button>
                    <button data-dojo-type=""lsmb/SetupLoginButton""
                            class=""submit""
                            data-dojo-props=""action:'create_db'""
                            tabindex=""5""
                            >[% text('Create') %]</button>
                  </div>
                </form>
            </div>
        </div>
    </div>
  </div>
</body>
[% END %]
",CWE-352,91.0,1
"[% WRAPPER ""ui-header.html""
stylesheet=""ledgersmb.css""
include_stylesheet=[""system/setup.css""];
       PROCESS ""elements.html"";
       PROCESS ""dynatable.html""; %]
<body id=""setup-edit-user"" class=""[% dojo_theme %]"">
 <div><div class=""setupconsole"">
        <div class=""listtop"">
            [%
               IF request.pls_import;
                       text('Duplicate User Found: Importing User');
                       action = 'save_user';
                ELSIF user.user_id;
                      text('Editing User');
                      action = 'edit_user';
                ELSE;
                      text('New User');
                      action = 'save_user';
                END %]
        </div>

    <form data-dojo-type=""lsmb/SimpleForm"" method=""POST"" action=""[% request.script %]"">
      <input type=""hidden"" name=""id"" value=""[% request.id %]"" />
      <input type=""hidden"" name=""database"" value=""[% request.database %]"" />
        <table id=""user-data"">

            [% IF user.user_id and not request.pls_import %]
            <tr>
                <td>[% text('Username') %]</td>
                <td>
                    [% user.username;
                    INCLUDE input element_data = {
                            name  = 'username'
                            type  = 'hidden'
                            value = user.username
                    } %]
                </td>
            </tr>

            [% ELSE %]
            <tr>
                <td>[% text('Username') %]</td>
                <td>
                    <input type=""text"" name=""username"" value=""[% user.username %]"" required/>
                </td>
            </tr>
            [% END %]
            <tr>
                <td><label for=""password"">[% text('Password') %]</label>
                </td>
                <td>
                  [% PROCESS input element_data = {
                               type = ""password""
                               id   = ""password""
                               name = ""password""
                               autocomplete = ""off""
                  } %]
                </td>
            </tr>

            [% IF (request.pls_import == 1) OR !user.username %]
            <tr>
                <td>[% text('Import') %]</td>
                [%
                  IF request.pls_import;
                      importc1 = 'CHECKED';
                      importc0 = '';
                  ELSE;
                      importc1 = '';
                      importc0 = 'CHECKED';
                  END; %]
                <td><div class=""input_line""><div overflow=""auto"" class=""input_group"">
                  [% INCLUDE input element_data = {
                           label   = 'Yes'
                           value   = '1'
                           checked = importc1
                           name    = 'pls_import'
                           type    = 'radio'
                   } %]</div><div overflow=""auto"" class=""input_group"">[%
                   INCLUDE input element_data = {
                           label   = 'No'
                           value   = '0'
                           checked = importc0
                           name    = 'pls_import'
                           type    = 'radio'
                   } %]</div></div></td>
            </tr>
            [% END # unless employee.entity_id %]
        </table>
           [% IF user.username and not request.pls_import;
                PROCESS button element_data  = {
                         text = text('Reset Password') #'
                         name = '__action'
                         type = 'submit'
                        class = 'submit'
                  value = 'reset_password'
                  attributes = { autocomplete = ""off"" }
                };
           ELSE;
                PROCESS button element_data  = {
                         text = text('Add User') #'
                         name = '__action'
                         type = 'submit'
                        class = 'submit'
                        value = 'create_user'
                };
           END;
    %]
    </form>
    [% IF user.user_id and not request.pls_import%]
        <hr />
        <form data-dojo-type=""lsmb/SimpleForm"" name=""groups"" method=""POST"" action=""[% request.script %]"">
            <input type=""hidden"" name=""database"" value=""[% request.database %]"" />
            [% PROCESS input element_data = {
               type=""hidden""
               name=""id""
               value=request.id
              };
           %]
        <input type=""hidden"" name=""entity_id"" value=""[% entity_id %]""/>
           <div>
            <table id=""user-roles"">
                <!-- Groups section -->
                <tr>
                [% FOREACH role IN roles %]
                    <td>
                        [% rolcheck = undef;
                           IF user.roles.grep(role.name).size;
                              rolcheck = ""checked"";
                           END %]
                        [% PROCESS input element_data = {
                               type = ""checkbox""
                               label = role.description
                               value = 1
                               name = role.name
                               id = role.name
                               checked = rolcheck
                         }, label_pos = 1 %]
                    </td>
                [% IF loop.even() %]
                </tr>
                <tr>
                [% END %]
                [% END %]
                </tr>
            </table>

            <table>
                <tr>
                    <td>[% PROCESS button element_data = {
                          text = text('Save Groups') #'
                          class = ""submit""
                          name = ""__action""
                          value = ""save_user_roles""
                          'data-lsmb-doing' = text('Saving...')
                          'data-lsmb-done' = text('Saved')
                    } %]</td>
                </tr>
            </table></div>
        </form>
[% END %]
</div></div>
</body>
[% END %]
",CWE-352,165.0,1
"[% WRAPPER ""ui-header.html""
stylesheet=""ledgersmb.css""
include_stylesheet=[""system/setup.css""] %]
[% PROCESS elements.html %]
<body id=""setup-select-coa"" class=""lsmb [% dojo_theme %]"">
<div class=""setupconsole"">
<h2>[% text('Database Management Console') %]</h2>
<div><div class=""listtop"">[% title %]</div>
<form data-dojo-type=""lsmb/SimpleForm"" action=""setup.pl"" method=""POST"" name=""credentials"">
  <div id=""sep"" class=""listheading"">
    Pre-defined Chart-of-Accounts selection
  </div>

  [% IF coa_lc;
   INCLUDE input element_data = {
        name = 'coa_lc'
        type = 'hidden'
       value = coa_lc
         } ;
         %]
  <p>
    The selected country ('[% coa_lc %]') has the following charts
    predefined.
  </p>
  [% ELSE %]
  <p>
    Please select a country from the list of countries with predefined
    charts of accounts, or select Skip and define or import accounts and
    headings later. Please do take note that you want to load a chart
    for evaluation purposes as many functions depend on accounts of
    certain types being defined.
  </p>
  [% END %]
<div class=""inputrow"">
[% IF coa_lc;
    INCLUDE select element_data = {
         options = charts
            name = 'chart'
       text_attr = 'name'
      value_attr = 'name'
           label = text('Chart of accounts')
    };
    IF gifis.size > 0;
-%]
</div>
<div class=""inputrow"">
[%
       INCLUDE select element_data = {
         options = gifis
            name = 'gifi'
       text_attr = 'name'
      value_attr = 'name'
           label = text('GIFI')
       };
    END;
    IF sics.size > 0;
-%]
</div>
<div class=""inputrow"">
[%
       INCLUDE select element_data = {
         options = sics
            name = 'sic'
       text_attr = 'name'
      value_attr = 'name'
           label = text('SIC')
       };
    END;
   ELSE;
    INCLUDE select element_data = {
         options = coa_lcs
            name = 'coa_lc'
       text_attr = 'name'
      value_attr = 'code'
           label = text('Country') #'
    };
END %]
</div>
<div class=""inputrow"">
[% INCLUDE input element_data = {
    name = 'database'
   value = database
    type = 'hidden'
} %]
</div>
<div class=""inputrow"">
[% INCLUDE button element_data = {
    name = '__action'
   value = 'select_coa'
    type = 'submit'
   class = 'submit'
    text = text('Next')
} %]
</div>
<div class=""inputrow"">
[% INCLUDE button element_data = {
    name = '__action'
   value = 'skip_coa'
    type = 'submit'
   class = 'submit'
    text = text('Skip')
} %]
</div>
</form>
</div></div>
</body>
[% END %]
",CWE-352,108.0,1
"[% WRAPPER ""ui-header.html""
stylesheet=""ledgersmb.css""
include_stylesheet=[""system/setup.css""] %]
[% PROCESS elements.html %]
<body id=""setup-upgrade-info"" class=""lsmb [% dojo_theme %]"">
<div><div class=""setupconsole"">
<h2>[% text('Database Management Console') %]</h2>
<div class=""listtop"">[% text('Upgrade Info') %]</div>
<form data-dojo-type=""lsmb/SimpleForm""
      action=""setup.pl"" method=""POST""
      name=""upgrade_info"">
[% INCLUDE input element_data = {
    name = 'database'
    type = 'hidden'
   value = database
};
INCLUDE input element_data = {
    name = 'slschema'
    type = 'hidden'
   value = slschema
};
INCLUDE input element_data = {
    name = 'lsmbversion'
    type = 'hidden'
   value = lsmbversion
} %]
<div class=""form"">
<p>
  [% text('LedgerSMB has introduced three new system wide default values which ' _
              'you will need to set as part of the upgrade process.') %]
</p>
<p>
  [% text('In addition to these new defaults LedgerSMB 1.3 adds stricter ' _
              'checks on data validity in the database. Because of these stricter checks ' _
              'it''s no longer valid to leave companies without a country or customers ' _
              'without accounts receivable reference. The defaults you choose below will ' _
              'be used to add values where these are currently missing but required.') %]
</p>
<div class=""input_row"">
[% INCLUDE select element_data = {
                          options = default_country
                            name  = 'default_country'
                           label  = text('Default Country') #'
                            class = 'country'
} %]
</div>
[% IF default_ar.size > 1; %]
<div class=""input_row"">
<p>
  [% text('LedgerSMB supports multiple <em>Accounts receivable (AR)</em> accounts ' _
              'per company. One of those must be the system default. Please select ' _
              'your default below in case of multiple. If the list below is empty, ' _
              'your database is in an inconsistent state and needs to be fixed first.') %]
</p>
[% INCLUDE select element_data = {
                            name  = 'default_ar'
                           label  = text('Default AR') #'
                            class = 'accno'
                            options = default_ar
} %]
</div>
[% ELSE;
INCLUDE input element_data = {
    name = 'default_ar'
    type = 'hidden'
   value = default_ar
};
END %]
[% IF default_ap.size > 1; %]
<div class=""input_row"">
<p>
  [% text('LedgerSMB supports multiple <em>Accounts payable (AP)</em> accounts ' _
              'per company. One of those must be the system default. Please select ' _
              'your default below in case of multiple. If the list below is empty, ' _
              'your database is in an inconsistent state and needs to be fixed first.') %]
</p>
[% INCLUDE select element_data = {
                            name  = 'default_ap'
                           label  = text('Default AP') #'
                            class = 'accno'
                            options = default_ap
} %]
</div>
[% ELSE;
INCLUDE input element_data = {
    name = 'default_ap'
    type = 'hidden'
   value = default_ap
};
END %]
<div class=""input_row"">
<p>
  [% text('Note that the process invoked by hitting the button below might ' _
              'take long to complete as it will run the upgrade process and will ' _
              'copy all data from the 1.2 tables into the 1.3 tables.') %]
</p>
[% INCLUDE button element_data = {
    text = text('Upgrade')
    name = '__action'
   value = upgrade_action
    type = 'submit'
   class = 'submit'
} %]
</div>
</div>
</form>
</div></div>
</body>
[% END %]
",CWE-352,110.0,1
"import os
import platform
import sys

from setuptools import Extension, setup

min_glibc = (2, 9)


def check_libc():
    """"""Return False if we have glibc < 2.9 and should not build the C extension.""""""

    # Borrowed from pip internals
    # https://github.com/pypa/pip/blob/20.1.1/src/pip/_internal/utils/glibc.py#L21-L36
    try:
        # os.confstr(""CS_GNU_LIBC_VERSION"") returns a string like ""glibc 2.17"":
        libc_name, libc_version = os.confstr(""CS_GNU_LIBC_VERSION"").split()
    except (AttributeError, OSError, ValueError):
        # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
        return True

    if libc_name != ""glibc"":
        # Attempt to build with musl or other libc
        return True

    libc_version_tuple = tuple(int(x) for x in libc_version.split(""."")[:2])
    return libc_version_tuple >= min_glibc


cpython = platform.python_implementation() == ""CPython""
windows = sys.platform.startswith(""win"")
use_c_ext = os.environ.get(""CBOR2_BUILD_C_EXTENSION"", None)
if use_c_ext == ""1"":
    build_c_ext = True
elif use_c_ext == ""0"":
    build_c_ext = False
else:
    build_c_ext = cpython and (windows or check_libc())

# Enable GNU features for libc's like musl, should have no effect
# on Apple/BSDs
if build_c_ext and not windows:
    gnu_flag = [""-D_GNU_SOURCE""]
else:
    gnu_flag = []

if build_c_ext:
    _cbor2 = Extension(
        ""_cbor2"",
        # math.h routines are built-in to MSVCRT
        libraries=[""m""] if not windows else [],
        extra_compile_args=[""-std=c99""] + gnu_flag,
        sources=[
            ""source/module.c"",
            ""source/encoder.c"",
            ""source/decoder.c"",
            ""source/tags.c"",
            ""source/halffloat.c"",
        ],
        optional=True,
    )
    kwargs = {""ext_modules"": [_cbor2]}
else:
    kwargs = {}


setup(
    use_scm_version={""version_scheme"": ""guess-next-dev"", ""local_scheme"": ""dirty-tag""},
    setup_requires=[""setuptools >= 61"", ""setuptools_scm >= 6.4""],
    **kwargs,
)
",CWE-120,72.0,1
"from .base import AbstractClient
from .http import AsyncHTTPClient
from .http import HTTPClient
from .http import SyncHTTPClient
from .proxy import RemoteProxy

__all__ = [
    ""AsyncHTTPClient"",
    ""SyncHTTPClient"",
    ""HTTPClient"",
    ""AbstractClient"",
    ""RemoteProxy"",
]
",CWE-1188,14.0,1
"from __future__ import annotations

import importlib
import pathlib
import sys
import typing as t

import yaml

if t.TYPE_CHECKING:
    from _bentoml_sdk import Service

BENTO_YAML_FILENAME = ""bento.yaml""


def normalize_identifier(
    service_identifier: str,
    working_dir: str | None = None,
) -> tuple[str, pathlib.Path]:
    """"""
    Normalize a service identifier to a package:Service format, and return the bento
    path.

    valid identifiers:
    - package:Service                        # bentoml serve projects or normalized
    - package:Service.dependency             # bentocloud dependencies services
    - ~/bentoml/bentos/my_bento/version      # bentocloud entry service
    - ~/bentoml/bentos/my_bento/version/bento.yaml
    - bento1/bentofile.yaml                  # bentoml serve from multi-target projects
    - my_service:a7ab819                     # bentoml serve built bentos
    - package.py:Service
    - package.py:Service.dependency
    - .
    """"""
    if working_dir is not None:
        path = pathlib.Path(working_dir).joinpath(service_identifier)
    else:
        path = pathlib.Path(service_identifier)
    if path.exists():
        if path.is_file() and path.name == BENTO_YAML_FILENAME:
            # this is a bento.yaml file
            yaml_path = path
            bento_path = path.parent.joinpath(""src"")
        elif path.is_dir() and path.joinpath(BENTO_YAML_FILENAME).is_file():
            # this is a bento directory
            yaml_path = path.joinpath(BENTO_YAML_FILENAME)
            bento_path = path.joinpath(""src"")
        elif path.is_file() and path.name == ""bentofile.yaml"":
            # this is a bentofile.yaml file
            yaml_path = path
            bento_path = (
                pathlib.Path(working_dir) if working_dir is not None else path.parent
            )
        elif path.is_dir() and path.joinpath(""bentofile.yaml"").is_file():
            # this is a bento project directory
            yaml_path = path.joinpath(""bentofile.yaml"")
            bento_path = (
                pathlib.Path(working_dir) if working_dir is not None else path.parent
            )
        else:
            raise ValueError(f""found a path but not a bento: {service_identifier}"")

        with open(yaml_path, ""r"") as f:
            bento_yaml = yaml.safe_load(f)
        assert ""service"" in bento_yaml, ""service field is required in bento.yaml""
        return normalize_package(bento_yaml[""service""]), bento_path

    elif "":"" in service_identifier:
        # a python import str or a built bento in store

        # TODO(jiang): bento store configs are sdk configs, should be moved to sdk in the future
        from bentoml._internal.configuration.containers import BentoMLContainer
        from bentoml.exceptions import NotFound

        bento_store = BentoMLContainer.bento_store.get()

        try:
            bento = bento_store.get(service_identifier)
        except NotFound:
            # a python import str
            return normalize_package(service_identifier), pathlib.Path(
                working_dir if working_dir is not None else "".""
            )
        else:
            # a built bento in bento store

            yaml_path = pathlib.Path(bento.path).joinpath(BENTO_YAML_FILENAME)
            with open(yaml_path, ""r"") as f:
                bento_yaml = yaml.safe_load(f)
            assert ""service"" in bento_yaml, ""service field is required in bento.yaml""
            return normalize_package(bento_yaml[""service""]), yaml_path.parent.joinpath(
                ""src""
            )
    else:
        raise ValueError(f""invalid service: {service_identifier}"")


def import_service(
    service_identifier: str,
    bento_path: pathlib.Path | None = None,
) -> Service[t.Any]:
    """"""
    import a service from a service identifier, which should be normalized by
    `normalize_identifier` function.
    """"""
    from _bentoml_sdk import Service

    if bento_path is None:
        bento_path = pathlib.Path(""."").absolute()

    # patch python path if needed
    if bento_path != pathlib.Path("".""):
        # a project
        extra_python_path = str(bento_path.absolute())
        sys.path.insert(0, extra_python_path)
    else:
        # a project under current directory
        extra_python_path = None

    # patch model store if needed
    if (
        bento_path.parent.joinpath(BENTO_YAML_FILENAME).exists()
        and bento_path.parent.joinpath(""models"").exists()
    ):
        from bentoml._internal.configuration.containers import BentoMLContainer
        from bentoml._internal.models import ModelStore

        original_model_store = BentoMLContainer.model_store.get()

        BentoMLContainer.model_store.set(
            ModelStore((bento_path.parent.joinpath(""models"").absolute()))
        )
    else:
        original_model_store = None

    try:
        module_name, _, attrs_str = service_identifier.partition("":"")

        assert (
            module_name and attrs_str
        ), f'Invalid import target ""{service_identifier}"", must format as ""<module>:<attribute>""'

        module = importlib.import_module(module_name)
        root_service_name, _, depend_path = attrs_str.partition(""."")
        root_service = getattr(module, root_service_name)

        assert isinstance(
            root_service, Service
        ), f'import target ""{module_name}:{attrs_str}"" is not a bentoml.Service instance'

        if not depend_path:
            return root_service  # type: ignore
        else:
            return root_service.find_dependent(depend_path)

    except (ImportError, AttributeError, KeyError, AssertionError) as e:
        sys_path = sys.path.copy()
        if extra_python_path is not None:
            sys.path.remove(extra_python_path)

        if original_model_store is not None:
            from bentoml._internal.configuration.containers import BentoMLContainer

            BentoMLContainer.model_store.set(original_model_store)
        from bentoml.exceptions import ImportServiceError

        raise ImportServiceError(
            f'Failed to import service ""{service_identifier}"": {e}, sys.path: {sys_path}, cwd: {pathlib.Path.cwd()}'
        ) from None


def normalize_package(service_identifier: str) -> str:
    """"""
    service.py:Service -> service:Service
    """"""
    package, _, service_path = service_identifier.partition("":"")
    if package.endswith("".py""):
        package = package[:-3]
    return "":"".join([package, service_path])
",CWE-1188,180.0,1
"from fastapi import HTTPException
from ascii_colors import ASCIIColors
from urllib.parse import urlparse
import socket
from pathlib import Path
from typing import List
import os
import re
import platform

def check_access(lollmsElfServer, client_id):
    client = lollmsElfServer.session.get_client(client_id)
    if not client:
        raise HTTPException(status_code=400, detail=f""Not accessible without id"")
    return client

def sanitize_code(code):
    # Split the code by newline characters
    lines = code.split('\n')
    
    # Keep only the first non-empty line and remove any potential malicious commands
    sanitized_code = """"
    
    for line in lines:
        if line.strip():  # Check if the line is not empty
            # Check for potential malicious commands
            if platform.system() == ""Windows"":
                if ""&"" in line:
                    line = line.split(""&"")[0]  # Keep only the first command before the ampersand
                if ""|"" in line:
                    line = line.split(""|"")[0]  # Keep only the first command before the pipe
            else:  # Linux
                if "";"" in line:
                    line = line.split("";"")[0]  # Keep only the first command before the semicolon
                if ""|"" in line:
                    line = line.split(""|"")[0]  # Keep only the first command before the pipe
            sanitized_code = line
            break
    
    return sanitized_code

def sanitize_path(path:str, allow_absolute_path:bool=False, error_text=""Absolute database path detected"", exception_text=""Detected an attempt of path traversal. Are you kidding me?""):
    if path is None:
        return path
    
    # Regular expression to detect patterns like ""...."" and multiple forward slashes
    suspicious_patterns = re.compile(r'(\.\.+)|(/+/)')
    
    if suspicious_patterns.search(str(path)) or ((not allow_absolute_path) and Path(path).is_absolute()):
        ASCIIColors.error(error_text)
        raise HTTPException(status_code=400, detail=exception_text)

    if not allow_absolute_path:
        path = path.lstrip('/')

    return path
    
def sanitize_path_from_endpoint(path: str, error_text=""A suspected LFI attack detected. The path sent to the server has suspicious elements in it!"", exception_text=""Invalid path!""):
    # Fix the case of ""/"" at the beginning on the path
    if path is None:
        return path
    
    # Regular expression to detect patterns like ""...."" and multiple forward slashes
    suspicious_patterns = re.compile(r'(\.\.+)|(/+/)')
    
    if suspicious_patterns.search(path) or Path(path).is_absolute():
        ASCIIColors.error(error_text)
        raise HTTPException(status_code=400, detail=exception_text)
    
    path = path.lstrip('/')
    return path


def forbid_remote_access(lollmsElfServer, exception_text = ""This functionality is forbidden if the server is exposed""):
    if not lollmsElfServer.config.force_accept_remote_access and lollmsElfServer.config.host!=""localhost"" and lollmsElfServer.config.host!=""127.0.0.1"":
        raise Exception(exception_text)

def validate_path(path, allowed_paths:List[str|Path]):
    # Convert the path to an absolute path
    abs_path = os.path.realpath(str(path))

    # Iterate over the allowed paths
    for allowed_path in allowed_paths:
        # Convert the allowed path to an absolute path
        abs_allowed_path = os.path.realpath(allowed_path)

        # Check if the absolute path starts with the absolute allowed path
        if abs_path.startswith(abs_allowed_path):
            return True

    # If the path is not within any of the allowed paths, return False
    return False

def is_allowed_url(url):
    # Check if url is legit
    parsed_url = urlparse(url)        
    # Check if scheme is not http or https, return False
    if parsed_url.scheme not in ['http', 'https']:
        return False
    
    hostname = parsed_url.hostname
    
    try:
        ip_address = socket.gethostbyname(hostname)
    except socket.gaierror:
        return False
    
    return not ip_address.startswith('127.') or ip_address.startswith('192.168.') or ip_address.startswith('10.') or ip_address.startswith('172.')


if __name__==""__main__"":
    sanitize_path_from_endpoint(""main"")
    sanitize_path_from_endpoint(""cat/main"")
    print(""Main passed"")
    sanitize_path_from_endpoint("".../user"")
    print(""hi"")",CWE-29,116.0,1
"""""""
File: lollms_web_ui.py
Author: ParisNeo
Description: Singleton class for the LoLLMS web UI.

This file is the entry point to the webui.
""""""

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from lollms.app import LollmsApplication
from lollms.paths import LollmsPaths
from lollms.main_config import LOLLMSConfig
from lollms.server.elf_server import LOLLMSElfServer
from pathlib import Path
from ascii_colors import ASCIIColors
import socketio
import uvicorn
import argparse
from socketio import ASGIApp


sio = socketio.AsyncServer(async_mode=""asgi"")
app = FastAPI(title=""LoLLMS"", description=""This is the LoLLMS-Elf API documentation"")

def main():
    # Parsong parameters
    parser = argparse.ArgumentParser(description=""Start the chatbot FastAPI app."")
    
    parser.add_argument(
        ""--host"", type=str, default=None, help=""the hostname to listen on""
    )
    parser.add_argument(""--port"", type=int, default=None, help=""the port to listen on"")

    args = parser.parse_args()
    root_path = Path(__file__).parent
    lollms_paths = LollmsPaths.find_paths(tool_prefix=""elf_"",force_local=True, custom_default_cfg_path=""configs/config.yaml"")
    config = LOLLMSConfig.autoload(lollms_paths)
    if args.host:
        config.host=args.host
    if args.port:
        config.port=args.port

    LOLLMSElfServer.build_instance(config=config, lollms_paths=lollms_paths, socketio=sio)
    from lollms.server.endpoints.lollms_binding_files_server import router as lollms_binding_files_server_router
    from lollms.server.endpoints.lollms_infos import router as lollms_infos_router
    from lollms.server.endpoints.lollms_hardware_infos import router as lollms_hardware_infos_router
    from lollms.server.endpoints.lollms_binding_infos import router as lollms_binding_infos_router
    from lollms.server.endpoints.lollms_models_infos import router as lollms_models_infos_router
    from lollms.server.endpoints.lollms_personalities_infos import router as lollms_personalities_infos_router
    from lollms.server.endpoints.lollms_extensions_infos import router as lollms_extensions_infos_router

    from lollms.server.endpoints.lollms_configuration_infos import router as lollms_configuration_infos_router
    

    
    from lollms.server.endpoints.lollms_generator import router as lollms_generator_router
    

    from lollms.server.events.lollms_generation_events import add_events as lollms_generation_events_add
    from lollms.server.events.lollms_personality_events import add_events as lollms_personality_events_add
    from lollms.server.events.lollms_model_events import add_events as lollms_model_events_add
    #from lollms.server.events.lollms_rag_events import add_events as lollms_rag_events_add
    

    app.include_router(lollms_binding_files_server_router)
    app.include_router(lollms_infos_router)
    app.include_router(lollms_hardware_infos_router)
    app.include_router(lollms_binding_infos_router)
    app.include_router(lollms_models_infos_router)
    app.include_router(lollms_personalities_infos_router)
    app.include_router(lollms_extensions_infos_router)
    
    
    app.include_router(lollms_generator_router)

    app.include_router(lollms_configuration_infos_router)
    


    lollms_generation_events_add(sio)
    lollms_personality_events_add(sio)
    lollms_model_events_add(sio)
    #lollms_rag_events_add(sio)

    app = ASGIApp(socketio_server=sio, other_asgi_app=app)


    uvicorn.run(app, host=config.host, port=config.port)

if __name__ == ""__main__"":
    main()",CWE-29,92.0,1
"from flask import blueprints, request, jsonify, send_file, make_response
from src.logger import Logger, route_logger
from src.config import Config
from src.project import ProjectManager
from ..state import AgentState

import os

project_bp = blueprints.Blueprint(""project"", __name__)

logger = Logger()
manager = ProjectManager()


# Project APIs
@project_bp.route(""/api/create-project"", methods=[""POST""])
@route_logger(logger)
def create_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.create_project(project_name)
    return jsonify({""message"": ""Project created""})


@project_bp.route(""/api/delete-project"", methods=[""POST""])
@route_logger(logger)
def delete_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.delete_project(project_name)
    AgentState().delete_state(project_name)
    return jsonify({""message"": ""Project deleted""})


@project_bp.route(""/api/download-project"", methods=[""GET""])
@route_logger(logger)
def download_project():
    project_name = request.args.get(""project_name"")
    manager.project_to_zip(project_name)
    project_path = manager.get_zip_path(project_name)
    return send_file(project_path, as_attachment=False)


@project_bp.route(""/api/download-project-pdf"", methods=[""GET""])
@route_logger(logger)
def download_project_pdf():
    project_name = request.args.get(""project_name"")
    pdf_dir = Config().get_pdfs_dir()
    pdf_path = os.path.join(pdf_dir, f""{project_name}.pdf"")

    response = make_response(send_file(pdf_path))
    response.headers['Content-Type'] = 'project_bplication/pdf'
    return response
",CWE-73,54.0,1
"from flask import blueprints, request, jsonify, send_file, make_response
from src.logger import Logger, route_logger
from src.config import Config
from src.project import ProjectManager
from ..state import AgentState

import os

project_bp = blueprints.Blueprint(""project"", __name__)

logger = Logger()
manager = ProjectManager()


# Project APIs
@project_bp.route(""/api/create-project"", methods=[""POST""])
@route_logger(logger)
def create_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.create_project(project_name)
    return jsonify({""message"": ""Project created""})


@project_bp.route(""/api/delete-project"", methods=[""POST""])
@route_logger(logger)
def delete_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.delete_project(project_name)
    AgentState().delete_state(project_name)
    return jsonify({""message"": ""Project deleted""})


@project_bp.route(""/api/download-project"", methods=[""GET""])
@route_logger(logger)
def download_project():
    project_name = request.args.get(""project_name"")
    manager.project_to_zip(project_name)
    project_path = manager.get_zip_path(project_name)
    return send_file(project_path, as_attachment=False)


@project_bp.route(""/api/download-project-pdf"", methods=[""GET""])
@route_logger(logger)
def download_project_pdf():
    project_name = request.args.get(""project_name"")
    pdf_dir = Config().get_pdfs_dir()
    pdf_path = os.path.join(pdf_dir, f""{project_name}.pdf"")

    response = make_response(send_file(pdf_path))
    response.headers['Content-Type'] = 'project_bplication/pdf'
    return response
",CWE-22,54.0,1
"from flask import blueprints, request, jsonify, send_file, make_response
from src.logger import Logger, route_logger
from src.config import Config
from src.project import ProjectManager
from ..state import AgentState

import os

project_bp = blueprints.Blueprint(""project"", __name__)

logger = Logger()
manager = ProjectManager()


# Project APIs
@project_bp.route(""/api/create-project"", methods=[""POST""])
@route_logger(logger)
def create_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.create_project(project_name)
    return jsonify({""message"": ""Project created""})


@project_bp.route(""/api/delete-project"", methods=[""POST""])
@route_logger(logger)
def delete_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.delete_project(project_name)
    AgentState().delete_state(project_name)
    return jsonify({""message"": ""Project deleted""})


@project_bp.route(""/api/download-project"", methods=[""GET""])
@route_logger(logger)
def download_project():
    project_name = request.args.get(""project_name"")
    manager.project_to_zip(project_name)
    project_path = manager.get_zip_path(project_name)
    return send_file(project_path, as_attachment=False)


@project_bp.route(""/api/download-project-pdf"", methods=[""GET""])
@route_logger(logger)
def download_project_pdf():
    project_name = request.args.get(""project_name"")
    pdf_dir = Config().get_pdfs_dir()
    pdf_path = os.path.join(pdf_dir, f""{project_name}.pdf"")

    response = make_response(send_file(pdf_path))
    response.headers['Content-Type'] = 'project_bplication/pdf'
    return response
",CWE-346,54.0,1
"from flask import blueprints, request, jsonify, send_file, make_response
from src.logger import Logger, route_logger
from src.config import Config
from src.project import ProjectManager
from ..state import AgentState

import os

project_bp = blueprints.Blueprint(""project"", __name__)

logger = Logger()
manager = ProjectManager()


# Project APIs
@project_bp.route(""/api/create-project"", methods=[""POST""])
@route_logger(logger)
def create_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.create_project(project_name)
    return jsonify({""message"": ""Project created""})


@project_bp.route(""/api/delete-project"", methods=[""POST""])
@route_logger(logger)
def delete_project():
    data = request.json
    project_name = data.get(""project_name"")
    manager.delete_project(project_name)
    AgentState().delete_state(project_name)
    return jsonify({""message"": ""Project deleted""})


@project_bp.route(""/api/download-project"", methods=[""GET""])
@route_logger(logger)
def download_project():
    project_name = request.args.get(""project_name"")
    manager.project_to_zip(project_name)
    project_path = manager.get_zip_path(project_name)
    return send_file(project_path, as_attachment=False)


@project_bp.route(""/api/download-project-pdf"", methods=[""GET""])
@route_logger(logger)
def download_project_pdf():
    project_name = request.args.get(""project_name"")
    pdf_dir = Config().get_pdfs_dir()
    pdf_path = os.path.join(pdf_dir, f""{project_name}.pdf"")

    response = make_response(send_file(pdf_path))
    response.headers['Content-Type'] = 'project_bplication/pdf'
    return response
",CWE-79,54.0,1
"import os
import json
import zipfile
from datetime import datetime
from typing import Optional
from src.socket_instance import emit_agent
from sqlmodel import Field, Session, SQLModel, create_engine
from src.config import Config


class Projects(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    message_stack_json: str


class ProjectManager:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.project_path = config.get_projects_dir()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_message(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""from_devika"": True,
            ""message"": None,
            ""timestamp"": timestamp
        }

    def create_project(self, project: str):
        with Session(self.engine) as session:
            project_state = Projects(project=project, message_stack_json=json.dumps([]))
            session.add(project_state)
            session.commit()

    def delete_project(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                session.delete(project_state)
                session.commit()

    def add_message_to_project(self, project: str, message: dict):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                message_stack.append(message)
                project_state.message_stack_json = json.dumps(message_stack)
                session.commit()
            else:
                message_stack = [message]
                project_state = Projects(project=project, message_stack_json=json.dumps(message_stack))
                session.add(project_state)
                session.commit()

    def add_message_from_devika(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def add_message_from_user(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        new_message[""from_devika""] = False
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def get_messages(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                return json.loads(project_state.message_stack_json)
            return None

    def get_latest_message_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if not message[""from_devika""]:
                        return message
            return None

    def validate_last_message_is_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                if message_stack:
                    return not message_stack[-1][""from_devika""]
            return False

    def get_latest_message_from_devika(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if message[""from_devika""]:
                        return message
            return None

    def get_project_list(self):
        with Session(self.engine) as session:
            projects = session.query(Projects).all()
            return [project.project for project in projects]

    def get_all_messages_formatted(self, project: str):
        formatted_messages = []

        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in message_stack:
                    if message[""from_devika""]:
                        formatted_messages.append(f""Devika: {message['message']}"")
                    else:
                        formatted_messages.append(f""User: {message['message']}"")

            return formatted_messages

    def get_project_path(self, project: str):
        return os.path.join(self.project_path, project.lower().replace("" "", ""-""))

    def project_to_zip(self, project: str):
        project_path = self.get_project_path(project)
        zip_path = f""{project_path}.zip""

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    relative_path = os.path.relpath(os.path.join(root, file), os.path.join(project_path, '..'))
                    zipf.write(os.path.join(root, file), arcname=relative_path)

        return zip_path

    def get_zip_path(self, project: str):
        return f""{self.get_project_path(project)}.zip""
",CWE-73,147.0,1
"import os
import json
import zipfile
from datetime import datetime
from typing import Optional
from src.socket_instance import emit_agent
from sqlmodel import Field, Session, SQLModel, create_engine
from src.config import Config


class Projects(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    message_stack_json: str


class ProjectManager:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.project_path = config.get_projects_dir()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_message(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""from_devika"": True,
            ""message"": None,
            ""timestamp"": timestamp
        }

    def create_project(self, project: str):
        with Session(self.engine) as session:
            project_state = Projects(project=project, message_stack_json=json.dumps([]))
            session.add(project_state)
            session.commit()

    def delete_project(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                session.delete(project_state)
                session.commit()

    def add_message_to_project(self, project: str, message: dict):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                message_stack.append(message)
                project_state.message_stack_json = json.dumps(message_stack)
                session.commit()
            else:
                message_stack = [message]
                project_state = Projects(project=project, message_stack_json=json.dumps(message_stack))
                session.add(project_state)
                session.commit()

    def add_message_from_devika(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def add_message_from_user(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        new_message[""from_devika""] = False
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def get_messages(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                return json.loads(project_state.message_stack_json)
            return None

    def get_latest_message_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if not message[""from_devika""]:
                        return message
            return None

    def validate_last_message_is_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                if message_stack:
                    return not message_stack[-1][""from_devika""]
            return False

    def get_latest_message_from_devika(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if message[""from_devika""]:
                        return message
            return None

    def get_project_list(self):
        with Session(self.engine) as session:
            projects = session.query(Projects).all()
            return [project.project for project in projects]

    def get_all_messages_formatted(self, project: str):
        formatted_messages = []

        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in message_stack:
                    if message[""from_devika""]:
                        formatted_messages.append(f""Devika: {message['message']}"")
                    else:
                        formatted_messages.append(f""User: {message['message']}"")

            return formatted_messages

    def get_project_path(self, project: str):
        return os.path.join(self.project_path, project.lower().replace("" "", ""-""))

    def project_to_zip(self, project: str):
        project_path = self.get_project_path(project)
        zip_path = f""{project_path}.zip""

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    relative_path = os.path.relpath(os.path.join(root, file), os.path.join(project_path, '..'))
                    zipf.write(os.path.join(root, file), arcname=relative_path)

        return zip_path

    def get_zip_path(self, project: str):
        return f""{self.get_project_path(project)}.zip""
",CWE-22,147.0,1
"import os
import json
import zipfile
from datetime import datetime
from typing import Optional
from src.socket_instance import emit_agent
from sqlmodel import Field, Session, SQLModel, create_engine
from src.config import Config


class Projects(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    message_stack_json: str


class ProjectManager:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.project_path = config.get_projects_dir()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_message(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""from_devika"": True,
            ""message"": None,
            ""timestamp"": timestamp
        }

    def create_project(self, project: str):
        with Session(self.engine) as session:
            project_state = Projects(project=project, message_stack_json=json.dumps([]))
            session.add(project_state)
            session.commit()

    def delete_project(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                session.delete(project_state)
                session.commit()

    def add_message_to_project(self, project: str, message: dict):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                message_stack.append(message)
                project_state.message_stack_json = json.dumps(message_stack)
                session.commit()
            else:
                message_stack = [message]
                project_state = Projects(project=project, message_stack_json=json.dumps(message_stack))
                session.add(project_state)
                session.commit()

    def add_message_from_devika(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def add_message_from_user(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        new_message[""from_devika""] = False
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def get_messages(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                return json.loads(project_state.message_stack_json)
            return None

    def get_latest_message_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if not message[""from_devika""]:
                        return message
            return None

    def validate_last_message_is_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                if message_stack:
                    return not message_stack[-1][""from_devika""]
            return False

    def get_latest_message_from_devika(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if message[""from_devika""]:
                        return message
            return None

    def get_project_list(self):
        with Session(self.engine) as session:
            projects = session.query(Projects).all()
            return [project.project for project in projects]

    def get_all_messages_formatted(self, project: str):
        formatted_messages = []

        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in message_stack:
                    if message[""from_devika""]:
                        formatted_messages.append(f""Devika: {message['message']}"")
                    else:
                        formatted_messages.append(f""User: {message['message']}"")

            return formatted_messages

    def get_project_path(self, project: str):
        return os.path.join(self.project_path, project.lower().replace("" "", ""-""))

    def project_to_zip(self, project: str):
        project_path = self.get_project_path(project)
        zip_path = f""{project_path}.zip""

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    relative_path = os.path.relpath(os.path.join(root, file), os.path.join(project_path, '..'))
                    zipf.write(os.path.join(root, file), arcname=relative_path)

        return zip_path

    def get_zip_path(self, project: str):
        return f""{self.get_project_path(project)}.zip""
",CWE-346,147.0,1
"import os
import json
import zipfile
from datetime import datetime
from typing import Optional
from src.socket_instance import emit_agent
from sqlmodel import Field, Session, SQLModel, create_engine
from src.config import Config


class Projects(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    message_stack_json: str


class ProjectManager:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.project_path = config.get_projects_dir()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_message(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""from_devika"": True,
            ""message"": None,
            ""timestamp"": timestamp
        }

    def create_project(self, project: str):
        with Session(self.engine) as session:
            project_state = Projects(project=project, message_stack_json=json.dumps([]))
            session.add(project_state)
            session.commit()

    def delete_project(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                session.delete(project_state)
                session.commit()

    def add_message_to_project(self, project: str, message: dict):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                message_stack.append(message)
                project_state.message_stack_json = json.dumps(message_stack)
                session.commit()
            else:
                message_stack = [message]
                project_state = Projects(project=project, message_stack_json=json.dumps(message_stack))
                session.add(project_state)
                session.commit()

    def add_message_from_devika(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def add_message_from_user(self, project: str, message: str):
        new_message = self.new_message()
        new_message[""message""] = message
        new_message[""from_devika""] = False
        emit_agent(""server-message"", {""messages"": new_message})
        self.add_message_to_project(project, new_message)

    def get_messages(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                return json.loads(project_state.message_stack_json)
            return None

    def get_latest_message_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if not message[""from_devika""]:
                        return message
            return None

    def validate_last_message_is_from_user(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                if message_stack:
                    return not message_stack[-1][""from_devika""]
            return False

    def get_latest_message_from_devika(self, project: str):
        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in reversed(message_stack):
                    if message[""from_devika""]:
                        return message
            return None

    def get_project_list(self):
        with Session(self.engine) as session:
            projects = session.query(Projects).all()
            return [project.project for project in projects]

    def get_all_messages_formatted(self, project: str):
        formatted_messages = []

        with Session(self.engine) as session:
            project_state = session.query(Projects).filter(Projects.project == project).first()
            if project_state:
                message_stack = json.loads(project_state.message_stack_json)
                for message in message_stack:
                    if message[""from_devika""]:
                        formatted_messages.append(f""Devika: {message['message']}"")
                    else:
                        formatted_messages.append(f""User: {message['message']}"")

            return formatted_messages

    def get_project_path(self, project: str):
        return os.path.join(self.project_path, project.lower().replace("" "", ""-""))

    def project_to_zip(self, project: str):
        project_path = self.get_project_path(project)
        zip_path = f""{project_path}.zip""

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(project_path):
                for file in files:
                    relative_path = os.path.relpath(os.path.join(root, file), os.path.join(project_path, '..'))
                    zipf.write(os.path.join(root, file), arcname=relative_path)

        return zip_path

    def get_zip_path(self, project: str):
        return f""{self.get_project_path(project)}.zip""
",CWE-79,147.0,1
"import json
import os
from datetime import datetime
from typing import Optional
from sqlmodel import Field, Session, SQLModel, create_engine
from src.socket_instance import emit_agent
from src.config import Config


class AgentStateModel(SQLModel, table=True):
    __tablename__ = ""agent_state""

    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    state_stack_json: str


class AgentState:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_state(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""internal_monologue"": '',
            ""browser_session"": {
                ""url"": None,
                ""screenshot"": None
            },
            ""terminal_session"": {
                ""command"": None,
                ""output"": None,
                ""title"": None
            },
            ""step"": int(),
            ""message"": None,
            ""completed"": False,
            ""agent_is_active"": True,
            ""token_usage"": 0,
            ""timestamp"": timestamp
        }

    def create_state(self, project: str):
        with Session(self.engine) as session:
            new_state = self.new_state()
            new_state[""step""] = 1
            new_state[""internal_monologue""] = ""I'm starting the work...""
            agent_state = AgentStateModel(project=project, state_stack_json=json.dumps([new_state]))
            session.add(agent_state)
            session.commit()
            emit_agent(""agent-state"", [new_state])

    def delete_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).all()
            if agent_state:
                for state in agent_state:
                    session.delete(state)
                session.commit()

    def add_to_current_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack.append(state)
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_current_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)
            return None

    def update_latest_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1] = state
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_latest_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1]
            return None

    def set_agent_active(self, project: str, is_active: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""agent_is_active""] = is_active
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""agent_is_active""] = is_active
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_active(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""agent_is_active""]
            return None

    def set_agent_completed(self, project: str, is_completed: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""internal_monologue""] = ""Agent has completed the task.""
                state_stack[-1][""completed""] = is_completed
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""completed""] = is_completed
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_completed(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""completed""]
            return None
            
    def update_token_usage(self, project: str, token_usage: int):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""token_usage""] += token_usage
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""token_usage""] = token_usage
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()

    def get_latest_token_usage(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""token_usage""]
            return 0

    def get_project_files(self, project_name: str):
        if not project_name:
            return []
        project_directory = ""-"".join(project_name.split("" ""))
        directory = os.path.join(os.getcwd(), 'data', 'projects', project_directory) 
        if(not os.path.exists(directory)):
            return []
        files = []
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_relative_path = os.path.relpath(root, directory)
                if file_relative_path == '.': file_relative_path = ''
                file_path = os.path.join(file_relative_path, filename)
                print(""file_path"",file_path)
                try:
                    with open(os.path.join(root, filename), 'r') as file:
                        print(""File:"", filename)
                        files.append({
                            ""file"": file_path,
                            ""code"": file.read()
                        })
                except Exception as e:
                    print(f""Error reading file {filename}: {e}"")
        return files",CWE-73,201.0,1
"import json
import os
from datetime import datetime
from typing import Optional
from sqlmodel import Field, Session, SQLModel, create_engine
from src.socket_instance import emit_agent
from src.config import Config


class AgentStateModel(SQLModel, table=True):
    __tablename__ = ""agent_state""

    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    state_stack_json: str


class AgentState:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_state(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""internal_monologue"": '',
            ""browser_session"": {
                ""url"": None,
                ""screenshot"": None
            },
            ""terminal_session"": {
                ""command"": None,
                ""output"": None,
                ""title"": None
            },
            ""step"": int(),
            ""message"": None,
            ""completed"": False,
            ""agent_is_active"": True,
            ""token_usage"": 0,
            ""timestamp"": timestamp
        }

    def create_state(self, project: str):
        with Session(self.engine) as session:
            new_state = self.new_state()
            new_state[""step""] = 1
            new_state[""internal_monologue""] = ""I'm starting the work...""
            agent_state = AgentStateModel(project=project, state_stack_json=json.dumps([new_state]))
            session.add(agent_state)
            session.commit()
            emit_agent(""agent-state"", [new_state])

    def delete_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).all()
            if agent_state:
                for state in agent_state:
                    session.delete(state)
                session.commit()

    def add_to_current_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack.append(state)
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_current_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)
            return None

    def update_latest_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1] = state
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_latest_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1]
            return None

    def set_agent_active(self, project: str, is_active: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""agent_is_active""] = is_active
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""agent_is_active""] = is_active
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_active(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""agent_is_active""]
            return None

    def set_agent_completed(self, project: str, is_completed: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""internal_monologue""] = ""Agent has completed the task.""
                state_stack[-1][""completed""] = is_completed
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""completed""] = is_completed
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_completed(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""completed""]
            return None
            
    def update_token_usage(self, project: str, token_usage: int):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""token_usage""] += token_usage
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""token_usage""] = token_usage
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()

    def get_latest_token_usage(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""token_usage""]
            return 0

    def get_project_files(self, project_name: str):
        if not project_name:
            return []
        project_directory = ""-"".join(project_name.split("" ""))
        directory = os.path.join(os.getcwd(), 'data', 'projects', project_directory) 
        if(not os.path.exists(directory)):
            return []
        files = []
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_relative_path = os.path.relpath(root, directory)
                if file_relative_path == '.': file_relative_path = ''
                file_path = os.path.join(file_relative_path, filename)
                print(""file_path"",file_path)
                try:
                    with open(os.path.join(root, filename), 'r') as file:
                        print(""File:"", filename)
                        files.append({
                            ""file"": file_path,
                            ""code"": file.read()
                        })
                except Exception as e:
                    print(f""Error reading file {filename}: {e}"")
        return files",CWE-22,201.0,1
"import json
import os
from datetime import datetime
from typing import Optional
from sqlmodel import Field, Session, SQLModel, create_engine
from src.socket_instance import emit_agent
from src.config import Config


class AgentStateModel(SQLModel, table=True):
    __tablename__ = ""agent_state""

    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    state_stack_json: str


class AgentState:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_state(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""internal_monologue"": '',
            ""browser_session"": {
                ""url"": None,
                ""screenshot"": None
            },
            ""terminal_session"": {
                ""command"": None,
                ""output"": None,
                ""title"": None
            },
            ""step"": int(),
            ""message"": None,
            ""completed"": False,
            ""agent_is_active"": True,
            ""token_usage"": 0,
            ""timestamp"": timestamp
        }

    def create_state(self, project: str):
        with Session(self.engine) as session:
            new_state = self.new_state()
            new_state[""step""] = 1
            new_state[""internal_monologue""] = ""I'm starting the work...""
            agent_state = AgentStateModel(project=project, state_stack_json=json.dumps([new_state]))
            session.add(agent_state)
            session.commit()
            emit_agent(""agent-state"", [new_state])

    def delete_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).all()
            if agent_state:
                for state in agent_state:
                    session.delete(state)
                session.commit()

    def add_to_current_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack.append(state)
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_current_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)
            return None

    def update_latest_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1] = state
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_latest_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1]
            return None

    def set_agent_active(self, project: str, is_active: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""agent_is_active""] = is_active
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""agent_is_active""] = is_active
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_active(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""agent_is_active""]
            return None

    def set_agent_completed(self, project: str, is_completed: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""internal_monologue""] = ""Agent has completed the task.""
                state_stack[-1][""completed""] = is_completed
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""completed""] = is_completed
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_completed(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""completed""]
            return None
            
    def update_token_usage(self, project: str, token_usage: int):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""token_usage""] += token_usage
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""token_usage""] = token_usage
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()

    def get_latest_token_usage(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""token_usage""]
            return 0

    def get_project_files(self, project_name: str):
        if not project_name:
            return []
        project_directory = ""-"".join(project_name.split("" ""))
        directory = os.path.join(os.getcwd(), 'data', 'projects', project_directory) 
        if(not os.path.exists(directory)):
            return []
        files = []
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_relative_path = os.path.relpath(root, directory)
                if file_relative_path == '.': file_relative_path = ''
                file_path = os.path.join(file_relative_path, filename)
                print(""file_path"",file_path)
                try:
                    with open(os.path.join(root, filename), 'r') as file:
                        print(""File:"", filename)
                        files.append({
                            ""file"": file_path,
                            ""code"": file.read()
                        })
                except Exception as e:
                    print(f""Error reading file {filename}: {e}"")
        return files",CWE-346,201.0,1
"import json
import os
from datetime import datetime
from typing import Optional
from sqlmodel import Field, Session, SQLModel, create_engine
from src.socket_instance import emit_agent
from src.config import Config


class AgentStateModel(SQLModel, table=True):
    __tablename__ = ""agent_state""

    id: Optional[int] = Field(default=None, primary_key=True)
    project: str
    state_stack_json: str


class AgentState:
    def __init__(self):
        config = Config()
        sqlite_path = config.get_sqlite_db()
        self.engine = create_engine(f""sqlite:///{sqlite_path}"")
        SQLModel.metadata.create_all(self.engine)

    def new_state(self):
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")

        return {
            ""internal_monologue"": '',
            ""browser_session"": {
                ""url"": None,
                ""screenshot"": None
            },
            ""terminal_session"": {
                ""command"": None,
                ""output"": None,
                ""title"": None
            },
            ""step"": int(),
            ""message"": None,
            ""completed"": False,
            ""agent_is_active"": True,
            ""token_usage"": 0,
            ""timestamp"": timestamp
        }

    def create_state(self, project: str):
        with Session(self.engine) as session:
            new_state = self.new_state()
            new_state[""step""] = 1
            new_state[""internal_monologue""] = ""I'm starting the work...""
            agent_state = AgentStateModel(project=project, state_stack_json=json.dumps([new_state]))
            session.add(agent_state)
            session.commit()
            emit_agent(""agent-state"", [new_state])

    def delete_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).all()
            if agent_state:
                for state in agent_state:
                    session.delete(state)
                session.commit()

    def add_to_current_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack.append(state)
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_current_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)
            return None

    def update_latest_state(self, project: str, state: dict):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1] = state
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [state]
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def get_latest_state(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1]
            return None

    def set_agent_active(self, project: str, is_active: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""agent_is_active""] = is_active
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""agent_is_active""] = is_active
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_active(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""agent_is_active""]
            return None

    def set_agent_completed(self, project: str, is_completed: bool):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""internal_monologue""] = ""Agent has completed the task.""
                state_stack[-1][""completed""] = is_completed
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""completed""] = is_completed
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()
            emit_agent(""agent-state"", state_stack)

    def is_agent_completed(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""completed""]
            return None
            
    def update_token_usage(self, project: str, token_usage: int):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                state_stack = json.loads(agent_state.state_stack_json)
                state_stack[-1][""token_usage""] += token_usage
                agent_state.state_stack_json = json.dumps(state_stack)
                session.commit()
            else:
                state_stack = [self.new_state()]
                state_stack[-1][""token_usage""] = token_usage
                agent_state = AgentStateModel(project=project, state_stack_json=json.dumps(state_stack))
                session.add(agent_state)
                session.commit()

    def get_latest_token_usage(self, project: str):
        with Session(self.engine) as session:
            agent_state = session.query(AgentStateModel).filter(AgentStateModel.project == project).first()
            if agent_state:
                return json.loads(agent_state.state_stack_json)[-1][""token_usage""]
            return 0

    def get_project_files(self, project_name: str):
        if not project_name:
            return []
        project_directory = ""-"".join(project_name.split("" ""))
        directory = os.path.join(os.getcwd(), 'data', 'projects', project_directory) 
        if(not os.path.exists(directory)):
            return []
        files = []
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_relative_path = os.path.relpath(root, directory)
                if file_relative_path == '.': file_relative_path = ''
                file_path = os.path.join(file_relative_path, filename)
                print(""file_path"",file_path)
                try:
                    with open(os.path.join(root, filename), 'r') as file:
                        print(""File:"", filename)
                        files.append({
                            ""file"": file_path,
                            ""code"": file.read()
                        })
                except Exception as e:
                    print(f""Error reading file {filename}: {e}"")
        return files",CWE-79,201.0,1
,CWE-119,,1
,CWE-119,,1
,CWE-310,,1
,CWE-89,,1
,CWE-787,,1
,CWE-125,,1
,CWE-190,,1
,CWE-119,,1
,CWE-119,,1
,CWE-79,,1
,CWE-79,,1
,CWE-295,,1
,CWE-295,,1
,CWE-295,,1
,CWE-532,,1
,CWE-532,,1
,CWE-331,,1
,CWE-401,,1
,CWE-20,,1
,CWE-697,,1
,CWE-20,,1
,CWE-918,,1
,CWE-20,,1
,CWE-918,,1
,CWE-20,,1
,CWE-918,,1
,CWE-20,,1
,CWE-918,,1
,CWE-74,,1
,CWE-94,,1
,CWE-400,,1
,CWE-770,,1
,CWE-89,,1
,CWE-400,,1
,CWE-400,,1
,CWE-120,,1
,CWE-120,,1
,CWE-347,,1
,CWE-611,,1
,CWE-611,,1
,CWE-601,,1
,CWE-287,,1
,CWE-200,,1
,CWE-79,,1
,CWE-200,,1
,CWE-200,,1
,CWE-36,,1
,CWE-78,,1
,CWE-79,,1
,CWE-359,,1
,CWE-601,,1
,CWE-290,,1
,CWE-290,,1
,CWE-79,,1
,CWE-667,,1
,CWE-287,,1
,CWE-327,,1
,CWE-863,,1
,CWE-613,,1
,CWE-290,,1
,CWE-22,,1
,CWE-918,,1
,CWE-77,,1
,CWE-77,,1
,CWE-200,,1
,CWE-306,,1
,CWE-287,,1
,CWE-400,,1
,CWE-400,,1
,CWE-913,,1
,CWE-640,,1
,CWE-400,,1
,CWE-20,,1
,CWE-366,,1
,CWE-79,,1
,CWE-384,,1
,CWE-79,,1
,CWE-22,,1
,CWE-22,,1
